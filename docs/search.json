[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "MATH 60604 - Modélisation statistique",
    "section": "",
    "text": "Bienvenue\nCes notes sont l’oeuvre de Léo Belzile (HEC Montréal) et sont mises à disposition sous la Licence publique Creative Commons Attribution - Utilisation non commerciale - Partage dans les mêmes conditions 4.0 International.\nCe cours traite de modélisation des données. Une citation célèbre attribuée à George Box dit que\nCe point de vue est réducteur; McCullagh et Nelder (1989) (traduction libre) expliquent dans le préambule de leur livre\nEt David R. Cox (traduction libre), de rajouter\nPourquoi utiliser des modèles? Paul Krugman écrivait en 2010 dans son blogue",
    "crumbs": [
      "Bienvenue"
    ]
  },
  {
    "objectID": "index.html#contenu-du-cours",
    "href": "index.html#contenu-du-cours",
    "title": "MATH 60604 - Modélisation statistique",
    "section": "Contenu du cours",
    "text": "Contenu du cours\nL’inférence statistique a pour but de tirer des conclusions formelles à partir de données. Dans le cadre de la recherche scientifique, le chercheur formule une hypothèse, collecte des données et conclut quant à la plausibilité de son hypothèse.\nOn distingue deux types de jeux de données: les données expérimentales sont typiquement collectées en milieu contrôlé suivant un protocole d’enquête et un plan d’expérience: elles servent à répondre à une question prédéterminée. L’approche expérimentale est désirable pour éviter le «jardin des embranchements» (une allégorie signifiant qu’un chercheur peut raffiner son hypothèse à la lumière des données, sans ajustement pour des variables confondantes), mais elle n’est pas toujours réalisable: par exemple, un économiste ne peut pas modifier les taux d’intérêts pour observer les impacts sur le taux d’épargne des consommateurs. Lorsque les données ont été collectées préalablement à d’autres fins, on parle de données observationnelles.\nPar modèle, on entendra la spécification d’une loi aléatoire pour les données et une équation reliant les paramètres ou l’espérance conditionnelle d’une variable réponse \\(Y\\) à un ensemble de variables explicatives \\(\\mathbf{X}\\). Ce modèle peut servir à des fins de prédiction (modèle prédictif) ou pour tester des hypothèses de recherche concernant les effets de ces variables (modèle explicatif). Ces deux objectifs ne sont pas mutuellement exclusifs même si on fait parfois une distinction entre inférence et prédiction.\nUn modèle prédictif permet d’obtenir des prédictions de la valeur de \\(Y\\) pour d’autres combinaisons de variables explicatives ou des données futures. Par exemple, on peut chercher à prédire la consommation énergétique d’une maison en fonction de la météo, du nombre d’habitants de la maison et de sa taille. La plupart des boîtes noires utilisées en apprentissage automatique tombent dans la catégorie des modèles prédictifs: ces modèles ne sont pas interprétables et ignorent parfois la structure inhérente aux données.\nPar contraste, les modèles explicatifs sont souvent simples et interprétables, et les modèles de régressions sont fréquemment utilisés pour l’inférence. On se concentrera dans ce cours sur les modèles explicatifs. Par exemple, on peut chercher à déterminer\n\nEst-ce que les décisions intégrées (décision combinée d’achat et de quantité) sont préférables aux décisions séquentielles (décision d’acheter, puis choix de la quantité) lors de l’achat d’un produit en ligne (Duke et Amir 2023)?\nQu’est-ce qui est le plus distrayant pour les utilisateurs de la route: parler au cellulaire, texter en conduisant, consulter sa montre intelligente (Brodeur et al. 2021)?\nQuel est l’impact de de l’inadéquation entre l’image d’un produit et sa description (Lee et Choi 2019)?\nQu’est-ce qui explique que les prix de l’essence soient plus élevés en Gaspésie qu’ailleurs au Québec? Un rapport de surveillance des prix de l’essence en Gaspésie par la Régie de l’énergie se penche sur la question.\nEst-ce que les examens pratiques de conduite en Grande-Bretagne sont plus faciles dans les régions à faible densité de population? Une analyse du journal britannique The Guardian laisse penser que c’est le cas.\nQuelle est la perception environnementale d’un emballage de carton (versus de plastique) s’il englobe un contenant en plastique (Sokolova, Krishna, et Döring 2023).\nQuel est l’impact psychologique des suggestions sur le montant de dons (Moon et VanEpps 2023)?\nEst-ce que la visioconférence réduit le nombre d’interactions et d’idée créatives générées lors d’une réunion, par rapport à une rencontre en personne (Brucks et Levav 2022)?\n\n\n\n\n\n\nBrodeur, Mathieu, Perrine Ruer, Pierre-Majorique Léger, et Sylvain Sénécal. 2021. « Smartwatches are more distracting than mobile phones while driving: Results from an experimental study ». Accident Analysis & Prevention 149: 105846. https://doi.org/10.1016/j.aap.2020.105846.\n\n\nBrucks, Melanie S., et Jonathan Levav. 2022. « Virtual communication curbs creative idea generation ». Nature 605 (7908): 108‑12. https://doi.org/10.1038/s41586-022-04643-y.\n\n\nDuke, Kristen E., et On Amir. 2023. « The Importance of Selling Formats: When Integrating Purchase and Quantity Decisions Increases Sales ». Marketing Science 42 (1): 87‑109. https://doi.org/10.1287/mksc.2022.1364.\n\n\nLee, Kiljae, et Jungsil Choi. 2019. « Image-text inconsistency effect on product evaluation in online retailing ». Journal of Retailing and Consumer Services 49: 279‑88. https://doi.org/10.1016/j.jretconser.2019.03.015.\n\n\nMcCullagh, P., et J. A. Nelder. 1989. Generalized linear models. Second edition. London: Chapman & Hall.\n\n\nMoon, Alice, et Eric M VanEpps. 2023. « Giving Suggestions: Using Quantity Requests to Increase Donations ». Journal of Consumer Research 50 (1): 190‑210. https://doi.org/10.1093/jcr/ucac047.\n\n\nSokolova, Tatiana, Aradhna Krishna, et Tim Döring. 2023. « Paper Meets Plastic: The Perceived Environmental Friendliness of Product Packaging ». Journal of Consumer Research 50 (3): 468‑91. https://doi.org/10.1093/jcr/ucad008.",
    "crumbs": [
      "Bienvenue"
    ]
  },
  {
    "objectID": "introduction.html",
    "href": "introduction.html",
    "title": "1  Introduction",
    "section": "",
    "text": "1.1 Population et échantillons\nCe qui différencie la statistique des autres sciences est la prise en compte de l’incertitude et de la notion d’aléatoire. Règle générale, on cherche à estimer une caractéristique d’une population définie à l’aide d’un échantillon (un sous-groupe de la population) de taille restreinte.\nLa population d’intérêt est un ensemble d’individus formant la matière première d’une étude statistique. Par exemple, pour l’Enquête sur la population active (EPA) de Statistique Canada, « la population cible comprend la population canadienne civile non institutionnalisée de 15 ans et plus ». Même si on faisait un recensement et qu’on interrogeait tous les membres de la population cible, la caractéristique d’intérêt peut varier selon le moment de la collecte; une personne peut trouver un emploi, quitter le marché du travail ou encore se retrouver au chômage. Cela explique la variabilité intrinsèque.\nEn général, on se base sur un échantillon pour obtenir de l’information parce que l’acquisition de données est coûteuse. L’inférence statistique vise à tirer des conclusions, pour toute la population, en utilisant seulement l’information contenue dans l’échantillon et en tenant compte des sources de variabilité. Le sondeur George Gallup (traduction libre) a fait cette merveilleuse analogie entre échantillon et population:\nUn échantillon est un sous-groupe d’individus de la population. Si on veut que ce dernier soit représentatif, il devrait être tiré aléatoirement de la population, ce qui nécessite une certaine connaissance de cette dernière. Au siècle dernier, les bottins téléphoniques pouvaient servir à créer des plans d’enquête. C’est un sujet complexe et des cours entiers d’échantillonnage y sont consacrés. Même si on ne collectera pas de données, il convient de noter la condition essentielle pour pouvoir tirer des conclusions fiables à partir d’un échantillon: ce dernier doit être représentatif de la population étudiée, en ce sens que sa composition doit être similaire à celle de la population, et aléatoire. On doit ainsi éviter les biais de sélection, notamment les échantillons de commodité qui consistent en une sélection d’amis et de connaissances.\nSi notre échantillon est aléatoire, notre mesure d’une caractéristique d’intérêt le sera également et la conclusion de notre procédure de test variera d’un échantillon à l’autre. Plus la taille de ce dernier est grande, plus on obtiendra une mesure précise de la quantité d’intérêt. L’exemple suivant illustre pourquoi le choix de l’échantillon est important.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "introduction.html#population-echantillon",
    "href": "introduction.html#population-echantillon",
    "title": "1  Introduction",
    "section": "",
    "text": "«Il n’est pas nécessaire de manger un bol complet de soupe pour savoir si elle est trop salé; pour autant qu’elle ait été bien brassée, une cuillère suffit.»\n\n\n\n\nExemple 1.1 (Gallup et l’élection présidentielle américaine de 1936) Désireuse de prédire le résultat de l’élection présidentielle américaine de 1936, la revue Literary Digest a sondé 10 millions d’électeurs par la poste, dont 2.4 millions ont répondu au sondage en donnant une nette avance au candidat républicain Alf Landon (57%) face au président sortant Franklin D. Roosevelt (43%). Ce dernier a néanmoins remporté l’élection avec 62% des suffrages, une erreur de prédiction de 19%. Le plan d’échantillonnage avait été conçu en utilisant des bottins téléphoniques, des enregistrements d’automobiles et des listes de membres de clubs privés, etc.: la non-réponse différentielle et un échantillon biaisé vers les classes supérieures sont en grande partie responsable de cette erreur.\nGallup avait de son côté correctement prédit la victoire de Roosevelt en utilisant un échantillon aléatoire de (seulement) 50 000 électeurs. Vous pouvez lire l’histoire complète (en anglais).",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "introduction.html#types-de-variables",
    "href": "introduction.html#types-de-variables",
    "title": "1  Introduction",
    "section": "1.2 Types de variables",
    "text": "1.2 Types de variables\nLe résultat d’une collecte de données est un tableau, ou base de données, contenant sur chaque ligne des observations et en colonne des variables. Le Tableau 1.1 donne un exemple de structure.\n\nUne variable représente une caractéristique de la population d’intérêt, par exemple le sexe d’un individu, le prix d’un article, etc.\nune observation, parfois appelée donnée, est un ensemble de mesures collectées sous des conditions identiques, par exemple pour un individu ou à un instant donné.\n\n\n\n\n\nTableau 1.1: Premières lignes de la base de données renfe, qui contient les prix de 10K billets de train entre Barcelone et Madrid. Les colonnes prix et duree sont des variables numériques continues, les autres des variables catégorielles.\n\n\n\n\n\n\nprix\ntype\nclasse\ntarif\ndest\nduree\njour\n\n\n\n\n143.4\nAVE\nPreferente\nPromo\nBarcelone-Madrid\n190\n6\n\n\n181.5\nAVE\nPreferente\nFlexible\nBarcelone-Madrid\n190\n2\n\n\n86.8\nAVE\nPreferente\nPromo\nBarcelone-Madrid\n165\n7\n\n\n86.8\nAVE\nPreferente\nPromo\nBarcelone-Madrid\n190\n7\n\n\n69.0\nAVE-TGV\nPreferente\nPromo\nBarcelone-Madrid\n175\n4\n\n\n\n\n\n\n\n\nLe choix de modèle statistique ou de test dépend souvent du type de variables collectées. Les variables peuvent être de plusieurs types: quantitatives (discrètes ou continues) si elles prennent des valeurs numériques, qualitatives (binaires, nominales ou ordinales) si elles peuvent être décrites par un adjectif; je préfère le terme catégorielle, plus évocateur.\nLa plupart des modèles avec lesquels nous interagirons sont des modèles dits de régression, dans lesquelles on modélisation la moyenne d’une variable quantitative en fonction d’autres variables dites explicatives. Il y a deux types de variables numériques:\n\nune variable discrète prend un nombre dénombrable de valeurs; ce sont souvent des variables de dénombrement ou des variables dichotomiques.\nune variable continue peut prendre (en théorie) une infinité de valeurs, même si les valeurs mesurées sont arrondies ou mesurées avec une précision limitée (temps, taille, masse, vitesse, salaire). Dans bien des cas, nous pouvons considérer comme continues des variables discrètes si elles prennent un assez grand nombre de valeurs.\n\nLes variables catégorielles représentent un ensemble fini de possibilités. On les regroupe en deux types, pour lesquels on ne fera pas de distinction:\n\nnominales s’il n’y a pas d’ordre entre les modalités (sexe, couleur, pays d’origine) ou\nordinale (échelle de Likert, tranche salariale).\n\nLa codification des modalités des variables catégorielle est arbitraire; en revanche, on préservera l’ordre lorsqu’on représentera graphiquement les variables ordinales. Lors de l’estimation, chaque variable catégorielle doit est transformée en un ensemble d’indicateurs binaires 0/1: il est donc essentiel de déclarer ces dernières dans votre logiciel statistique, surtout si elles sont parfois encodées dans la base de données à l’aide de valeurs entières.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "introduction.html#variable-aleatoire",
    "href": "introduction.html#variable-aleatoire",
    "title": "1  Introduction",
    "section": "1.3 Variables aléatoires",
    "text": "1.3 Variables aléatoires\nSuppsons qu’on cherche à décrire le comportement d’un phénomène aléatoire. Pour ce faire, on cherche à décrire l’ensemble des valeurs possibles et leur probabilité/fréquence relative au sein de la population: ces dernières sont encodées dans la loi de la variable aléatoire.\nOn dénote les variables aléatoires par des lettres majuscules, et leurs réalisations par des minuscules: par exemple, \\(Y \\sim \\mathsf{normale}(\\mu, \\sigma^2)\\) indique que \\(Y\\) suit une loi normale de paramètres \\(\\mu \\in \\mathbb{R}\\) et \\(\\sigma &gt; 0\\). On parle de famille de lois si la valeur des paramètres ne sont pas spécifiées; si on fixe plutôt ces dernière, on obtient une représentation qui encode les probabilité.\n\nDéfinition 1.1 (Fonctions de répartition, de masse et de densité) La fonction de répartition \\(F(y)\\) donne la probabilité cumulative qu’un événement n’excède pas une variable donnée, \\(F(y) = \\mathsf{Pr}(Y \\leq y)\\). Si la variable \\(Y\\) prend des valeurs discrètes, alors on utilise la fonction de masse \\(f(y)=\\mathsf{Pr}(Y=y)\\) qui donne la probabilité pour chacune des valeurs de \\(y\\). Si la variable \\(Y\\) est continue, aucune valeur numérique de \\(y\\) n’a de probabilité non-nulle et \\(\\Pr(Y=y) = 0\\) pour toute valeur réelle \\(y\\); la densité, aussi dénotée \\(f(x)\\), est une fonction est non-négative et satisfait \\(\\int_{\\mathbb{R}} f(x) \\mathrm{d}x=1\\): elle décrit la probabilité d’obtenir un résultat dans un ensemble donné des réels \\(\\mathbb{R}\\), pour n’importe lequel intervalle. La densité sert à estimer la probabilité que la variable continue \\(Y\\) appartienne à un ensemble \\(B\\), via \\(\\mathsf{Pr}(Y \\in B) = \\int_B f(y) \\mathrm{d} y\\); la fonction de répartition est ainsi définie comme \\(F(y) = \\int_{-\\infty}^y f(x) \\mathrm{d} x\\).\n\n\n\n\n\n\n\n\nFigure 1.1: Fonctions de répartition (panneau supérieur) et fonctions de densité et de masse (panneau inférieur) pour une loi continue (gauche) et discrète (droite).\n\n\n\n\n\n\nUn premier cours de statistique débute souvent par la présentation de statistiques descriptives comme la moyenne et l’écart-type. Ce sont des estimateurs des moments (centrés), qui caractérisent la loi du phénomène d’intérêt. Dans le cas de la loi normale unidimensionnelle, qui a deux paramètres, l’espérance et la variance caractérisent complètement le modèle.\n\nDéfinition 1.2 (Moments) Soit \\(Y\\) une variable aléatoire de fonction de densité (ou de masse) \\(f(x)\\). On définit l’espérance d’une variable aléatoire \\(Y\\) comme \\[\\begin{align*}\n\\mathsf{E}(Y)=\\int_{\\mathbb{R}} y f(y) \\mathrm{d} y.\n\\end{align*}\\] L’espérance est la « moyenne théorique», ou moment de premier ordre : dans le cas discret, \\(\\mu = \\mathsf{E}(Y)=\\sum_{y \\in \\mathcal{y}} y \\mathsf{Pr}(y=y)\\), où \\(\\mathcal{Y}\\) représente le support de la loi, à savoir les valeurs qui peuvent prendre \\(Y\\). Plus généralement, l’espérance d’une fonction \\(g(y)\\) pour une variable aléatoire \\(Y\\) est simplement l’intégrale de \\(g(y)\\) pondérée par la densité \\(f(y)\\). De même, si l’intégrale est convergente, la variance est \\[\\begin{align*}\n\\mathsf{Va}(Y)&=\\int_{\\mathbb{R}} (y-\\mu)^2 f(y) \\mathrm{d} y \\\\&=\\mathsf{E}\\{Y-\\mathsf{E}(Y)\\}^2 \\\\&= \\mathsf{E}(Y^2) - \\{\\mathsf{E}(Y)\\}^2.\n\\end{align*}\\]\nL’écart-type est défini comme la racine carrée de la variance, \\(\\mathsf{sd}(Y)=\\sqrt{\\mathsf{Va}(Y)}\\): elle est exprimé dans les mêmes unités que celle de \\(Y\\) et donc plus facilement interprétable.\nLa notion de moments peut être généralisé à des vecteurs. Si \\(\\boldsymbol{Y}\\) est un \\(n\\)-vecteur, comprenant par exemple dans le cadre d’une régression des mesures d’un ensemble d’observations, alors l’espérance est calculée composante par composante,\n\\[\\begin{align*}\n\\mathsf{E}(\\boldsymbol{Y}) &= \\boldsymbol{\\mu}=\n\\begin{pmatrix}\n\\mathsf{E}(Y_1) &\n\\cdots  &\n\\mathsf{E}(Y_n)\n\\end{pmatrix}^\\top\n\\end{align*}\\] tandis que la matrice \\(n \\times n\\) de deuxième moments centrés de \\(\\boldsymbol{Y}\\), dite matrice de variance ou matrice de covariance, est \\[\\begin{align*}\n\\mathsf{Va}(\\boldsymbol{Y}) &= \\boldsymbol{\\Sigma} = \\begin{pmatrix} \\mathsf{Va}(Y_1) & \\mathsf{Co}(Y_1, Y_2)  & \\cdots & \\mathsf{Co}(Y_1, Y_n) \\\\\n\\mathsf{Co}(Y_2, Y_1) & \\mathsf{Va}(Y_2) & \\ddots & \\vdots \\\\\n\\vdots & \\ddots & \\ddots & \\vdots \\\\\n\\mathsf{Co}(Y_n, Y_1) & \\mathsf{Co}(Y_n, Y_2) &\\cdots & \\mathsf{Va}(Y_n)\n\\end{pmatrix}\n\\end{align*}\\] Le \\(i\\)e élément diagonal de \\(\\boldsymbol{\\Sigma}\\), \\(\\sigma_{ii}=\\sigma_i^2\\), est la variance de \\(Y_i\\), tandis que les éléments hors de la diagonale, \\(\\sigma_{ij}=\\sigma_{ji}\\) \\((i \\neq j)\\), sont les covariances des paires \\[\\begin{align*}\n\\mathsf{Co}(Y_i, Y_j) = \\int_{\\mathbb{R}^2} (y_i-\\mu_i)(y_j-\\mu_j) f_{Y_i, Y_j}(y_i, y_j) \\mathrm{d} y_i \\mathrm{d} y_j.\n\\end{align*}\\] Par construction, la matrice de covariance \\(\\boldsymbol{\\Sigma}\\) est symmétrique. Il est d’usage de considérer la relation deux-à-deux de variables standardisées, afin de séparer la dépendance linéaire de la variabilité de chaque composante. La corrélation linéaire entre \\(Y_i\\) et \\(Y_j\\) est \\[\\begin{align*}\n\\rho_{ij}=\\mathsf{Cor}(Y_i,Y_j)=\\frac{\\mathsf{Co}(Y_i, Y_j)}{\\sqrt{\\mathsf{Va}(Y_i)}\\sqrt{\\mathsf{Va}(Y_j)}}=\\frac{\\sigma_{ij}}{\\sigma_i\\sigma_j}.\n\\end{align*}\\] La matrice de corrélation de \\(\\boldsymbol{Y}\\) est une matrice symmétrique \\(n\\times n\\) avec des uns sur la diagonale et les corrélations des pairs hors diagonale, \\[\\begin{align*}\n\\mathsf{Cor}(\\boldsymbol{Y})=\n\\begin{pmatrix}\n1 & \\rho_{12} & \\rho_{13} & \\cdots & \\rho_{1n}\\\\\n\\rho_{21} & 1 & \\rho_{23} & \\cdots & \\rho_{2n} \\\\\n\\rho_{31} & \\rho_{32} & 1 & \\ddots & \\rho_{3n} \\\\\n\\vdots & \\vdots & \\ddots & \\ddots & \\vdots \\\\\n\\rho_{n1} & \\rho_{n2} & \\rho_{n3} & \\cdots & 1\n\\end{pmatrix}.\n\\end{align*}\\] Nous modéliserons la matrice de covariance ou de corrélation des données corrélées et longitudinales par individus du même groupe (ou du même individu pour les mesures répétées) dans le Chapitre 5.\n\n\nDéfinition 1.3 (Biais) Le biais d’un estimateur \\(\\hat{\\theta}\\) pour un paramètre \\(\\theta\\) est \\[\\begin{align*}\n\\mathsf{biais}(\\hat{\\theta})=\\mathsf{E}(\\hat{\\theta})- \\theta\n\\end{align*}\\] L’estimateur est non biaisé si \\(\\mathsf{biais}(\\hat{\\theta})=0\\).\n\n\nExemple 1.2 (Estimateurs sans biais) L’estimateur sans biais de l’espérance de \\(Y\\) pour un échantillon aléatoire simple \\(Y_1, \\ldots, Y_n\\) est la moyenne empirique \\(\\overline{Y}_n = n^{-1} \\sum_{i=1}^n Y_i\\) et celui de la variance \\(S_n = (n-1)^{-1} \\sum_{i=1}^n (Y_i-\\overline{Y})^2\\).\n\nUn estimateur sans biais est souhaitable, mais pas toujours optimal. Quelquefois, il n’existe pas d’estimateur non-biaisé pour un paramètre! Dans plusieurs cas, on cherche un estimateur qui minimise l’erreur quadratique moyenne.\nSouvent, on cherche à balancer le biais et la variance: rappelez-vous qu’un estimateur est une variable aléatoire (étant une fonction de variables aléatoires) et qu’il est lui-même variable: même s’il est sans biais, la valeur numérique obtenue fluctuera d’un échantillon à l’autre.\n\nDéfinition 1.4 (Erreur quadratique moyenne) On peut chercher un estimateur qui minimise l’erreur quadratique moyenne, \\[\\begin{align*}\n\\mathsf{EQM}(\\hat{\\theta}) = \\mathsf{E}\\{(\\hat{\\theta}-\\theta)^2\\}=\\mathsf{Va}(\\hat{\\theta}) + \\{\\mathsf{E}(\\hat{\\theta})\\}^2.\n\\end{align*}\\] Cette fonction objective est donc un compromis entre le carré du biais et la variance de l’estimateur.\n\nLa plupart des estimateurs que nous considérerons dans le cadre du cours sont des estimateurs du maximum de vraisemblance. Ces derniers sont asymptotiquement efficaces, c’est-à-dire qu’ils minimisent l’erreur quadratique moyenne parmi tous les estimateurs possibles quand la taille de l’échantillon est suffisamment grande. Ils ont également d’autre propriétés qui les rendent attractifs comme choix par défaut pour l’estimation. Il ne sont pas nécessairement sans biais",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "introduction.html#loi-discrètes",
    "href": "introduction.html#loi-discrètes",
    "title": "1  Introduction",
    "section": "1.4 Loi discrètes",
    "text": "1.4 Loi discrètes\nPlusieurs lois aléatoires décrivent des phénomènes physiques simples et ont donc une justification empirique; on revisite les distributions ou loi discrètes les plus fréquemment couvertes.\n\nDéfinition 1.5 (Loi de Bernoulli) On considère un phénomène binaire, comme le lancer d’une pièce de monnaie (pile/face). De manière générale, on associe les deux possibilités à succès/échec et on suppose que la probabilité de “succès” est \\(p\\). Par convention, on représente les échecs (non) par des zéros et les réussites (oui) par des uns. Donc, si la variable \\(Y\\) vaut \\(0\\) ou \\(1\\), alors \\(\\mathsf{Pr}(Y=1)=p\\) et la probabilité complémentaire est \\(\\mathsf{Pr}(Y=0)=1-p\\). La fonction de masse de la loi Bernoulli s’écrit de façon plus compacte \\[\\begin{align*}\n\\mathsf{Pr}(Y=y) = p^y (1-p)^{1-y}, \\quad y=0, 1.\n\\end{align*}\\]\n\nUn calcul rapide montre que \\(\\mathsf{E}(Y)=p\\) et \\(\\mathsf{Va}(Y)=p(1-p)\\). Effectivement, \\[\\begin{align*}\n\\mathsf{E}(Y) = \\mathsf{E}(Y^2) = p \\cdot 1 + (1-p) \\cdot 0 = p.\n\\end{align*}\\]\nVoici quelques exemples de questions de recherches comprenant une variable réponse binaire:\n\nest-ce qu’un client potentiel a répondu favorablement à une offre promotionnelle?\nest-ce qu’un client est satisfait du service après-vente?\nest-ce qu’une firme va faire faillite au cours des trois prochaines années?\nest-ce qu’un participant à une étude réussit une tâche assignée?\n\nPlus généralement, on aura accès à des données aggrégées.\n\nExemple 1.3 (Loi binomiale) Si les données représentent la somme d’événements Bernoulli indépendants, la loi du nombre de réussites \\(Y\\) pour un nombre d’essais donné \\(m\\) est dite binomiale, dénotée \\(\\mathsf{Bin}(m, p)\\); sa fonction de masse est \\[\\begin{align*}\n\\mathsf{Pr}(Y=y) = \\binom{m}{y}p^y (1-p)^{1-y}, \\quad y=0, 1.\n\\end{align*}\\] La vraisemblance pour un échantillon de la loi binomiale est (à constante de normalisation près qui ne dépend pas de \\(p\\)) la même que pour un échantillon aléatoire de \\(m\\) variables Bernoulli indépendantes. L’espérance d’une variable binomiale est \\(\\mathsf{E}(Y)=mp\\) et la variance \\(\\mathsf{Va}(Y)=mp(1-p)\\).\n\nOn peut ainsi considérer le nombre de personnes qui ont obtenu leur permis de conduire parmi \\(m\\) candidat(e)s ou le nombre de clients sur \\(m\\) qui ont passé une commande de plus de 10$ dans un magasin.\nPlus généralement, on peut considérer des variables de dénombrement qui prennent des valeurs entières. Parmi les exemples de questions de recherches comprenant une variable réponse de dénombrement:\n\nle nombre de réclamations faites par un client d’une compagnie d’assurance au cours d’une année.\nle nombre d’achats effectués par un client depuis un mois.\nle nombre de tâches réussies par un participant lors d’une étude.\n\n\n\nExemple 1.4 (Loi de Poisson) Si la probabilité d’un événement Bernoulli est petite et qu’il est rare d’obtenir un succès dans le sens où \\(mp \\to \\lambda\\) quand le nombre d’essais \\(m\\) augmente, alors le nombre de succès suit approximateivement une loi de Poisson de fonction de masse \\[\\begin{align*}\n\\mathsf{Pr}(Y=y) = \\frac{\\exp(-\\lambda)\\lambda^y}{\\Gamma(y+1)}, \\quad y=0, 1, 2, \\ldots\n\\end{align*}\\] où \\(\\Gamma(\\cdot)\\) dénote la fonction gamma, et \\(\\Gamma(y+1) = y!\\) si \\(y\\) est un entier. Le paramètre \\(\\lambda\\) de la loi de Poisson représente à la fois l’espérance et la variance de la variable, c’est-à-dire que \\(\\mathsf{E}(Y)=\\mathsf{Va}(Y)=\\lambda\\).\n\n\nExemple 1.5 (Loi binomiale négative) On considère une série d’essais Bernoulli de probabilité de succès \\(p\\) jusqu’à l’obtention de \\(m\\) succès. Soit \\(Y\\), le nombre d’échecs: puisque la dernière réalisation doit forcément être un succès, mais que l’ordre des succès/échecs précédents n’importe pas, la fonction de masse de la loi binomiale négative est \\[\\begin{align*}\n\\mathsf{Pr}(Y=y)= \\binom{m-1+y}{y} p^m (1-p)^{y}.\n\\end{align*}\\]\nLa loi binomiale négative apparaît également si on considère la loi non-conditionnelle du modèle hiérarchique gamma-Poisson, dans lequel on suppose que le paramètre de la moyenne de la loi Poisson est aussi aléatoire, c’est-à-dire \\(Y \\mid \\Lambda=\\lambda \\sim \\mathsf{Po}(\\lambda)\\) et \\(\\Lambda\\) suit une loi gamma de paramètre de forme \\(r\\) et de paramètre d’échelle \\(\\theta\\), dont la densité est \\[\\begin{align*}\nf(x) = \\theta^{-r}x^{r-1}\\exp(-x/\\theta)/\\Gamma(r).\\end{align*}\\] Le nombre d’événements suit alors une loi binomiale négative.\nLa paramétrisation la plus courante pour la modélisation est légèrement différente: pour un paramètre \\(r&gt;0\\) (pas forcément entier), on écrit la fonction de masse \\[\\begin{align*}\n\\mathsf{Pr}(Y=y)=\\frac{\\Gamma(y+r)}{\\Gamma(y+1)\\Gamma(r)} \\left(\\frac{r}{r + \\mu} \\right)^{r} \\left(\\frac{\\mu}{r+\\mu}\\right)^y,\n\\end{align*}\\] où \\(\\Gamma\\) dénote la fonction gamma. Dans cette paramétrisation, la moyenne théorique et la variance sont \\(\\mathsf{E}(Y)=\\mu\\) et \\(\\mathsf{Va}(Y)=\\mu+k\\mu^2\\), où \\(k=1/r\\). La variance d’une variable binomiale négative est supérieure à sa moyenne et le modèle est utilisé comme alternative à la loi de Poisson pour modéliser la surdispersion.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "introduction.html#lois-continues",
    "href": "introduction.html#lois-continues",
    "title": "1  Introduction",
    "section": "1.5 Lois continues",
    "text": "1.5 Lois continues\nOn considère plusieurs lois de variables aléatoires continues; certaines servent de lois pour des tests d’hypothèse et découlent du théorème central limite (notamment les lois normales, Student, Fisher ou \\(F\\), et khi-deux).\n\nDéfinition 1.6 (Loi beta) La loi beta \\(\\mathsf{Beta}(\\alpha, \\beta)\\) est une loi sur l’intervalle \\([0,1]\\) avec paramètres de forme \\(\\alpha&gt;0\\) et \\(\\beta&gt;0\\). Sa densité est \\[\\begin{align*}\nf(x) = \\frac{\\Gamma(\\alpha)\\Gamma(\\beta)}{\\Gamma(\\alpha+\\beta)}x^{\\alpha-1}(1-x)^{1-\\beta}, \\qquad x \\in [0,1].\n\\end{align*}\\] Le cas \\(\\alpha=\\beta=1\\), dénotée également \\(\\mathsf{unif}(0,1)\\), correspond à la loi standard uniforme.\n\n\n\n\n\n\n\n\nFigure 1.2: Fonctions de densité de lois uniformes et beta(2, 3/4) sur l’intervalle [0,1].\n\n\n\n\n\n\n\nDéfinition 1.7 (Loi exponentielle) La loi exponentielle figure de manière proéminente dans l’étude des temps d’attente pour les phénomènes Poisson et en analyse de survie. Une caractéristique clé de la loi est son absence de mémoire: \\(\\Pr(Y \\geq y + u \\mid Y &gt; u) = \\Pr(Y &gt; u)\\) pour \\(Y &gt; 0\\) et \\(y, u&gt;0\\).\nLa fonction de répartition de la loi exponentielle \\(Y \\sim \\mathsf{Exp}(\\beta)\\) où \\(\\beta&gt;0\\), est \\(F(x) = 1-\\exp(-\\beta x)\\) et sa fonction de densité est \\(f(x) =\\beta\\exp(-\\beta x)\\) pour \\(x &gt;0\\). La moyenne théorique de la loi est \\(\\beta\\).\n\n\nDéfinition 1.8 (Loi normale) De loin la plus continue des distributions, la loi normale intervient dans le théorème central limite, qui dicte le comportement aléatoire de la moyenne de grand échantillons. La loi normale est pleinement caractérisée par son espérance \\(\\mu \\in \\mathbb{R}\\) et son écart-type \\(\\sigma&gt;0\\). Loi symmétrique autour de \\(\\mu\\), c’est une famille de localisation et d’échelle. Sa fonction de densité, \\[\\begin{align*}\nf(x) = (2\\pi\\sigma^2)^{-1/2} \\exp \\left\\{ - \\frac{(x-\\mu)^2}{2\\sigma^2}\\right\\}, \\qquad x \\in \\mathbb{R}.\n\\end{align*}\\] en forme de cloche, est symmétrique autour de \\(\\mu\\), qui est aussi le mode de la distribution.\n\n\n\n\n\n\n\n\nFigure 1.3: Densités de loi normales avec des paramètres de moyenne différents (gauche) et des paramètres d’échelle différents (droite).\n\n\n\n\n\nThe distribution function of the normal distribution is not available in closed-form. La loi normale est une famille de localisation échelle: si \\(Y \\sim \\mathsf{normale}(\\mu, \\sigma^2)\\), alors \\(Z = (Y-\\mu)/\\sigma \\sim \\mathsf{normale}(0,1)\\). Inversement, si \\(Z \\sim \\mathsf{normale}(0,1)\\), alors \\(Y = \\mu + \\sigma Z \\sim \\mathsf{normale}(\\mu, \\sigma^2)\\).\nNous verrons aussi l’extension multidimensionnelle de la loi normale: un \\(d\\) vecteur \\(\\boldsymbol{Y} \\sim \\mathsf{normal}_d(\\boldsymbol{\\mu}, \\boldsymbol{\\Sigma})\\) admet une fonction de densité égale à \\[\\begin{align*}\nf(\\boldsymbol{x}) = (2\\pi)^{-d/2} |\\boldsymbol{\\Sigma}|^{-1/2} \\exp \\left\\{ - \\frac{1}{2} (\\boldsymbol{x}-\\boldsymbol{\\mu})^\\top \\boldsymbol{\\Sigma}^{-1}(\\boldsymbol{x}-\\boldsymbol{\\mu})\\right\\}\n\\end{align*}\\]\nLe vecteur de moyenne \\(\\boldsymbol{\\mu}\\) contient l’espérance de chaque composante, tandis que \\(\\boldsymbol{\\Sigma}\\) est la matrice de covariance de \\(\\boldsymbol{Y}\\). Une propriété unique à la loi normale (muldimensionnelle) est le lien entre indépendance et matrice de covariance: si \\(Y_i\\) et \\(Y_j\\) sont indépendants, alors l’entrée \\((i,j)\\) hors diagonale de \\(\\boldsymbol{\\Sigma}\\) est nulle.\n\nLes trois lois suivantes ne sont pas couvertes dans les cours d’introduction, mais elles interviennent régulièrement dans les cours de mathématique statistique et serviront d’étalon de mesure pour déterminer si les statistiques de test sont extrêmes sous l’hypothèse nulle.\n\nDéfinition 1.9 (Loi khi-deux) La loi de khi-deux avec \\(\\nu&gt;0\\) degrés de liberté, dénotée \\(\\chi^2_{\\nu}\\) ou \\(\\mathsf{khi-deux}(\\nu)\\) joue un rôle important en statistique. Sa densité est \\[\\begin{align*}\nf(x; \\nu) = \\frac{1}{2^{\\nu/2}\\Gamma(\\nu/2)}x^{\\nu/2-1}\\exp(-x/2),\\qquad x &gt;0.\n\\end{align*}\\] Elle est obtenue pour \\(\\nu\\) entier en prenant la somme de variables normales centrées et réduites au carré: si \\(Y_i \\stackrel{\\mathrm{iid}}{\\sim}\\mathsf{normale}(0,1)\\) pour \\(i=1, \\ldots, k\\), alors \\(\\sum_{i=1}^k Y_i^2 \\sim \\chi^2_k\\). L’espérance de la loi \\(\\chi^2_k\\) est \\(k\\).\n\nSi on considère un échantillon aléatoire et identiquement distribution de \\(n\\) observations de lois normales, alors la variance empirique repondérée satisfait \\((n-1)S^2/\\sigma^2 \\sim \\chi^2_{n-1}\\).\n\nDéfinition 1.10 (Loi Student-\\(t\\)) La loi Student-\\(t\\) avec \\(\\nu&gt;0\\) degrés de liberté est une famille de localisation et d’échelle de densité symmétrique. On la dénote \\(\\mathsf{Student}(\\nu)\\) dans le cas centré réduit.\nSon nom provient d’un article de William Gosset sous le pseudonyme Student (Gosset 1908), qui a introduit la loi comme approximation au comportement de la statistique \\(t\\).  La densité d’une loi Student standard avec \\(\\nu\\) degrés de liberté est \\[\\begin{align*}\nf(y; \\nu) = \\frac{\\Gamma \\left( \\frac{\\nu+1}{2}\\right)}{\\Gamma\\left(\\frac{\\nu}{2}\\right)\n\\sqrt{\\nu\\pi}}\\left(1+\\frac{y^{2}}{\\nu}\\right)^{-\\frac{\\nu+1}{2}}.\n\\end{align*}\\] La loi a des ailes à décroissance polynomiale, est symmétrique autour de zéro et unimodale. Quand \\(\\nu \\to \\infty\\), on recouvre une loi normale, mais les ailes sont plus lourdes que la loi normale. Effectivement, seuls les \\(\\nu-1\\) premiers moments de la distribution existent: la loi \\(\\mathsf{Student}(2)\\) n’a pas de variance.\nSi les \\(n\\) observations indépendantes et identiquement distribuées \\(Y_i \\sim \\mathsf{normale}(\\mu, \\sigma^2)\\), alors la moyenne empirique centrée, divisée par la variance empirique, \\((\\overline{Y}-\\mu)/S^2\\), suit une loi Student-\\(t\\) avec \\(n-1\\) degrés de liberté.\n\n\n\n\n\n\n\n\nFigure 1.4: Comparaison de la densité Student-\\(t\\) versus normale pour différents degrés de liberté avec \\(\\nu=2\\) (pointillé), \\(\\nu=10\\) (traitillé) et la loi normale (\\(\\nu = \\infty)\\).\n\n\n\n\n\n\n\nDéfinition 1.11 (Loi de Fisher) La loi de Fisher, ou loi \\(F\\), sert à déterminer le comportement en grand échantillon de statistiques de test pour la comparaison de plusieurs moyennes (analyse de variance) sous un postulat de normalité des observations.\nLa loi \\(F\\), dite de Fisher et dénotée \\(\\mathsf{Fisher}(\\nu_1, \\nu_2)\\), est obtenue en divisant deux variables khi-deux indépendantes de degrés de liberté \\(\\nu_1\\) et \\(\\nu_2\\). Spécifiquement, si \\(Y_1 \\sim \\chi^2_{\\nu_1}\\) et \\(Y_2 \\sim \\chi^2_{\\nu_2}\\), alors \\[\\begin{align*}\nF = \\frac{Y_1/\\nu_1}{Y_2/\\nu_2} \\sim \\mathsf{Fisher}(\\nu_1, \\nu_2)\n\\end{align*}\\]\nLa loi de Fisher tend vers une loi \\(\\chi^2_{\\nu_1}\\) quand \\(\\nu_2 \\to \\infty\\).",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "introduction.html#graphiques",
    "href": "introduction.html#graphiques",
    "title": "1  Introduction",
    "section": "1.6 Graphiques",
    "text": "1.6 Graphiques\nCette section sert à réviser les principales représentations graphiques de jeux de données selon la catégorie des variables.\nLe principal type de graphique pour représenter la distribution d’une variable catégorielle est le diagramme en bâtons, dans lequel la fréquence de chaque catégorie est présentée sur l’axe des ordonnées (\\(y\\)) en fonction de la modalité, sur l’axe des abscisses (\\(x\\)), et ordonnées pour des variables ordinales. Cette représentation est en tout point supérieur au diagramme en camembert, une engeance répandu qui devrait être honnie (notamment parce que l’humain juge mal les différences d’aires, qu’une simple rotation change la perception du graphique et qu’il est difficile de mesurer les proportions) — ce n’est pas de la tarte!\n\n\n\n\n\n\n\n\nFigure 1.5: Diagramme en bâtons pour la classe des billets de trains du jeu de données Renfe.\n\n\n\n\n\nPuisque les variables continues peuvent prendre autant de valeurs distinctes qu’il y a d’observations, on ne peut simplement compter le nombre d’occurrence par valeur unique. On regroupera plutôt dans un certain nombre d’intervalle, en discrétisant l’ensemble des valeurs en classes pour obtenir un histogramme. Le nombre de classes dépendra du nombre d’observations si on veut que l’estimation ne soit pas impactée par le faible nombre d’observations par classe: règle générale, le nombre de classes ne devrait pas dépasser \\(\\sqrt{n}\\), où \\(n\\) est le nombre d’observations de l’échantillon. On obtiendra la fréquence de chaque classe, mais si on normalise l’histogramme (de façon à ce que l’aire sous les bandes verticales égale un), on obtient une approximation discrète de la fonction de densité. Faire varier le nombre de classes permet parfois de faire apparaître des caractéristiques de la variable (notamment la multimodalité, l’asymmétrie et les arrondis).\nPuisque qu’on groupe les observations en classe pour tracer l’histogramme, il est difficile de voir l’étendue des valeurs que prenne la variable: on peut rajouter des traits sous l’histogramme pour représenter les valeurs uniques prises par la variable, tandis que la hauteur de l’histogramme nous renseigne sur leur fréquence relative.\n\n\n\n\n\n\n\n\nFigure 1.6: Histogramme du prix des billets au tarif Promo de trains du jeu de données Renfe\n\n\n\n\n\n\nDéfinition 1.12 (Boîte à moustaches) Elle représente graphiquement cinq statistiques descriptives.\n\nLa boîte donne les 1e, 2e et 3e quartiles \\(q_1, q_2, q_3\\). Il y a donc 50% des observations sont au-dessus/en-dessous de la médiane \\(q_2\\) qui sépare en deux la boîte.\nLa longueur des moustaches est moins de \\(1.5\\) fois l’écart interquartile \\(q_3-q_1\\) (tracée entre 3e quartile et le dernier point plus petit que \\(q_3+1.5(q_3-q_1)\\), etc.)\nLes observations au-delà des moustaches sont encerclées. Notez que plus le nombre d’observations est élevé, plus le nombres de valeurs aberrantes augmente. C’est un défaut de la boîte à moustache, qui a été conçue pour des jeux de données qui passeraient pour petits selon les standards actuels.\n\n\n\n\n\n\nBoîte à moustache.\n\n\n\n\n\nOn peut représenter la distribution d’une variable réponse continue en fonction d’une variable catégorielle en traçant une boîte à moustaches pour chaque catégorie et en les disposant côte-à-côte. Une troisième variable catégorielle peut être ajoutée par le biais de couleurs, comme dans la Figure 1.7.\n\n\n\n\n\n\n\n\nFigure 1.7: Boîte à moustaches du prix des billets au tarif Promo en fonction de la classe pour le jeu de données Renfe.\n\n\n\n\n\nSi on veut représenter la covariabilité de deux variables continues, on utilise un nuage de points où chaque variable est représentée sur un axe et chaque observation donne la coordonnée des points. Si la représentation graphique est dominée par quelques valeurs très grandes, une transformation des données peut être utile: vous verrez souvent des données positives à l’échelle logarithmique. Si le nombre d’observations est très grand, il devient difficile de distinguer quoi que ce soit. On peut alors ajouter de la transparence ou regrouper des données en compartiments bidimensionnels (un histogramme bidimensionnel), dont la couleur représente la fréquence de chaque compartiment. Le paneau gauche de Figure 1.8 montre un nuage de points de 100 observations simulées, tandis que celui de droite représente des compartiments hexagonaux contenant 10 000 points.\n\n\n\n\n\n\n\n\nFigure 1.8: Nuage de points (gauche) et diagramme hexagonal (droite) pour des données simulées.\n\n\n\n\n\nSi on ajuste un modèle à des données, il convient de vérifier la qualité de l’ajustement et l’adéquation du modèle, par exemple graphiquement.\n\nDéfinition 1.13 (Diagrammes quantiles-quantiles) Le diagramme quantile-quantile sert à vérifier l’adéquation du modèle et découle du constat suivant: si \\(Y\\) est une variable aléatoire continue et \\(F\\) sa fonction de répartition, alors l’application \\(F(Y) \\sim \\mathsf{unif}(0,1)\\), une loi uniforme standard. De la même façon, appliquer la fonction quantile à une variable uniforme permet de simuler de la loi \\(F\\), et donc \\(F^{-1}(U)\\). Supposons un échantillon uniforme de taille \\(n\\). On peut démontrer que, pour des variables continues, les statistiques d’ordre \\(U_{(1)} \\leq \\cdots \\leq U_{(n)}\\) ont une loi marginale beta, avec \\(U_{(k)} \\sim \\mathsf{Beta}(k, n+1-k)\\) d’espérance \\(k/(n+1)\\).\nLes paramètres de la loi \\(F\\) sont inconnus, mais on peut obtenir un estimateur \\(\\widehat{F}\\) et appliquer la transformation inverse pour obtenir une variable approximativement uniforme. Un diagramme quantile-quantile représente les données en fonction des moments des statistiques d’ordre transformées\n\nsur l’axe des abscisses, les quantiles théoriques \\(\\widehat{F}^{-1}\\{\\mathrm{rang}(Y_i)/(n+1)\\}\\)\nsur l’axe des ordonnées, les quantiles empiriques \\(Y_i\\)\n\nSi le modèle est adéquat, les valeurs ordonnées devraient suivre une droite de pente unitaire qui passe par l’origine. Le diagramme probabilité-probabilité représente plutôt les données à l’échelle uniforme \\(\\{\\mathrm{rang}(Y_i)/(n+1), \\widehat{F}(Y_i)\\}\\).\n\n\n\n\n\n\n\n\n\nFigure 1.9: Diagramme probabilité-probabilité (gauche) et quantile-quantile normal (droite)\n\n\n\n\n\nMême si on connaissait exactement la loi aléatoire des données, la variabilité intrinsèque à l’échantillon fait en sorte que des déviations qui semblent significatives et anormales à l’oeil de l’analyste sont en fait compatibles avec le modèle: un simple estimé ponctuel sans mesure d’incertitude ne permet donc pas facilement de voir ce qui est plausible ou pas. On va donc idéalement ajouter un intervalle de confiance (approximatif) ponctuel ou conjoint au diagramme.\nPour obtenir l’intervalle de confiance approximatif, la méthode la plus simple est par simulation, en répétant \\(B\\) fois les étapes suivantes\n\nsimuler un échantillon \\(\\{Y^{(b)}_{i}\\} (i=1,\\ldots, n)\\) du modèle \\(\\widehat{F}\\)\nestimer les paramètres du modèle \\(F\\) pour obtenir \\(\\widehat{F}_{(b)}\\)\ncalculer et stocker les positions \\(\\widehat{F}^{-1}_{(b)}\\{i/(n+1)\\}\\).\n\nLe résultat de cette opération sera une matrice \\(n \\times B\\) de données simulées; on obtient un intervalle de confiance symmétrique en conservant le quantile \\(\\alpha/2\\) et \\(1-\\alpha/2\\) de chaque ligne. Le nombre de simulation \\(B\\) devrait être large (typiquement 999 ou davantage) et être choisi de manière à ce que \\(B/\\alpha\\) soit un entier.\nPour l’intervalle de confiance ponctuel, chaque valeur représente une statistique et donc individuellement, la probabilité qu’une statistique d’ordre sorte de l’intervalle de confiance est \\(\\alpha\\). En revanche, les statistiques d’ordres ne sont pas indépendantes et sont qui est plus ordonnées, ce qui fait qu’un point hors de l’intervalle risque de n’être pas isolé. Les intervalles présentés dans la Figure 1.9 sont donc ponctuels. La variabilité des statistiques d’ordre uniformes est plus grande autour de 1/2, mais celles des variables transformées dépend de \\(F\\).\nL’interprétation d’un diagramme quantile-quantile nécessite une bonne dose de pratique et de l’expérience: cette publication par Glen_b sur StackOverflow résume bien ce qu’on peut détecter ou pas en lisant le diagramme.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "introduction.html#loi-grands-nombres",
    "href": "introduction.html#loi-grands-nombres",
    "title": "1  Introduction",
    "section": "1.7 Loi des grands nombres",
    "text": "1.7 Loi des grands nombres\nUn estimateur est dit convergent si la valeur obtenue à mesure que la taille de l’échantillon augmente s’approche de la vraie valeur que l’on cherche à estimer. Mathématiquement parlant, un estimateur est dit convergent s’il converge en probabilité, ou \\(\\hat{\\theta} \\stackrel{\\mathsf{Pr}}{\\to} \\theta\\): en langage commun, la probabilité que la différence entre \\(\\hat{\\theta}\\) et \\(\\theta\\) diffèrent est négligeable quand \\(n\\) est grand.\nLa condition a minima pour le choix d’un estimateur est donc la convergence: plus on récolte d’information, plus notre estimateur devrait s’approcher de la valeur qu’on tente d’estimer.\nLa loi des grands nombres établit que la moyenne empirique de \\(n\\) observations indépendantes de même espérance, \\(\\overline{Y}_n\\), tend vers l’espérance commune des variables \\(\\mu\\), où \\(\\overline{Y}_n \\rightarrow \\mu\\). En gros, ce résultat nous dit que l’on réussit à approximer de mieux en mieux la quantité d’intérêt quand la taille de l’échantillon (et donc la quantité d’information disponible sur le paramètre) augmente. La loi des grands nombres est très utile dans les expériences Monte Carlo: on peut ainsi approximer par simulation la moyenne d’une fonction \\(g(x)\\) de variables aléatoires en simulant de façon répétée des variables \\(Y\\) indépendantes et identiquement distribuées et en prenant la moyenne empirique \\(n^{-1} \\sum_{i=1}^n g(Y_i)\\).\nSi la loi des grands nombres nous renseigne sur le comportement limite ponctuel, il ne nous donne aucune information sur la variabilité de notre estimé de la moyenne et la vitesse à laquelle on s’approche de la vraie valeur du paramètre.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "introduction.html#TCL",
    "href": "introduction.html#TCL",
    "title": "1  Introduction",
    "section": "1.8 Théorème central limite",
    "text": "1.8 Théorème central limite\nLe théorème central limite dit que, pour un échantillon aléatoire de taille \\(n\\) dont les observations sont indépendantes et tirées d’une loi quelconque d’espérance \\(\\mu\\) et de variance finie \\(\\sigma^2\\), alors la moyenne empirique tend non seulement vers \\(\\mu\\), mais à une vitesse précise:\n\nl’estimateur \\(\\overline{Y}\\) sera centré autour de \\(\\mu\\),\nl’erreur-type sera de \\(\\sigma/\\sqrt{n}\\); le taux de convergence est donc de \\(\\sqrt{n}\\). Ainsi, pour un échantillon de taille 100, l’erreur-type de la moyenne empirique sera 10 fois moindre que l’écart-type de la variable aléatoire sous-jacente.\nla loi approximative de la moyenne \\(\\overline{Y}\\) sera normale.\n\nMathématiquement, le théorème central limite dicte que \\(\\sqrt{n}(\\overline{Y}-\\mu) \\stackrel{\\mathrm{d}}{\\rightarrow} \\mathsf{normale}(0, \\sigma^2)\\). Si \\(n\\) est grand (typiquement supérieur à \\(30\\), mais cette règle dépend de la loi sous-jacente de \\(Y\\)), alors \\(\\overline{Y} \\stackrel{\\cdot}{\\sim} \\mathsf{normale}(\\mu, \\sigma^2/n)\\).\nComment interpréter ce résultat? On considère comme exemple le temps de trajet moyen de trains à haute vitesse AVE entre Madrid et Barcelone opérés par la Renfe.\n\n\n\n\n\n\n\n\nFigure 1.10: Distribution empirique des temps de trajet en trains à grande vitesse.\n\n\n\n\n\nUne analyse exploratoire indique que la durée du trajet de la base de données est celle affichée sur le billet (et non le temps réel du parcours). Ainsi, il n’y a ainsi que 15 valeurs possibles. Le temps affiché moyen pour le parcours, estimé sur la base de 9603 observations, est de 170 minutes et 41 secondes. La Figure 1.10 montre la distribution empirique des données.\nConsidérons maintenant des échantillons de taille \\(n=10\\). Dans notre premier échantillon aléatoire, la durée moyenne affichée est 169.3 minutes, elle est de 167 minutes dans le deuxième, de 157.9 dans le troisième, et ainsi de suite.\n\n\n\n\n\n\n\n\nFigure 1.11: Représentation graphique du théorème central limite: échantillon aléatoire de 20 observations avec leur moyenne empirique (trait vertical rouge) (en haut à gauche). Les trois autres panneaux montrent les histogrammes des moyennes empiriques d’échantillons répétés de taille 5 (en haut à droite), 20 (en bas à gauche) et les histogrammes pour \\(n=5, 20, 100\\) (en bas à droite) avec courbe de densité de l’approximation normale fournie par le théorème central limite.\n\n\n\n\n\nSupposons qu’on tire \\(B=1000\\) échantillons différents, chacun de taille \\(n=5\\), de notre ensemble, et qu’on calcule la moyenne de chacun d’entre eux. Le graphique supérieur droit de la Figure 1.11 montre un de ces 1000 échantillons aléatoire de taille \\(n=20\\) tiré de notre base de données. Les autres graphiques de la Figure 1.11 illustrent l’effet de l’augmentation de la taille de l’échantillon: si l’approximation normale est approximative avec \\(n=5\\), la distribution des moyennes est virtuellement identique à partir de \\(n=20\\). Plus la moyenne est calculée à partir d’un grand échantillon (c’est-à-dire, plus \\(n\\) augmente), plus la qualité de l’approximation normale est meilleure et plus la courbe se concentre autour de la vraie moyenne; malgré le fait que nos données sont discrètes, la distribution des moyennes est approximativement normale.\nOn a considéré une seule loi aléatoire inspirée de l’exemple, mais vous pouvez vous amuser à regarder l’effet de la distribution sous-jacent et de la taille de l’échantillon nécessaire pour que l’effet du théorème central limite prenne effet: il suffit pour cela de simulant des observations d’une loi quelconque de variance finie, en utilisant par exemple cette applette.\nLes statistiques de test qui découlent d’une moyenne centrée-réduite (ou d’une quantité équivalente pour laquelle un théorème central limite s’applique) ont souvent une loi nulle standard normale, du moins asymptotiquement (quand \\(n\\) est grand, typiquement \\(n&gt;30\\) est suffisant). C’est ce qui garantie la validité de notre inférence!\n\n\n\n\nGosset, William Sealy. 1908. « The probable error of a mean ». Biometrika 6 (1): 1‑25. https://doi.org/10.1093/biomet/6.1.1.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "inference.html",
    "href": "inference.html",
    "title": "2  Inférence statistique",
    "section": "",
    "text": "2.1 Variabilité échantillonale\nUn chercheur s’intéressera à l’estimation de certaines caractéristiques de la population à partir d’une base de données. Nous pouvons caractériser l’ensemble de toutes les valeurs potentielles que leurs mesures peuvent prendre, ainsi que leur fréquence, au moyen d’une loi d’une variable aléatoire.\nL’objectif de cette section est d’illustrer le fait que nous ne pouvons pas simplement utiliser les différences brutes entre les groupes pour effectuer des comparaisons significatives: en raison de la variabilité due à l’échantillonnage, les échantillons seront semblables même s’ils sont générés de la même manière, mais il y aura toujours des différences entre les statistiques récapitulatives calculées sur des échantillons différents. Ces différences ont tendance à s’atténuer (ou à augmenter) au fur et à mesure que l’on collecte davantage d’observations. Plus nous recueillons de données (et donc d’informations) sur notre cible, plus le portrait devient précis. C’est somme toute ce qui nous permet de tirer des conclusions mais, pour ce faire, nous devons d’abord déterminer ce qui est probable ou plausible et donc le fruit du hsard, de ce qui n’est pas ou peu susceptible de se produire.\nNous appelons statistiques les résumés numériques des données. Il est important de faire la distinction entre les procédures ou formules et leurs valeurs numériques. Un estimateur est une règle ou une formule utilisée pour calculer une estimation d’un paramètre ou d’une quantité d’intérêt sur la base de données observées (comme une recette de gâteau). Une fois que nous disposons de données observées, nous pouvons calculer la moyenne de l’échantillon, c’est-à-dire que nous disposons d’une estimation — d’une valeur réelle (le gâteau), qui est une réalisation unique et non aléatoire. En d’autres termes,\nPar exemple, si l’estimand est l’espérance de la population \\(\\mu,\\) l’estimateur sera la moyenne arithmétique, soit la somme des éléments de l’échantillon aléatoire divisé par la taille de l’échantillon, ou, \\(\\overline{Y}=(Y_1 + \\cdots + Y_n)/n.\\) L’estimé sera une valeur numérique, disons 4.3.\nParce que les intrants de l’estimateur sont aléatoires, la sortie l’est également et varie d’un échantillon à l’autre. Autrement dit, même si on répète une recette, on n’obtient pas le même résultat à chaque coup, comme le montre si bien la Figure 2.3.\nFigure 2.3: Bande dessinée xkcd 2581 (Health Stats) par Randall Munroe. Texte alternatif: You will live on forever in our hearts, pushing a little extra blood toward our left hands now and then to give them a squeeze. Bande réimprimée sous license CC BY-NC 2.5.\nPour illustrer ce point, Figure 2.4 montre cinq échantillons aléatoires simples de taille \\(n=10\\) tirés d’une population hypothétique de moyenne théorique \\(\\mu\\) et d’écart-type \\(\\sigma,\\) ainsi que leur moyenne d’échantillon \\(\\overline{y}.\\) En raison de la variabilité échantillonnale, les moyennes des sous-groupes sont différentes même si elles proviennent de la même population. Vous pouvez considérer la variabilité d’échantillonnage comme du bruit: notre objectif est d’extraire le signal (typiquement les différences de moyennes) tout en tenant compte du bruit de fond.\nFigure 2.4: Cinq échantillons de taille \\(n=10\\) tirés d’une population commune de moyenne \\(\\mu\\) (ligne horizontale). Les segments colorés représentent les moyennes empiriques de chaque groupe.\nL’oeil avisé pourra remarquer que les moyennes des cinq échantillons (segments horizontaux colorés) sont moins dispersées autour de la ligne horizontale noire représentant la moyenne de la population \\(\\mu\\) que ne le sont les observations. Il s’agit là d’un principe fondamental de la statistique: l’information s’accumule au fur et à mesure que l’on obtient plus de données.\nLes valeurs de la moyenne de l’échantillon ne donnent pas une image complète et l’étude des différences de moyenne (entre les groupes ou par rapport à une valeur de référence postulée) n’est pas suffisante pour tirer des conclusions. Dans la plupart des cas, rien ne garantit que la moyenne de l’échantillon sera égale à sa valeur réelle, car elle varie d’un échantillon à l’autre: la seule garantie que nous ayons est qu’elle sera en moyenne égale à la moyenne de la population dans des échantillons répétés. Selon le choix de la mesure et la variabilité de la population, il peut y avoir des différences considérables d’une observation à l’autre, ce qui signifie que la différence observée peut être un coup de chance.\nPour avoir une idée du degré de certitude d’une chose, nous devons considérer la variabilité d’une observation \\(Y_i.\\) Cette variance d’une observation tirée de la population est typiquement notée \\(\\sigma^2\\) et sa racine carrée, l’écart-type, par \\(\\sigma.\\)\nL’écart-type d’une statistique est appelé erreur-type; il ne doit pas être confondu avec l’écart-type \\(\\sigma\\) de la population dont sont tirées les observations de l’échantillon \\(Y_1, \\ldots, Y_n.\\) L’écart-type et l’erreur-type sont exprimés dans les mêmes unités que les données et sont donc plus faciles à interpréter que la variance. L’erreur-type étant fonction de la taille de l’échantillon, il est d’usage de rapporter plutôt l’écart-type dans les rapports.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Inférence statistique</span>"
    ]
  },
  {
    "objectID": "inference.html#variabilité-échantillonale",
    "href": "inference.html#variabilité-échantillonale",
    "title": "2  Inférence statistique",
    "section": "",
    "text": "un estimand est notre cible conceptuelle, comme la caractéristique de la population qui nous intéresse (la moyenne de la population).\nun estimateur est la procédure ou la formule qui nous indique comment transformer les données de l’échantillon en un résumé numérique qui est une approximation de notre cible.\nune estimation (ou un estimé) est un nombre, la valeur numérique obtenue lorsque nous appliquons la formule à un échantillon en praticulier.\n\n\n\n\n\n\n\n\n\n\n\n\n(a) Estimand\n\n\n\n\n\n\n\n\n\n\n\n(b) Estimateur\n\n\n\n\n\n\n\n\n\n\n\n(c) Estimé\n\n\n\n\n\n\n\nFigure 2.2: Les concepts d’estimand (gauche), estimateur (milieu) et estimaté (droite), illustrés à l’aide de gâteau, une variation d’un idée originale de Simon Grund. Les photos de gâteau sont partagées sous licence CC BY-NC 2.0.\n\n\n\n\n\n\n\n\n\n\n\n\n\nExemple 2.1 (Proportion échantillonale et tirages uniformes) Pour illustrer le concept de variabilité échantillonnale, nous suivons l’exemple de [Matthew Crump] (https://www.crumplab.com/statistics/foundations-for-inference.html) et considérons des échantillons provenant d’une distribution uniforme sur \\(\\{1, 2, \\ldots, 10\\}\\): chaque entier de cet intervalle a la même probabilité d’être tiré.\n\n\n\n\n\n\n\n\nFigure 2.5: Histogrammes de 10 échantillons aléatoires de taille \\(n=20\\) de loi uniforme discrète.\n\n\n\n\n\nMême s’ils sont tirés de la même population, les 10 échantillons de Figure 2.5 sont très différents. La seule chose en jeu ici est la variabilité de l’échantillon: puisqu’il y a \\(n=20\\) d’observations au total, il devrait y avoir en moyenne 10% des observations dans chacun des 10 bacs, mais certains bacs sont vides et d’autres ont plus d’effectifs que prévu. Cette fluctuation est le fruit du hasard.\nComment pouvons-nous donc déterminer si ce que nous voyons est compatible avec le modèle qui, selon nous, a généré les données ? Il suffit de collecter davantage d’observations: la hauteur de la barre est la proportion de l’échantillon, une moyenne de valeurs 0/1, où la valeur ‘un’ indique que l’observation se trouve dans la case, et ‘zéro’ dans le cas contraire.\nConsidérons maintenant ce qui se passe lorsque nous augmentons la taille de l’échantillon: le panneau supérieur de Figure 2.6 montre des échantillons uniformes pour une taille d’échantillon croissante. Le diagramme à bande ressemble de plus en plus à la véritable distribution sous-jacente (fonction de masse constante, donc chaque case ayant la même fréquence) à mesure que la taille de l’échantillon augmente. La distribution des points de l’échantillon est presque indiscernable de la distribution théorique (ligne droite) lorsque \\(n=10 000.\\)1. Le panneau du bas, en revanche, ne provient pas d’une distribution uniforme. Plus l’échantillon grossit, plus l’approximation de la fonction de masse se rapproche de la vraie valeur. Nous n’aurions pas pu remarquer cette différence dans les deux premiers graphiques, car la variabilité de l’échantillonnage est trop importante; là, le manque de données dans certaines cases pourrait être un obstacle à l’obtention d’une distribution uniforme.\n\n\n\n\n\n\n\n\nFigure 2.6: Histogrammes de données tirées d’une loi uniforme (haut) et d’une loi non-uniforme (bas) pour des tailles d’échantillons de 10, 100, 1000 and 10 000 (de gauche à droite).",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Inférence statistique</span>"
    ]
  },
  {
    "objectID": "inference.html#tests",
    "href": "inference.html#tests",
    "title": "2  Inférence statistique",
    "section": "2.2 Tests d’hypothèse",
    "text": "2.2 Tests d’hypothèse\nUn test d’hypothèse statistique est une façon d’évaluer la preuve statistique provenant d’un échantillon afin de faire une décision quant à la population sous-jacente. Les étapes principales sont:\n\ndéfinir les paramètres du modèle,\nformuler les hypothèses alternative et nulle,\nchoisir et calculer la statistique de test,\ndéterminer son comportement sous \\(\\mathscr{H}_0\\) (loi nulle),\ncalculer la valeur-p,\nconclure dans le contexte du problème (rejeter ou ne pas rejeter \\(\\mathscr{H}_0\\)).\n\nMon approche privilégiée pour présenter les tests d’hypothèse est de faire un parallèle avec un procès pour meurtre où vous êtes nommé juré.\n\nLe juge vous demande de choisir entre deux hypothèses mutuellement exclusives, coupable ou non-coupable, sur la base des preuves présentées.\nVotre postulat de départ repose sur la présomption d’innocence: vous condamnerez uniquement le suspect si la preuve est accablante. Cela permet d’éviter les erreurs judiciaires. L’hypothèse nulle \\(\\mathscr{H}_0\\) est donc non-coupable, et l’hypothèse alternative \\(\\mathscr{H}_a\\) est coupable. En cas de doute raisonnable, vous émettrez un verdict de non-culpabilité.\nLa choix de la statistique de test représente la preuve. Plus la preuve est accablante, plus grande est la chance d’un verdict de culpabilité — le procureur a donc tout intérêt à bien choisir les faits présentés en cour. Le choix de la statistique devrait donc idéalement maximiser la preuve pour appuyer le postulat de culpabilité le mieux possible (ce choix reflète la puissance du test).\nEn qualité de juré, vous analysez la preuve à partir de la jurisprudence et de l’avis d’expert pour vous assurer que les faits ne relèvent pas du hasard. Pour le test d’hypothèse, ce rôle est tenu par la loi sous \\(\\mathscr{H}_0\\): si la personne était innocente, est-ce que les preuves présentées tiendraient la route? des traces d’ADN auront davantage de poids que des ouï-dire (la pièce de théâtre Douze hommes en colère de Reginald Rose présente un bel exemple de procès où un des juré émet un doute raisonnable et convainc un à un les autres membres du jury de prononcer un verdict de non-culpabilité).\nVous émettez un verdict, à savoir une décision binaire, où l’accusé est déclaré soit non-coupable, soit coupable. Si vous avez une valeur-p, disons \\(P,\\) pour votre statistique de test et que vous effectuez ce dernier à niveau \\(\\alpha,\\) la règle de décision revient à rejeter \\(\\mathscr{H}_0\\) si \\(P &lt; \\alpha.\\)\n\nOn s’attarde davantage sur ces définitions heuristiques et le vocabulaire employé pour parler de tests d’hypothèse.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Inférence statistique</span>"
    ]
  },
  {
    "objectID": "inference.html#hypothèse",
    "href": "inference.html#hypothèse",
    "title": "2  Inférence statistique",
    "section": "2.3 Hypothèse",
    "text": "2.3 Hypothèse\nDans les test statistique il y a toujours deux hypothèse: l’hypothèse nulle (\\(\\mathscr{H}_{0}\\)) et l’hypothèse alternative (\\(\\mathscr{H}_a\\)). Habituellement, l’hypothèse nulle est le « statu quo » et l’alternative est l’hypothèse que l’on cherche à démontrer. On se fait l’avocat du Diable en défendant l’hypothèse nulle et en analysant toutes les preuves sous l’angle: « est-ce que les données entrent en contradiction avec \\(\\mathscr{H}_0\\)? ». Un test d’hypothèse statistique nous permet de décider si nos données nous fournissent assez de preuves pour rejeter \\(\\mathscr{H}_0\\) en faveur de \\(\\mathscr{H}_a,\\) selon un risque d’erreur spécifié.\nGénéralement, les tests d’hypothèses sont exprimés en fonction de paramètres (de valeurs inconnues) du modèle sous-jacent, par ex. \\(\\theta.\\) Un test d’hypothèse bilatéral concernant un paramètre scalaire \\(\\theta\\) s’exprimerait la forme suivante: \\[\\begin{align*}\n\\mathscr{H}_0: \\theta=\\theta_0 \\qquad \\text{versus} \\qquad \\mathscr{H}_a:\\theta \\neq \\theta_0.\n\\end{align*}\\] Ces hypothèses permettent de tester si \\(\\theta\\) est égal à une valeur numérique précise \\(\\theta_0.\\)\nPar exemple, pour un test bilatéral concernant le paramètre d’un modèle de régression \\(\\beta_j\\) associé à une variable explicative d’intérêt \\(\\mathrm{X}_j,\\) les hypothèses sont \\[\\begin{align*}\n\\mathscr{H}_0: \\beta_j=\\beta_j^0 \\qquad \\text{versus} \\qquad \\mathscr{H}_a:\\beta_j \\neq \\beta_j^0,\n\\end{align*}\\] où \\(\\beta_j^0\\) est une valeur précise qui est reliée à la question de recherche. Par exemple, si \\(\\beta_j^0=0\\) la question de recherche sous-jacente est: est-ce que la covariable \\(\\mathrm{X}_j\\) impacte la variable réponse d’intérêt \\(Y\\) une fois l’effet des autres variables pris en compte?\nIl est possible d’imposer une direction dans les tests en considérant une hypothèse alternative de la forme \\(\\mathscr{H}_a: \\theta &gt; \\theta_0\\) ou \\(\\mathscr{H}_a: \\theta &lt; \\theta_0.\\)",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Inférence statistique</span>"
    ]
  },
  {
    "objectID": "inference.html#statistique-de-test",
    "href": "inference.html#statistique-de-test",
    "title": "2  Inférence statistique",
    "section": "2.4 Statistique de test",
    "text": "2.4 Statistique de test\nUne statistique de test \\(T\\) est une fonction des données qui résume l’information contenue dans les données pour \\(\\theta.\\) La forme de la statistique de test est choisie de façon à ce que son comportement sous \\(\\mathscr{H}_0,\\) c’est-à-dire l’ensemble des valeurs que prend \\(T\\) si \\(\\mathscr{H}_0\\) est vraie et leur probabilité relative, soit connu. En effet, \\(T\\) est une variable aléatoire et sa valeur va changer selon l’échantillon. La loi nulle de la statistique de test nous permet de déterminer quelles valeurs de \\(T\\) sont plausibles si \\(\\mathscr{H}_0\\) est vraie. Plusieurs statistiques que l’on couvrira dans ce cours sont des statistiques de Wald, de la forme \\[\\begin{align*}\nT = \\frac{\\widehat{\\theta} - \\theta_0}{\\mathrm{se}(\\widehat{\\theta})}\n\\end{align*}\\] où \\(\\widehat{\\theta}\\) est l’estimateur du paramètre \\(\\theta,\\) \\(\\theta_0\\) la valeur numérique postulée (par ex., zéro) et \\(\\mathrm{se}(\\widehat{\\theta})\\) est l’estimateur de l’écart-type de \\(\\widehat{\\theta}.\\)\nPar exemple, pour une hypothèse sur la moyenne d’une population de la forme \\[\\begin{align*}\n\\mathscr{H}_0: \\mu=0, \\qquad  \\mathscr{H}_a:\\mu \\neq 0,\n\\end{align*}\\] la statistique de test de Wald est \\[\\begin{align*}\nT &= \\frac{\\overline{X}-0}{S_n/\\sqrt{n}}\n\\end{align*}\\] où \\(\\overline{X}\\) est la moyenne de l’échantillon \\(X_1, \\ldots, X_n,\\) \\[\\begin{align*}\n\\overline{X} &= \\frac{1}{n} \\sum_{i=1}^n X_i = \\frac{X_1+ \\cdots + X_n}{n}\n\\end{align*}\\] et l’erreur-type de la moyenne \\(\\overline{X}\\) est \\(S_n/\\sqrt{n}\\); l’écart-type \\(S_n\\) est un estimateur de \\(\\sigma,\\) où \\[\\begin{align*}\nS^2_n &= \\frac{1}{n-1} \\sum_{i=1}^n (X_i-\\overline{X})^2.\n\\end{align*}\\]",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Inférence statistique</span>"
    ]
  },
  {
    "objectID": "inference.html#loi-nulle-et-valeur-p",
    "href": "inference.html#loi-nulle-et-valeur-p",
    "title": "2  Inférence statistique",
    "section": "2.5 Loi nulle et valeur-p",
    "text": "2.5 Loi nulle et valeur-p\nLa valeur-p nous permet de déterminer si la valeur observée de la statistique de test \\(T\\) est plausible sous \\(\\mathscr{H}_0.\\) Plus précisément, la valeur-p est la probabilité, si \\(\\mathscr{H}_0\\) est vraie, que la statistique de test soit égale or plus extrême à ce qu’on observe. Supposons qu’on a un échantillon \\(X_1, \\ldots, X_n\\) et qu’on observe une valeur de la statistique de test de \\(T=t.\\) Pour un test d’hypothèse bilatéral \\(\\mathscr{H}_0:\\theta=\\theta_0\\) vs. \\(\\mathscr{H}_a:\\theta \\neq \\theta_0,\\) la valeur-p est \\(\\Pr{\\!}_0(|T| \\geq |t|).\\) Si la distribution de \\(T\\) est symétrique autour de zéro, la valeur-p vaut \\[\\begin{align*}\np = 2 \\times \\Pr{\\!}_0(T \\geq |t|).\n\\end{align*}\\]\nLa Figure 2.7 montre la loi des valeurs-\\(p\\) sous deux scénarios: à gauche, une loi nulle et à droite, une loi alternative. La probabilité de rejetter \\(\\mathscr{H}_0\\) est obtenue en calculant l’aire sous la courbe sous la courbe de densité et \\(\\alpha=0.1.\\) Sous l’hypothèse nulle, le modèle est calibré et la loi des valeurs-\\(p\\) est uniforme (un rectangle de hauteur 1), ce qui veut dire que toutes les valeurs sont également plausibles. Sous l’alternative, l’obtention de petites valeurs\\(-\\)p est plus plausible.\n\n\n\n\n\n\n\n\nFigure 2.7: Densité des valeurs-\\(p\\) sou l’hypothèse nulle (gauche) et une alternative avec un ratio signal-bruit de 0.5 (droite).\n\n\n\n\n\nIl existe généralement trois façons d’obtenir des lois nulles pour évaluer le degré de preuve contre l’hypothèse nulle\n\nles calculs exacts (combinatoires)\nla théorie des grands échantillons (appelée « régime asymptotique » dans le jargon statistique)\nles méthodes de simulation Monte Carlo.\n\nBien que souhaitable, la première méthode n’est applicable que dans des cas simples (comme le calcul de la probabilité d’obtenir deux six en lançant deux dés identiques). La deuxième méthode est la plus couramment utilisée en raison de sa généralité et de sa facilité d’utilisation (en particulier dans les temps anciens où la puissance de calcul était rare), mais elle ne donne pas de bons résultats avec des échantillons de petite taille (où la noti de « trop petit » dépend du contexte et du test). La dernière approche peut être utilisée pour approcher la distribution nulle dans de nombreux scénarios, mais elle ajoute une couche d’aléatoire et les coûts de calcul supplémentaires n’en valent parfois pas la peine.\nPrenons l’exemple d’un test d’hypothèse bilatéral pour la moyenne au population \\(\\mathscr{H}_0:\\mu=0\\) contre \\(\\mathscr{H}_a:\\mu \\neq 0.\\) Si l’échantillon provient d’une (population de) loi normale \\(\\mathsf{normale}(\\mu, \\sigma^2),\\) on peut démontrer que, si \\(\\mathscr{H}_0\\) est vraie et donc \\(\\mu=0\\)), la statistique de test \\[\\begin{align*}\nT = \\frac{\\overline{X}}{S/\\sqrt{n}}\n\\end{align*}\\] suit une loi de Student-\\(t\\) avec \\(n-1\\) degrés de liberté, dénotée \\(\\mathsf{Student}_{n-1}.\\) À partir de cette loi nulle, on peut calculer la valeur-p (ou bien à partir d’une table ou d’un logiciel statistique). Puisque la distribution Student-\\(t\\) est symétrique autour de \\(0,\\) on peut calculer la valeur-p comme \\(P = 2\\times\\Pr(T &gt; |t|),\\) où \\(T \\sim \\mathsf{Student}_{n-1}.\\)",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Inférence statistique</span>"
    ]
  },
  {
    "objectID": "inference.html#intervalle-de-confiance",
    "href": "inference.html#intervalle-de-confiance",
    "title": "2  Inférence statistique",
    "section": "2.6 Intervalle de confiance",
    "text": "2.6 Intervalle de confiance\nUn intervalle de confiance est une manière alternative de rapporter les conclusions d’un test, en ce sens qu’on fournit une estimation ponctuelle de \\(\\hat{\\theta}\\) avec une marge d’erreur. L’intervalle de confiance donne donc une indication de la variabilité de la procédure d’estimation. Un intervalle de confiance de Wald à \\((1-\\alpha)\\) pour un paramètre \\(\\theta\\) est de la forme \\[\\begin{align*}\n[\\widehat{\\theta} + \\mathfrak{q}_{\\alpha/2}\\mathrm{se}(\\widehat{\\theta}), \\widehat{\\theta} +\\mathfrak{q}_{1-\\alpha/2}\\times \\mathrm{se}(\\widehat{\\theta})]\n\\end{align*}\\] où \\(\\mathfrak{q}_{\\alpha}\\) dénote le quantile d’ordre \\(\\alpha \\in (0,1)\\) de la loi nulle de la statistique de Wald, \\[\\begin{align*}\nT =\\frac{\\widehat{\\theta}-\\theta}{\\mathrm{se}(\\widehat{\\theta})},\n\\end{align*}\\] et où \\(\\theta\\) représente la valeur du paramètre \\(\\theta\\) (supposé fixe, mais inconnu) de la population.\nPar exemple, pour un échantillon aléatoire \\(X_1, \\ldots, X_n\\) provenant d’une loi \\(\\mathsf{normale}(\\mu, \\sigma),\\) l’intervalle de confiance à \\((1-\\alpha)\\) pour la moyenne (dans la population) \\(\\mu\\) est \\[\\begin{align*}\n\\overline{X} \\pm t_{n-1, \\alpha/2} \\frac{S}{\\sqrt{n}}\n\\end{align*}\\] où \\(t_{n-1, \\alpha/2}\\) est le quantile d’ordre \\(1-\\alpha/2\\) de la loi Student-\\(t\\) avec \\(n-1\\) degrés de libertés.\nLes bornes de l’intervalle de confiance sont aléatoires puisque \\(\\widehat{\\theta}\\) et \\(\\mathrm{se}(\\widehat{\\theta})\\) sont des variable aléatoires: leurs valeurs observées changent d’un échantillon à un autre. Avant qu’on calcule l’intervalle de confiance, il y a une probabilité de \\(1-\\alpha\\) que \\(\\theta\\) soit contenu dans l’intervalle aléatoire symmétrique \\((\\widehat{\\theta} - \\mathfrak{q}_{\\alpha/2} \\; \\mathrm{se}(\\widehat{\\theta}), \\widehat{\\theta} + \\mathfrak{q}_{\\alpha/2} \\; \\mathrm{se}(\\widehat{\\theta})),\\) où \\(\\widehat{\\theta}\\) dénote l’estimateur de \\(\\theta.\\) Une fois qu’on obtient un échantillon et qu’on calcule les bornes de l’intervalle de confiance, il n’y a plus de notion de probabilité: la vraie valeur du paramètre \\(\\theta\\) (inconnue) est soit contenue dans l’intervalle de confiance, soit pas. La seule interprétation de l’intervalle de confiance qui soit valable alors est la suivante: si on répète l’expérience plusieurs fois et qu’à chaque fois on calcule un intervalle de confiance à \\(1-\\alpha,\\) alors une proportion de \\((1-\\alpha)\\) de ces intervalles devraient contenir la vraie valeur de \\(\\theta\\) (de la même manière, si vous lancez une pièce de monnaie équilibrée, vous devriez obtenir grosso modo une fréquence de 50% de pile et 50% de face, mais chaque lancer donnera un ou l’autre de ces choix). Notre « confiance » est dans la procédure et non pas dans les valeurs numériques obtenues pour un échantillon donné.\n\n\n\n\n\n\n\n\nFigure 2.8: Intervalles de confiance à 95% pour la moyenne d’une population normale standard pour 100 échantillons aléatoires. En moyenne, 5% de ces intervalles (en rouge) n’incluent pas la vraie valeur de la moyenne de zéro.\n\n\n\n\n\nSi on s’intéresse seulement à la décision rejeter/ne pas rejeter \\(\\mathscr{H}_0,\\) l’intervalle de confiance est équivalent à la valeur-p en ce sens qu’il mène à la même décision. L’intervalle de confiance donne en revanche l’ensemble des valeurs pour lesquelles la statistique de test ne fournit pas assez de preuves pour rejeter \\(\\mathscr{H}_0\\): pour un test à niveau \\(\\alpha,\\) on ne rejetterait aucune des valeurs contenues dans l’intervalle de confiance de niveau \\(1-\\alpha.\\) Si la valeur-p est inférieure à \\(\\alpha,\\) la valeur postulée pour \\(\\theta\\) est donc hors de l’intervalle de confiance calculé. À l’inverse, la valeur-p ne donne la probabilité d’obtenir un résultat aussi extrême sous l’hypothèse nulle que pour une seule valeur numérique, mais permet de quantifier précisément à quel point le résultat est extrême.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Inférence statistique</span>"
    ]
  },
  {
    "objectID": "inference.html#conclusion",
    "href": "inference.html#conclusion",
    "title": "2  Inférence statistique",
    "section": "2.7 Conclusion",
    "text": "2.7 Conclusion\nLa valeur-p nous permet de faire une décision quant aux hypothèses du test. Si \\(\\mathscr{H}_0\\) est vraie, la valeur-p suit une loi uniforme. Si la valeur-p est petite, ça veut dire que le fait d’observer une statistique de test égal ou encore plus extrême que \\(T=t\\) est peu probable, et donc nous aurons tendance de croire que \\(\\mathscr{H}_0\\) n’est pas vraie. Il y a pourtant toujours un risque sous-jacent de commettre un erreur quand on prend une décision. En statistique, il y a deux types d’erreurs:\n\nerreur de type I: on rejette \\(\\mathscr{H}_0\\) alors que \\(\\mathscr{H}_0\\) est vraie\nerreur de type II: on ne rejette pas \\(\\mathscr{H}_0\\) alors que \\(\\mathscr{H}_0\\) est fausse\n\nCes deux erreurs ne sont pas égales: on cherche souvent à contrôler l’erreur de type I (une erreur judiciaire, condamner un innocent). Pour se prémunir face à ce risque, on fixe préalablement un niveau de tolérance. Plus notre seuil de tolérance \\(\\alpha\\) est grand, plus on rejette souvent l’hypothèse nulle même si cette dernière est vraie. La valeur de \\(\\alpha \\in (0, 1)\\) est la probabilité qu’on rejette \\(\\mathscr{H}_0\\) quand \\(\\mathscr{H}_0\\) est en fait vraie. \\[\\begin{align*}\n\\alpha = \\Pr{\\!}_0\\left(\\text{ rejeter } \\mathscr{H}_0\\right).\n\\end{align*}\\] Comme chercheur, on choisit ce niveau \\(\\alpha\\); habituellement \\(1\\)%, \\(5\\)% ou \\(10\\)%. La probabilité de commettre une erreur de type I est \\(\\alpha\\) seulement si le modèle nul postulé pour \\(\\mathscr{H}_0\\) est correctement spécifié (sic) et correspond au modèle générateur des données.\nLe choix du statu quo (typiquement \\(\\mathscr{H}_0\\)) s’explique plus facilement avec un exemple médical. Si vous voulez prouver qu’un nouveau traitement est meilleur que l’actuel (ou l’absence de traitement), vous devez démontrer hors de tout doute raisonnable que ce dernier ne cause pas de torts aux patients et offre une nette amélioration (pensez à Didier Raoult et ses allégations non-étayées voulant que l’hydrochloroquine, un antipaludique, soit efficace face au virus de la Covid19).\n\n\n\n\n\n\n\n\nDécision \\ vrai modèle\n\\(\\mathscr{H}_0\\)\n\\(\\mathscr{H}_a\\)\n\n\n\n\nne pas rejeter \\(\\mathscr{H}_0\\)\n\\(\\checkmark\\)\nerreur de type II\n\n\nrejeter \\(\\mathscr{H}_0\\)\nerreur de type I\n\\(\\checkmark\\)\n\n\n\nPour prendre une décision, on doit comparer la valeur-p \\(P\\) avec le niveau du test \\(\\alpha\\):\n\nsi \\(P &lt; \\alpha\\) on rejette \\(\\mathscr{H}_0,\\)\nsi \\(P \\geq \\alpha\\) on ne rejette pas \\(\\mathscr{H}_0.\\)\n\nAttention à ne pas confondre niveau du test (probabilité fixée au préalable par l’expérimentateur) et la valeur-p (qui dépend de l’échantillon). Si vous faites un test à un niveau 5% la probabilité de faire une erreur de type I est de 5% par définition, quelque soit la valeur de la valeur-p. La valeur-p s’interprète comme la probabilité d’obtenir une valeur de la statistique de test égale ou même plus grande que celle qu’on a observée dans l’échantillon, si \\(\\mathscr{H}_0\\) est vraie.\n\n\n\n\n\n\nMise en garde\n\n\n\nL’American Statistical Association (ASA) a publié une liste de principes détaillant les principales erreurs d’interprétation des valeurs-\\(p,\\) notamment\n\n\nLes valeurs-\\(p\\) ne mesurent pas la probabilité que l’hypothèse étudiée est vrai\n\n\n\n\nLes décisions d’affaires et scientiques ne devraient pas seulement être basées sur le fait qu’une valeur-\\(p\\) est inférieure à un seuil spécifié.\n\n\n\n\nLes analyses statistiques et les valeurs-\\(p\\) associées ne devraient pas être rapportées de manière sélective.\n\n\n\n\nLes valeurs-\\(p,\\) ou la significativité statistiques, ne mesurent pas la taille de l’effet ou l’importance d’un résultat.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Inférence statistique</span>"
    ]
  },
  {
    "objectID": "inference.html#puissance-statistique",
    "href": "inference.html#puissance-statistique",
    "title": "2  Inférence statistique",
    "section": "2.8 Puissance statistique",
    "text": "2.8 Puissance statistique\nLe but du test d’hypothèse est de prouver (hors de tout doute raisonnable) qu’une différence ou un effet est significatif: par exemple, si une nouvelle configuration d’un site web (hypothèse alternative) permet d’augmenter les ventes par rapport au statu quo. Notre capacité à détecter cette amélioration dépend de la puissance du test: plus cette dernière est élevée, plus grande est notre capacité à rejeter \\(\\mathscr{H}_0\\) quand ce dernier est faux.\nQuand on ne rejette pas \\(\\mathscr{H}_0\\) et que \\(\\mathscr{H}_a\\) est en fait vraie, on commet une erreur de type II: cette dernière survient avec probabilité \\(1-\\gamma.\\) La puissance statistique d’un test est la probabilité que le test rejette \\(\\mathscr{H}_0\\) alors que \\(\\mathscr{H}_0\\) est fausse, soit \\[\\begin{align*}\n\\gamma = \\Pr{\\!}_a(\\text{rejeter } \\mathscr{H}_0)\n\\end{align*}\\] Selon le choix de l’alternative, il est plus ou moins facile de rejeter l’hypothèse nulle en faveur de l’alternative.\n\n\n\n\n\n\n\n\nFigure 2.9: Comparaison de la loi nulle (ligne pleine) et d’une alternative spécifique pour un test-\\(t\\) (ligne traitillée). La puissance correspond à l’aire sous la courbe de la densité de la loi alternative qui est dans la zone de rejet du test (en blanc). Le panneau du milieu représente l’augmentation de la puissance suite à l’augmentation de la taille d’effet (différence moyenne entre groupes plus élevée) sous l’hypothèse alternative. Le panneau de droite correspond à un scénario alternatif avec la même taille d’effet, mais une taille d’échantillon ou une précision plus grande.\n\n\n\n\n\nOn veut qu’un test ait une puissance élevée, c’est-à-dire, le plus près de 1 possible. Minimalement, la puissance du test devrait être \\(\\alpha\\) si on rejette l’hypothèse nulle une fraction \\(\\alpha\\) du temps quand cette dernière est vraie. La puissance dépend de plusieurs critères, à savoir:\n\nla taille de l’effet: plus la différence est grande entre la valeur postulée \\(\\theta_0\\) du paramètre sous \\(\\mathscr{H}_0\\) et le comportement observé, plus il est facile de le détecter (panneau du milieu de Figure 2.9);\nla variabilité: moins les observations sont variables, plus il est facile de déterminer que la différence observée est significative (les grandes différences sont alors moins plausibles, comme l’illustre le panneau de droite de Figure 2.9);\nla taille de l’échantillon: plus on a d’observations, plus notre capacité à détecter une différence significative augmente parce que l’erreur-type décroît avec la taille de l’échantillon à un rythme (ordinairement) de \\(n^{-1/2}.\\) La loi nulle devient aussi plus concentrée quand la taille de l’échantillon augmente.\nle choix de la statistique de test: par exemple, les statistiques basées sur les rangs n’utilisent pas les valeurs numériques qu’à travers le rang relatif. Ces tests sont donc moins puissants parce qu’ils n’utilisent pas toute l’information dans l’échantillon; en contrepartie, ils sont souvent plus robustes en présence de valeurs aberrantes et si le modèle est mal spécifié. Les statistiques de test que nous choisirons sont souvent standards et parmi les plus puissantes qui soient, aussi on ne traitera pas de ce point davantage dans le cadre du cours.\n\nPour calculer la puissance d’un test, il faut choisir une alternative spécifique. Pour des exemples simples de statistiques, on peut obtenir une formule explicite pour la puissance. Généralement, on détermine la puissance à l’aide de méthodes de Monte Carlo en simulant des observations d’une alternative donnée, en calculant la statistique de test sur le nouvel échantillon simulé et en calculant la valeur-p associée à notre hypothèse nulle de façon répétée. On calcule par la suite la proportion de tests qui mènent au rejet de l’hypothèse nulle à niveau \\(\\alpha,\\) ce qui correspond au pourcentage de valeurs-\\(p\\) inférieures à \\(\\alpha.\\)",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Inférence statistique</span>"
    ]
  },
  {
    "objectID": "inference.html#exemples",
    "href": "inference.html#exemples",
    "title": "2  Inférence statistique",
    "section": "2.9 Exemples",
    "text": "2.9 Exemples\n\nExemple 2.2 (Inégalité de genre et tests de permutation) Nous examinons les données de Rosen et Jerdee (1974), qui étudie les stéréotypes de genre et leur impact sur la promotion et les opportunités pour les femmes candidates. L’expérience s’est déroulée en 1972 et les unités expérimentales, composées de 95 superviseurs bancaires masculins, ont reçu divers mémorandums et ont été invitées à fournir des évaluations de candidatures pour un poste de cadre. Ils devaient prendre des décisions sur la base des informations fournies.\nNous nous intéressons à l’expérience 1 relative à la promotion des employés: les responsables devaient décider de promouvoir ou non un employé au poste de directeur de succursale sur la base de recommandations et d’évaluations du potentiel de relations avec les clients et les employés. L’intervention des auteurs s’est concentrée sur la description de la nature (complexité) du travail du gestionnaire (simple ou complexe) et sur le sexe du candidat (homme ou femme): tous les dossiers étaient par ailleurs similaires.\nPour des raisons de simplicité, nous ne considérons que le facteur sexe et nous agrégeons sur le poste pour les \\(n=93\\) réponses. La table Tableau 2.1 montre le décompte des recommendations pour chaque possibilité.\n\n\n\n\nTableau 2.1: Recommendations de promotion pour le poste de gestionnaire de branche selon le sexe de la personne qui postule.\n\n\n\n\n\n\n\nmale\nfemale\n\n\n\n\npromouvoir\n32\n19\n\n\nne pas promouvoir\n12\n30\n\n\n\n\n\n\n\n\n\n\nL’hypothèse nulle qui nous intéresse ici est que le sexe n’a pas d’impact, de sorte que la probabilité de promotion est la même pour les hommes et les femmes. Soit \\(p_{\\text{h}}\\) et \\(p_{\\text{f}}\\) ces probabilités respectives; nous pouvons donc écrire mathématiquement l’hypothèse nulle comme \\(\\mathscr{H}_0: p_{\\text{h}} = p_{\\text{f}}\\) contre l’alternative \\(\\mathscr{H}_a: p_{\\text{h}} \\neq p_{\\text{f}}\\).\nLa statistique de test généralement employée pour les tableaux de contingence est un test du chi carré2, qui compare les proportions globales de promotion de chaque sous-groupe. La proportion de l’échantillon pour les hommes est de 32/42 = ~76%, contre 19/49 =~49% pour les femmes. Bien que cette différence de 16 % semble importante, elle pourrait être trompeuse: l’erreur type pour les proportions de l’échantillon est d’environ 3.2 % pour les hommes et 3.4 % pour les femmes.\nS’il n’y avait pas de discrimination fondée sur le sexe, nous nous attendrions à ce que la proportion de personnes promues soit la même dans l’ensemble; elle est de 51/93 ou 0.55 pour l’échantillon regroupé. Nous pourrions nous contenter de tester la différence moyenne, mais nous nous appuyons plutôt sur le test de contingence \\(X^2_p\\) de Pearson (également appelé test du khi-carré), qui compare les chiffres attendus (sur la base de taux de promotion égaux) aux chiffres observés, convenablement normalisés. convenablement normalisés. Si l’écart est important entre les chiffres attendus et les chiffres observés, cela met en doute la véracité de l’hypothèse nulle.\nSi les effectifs de chaque cellule sont importants, la distribution nulle du test du chi-deux est bien approximée par une distribution de \\(\\chi^2\\). La sortie du test comprend la valeur de la statistique, \\(10.79,\\) les degrés de liberté de l’approximation \\(\\chi^2\\) et la valeur p, qui donne la probabilité qu’un tirage aléatoire d’une distribution \\(\\chi^2_1\\) soit plus grand que la statistique de test observée en supposant que l’hypothèse nulle est vraie. La valeur p est très petite, \\(0.001\\), ce qui signifie qu’il est très peu probable qu’un tel résultat soit le fruit du hasard s’il n’y a pas eu de discrimination fondée sur le sexe.\nUne autre solution pour obtenir un point de référence permettant d’évaluer le caractère exagéré du rapport de cotes observé consiste à utiliser des simulations: les tests de permutation sont efficaces [illustrés par Jared Wilber] (https://www.jwilber.me/permutationtest/). Considérons une base de données contenant les données brutes avec 93 lignes, une pour chaque gestionnaie, avec pour chacune un indicateur d’action et le sexe de l’employé hypothétique présenté dans la tâche.\n\n\n\n\nTableau 2.2: Les cinq premières lignes de la base de données en format long pour l’expérience 1 de Rosen et Jerdee (1974).\n\n\n\n\n\n\naction\nsexe\n\n\n\n\npromouvoir\nhomme\n\n\nne pas promouvoir\nfemme\n\n\npromouvoir\nhomme\n\n\nne pas promouvoir\nfemme\n\n\nne pas promouvoir\nhomme\n\n\n\n\n\n\n\n\n\n\nSous l’hypothèse nulle, le sexe n’a aucune incidence sur l’action du gestionnaire. Cela signifie que nous pourrions dresser un portrait du monde sans discrimination en mélangeant les étiquettes de sexe de manière répétée. Ainsi, nous pourrions obtenir une référence en répétant les étapes suivantes plusieurs fois :\n\npermuter les étiquettes pour le sexe,\nrecréer un tableau de contingence en agrégeant les effectifs,\ncalculer une statistique de test pour le tableau simulé.\n\nComme statistique de test, nous utilisons le rapport des cotes: la probabilité d’un événement est le rapport entre le nombre de succès et le nombre d’échecs. Dans notre exemple, il s’agirait du nombre de dossiers promus par rapport au nombre de dossiers retenus. La probabilité de promotion d’un homme est de \\(32/12,\\) alors que celle d’une femme est de \\(19/30.\\) Le rapport des cotes pour un homme par rapport à une femme est donc \\(\\mathsf{RC}=(32/12) / (19/30)= 4.21.\\) Sous l’hypothèse nulle, \\(\\mathscr{H}_0: \\mathsf{OR}= 1\\) (même probabilité d’être promu) (pourquoi ?)\n\n\n\n\n\n\n\n\nFigure 2.10: Histogramme de simulations de la loi nulle pour le rapport de cote, obtenu par le biais d’un test de permutation; la ligne verticale rouge indique le rapport de cote échantillonal.\n\n\n\n\n\nL’histogramme de la Figure 2.10 montre la distribution du rapport de cotes sur la base de 10 000 permutations. Il est rassurant de constater que nous obtenons à peu près la même valeur p approximative, ici 0.002.3.\nL’article concluait (à la lumière de ce qui précède et d’autres expériences)\n\nLes résultats ont confirmé l’hypothèse selon laquelle les administrateurs masculins ont tendance à discriminer les employées dans les décisions concernant la promotion, le développement et la supervision du personnel.\n\nRécapitulatif\n\nParamètres du modèle: probabilité de promotion pour les hommes et les femmes, respectivement \\(p_{\\text{h}}\\) et \\(p_{\\text{f}}\\).\nHypothèses: pas de discrimination fondée sur le sexe, ce qui signifie une probabilité de promotion égale (hypothèse nulle \\(\\mathscr{H}_0: p_{\\text{h}}=p_{\\text{f}},\\) contre hypothèse alternative \\(\\mathscr{H}_a: p_{\\text{h}}\\neq p_{\\text{f}}\\)).\nStatistique de test: (1) test du khi-deux pour les tableaux de contingence et (2) rapport de cotes.\nValeur-\\(p\\): (1) \\(.0010\\) et (2) \\(.0024\\) pour le test de permutation.\nConclusion: rejeter l’hypothèse nulle, car il existe des preuves d’une discrimination fondée sur le sexe, avec une probabilité de promotion différente pour les hommes et les femmes.\n\nConformément aux directives de l’APA, la statistique \\(\\chi^2\\) serait présentée sous la forme \\(\\chi^2(1, n = 93) = 10.79\\), \\(p = .001\\) en même temps que les effectifs et les proportions de l’échantillon.\n\n\nExemple 2.3 (L’élément de surprise d’une prise de contact inattendue) Liu et al. (2023) étudie les interactions sociales et l’impact de la surprise sur les personnes qui contactent de vieilles connaissances de manière inattendue. L’expérience 1 se concentre sur des questionnaires où la condition expérimentale est l’appréciation perçue du fait d’envoyer une communication à quelqu’un avec qui on n’a pas correspondu depuis longtemps (par opposition au fait de se faire contacter). L’étude a utilisé un questionnaire envoyé à 200 adultes américains recrutés sur la plateforme Prolific Academic. L’indice de réponse consiste en la moyenne de quatre questions mesurées sur une échelle de Likert allant de 1 à 7, les valeurs les plus élevées indiquant une plus grande appréciation de la prise de contact.\nNous pouvons commencer par examiner les statistiques sommaires des variables sociodémographiques (sexe et âge) afin d’évaluer si l’échantillon est représentatif de la population générale dans son ensemble. La proportion d’« autres » (comprenant les personnes non binaires) est beaucoup plus élevée que celle du recensement général, et la population est plutôt jeune selon Tableau 2.3.\n\n\n\n\nTableau 2.3: Statistiques descriptives de l’âge des participants, et décompte par genre.\n\n\n\n\n\n\ngenre\nmin\nmax\nmoyenne\nn\n\n\n\n\nhomme\n18\n78\n32.0\n105\n\n\nfemme\n19\n68\n36.5\n92\n\n\nautre\n24\n30\n27.7\n3\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTableau 2.4: Appréciation moyenne (écart-type), et nombre de participants par condition expérimentale.\n\n\n\n\n\n\nrôle\nmoyenne\nécart-type\nn\n\n\n\n\ninitiateur\n5.50\n1.28\n103\n\n\ndestinataire\n5.87\n1.27\n97\n\n\n\n\n\n\n\n\n\n\nComme il n’y a que deux groupes sans chevauchements (c’est à dire que les personnes ont un seul rôle), soit initiateur ou destinataire, le test logique à utiliser est un test-\\(t\\) pour deux échantillons indépendants, ou une variante de celui-ci. En utilisant la statistique du \\(t\\)-test de Welch, la moyenne et l’écart-type de chaque groupe sont estimés à l’aide des données fournies.\nLe logiciel renvoie comme valeur du test , ce qui conduit au rejet de l’hypothèse nulle d’absence de différence d’appréciation en fonction du rôle de l’individu (initiateur ou destinataire). La différence moyenne estimée est \\(\\Delta M = -0.37\\), 95% CI \\([-0.73, -0.01]\\); puisque \\(0\\) n’est pas inclus dans l’intervalle de confiance, nous rejetons également l’hypothèse nulle au niveau 5%. L’estimation suggère que les initiateurs sous-estiment l’importance de contacter de manière inattendue.4.\nRécapitulatif\n\nParamètres du modèle: score d’appréciation moyen \\(\\mu_{\\mathrm{i}}\\) et \\(\\mu_{\\mathrm{d}}\\) des initiateurs et des destinataires, respectivement.\nHypothèse: le score d’appréciation attendu est le même pour les initiateurs et les destinataires, \\(\\mathscr{H}_0: \\mu_{\\mathrm{i}}=\\mu_{\\mathrm{d}}\\) contre l’alternative \\(\\mathscr{H}_0: \\mu_{\\mathrm{i}} \\neq \\mu_{\\mathrm{r}}\\) qu’ils sont différents.\nStatistique de test: test-\\(t\\) de Welch pour deux échantillons indépendants\nValeur-\\(p\\): 0.041\nConclusion: rejet de l’hypothèse nulle, le score moyen d’appréciation diffère selon le rôle tenu.\n\n\n\nExemple 2.4 (Les communications virtuelles réduisent le nombre d’idées créatives) Une étude de Nature a réalisé une expérience pour voir comment les communications virtuelles impactent le travail d’équipe en comparant le nombre d’idées créatives générées par des binômes au cours d’une tempête d’idée, ainsi que leur qualité telle que mesurée par des arbitres externes. L’échantillon était composé de 301 paires de participants qui ont interagi par vidéoconférence ou en face à face.\nLes auteurs ont comparé le nombre d’idées créatives, un sous-ensemble d’idées générées avec un score de créativité supérieur à la moyenne. Le nombre moyen d’idées créatives pour le face à face est \\(7.92\\) idées (écart-type \\(3.40\\)), comparativement à \\(6.73\\) idées (écart-type¸ \\(3.27\\)) pour la vidéoconférence.\nBrucks et Levav (2022) a utilisé un modèle de régression binomiale négative: dans leur modèle, le nombre moyen d’idées créatives générées est \\[\\begin{align*}\n\\mathsf{E}(\\texttt{ncreative}) = \\exp(\\beta_0 + \\beta_1 \\texttt{video})\n\\end{align*}\\] où \\(\\texttt{video}=0\\) si la paire se trouve dans la même pièce et \\(\\texttt{video}=1\\) si elle interagit plutôt par vidéoconférence.\nLe nombre moyen d’idées pour la vidéoconférence est donc \\(\\exp(\\beta_1)\\) multiplié par celui du face à face: l’estimation du facteur multiplicatif est \\(\\exp(\\beta_1)\\) est \\(0.85\\) 95% CI \\([0.77, 0.94]\\).\nL’absence de différence entre les conditions expérimentales se traduit par l’hypothèse nulle \\(\\mathscr{H}_0: \\beta_1=0\\) vs \\(\\mathscr{H}_0: \\beta_1 \\neq 0\\) ou, de manière équivalente, \\(\\mathscr{H}_0: \\exp(\\beta_1)=1\\). Le test du rapport de vraisemblance comparant le modèle de régression avec et sans \\(\\texttt{video}\\) la statistique est \\(R=9.89\\) (valeur-\\(p\\) basée sur \\(\\chi^2_1\\) de \\(.002\\)). Nous concluons que le nombre moyen d’idées est différent, les statistiques sommaires suggérant que les paires virtuelles génèrent moins d’idées.\nSi nous avions eu recours à un test-\\(t\\) pour deux échantillons indépendants, nous aurions trouvé une différence moyenne dans le nombre d’idées créatives de \\(\\Delta M = 1.19\\), 95% CI \\([0.43, 1.95]\\), \\(t(299) = 3.09\\), \\(p = .002\\).\nLes deux tests reposent sur des hypothèses légèrement différentes, mais aboutissent à des conclusions similaires: il a de forts indices que le nombre d’idées créatives est plus faible lorsque les personnes interagissent par vidéoconférence.\n\n\nExemple 2.5 (Prix de billets de trains à grande vitesse espagnols) La compagnie nationale de chemin de fer Renfe gère les trains régionaux et les trains à haute vitesse dans toute l’Espagne. Les prix des billets vendus par Renfe sont aggrégés par une compagnie. On s’intéresse ici à une seule ligne, Madrid–Barcelone. Notre question scientifique est la suivante: est-ce que le prix des billets pour un aller (une direction) est plus chère pour un retour? Pour ce faire, on considère un échantillon de 10000 billets entre les deux plus grandes villes espagnoles. On s’intéresse au billets de TGV vendus (AVE) au tarif Promotionnel. Notre statistique de test sera simplement la différence de moyenne entre les deux échantillons: la différence entre le prix en euros d’un train Madrid–Barcelone (\\(\\mu_1\\)) et le prix d’un billet Barcelone–Madrid (\\(\\mu_2\\)) est \\(\\mu_1-\\mu_2\\) et notre hypothèse nulle est qu’il n’y a aucune différence de prix, soit \\(\\mathscr{H}_0: \\mu_1-\\mu_2=0.\\)\nOn utilise de nouveau le test de Welch pour deux échantillons en filtrant les données pour ne conserver que les billets au tarif Promo: la moyenne des billets Barcelone-Madrid est 82.11 euros, ceux pour Madrid-Barcelone 82.56 euros et la valeur de la statistique de Welch est -1.33. Si on utilise l’approximation normale, on obtient une valeur-\\(p\\) de 0.18.\nPlutôt que d’utiliser la loi asymptotique (qui est valide pour de grands échantillons à cause du théorème central limite), on peut considérer une approximation sous une hypothèse moins restrictive en supposant que les données sont échangeables. Sous l’hypothèse nulle, il n’y aucune différence entre les deux destinations et les étiquettes pour la destination (une variable catégorielle binaire) sont arbitraires. On pourrait considérer les mêmes données, mais avec une permutation des variables explicatives: c’est ce qu’on appelle un test de permutation. On va recréer deux groupes de taille identique à notre échantillon original, mais en changeant les observations. On recalcule la statistique de test sur ces nouvelle données (si on a une poignée d’observations, il est possible de lister toutes les permutations possibles; typiquement, il suffit de considérer un grand nombre de telles permutations, disons 9999). Pour chaque nouveau jeu de données, on calculera la statistique de test et on calculera le rang de notre statistique par rapport à cette référence. Si la valeur de notre statistique observée sur l’échantillon original est extrême en comparaison, c’est autant de preuves contre l’hypothèse nulle.\n\n\n\n\n\n\n\n\nFigure 2.11: Approximation par permutation de la loi nulle de la statistique de test de Welch (histogramme et trait noir) et loi asymptotique normale standard (trait bleu) pour le prix de billets de trains AVE au tarif promotionnel entre Madrid et Barcelone. La valeur de la statistique de test de l’échantillon original est représentée par un trait vertical.\n\n\n\n\n\nLa valeur-p du test de permutation, \\(0.186,\\) est la proportion de statistiques plus extrêmes que celle observée. Cette valeur-p est quasi-identique à celle de l’approximation de Satterthwaite, à savoir \\(0.182\\) (la loi Student-\\(t\\) est numériquement équivalente à une loi standard normale avec autant de degrés de liberté), tel que représenté dans la Figure 2.11. Malgré que notre échantillon soit très grand, avec \\(n=8059\\) observations, la différence n’est pas jugée significative. Avec un échantillon de deux millions de billets, on pourrait estimer précisément la moyenne (au centime près): la différence de prix entre les deux destinations et cette dernière deviendrait statistiquement significative. Elle n’est pas en revanche pas pertinente en partique, car une différence de \\(0.28\\) euros sur un prix moyen de \\(82.56\\) euros est quantité négligeable.\n\n\n\n\n\n\nBrucks, Melanie S., et Jonathan Levav. 2022. « Virtual communication curbs creative idea generation ». Nature 605 (7908): 108‑12. https://doi.org/10.1038/s41586-022-04643-y.\n\n\nLiu, Peggy J., SoYon Rim, Lauren Min, et Kate E. Min. 2023. « The surprise of reaching out: Appreciated more than we think. » Journal of Personality and Social Psychology 124 (4): 754‑71. https://doi.org/10.1037/pspi0000402.\n\n\nRosen, B., et T. H. Jerdee. 1974. « Influence of sex role stereotypes on personnel decisions. » Journal of Applied Psychology 59: 9‑14.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Inférence statistique</span>"
    ]
  },
  {
    "objectID": "inference.html#footnotes",
    "href": "inference.html#footnotes",
    "title": "2  Inférence statistique",
    "section": "",
    "text": "La formule montre que l’erreur standard diminue d’un facteur 10 chaque fois que la taille de l’échantillon augmente d’un facteur 100.↩︎\nSi vous avez suivi des cours de modélisation avancés, il s’agit d’un test de score obtenu en ajustant une régression de Poisson avec sexe et action comme covariables; l’hypothèse nulle correspondant à l’absence de terme d’interaction entre les deux.↩︎\nLa valeur p obtenue pour le test de permutation changerait d’une exécution à l’autre puisque les intrants sont aléatoires. Cependant, la précision de la statistique est suffisante pour la prise de décision↩︎\nEn supposant que la variance de chaque sous-groupe soit égale, nous aurions pu utiliser un \\(t\\)-test à deux échantillons à la place. La différence dans la conclusion est insignifiante, avec une valeur p presque égale↩︎",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Inférence statistique</span>"
    ]
  },
  {
    "objectID": "vraisemblance.html",
    "href": "vraisemblance.html",
    "title": "3  Inférence basée sur la vraisemblance",
    "section": "",
    "text": "3.1 Estimation par maximum de vraisemblance\nPour chaque valeur du paramètre \\(\\boldsymbol{\\theta},\\) on obtient une fonction de densité ou de masse pour les obserations qui varie en fonction de la compatibilité entre le modèle et les données recueillies. Cela nous permet d’obtenir une fonction objective pour l’estimation des paramètres\nSi nous supposons que notre modèle est correct, nous nous attendons à observer ce qui a été réalisé, et nous trouvons donc le vecteur de paramètres qui rend l’échantillon le plus susceptible d’avoir été généré par notre modèle. Plusieurs propriétés de l’estimateur du maximum de vraisemblance le rendent intéressant pour l’inférence. L’estimateur du maximum de vraisemblance est efficace, c’est-à-dire qu’il présente l’erreur quadratique moyenne asymptotique la plus faible de tous les estimateurs. L’estimateur du maximum de vraisemblance est également convergent, c’est-à-dire qu’il approche de la vraie valeur du paramètre inconnu à mesure que la taille de l’échantillon augmente (asymptotiquement sans biais).\nLa plupart du temps, nous allons recourir à des routines d’optimisation numérique pour trouver la valeur de l’estimation du maximum de vraisemblance, ou parfois dériver des expressions explicites pour l’estimateur, à partir de la log-vraisemblance. Le panneau de droite de Figure 3.1 montre la log-vraisemblance exponentielle, qui atteint un maximum à \\(\\widehat{\\lambda}=28.935\\) secondes, la moyenne de l’échantillon des observations. La fonction diminue de part et d’autre de ces valeurs à mesure que les données deviennent moins compatibles avec le modèle. Compte tenu de l’échelle pour la log-vraisemblance, ici pour un petit échantillon, il est facile de voir que l’optimisation directe de la fonction de vraisemblance (plutôt que de son logarithme naturel) pourrait conduire à un débordement numérique, puisque \\(\\exp(-270) \\approx 5.5 \\times 10^{-118},\\) et que les valeurs logarithmiques inférieures à \\(-746\\) seraient arrondies à zéro.\nLa propriété d’invariance explique l’utilisation répandue de l’estimation du maximum de vraisemblance. Par exemple, après avoir estimé le paramètre \\(\\lambda,\\) nous pouvons maintenant utiliser le modèle pour dériver d’autres quantités d’intérêt et obtenir les “meilleures” estimations gratuitement. Par exemple, nous pourrions calculer l’estimation du maximum de vraisemblance de la probabilité d’attendre plus d’une minute, \\(\\Pr(T&gt;60) = \\exp(-60/\\widehat{\\lambda})= 0.126.\\) On peut utiliser la fonction de répartition pexp dans R,\n# Note: la paramétrisation usuelle dans R pour la loi exponentielle\n# est en terme d'intensité (réciproque du paramètre d'échelle)\npexp(q = 60, rate = 1/mean(attente), lower.tail = FALSE)\n#&gt; [1] 0.126\nUn autre intérêt de la propriété d’invariance est la possibilité de calculer l’EMV dans la paramétrisation la plus simple, ce qui est pratique si le support est contraint. Si \\(g\\) est une fonction bijective de \\(\\boldsymbol{\\theta},\\) par exemple si \\(\\theta &gt;0,\\) maximiser le modèle paramétré en terme de \\(g(\\theta) = \\ln \\theta\\) ou de \\(g(\\theta) = \\ln(\\theta) - \\ln(1-\\theta) \\in \\mathbb{R}\\) si \\(0 \\leq \\theta \\leq 1,\\) élimine les contraintes pour l’optimisation numérique.\nLe modèle exponentiel peut s’avérer restrictif pour adéquatement capturer nos données, c’est pourquoi nous considérons une loi de Weibull comme généralisation.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Inférence basée sur la vraisemblance</span>"
    ]
  },
  {
    "objectID": "vraisemblance.html#estimation-par-maximum-de-vraisemblance",
    "href": "vraisemblance.html#estimation-par-maximum-de-vraisemblance",
    "title": "3  Inférence basée sur la vraisemblance",
    "section": "",
    "text": "Définition 3.1 (Vraisemblance) La vraisemblance \\(L(\\boldsymbol{\\theta})\\) est une fonction des paramètres \\(\\boldsymbol{\\theta}\\) qui donne la probabilité (ou densité) d’observer un échantillon selon une loi postulée, en traitant les observations comme fixes, \\[\\begin{align*}\nL(\\boldsymbol{\\theta}; \\boldsymbol{y}) = f(\\boldsymbol{y}; \\boldsymbol{\\theta}),\n\\end{align*}\\] où \\(f(\\boldsymbol{y}; \\boldsymbol{\\theta})\\) désigne la densité ou la fonction de masse conjointe du \\(n\\)-vecteur des observations.\nSi ces dernières sont indépendantes, la densité conjointe se factorise en un produit de densité unidimensionnelle pour chaque observation et la vraisemblance devient alors \\[\\begin{align*}\nL(\\boldsymbol{\\theta}; \\boldsymbol{y})=\\prod_{i=1}^n f_i(y_i; \\boldsymbol{\\theta}) = f_1(y_1; \\boldsymbol{\\theta}) \\times \\cdots \\times f_n(y_n; \\boldsymbol{\\theta}).\n\\end{align*}\\] La fonction de log-vraisemblance correspondante pour des données indépendantes et identiquement distribuées est \\[\\begin{align*}\n\\ell(\\boldsymbol{\\theta}; \\boldsymbol{y}) = \\sum_{i=1}^n \\ln f(y_i; \\boldsymbol{\\theta})\n\\end{align*}\\]\n\n\nExemple 3.2 (Données dépendantes) La fonction de densité conjointe ne se factorise que pour les données indépendantes, mais une décomposition séquentielle alternative peut s’avérer utile. Par exemple, nous pouvons écrire la densité conjointe \\(f(y_1, \\ldots, y_n)\\) en utilisant la factorisation \\[\\begin{align*}\nf(\\boldsymbol{y}) = f(y_1) \\times f(y_2 \\mid y_1) \\times \\ldots f(y_n \\mid y_1, \\ldots, y_n)\n\\end{align*}\\] en termes de densitées conditionnelles. Une telle décomposition est particulièrement utile pour les séries temporelles, où les données sont ordonnées du temps \\(1\\) au temps \\(n\\) et où les modèles relient généralement l’observation \\(y_n\\) à son passé. Par exemple, le processus \\(\\mathsf{AR}(1)\\) stipule que \\(Y_t \\mid Y_{t-1}=y_{t-1} \\sim \\mathsf{normale}(\\alpha + \\beta y_{t-1}, \\sigma^2)\\) et nous pouvons simplifier la log-vraisemblance en utilisant la propriété de Markov, qui stipule que la réalisation actuelle dépend du passé, \\(Y_t \\mid Y_1, \\ldots, Y_{t-1},\\) uniquement à travers la valeur la plus récente \\(Y_{t-1}\\). La log-vraisemblance devient donc \\[\\begin{align*}\n\\ell(\\boldsymbol{\\theta}) = \\ln f(y_1) + \\sum_{i=2}^n f(y_i \\mid y_{i-1}).\n\\end{align*}\\]\n\n\nDéfinition 3.2 (Estimateur du maximum de vraisemblance) L’estimateur du maximum de vraisemblance (EMV) \\(\\widehat{\\boldsymbol{\\theta}}\\) est la valeur du vecteur qui maximise la vraisemblance, \\[\\begin{align*}\n\\widehat{\\boldsymbol{\\theta}} = \\mathrm{arg max}_{\\boldsymbol{\\theta} \\in \\boldsymbol{\\Theta}} L(\\boldsymbol{\\theta}; \\boldsymbol{y}).\n\\end{align*}\\] Le logarithme naturel \\(\\ln\\) est une transformation monotone, il est donc préférable de calculer les EMV sur l’échelle logarithmique pour éviter les imprécisions numériques et maximiser de manière équivalente la log-vraisemblance \\(\\ell(\\boldsymbol{\\theta}; \\boldsymbol{y}) = \\ln L(\\boldsymbol{\\theta}; \\boldsymbol{y}).\\)2\n\n\n\n\nExemple 3.3 (Calcul de l’estimateur du maximum de vraisemblance d’une loi exponentielle) La Figure 3.1 révèle que la log-vraisemblance exponentielle est unimodale. Nous pouvons utiliser le calcul différentiel pour obtenir une expression explicite pour \\(\\widehat{\\lambda}\\) sur la base de la log-vraisemblance \\[\\begin{align*}\n\\ell(\\lambda) = -n \\ln\\lambda -\\frac{1}{\\lambda} \\sum_{i=1}^n y_i.\n\\end{align*}\\] Si on calcule la dérivée première et que l’on fixe cette dernière à zéro, on obtient \\[\\begin{align*}\n\\frac{\\mathrm{d} \\ell(\\lambda)}{\\mathrm{d} \\lambda}  = -\\frac{n}{\\lambda} + \\frac{1}{\\lambda^2} \\sum_{i=1}^n y_i = 0.\n\\end{align*}\\] En réarrangeant cette expression pour amener \\(-n/\\lambda\\) à droite de l’égalité, et en multipliant les deux côtés par \\(\\lambda^2&gt;0,\\) on obtient que le point d’inflexion se situe à \\(\\widehat{\\lambda} = \\sum_{i=1}^n y_i / n.\\) La dérivée deuxième de la log vraisemblance est \\(\\mathrm{d}^2 \\ell(\\lambda)/\\mathrm{d} \\lambda^2 = n(\\lambda^{-2} - 2\\lambda^{-3}\\overline{y}),\\) et si on évalue cette dernière à \\(\\lambda = \\overline{y}\\), on trouve une valeur négative, \\(-n/\\overline{y}^2.\\) Cela confirme que \\(\\widehat{\\lambda}\\) est la valeur où la fonction atteint son maximum.\n\n\nExemple 3.4 (Échantillons de loi normale) Supposons que nous disposions de \\(n\\) observations de loi normale de paramètres de moyenne \\(\\mu\\) et de variance \\(\\sigma^2\\), où \\(Y_i \\sim \\mathsf{normale}(\\mu, \\sigma^2)\\) sont indépendants. Rappelons que la densité de la loi normale est \\[\\begin{align*}\nf(y; \\mu, \\sigma^2)=\\frac{1}{(2\\pi \\sigma^2)^{1/2}}\\exp\\left\\{-\\frac{1}{2\\sigma^2}(x-\\mu)^2\\right\\}.\n\\end{align*}\\] Pour une réalisation \\(y_1, \\ldots, y_n\\) tirée d’un échantillon aléatoire simple, la vraisemblance est \\[\\begin{align*}\nL(\\mu, \\sigma^2; \\boldsymbol{y})=&\\prod_{i=1}^n\\frac{1}{({2\\pi \\sigma^2})^{1/2}}\\exp\\left\\{-\\frac{1}{2\\sigma^2}(y_i-\\mu)^2\\right\\}\\\\\n=&(2\\pi \\sigma^2)^{-n/2}\\exp\\left\\{-\\frac{1}{2\\sigma^2}\\sum_{i=1}^n(y_i-\\mu)^2\\right\\}.\n\\end{align*}\\] et la log-vraisemblance s’écrit \\[\\begin{align*}\n\\ell(\\mu, \\sigma^2; \\boldsymbol{y})=-\\frac{n}{2}\\ln(2\\pi) -\\frac{n}{2}\\ln(\\sigma^2)-\\frac{1}{2\\sigma^2}\\sum_{i=1}^n (y_i-\\mu)^2.\n\\end{align*}\\] On peut montrer que les estimateurs du maximum de vraisemblance pour les deux paramètres sont \\[\\begin{align*}\n\\widehat{\\mu}=\\overline{Y}=\\frac{1}{n} \\sum_{i=1}^n Y_i, \\qquad \\widehat{\\sigma}^2=\\frac{1}{n}\\sum_{i=1}^n (Y_i-\\overline{Y})^2.\n\\end{align*}\\]\nLe fait que l’estimateur de la moyenne théorique \\(\\mu\\) soit la moyenne de l’échantillon est assez intuitif et on peut montrer que l’estimateur est sans biais pour \\(\\mu\\). L’estimateur sans biais de la variance de l’échantillon est \\[\\begin{align*}\nS^2=\\frac{1}{n-1} \\sum_{i=1}^n (Y_i-\\overline{Y})^2.\n\\end{align*}\\] Puisque \\(\\widehat{\\sigma}^2=(n-1)/n S^2\\), il s’ensuit que l’estimateur du maximum de vraisemblance de \\(\\sigma^2\\) est biaisé, mais les deux estimateurs sont convergents et s’approcheront donc de la vraie valeur \\(\\sigma^2\\) pour \\(n\\) suffisamment grand.\n\n\nExemple 3.5 (Ordinary least squares) Le cas des données normalement distribuées est intimement lié à la régression linéaire et aux moindres carrés ordinaires : en supposant la normalité des erreurs, les estimateurs des moindres carrés de \\(\\boldsymbol{\\beta}\\) coïncident avec l’estimateur du maximum de vraisemblance de \\(\\boldsymbol{\\beta}\\).\nLe modèle de régression linéaire spécifie que \\(Y_i \\sim \\mathsf{normale}(\\mathbf{X}_i\\boldsymbol{\\beta}, \\sigma^2)\\), ou de manière équivalente \\[\\begin{align*}\nY_i=\\beta_0+\\beta_1 \\mathrm{X}_{i1}+\\beta_2 \\mathrm{X}_{i2}+\\ldots +\\beta_p \\mathrm{X}_{ip} + \\varepsilon_i, \\qquad  (i=1, \\ldots, n),\n\\end{align*}\\] avec des aléas \\(\\varepsilon_i \\sim \\mathsf{normale}(0, \\sigma^2)\\). Le modèle linéaire a \\(p+2\\) paramètres (\\(\\boldsymbol{\\beta}\\) et \\(\\sigma^2\\)) et la log-vraisemblance est \\[\\begin{align*}\n\\ell(\\boldsymbol{\\theta})&=-\\frac{n}{2} \\ln(2\\pi)-\\frac{n}{2} \\ln (\\sigma^2) -\\frac{1}{2\\sigma^2}\\left\\{(\\boldsymbol{y}-\\mathbf{X}\\boldsymbol{\\beta})^\\top(\\boldsymbol{y}-\\mathbf{X}\\boldsymbol{\\beta})\\right\\}^2.\n\\end{align*}\\] Maximiser la log-vraisemblance par rapport à \\(\\boldsymbol{\\beta}\\) équivaut à minimiser la somme des erreurs quadratiques \\(\\|\\boldsymbol{y} - \\widehat{\\boldsymbol{y}}\\|^2\\). Cette fonction objective étant la même que celle des moindres carrés, il s’ensuit que l’estimateur des moindres carrés \\(\\widehat{\\boldsymbol{\\beta}}\\) pour les paramètres de la moyenne est aussi l’estimateur du maximum de vraisemblance si les aléas ont la même variance \\(\\sigma^2\\), quelle que soit la valeur de cette dernière. L’estimateur du maximum de vraisemblance \\(\\widehat{\\sigma}^2\\) est donc \\[\\begin{align*}\n\\widehat{\\sigma}^2=\\max_{\\sigma^2} \\ell(\\widehat{\\boldsymbol{\\beta}}, \\sigma^2).\n\\end{align*}\\] La log-vraisemblance, en omettant tout terme ou constante qui n’est pas fonction de \\(\\sigma^2\\), est \\[\\begin{align*}\n\\ell(\\widehat{\\boldsymbol{\\beta}}, \\sigma^2)\n&\\propto-\\frac{1}{2}\\left\\{n\\ln\\sigma^2+\\frac{1}{\\sigma^2}(\\boldsymbol{y}-\\mathbf{X}\\hat{\\boldsymbol{\\beta}})^\\top(\\boldsymbol{y}-\\mathbf{X}\\hat{\\boldsymbol{\\beta}})\\right\\}.\n\\end{align*}\\] En différenciant chaque terme par rapport à \\(\\sigma^2\\) et en fixant le gradient à zéro, on obtient l’estimateur du maximum de vraisemblance \\[\\begin{align*}\n\\widehat{\\sigma}^2=\\frac{1}{n}(\\boldsymbol{Y}-\\mathbf{X}\\hat{\\boldsymbol{\\beta}})^\\top(\\boldsymbol{Y}-\\mathbf{X}\\hat{\\boldsymbol{\\beta}})= \\frac{1}{n} \\sum_{i=1}^n e_i^2= \\frac{\\mathsf{SS}_e}{n};\n\\end{align*}\\] où \\(\\mathsf{SS}_e\\) est la somme des carrés des résidus. L’estimateur sans biais habituel de \\(\\sigma^2\\) calculé par le logiciel est \\(S^2=\\mathsf{SS}_e/(n-p-1)\\), où le dénominateur est la taille de l’échantillon \\(n\\) moins le nombre de paramètres de la moyenne \\(\\boldsymbol{\\beta}\\), soit \\(p+1\\).\n\n\nProposition 3.1 (Invariance des estimateurs du maximum de vraisemblance) Si \\(g(\\boldsymbol{\\theta}): \\mathbb{R}^p \\mapsto \\mathbb{R}^k\\) pour \\(k \\leq p\\) est une fonction des paramètres, alors \\(g(\\widehat{\\boldsymbol{\\theta}})\\) est l’estimateur du maximum de vraisemblance de cette fonction.\n\n\n\n\n\nDéfinition 3.3 (Score et information) Soit \\(\\ell(\\boldsymbol{\\theta}),\\) \\(\\boldsymbol{\\theta} \\in \\boldsymbol{\\Theta} \\subseteq \\mathbb{R}^p,\\) la fonction de log-vraisemblance. Le gradient (ou vecteur de dérivée première) de la log-vraisemblance \\(U(\\boldsymbol{\\theta}) = \\partial \\ell(\\boldsymbol{\\theta}) / \\partial \\boldsymbol{\\theta}\\) est appelé fonction de score.\nL’‘information observée** est la hessienne (matrice de dérivée deuxième) du négatif de la log-vraisemblance \\[\\begin{align*}\nj(\\boldsymbol{\\theta}; \\boldsymbol{y})=-\\frac{\\partial^2 \\ell(\\boldsymbol{\\theta}; \\boldsymbol{y})}{\\partial \\boldsymbol{\\theta} \\partial \\boldsymbol{\\theta}^\\top}.\n\\end{align*}\\] En pratique, on évalue cette fonction à l’estimation du maximum de vraisemblance \\(\\widehat{\\boldsymbol{\\theta}},\\) d’où le terme information observée pour désigner plutôt \\(j(\\widehat{\\boldsymbol{\\theta}}).\\) Sous des conditions de régularité, l’information de Fisher** est \\[\\begin{align*}\ni(\\boldsymbol{\\theta}) = \\mathsf{E}\\left\\{U(\\boldsymbol{\\theta}; \\boldsymbol{Y}) U(\\boldsymbol{\\theta}; \\boldsymbol{Y})^\\top\\right\\} = \\mathsf{E}\\left\\{j(\\boldsymbol{\\theta}; \\boldsymbol{Y})\\right\\}\n\\end{align*}\\] La différence est qu’on prend l’espérance de chaque fonction des observations à l’intérieur des entrées de la matrice. Quand elle évaluée au point \\(\\widehat{\\boldsymbol{\\theta}}\\), l’information de Fisher mesure la variance du score, ou la courbure de ce dernier. La matrice de Fisher et la matrice d’information sont toutes deux symmétriques.\n\n\nExemple 3.6 (Information pour le modèle exponentiel) L’information de Fisher et observée pour un échantillon aléatoire simple du modèle exponentiel, \\(Y_1, \\ldots, Y_n,\\), paramétré en terme d’échelle \\(\\lambda,\\) est \\[\\begin{align*}\nj(\\lambda; \\boldsymbol{y}) &= -\\frac{\\partial^2 \\ell(\\lambda)}{\\partial \\lambda^2} = \\frac{n}{\\lambda^{2}} + \\frac{2}{n\\lambda^{3}}\\sum_{i=1}^n y_i \\\\\ni(\\lambda) &= \\frac{n}{\\lambda^{2}} + \\frac{2}{n\\lambda^{3}}\\sum_{i=1}^n \\mathsf{E}(Y_i)  = \\frac{n}{\\lambda^{2}}\n\\end{align*}\\] puisque \\(\\mathsf{E}(Y_i) = \\lambda\\) et que l’espérance est un opérateur linéaire. On trouve que \\(i(\\widehat{\\lambda}) = j(\\widehat{\\lambda}) = n/\\overline{y}^2\\), mais cette égalité ne tient qu’à l’EMV.\n\n\n\nDéfinition 3.4 (Loi de Weibull) La fonction de répartition d’une variable aléatoire de loi Weibull, de paramètres d’échelle \\(\\lambda&gt;0\\) et de forme \\(\\alpha&gt;0\\) est \\[\\begin{align*}\nF(x; \\lambda, \\alpha) &= 1 - \\exp\\left\\{-(x/\\lambda)^\\alpha\\right\\}, \\qquad x \\geq 0, \\lambda&gt;0, \\alpha&gt;0,\n\\end{align*}\\] alors que sa densité est \\[\\begin{align*}\nf(x; \\lambda, \\alpha) &= \\frac{\\alpha}{\\lambda^\\alpha} x^{\\alpha-1}\\exp\\left\\{-(x/\\lambda)^\\alpha\\right\\}, \\qquad x \\geq 0, \\lambda&gt;0, \\alpha&gt;0.\n\\end{align*}\\] La fonction quantile, qui est l’inverse de la fonction de répartition, est \\(Q(p) = \\lambda\\{-\\ln(1-p)\\}^{1/\\alpha}.\\) La loi Weibull inclut la loi exponentielle comme cas spécial quand \\(\\alpha=1.\\) L’espérance de \\(Y \\sim \\mathsf{Weibull}(\\lambda, \\alpha)\\) est \\(\\mathsf{E}(Y) = \\lambda \\Gamma(1+1/\\alpha).\\)\n\n\nExemple 3.7 (Score et information d’une loi Weibull) La log-vraisemblance d’un échantillon aléatoire simple de taille \\(n\\) dont la réalisation est dénotée \\(y_1, \\ldots, y_n\\), tirée d’une loi \\(\\mathsf{Weibull}(\\lambda, \\alpha)\\), est \\[\\begin{align*}\n\\ell(\\lambda, \\alpha) = n \\ln(\\alpha) - n\\alpha\\ln(\\lambda) + (\\alpha-1) \\sum_{i=1}^n \\ln y_i  - \\lambda^{-\\alpha}\\sum_{i=1}^n y_i^\\alpha.\n\\end{align*}\\] Le gradient de cette fonction est3 \\[\\begin{align*}\nU(\\lambda, \\alpha) = \\begin{pmatrix}\\frac{\\partial \\ell(\\lambda, \\alpha)}{\\partial \\lambda} \\\\\n\\frac{\\partial \\ell(\\lambda, \\alpha)}{\\partial \\alpha} \\end{pmatrix} &=\n\\begin{pmatrix}\n-\\frac{n\\alpha}{\\lambda} +\\alpha\\lambda^{-\\alpha-1}\\sum_{i=1}^n y_i^\\alpha\n\\\\\n\\frac{n}{\\alpha} - n \\ln(\\lambda) + \\sum_{i=1}^n \\ln y_i  - \\sum_{i=1}^n \\left(\\frac{y_i}{\\lambda}\\right)^{\\alpha} \\times\\ln\\left(\\frac{y_i}{\\lambda}\\right).\n\\end{pmatrix}\n\\end{align*}\\] et l’information observée est \\[\\begin{align*}\nj(\\lambda, \\alpha) &= - \\begin{pmatrix}\n\\frac{\\partial^2 \\ell(\\lambda, \\alpha)}{\\partial \\lambda^2} &  \\frac{\\partial^2 \\ell(\\lambda, \\alpha)}{\\partial \\lambda \\partial \\alpha} \\\\ \\frac{\\partial^2 \\ell(\\lambda, \\alpha)}{\\partial \\alpha \\partial \\lambda} & \\frac{\\partial^2 \\ell(\\lambda, \\alpha)}{\\partial \\alpha^2}\n\\end{pmatrix}\n\\\\&= \\begin{pmatrix}\n\\lambda^{-2}\\left\\{-n\\alpha + \\alpha(\\alpha+1)\\sum_{i=1}^n (y_i/\\lambda)^2\\right\\} & \\lambda^{-1}\\sum_{i=1}^n [1-(y_i/\\lambda)^\\alpha\\{1+\\alpha\\ln(y_i/\\lambda)\\}]\\\\ \\lambda^{-1}\\sum_{i=1}^n [1-(y_i/\\lambda)^\\alpha\\{1+\\alpha\\ln(y_i/\\lambda)\\}]& n\\alpha^{-2} + \\sum_{i=1}^n (y_i/\\lambda)^\\alpha \\{\\ln(y_i/\\theta)\\}^2\n\\end{pmatrix}\n\\end{align*}\\]\n\n\nProposition 3.2 (Optimisation basée sur le gradient) Pour obtenir l’estimateur du maximum de vraisemblance, nous trouverons généralement la valeur du vecteur \\(\\boldsymbol{\\theta}\\) qui résout le vecteur de score, c’est-à-dire \\(U(\\widehat{\\boldsymbol{\\theta}})=\\boldsymbol{0}_p.\\) Cela revient à résoudre simultanément un système de \\(p\\) équations en fixant à zéro la dérivée première par rapport à chaque élément de \\(\\boldsymbol{\\theta}\\). Si \\(j(\\widehat{\\boldsymbol{\\theta}})\\) est une matrice définie positive (c’est-à-dire que toutes ses valeurs propres sont positives), alors le vecteur \\(\\widehat{\\boldsymbol{\\theta}}\\) maximise la fonction de log-vraisemblance et est l’estimateur du maximum de vraisemblance.\nNous pouvons utiliser une variante de l’algorithme de Newton–Raphson si la vraisemblance est trois fois différentiable et si l’estimateur du maximum de vraisemblance ne se trouve pas sur la frontière de l’espace des paramètres. Si nous considérons une valeur initiale \\(\\boldsymbol{\\theta}^{\\dagger},\\) alors une expansion en série de Taylor du premier ordre de la vraisemblance du score dans un voisinage \\(\\boldsymbol{\\theta}^{\\dagger}\\) de l’EMV \\(\\widehat{\\boldsymbol{\\theta}}\\) donne \\[\\begin{align*}\n\\boldsymbol{0}_p & = U(\\widehat{\\boldsymbol{\\theta}}) \\stackrel{\\cdot}{\\simeq} \\left.\n\\frac{\\partial \\ell(\\boldsymbol{\\theta})}{\\partial \\boldsymbol{\\theta}} \\right|_{\\boldsymbol{\\theta} = \\boldsymbol{\\theta}^{\\dagger}} + \\left.\n\\frac{\\partial^2 \\ell(\\boldsymbol{\\theta})}{\\partial \\boldsymbol{\\theta} \\partial \\boldsymbol{\\theta}^\\top}\\right|_{\\boldsymbol{\\theta} = \\boldsymbol{\\theta}^{\\dagger}}(\\widehat{\\boldsymbol{\\theta}} - \\boldsymbol{\\theta}^{\\dagger})\\\\&=U(\\boldsymbol{\\theta}^{\\dagger}) - j(\\boldsymbol{\\theta}^{\\dagger})(\\widehat{\\boldsymbol{\\theta}} - \\boldsymbol{\\theta}^{\\dagger}).\n\\end{align*}\\] En réarrangeant cette expression pour isoler \\(\\widehat{\\boldsymbol{\\theta}}\\) (pourvu que la matrice \\(p \\times p\\) d’information observée \\(j(\\widehat{\\boldsymbol{\\theta}})\\) soit inversible à l’EMV), on obtient \\[\\begin{align*}\n\\widehat{\\boldsymbol{\\theta}} \\stackrel{\\cdot}{\\simeq} \\boldsymbol{\\theta}^{\\dagger} +\nj^{-1}(\\boldsymbol{\\theta}^{\\dagger})U(\\boldsymbol{\\theta}^{\\dagger}).\n\\end{align*}\\] Cela suggère l’utilisation d’une procédure itérative: à partir d’une valeur de départ \\(\\boldsymbol{\\theta}^{\\dagger}\\) dans le voisinage du mode, on applique le schéma de mise à jour jusqu’à ce que le gradient soit approximativement nul. Si la valeur est éloignée du mode, l’algorithme peut diverger. Pour éviter cela, nous pouvons multiplier le terme \\(j^{-1}(\\boldsymbol{\\theta}^{\\dagger})U(\\boldsymbol{\\theta}^{\\dagger})\\) par un facteur d’amortissement \\(c&lt;1\\). Une variante de l’algorithme, appelée score de Fisher, utilise l’information de Fisher \\(i(\\boldsymbol{\\theta})\\) au lieu de l’information observée, \\(j(\\boldsymbol{\\theta}),\\) pour des raisons de stabilité numérique et pour éviter les situations où cette dernière n’est pas définie positive. Il s’agit de la routine d’optimisation utilisée dans la fonction glm de R.\n\n\n\nExemple 3.8 (Estimateurs du maximum de vraisemblance d’un échantillon Weibull) Nous nous tournons vers l’optimisation numérique pour obtenir l’estimation du maximum de vraisemblance de la loi de Weibull, en l’absence formule explicite pour les EMV. À cette fin, il faut écrire une fonction qui encodent la log-vraisemblance, ici la somme des contributions de la log-densité. La fonction nll_weibull ci-dessous prend comme premier argument le vecteur de paramètres, pars, et renvoie la valeur négative de la log-vraisemblance que nous souhaitons minimiser4. Nous codons également le gradient, bien que nous puissions recourir à la différenciation numérique. Nous utilisons ensuite optim, la routine d’optimisation par défaut de R, pour minimiser nll_weibull. La fonction renvoie une liste contenant un code de convergence (0 indiquant la convergence), les EMV dans par, la log-vraisemblance \\(\\ell(\\widehat{\\boldsymbol{\\theta}})\\) et la hessienne, qui est la matrice d’information observée évaluée à \\(\\widehat{\\boldsymbol{\\theta}}.\\) La surface de log-vraisemblance, pour les paires de vecteurs d’échelle et de forme \\(\\boldsymbol{\\theta} = (\\lambda, \\alpha),\\) est représentée dans la Figure 3.3. Nous pouvons voir que l’algorithme a convergé vers le maximum de vraisemblance et vérifier que le score satisfait \\(U(\\widehat{\\boldsymbol{\\theta}}) = 0\\) à la valeur optimale retournée.\n\n\nCode\n# Charger les données\ndata(attente, package = \"hecstatmod\")\n\n# Négatif de la log vraisemblance pour un échantillon Weibull\nnll_weibull &lt;- function(pars, y) {\n  # Gérer le cas de paramètres négatifs (impossible)\n  if (isTRUE(any(pars &lt;= 0))) {\n    return(1e10) # retourner une valeur large finie (pour éviter les messages d'avertissement)\n  }\n  - sum(dweibull(\n    x = y,\n    scale = pars[1],\n    shape = pars[2],\n    log = TRUE\n  ))\n}\n# Gradient du négatif de la fonction de log vraisemblance Weibull\ngr_nll_weibull &lt;- function(pars, y) {\n  scale &lt;- pars[1]\n  shape &lt;- pars[2]\n  n &lt;- length(y)\n  grad_ll &lt;- c(\n    scale = -n * shape / scale + shape * scale^(-shape - 1) * sum(y^shape),\n    shape = n / shape - n * log(scale) + sum(log(y)) -\n      sum(log(y / scale) * (y / scale)^shape)\n  )\n  return(-grad_ll)\n}\n\n# Utiliser les EMV du modèle exponentiel pour l'initialisation\nvalinit &lt;- c(mean(attente), 1)\n# Vérifier préalablement que le gradient est correct!\n# La commande retourne TRUE si la dérivée numérique égale sa version analytique à tolérance donnée\nisTRUE(all.equal(\n  numDeriv::grad(nll_weibull, x = valinit, y = attente),\n  gr_nll_weibull(pars = valinit, y = attente),\n  check.attributes = FALSE\n))\n#&gt; [1] TRUE\n# Optimisation numérique avec optim\nopt_weibull &lt;- optim(\n  par = valinit,\n  # valeurs initiales\n  fn = nll_weibull,\n  # passer la fonction à optimiser, son premier argument doit être le vecteur de paramètres\n  gr = gr_nll_weibull,\n  # gradient (optionnel)\n  method = \"BFGS\",\n  # algorithme BFGS est basé sur le gradient, une alternative robuste est\"Nelder\"\n  y = attente,\n  # vecteur d'observations passées en argument additionnel à \"fn\"\n  hessian = TRUE # retourner la matrice de dérivée secondes évaluée aux EMV\n) \n# Alternative avec un Newton\n# nlm(f = nll_weibull, p = valinit, hessian = TRUE, y = attente)\n# Estimations du maximum de vraisemblance\n(mle_weibull &lt;- opt_weibull$par)\n#&gt; [1] 32.6  2.6\n# Vérifier la convergence numérique à l'aide du gradient\ngr_nll_weibull(mle_weibull, y = attente)\n#&gt;     scale     shape \n#&gt; 0.0000142 0.0001136\n# Vérifier que la hessienne est positive définite\n# Toutes les valeurs propres sont positives\n# Si oui, on a trouvé un maximum et la matrice est invertible\nisTRUE(all(eigen(opt_weibull$hessian)$values &gt; 0))\n#&gt; [1] TRUE",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Inférence basée sur la vraisemblance</span>"
    ]
  },
  {
    "objectID": "vraisemblance.html#loi-déchantillonage",
    "href": "vraisemblance.html#loi-déchantillonage",
    "title": "3  Inférence basée sur la vraisemblance",
    "section": "3.2 Loi d’échantillonage",
    "text": "3.2 Loi d’échantillonage\nLa loi d’échantillonnage d’un estimateur \\(\\widehat{\\boldsymbol{\\theta}}\\) est la loi de probabilité induite par les données aléatoires sous-jacentes.\nSupposons que nous disposons d’un échantillon aléatoire simple, de sorte que la log-vraisemblance est constitutée d’une somme de \\(n\\) termes et que l’information s’accumule linéairement avec la taille de l’échantillon. Nous dénotons la vraie valeur du vecteur de paramètres inconnu \\(\\boldsymbol{\\theta}_0.\\) Sous des conditions de régularité appropriées, cf. section 4.4.2 de Davison (2003), pour un échantillon de grande taille \\(n,\\) nous pouvons effectuer une série de Taylor du score et appliquer le théorème de la limite centrale à la moyenne résultante puisque \\(U(\\boldsymbol{\\theta})\\) et \\(i(\\boldsymbol{\\theta})\\) sont la somme de \\(n\\) variables aléatoires indépendantes, et que \\(\\mathsf{E}\\{U(\\boldsymbol{\\theta})\\}=\\boldsymbol{0}_p,\\) et \\(\\mathsf{Var}\\{U(\\boldsymbol{\\theta})\\}=i(\\boldsymbol{\\theta}),\\) l’application du théorème de la limite centrale et de la loi des grands nombres donne \\[\\begin{align*}\ni(\\boldsymbol{\\theta}_0)^{-1/2}U(\\boldsymbol{\\theta}_0) \\stackrel{\\cdot}{\\sim}\\mathsf{normale}_p(\\boldsymbol{0}, \\mathbf{I}_p).\n\\end{align*}\\] \nOn peut utiliser ce résultat pour obtenir une approximation à la loi d’échantillonage des estimateurs du maximum de vraisemblance de \\(\\widehat{\\boldsymbol{\\theta}},\\) \\[\\begin{align*}\n\\widehat{\\boldsymbol{\\theta}} \\stackrel{\\cdot}{\\sim} \\mathsf{normale}_p\\{\\boldsymbol{\\theta}_0, i^{-1}(\\boldsymbol{\\theta})\\}\n\\end{align*}\\] ou la matrice de covariance est l’inverse de l’information de Fisher. En pratique, puisque la valeur des paramètres \\(\\boldsymbol{\\theta}_0\\) est inconnue, on remplace la covariance soit par \\(i^{-1}(\\widehat{\\boldsymbol{\\theta}})\\) ou par l’inverse de l’information observée, \\(j^{-1}(\\widehat{\\boldsymbol{\\theta}}).\\) Cela est justifié par le fait que les deux matrices d’informations \\(i(\\widehat{\\boldsymbol{\\theta}})\\) et \\(j(\\widehat{\\boldsymbol{\\theta}})\\) convergent vers \\(i(\\boldsymbol{\\theta})\\) quand \\(n \\to \\infty\\).\nAu fur et à mesure que la taille de l’échantillon augmente, l’estimateur du maximum de vraisemblance \\(\\widehat{\\boldsymbol{\\theta}}\\) devient centré autour de la valeur \\(\\boldsymbol{\\theta}_0\\) qui minimise l’écart entre le modèle et le véritable processus de génération des données. Dans les grands échantillons, la loi d’échantillonnage de l’estimateur du maximum de vraisemblance est approximativement quadratique.\n\n\nExemple 3.9 (Matrice de covariance et erreurs-type pour le modèle de Weibull) Nous utilisons la sortie de notre procédure d’optimisation pour obtenir la matrice d’information observée et les erreurs-type pour les paramètres du modèle de Weibull. Ces dernières sont simplement la racine carrée des entrées diagonales de l’information observée évaluée aux EMV, \\([\\mathrm{diag}\\{j^{-1}(\\widehat{\\boldsymbol{\\theta}})\\}]^{1/2}\\).\n\n# La hessienne du négatif de la log vraisemblance, évaluée aux EMV\n# est la matrice d'information observée\nobsinfo_weibull &lt;- opt_weibull$hessian\nvmat_weibull &lt;- solve(obsinfo_weibull)\n# Erreurs-type\nse_weibull &lt;- sqrt(diag(vmat_weibull))\n\n\nUne fois que l’on a les estimations du maximum de vraisemblance et les erreurs-type, on peut dériver des intervalles de confiance ponctuels de Wald pour les paramètres de \\(\\boldsymbol{\\theta}.\\) Si la quantité d’intérêt est une transformation des paramètres du modèle, on peut utiliser le résultat suivant pour procéder.\n\nProposition 3.3 (Normalité asymptotique et transformations) Le résultat de normalité asymptotique peut être utilisé pour dériver les erreurs standard pour d’autres quantités d’intérêt. Si \\(\\phi = g(\\boldsymbol{\\theta})\\) est une fonction différentiable de \\(\\boldsymbol{\\theta}\\) dont le gradient est non-nul lorsque évalué à \\(\\widehat{\\boldsymbol{\\theta}}\\), alors \\(\\widehat{\\phi} \\stackrel{\\cdot}{\\sim}\\mathsf{normale}(\\phi_0, \\mathrm{V}_\\phi),\\) with \\(\\mathrm{V}_\\phi = \\nabla \\phi^\\top \\mathbf{V}_{\\boldsymbol{\\theta}} \\nabla \\phi,\\) où \\(\\nabla \\phi=[\\partial \\phi/\\partial \\theta_1, \\ldots, \\partial \\phi/\\partial \\theta_p]^\\top.\\) La matrice de covariance et le gradient sont évalués aux estimations du maximum de vraisemblance \\(\\widehat{\\boldsymbol{\\theta}}.\\) Ce résultat se généralise aux fonctions vectorielles \\(\\boldsymbol{\\phi} \\in \\mathbb{R}^k\\) pour \\(k \\leq p,\\) où \\(\\nabla \\phi\\) est la jacobienne de la transformation.\n\n\nExemple 3.10 (Probabilité d’attente pour un modèle exponentiel.) Considérons les données sur le temps d’attente dans le métro et la probabilité d’attendre plus d’une minute, \\(\\phi=g(\\lambda) = \\exp(-60/\\lambda).\\) L’estimation du maximum de vraisemblance est, par invariance, \\(0.126\\) et le gradient de \\(g\\) par rapport au paramètre d’échelle est \\(\\nabla \\phi = \\partial \\phi / \\partial \\lambda = 60\\exp(-60/\\lambda)/\\lambda^2.\\)\n\n# Exemple de dérivation des erreurs-type pour une\n# transformation des paramètres\n# Ici, on calcule Pr(Y&gt;60) selon le modèle exponentiel\nlambda_hat &lt;- mean(attente)\n# Définir la fonction d'intérêt\nphi_hat &lt;- exp(-60 / lambda_hat)\n# jacobien de la transformation\ndphi &lt;- function(lambda) {\n  60 * exp(-60 / lambda) / (lambda^2)\n}\n# variance du paramètre exponentiel\nV_lambda &lt;- lambda_hat^2 / length(attente)\n# variance de Pr(Y&gt;60) via la méthode delta\nV_phi &lt;- dphi(lambda_hat)^2 * V_lambda\n# extraire et imprimer les erreurs-type\n(se_phi &lt;- sqrt(V_phi))\n#&gt; [1] 0.0331",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Inférence basée sur la vraisemblance</span>"
    ]
  },
  {
    "objectID": "vraisemblance.html#testsvrais",
    "href": "vraisemblance.html#testsvrais",
    "title": "3  Inférence basée sur la vraisemblance",
    "section": "3.3 Tests dérivés de la vraisemblance",
    "text": "3.3 Tests dérivés de la vraisemblance\nNous considérons une hypothèse nulle \\(\\mathscr{H}_0\\) qui impose des restrictions sur les valeurs possibles de \\(\\boldsymbol{\\theta}\\), par rapport à une alternative sans contrainte \\(\\mathscr{H}_1.\\) Nous avons besoin de deux modèles emboîtés : un modèle complet et un modèle réduit, pour lequel l’espace des paramèteres est un sous-ensemble du modèle complet suite à l’imposition des \\(q\\) restrictions. Par exemple, la loi exponentielle est un cas particulier de la loi de Weibull si \\(\\alpha=1\\).\nL’hypothèse nulle \\(\\mathscr{H}_0\\) testée est “le modèle réduit est une simplification adéquate du modèle complet”. Soit \\(\\widehat{\\boldsymbol{\\theta}}_0\\) les EMV contraints pour le modèle sous l’hypothèse nulle, et \\(\\widehat{\\boldsymbol{\\theta}}\\) les EMV du modèle complet. La vraisemblance fournit trois classes principales de statistiques pour tester cette hypothèse, soit\n\nles statistiques des tests du rapport de vraisemblance, notées \\(R,\\) qui mesurent la différence de log vraisemblance (distance verticale) entre \\(\\ell(\\widehat{\\boldsymbol{\\theta}})\\) et \\(\\ell(\\widehat{\\boldsymbol{\\theta}}_0).\\)\nles statistiques des tests de Wald, notées \\(W,\\) qui considèrent la distance horizontale normalisée entre \\(\\widehat{\\boldsymbol{\\theta}}\\) et \\(\\widehat{\\boldsymbol{\\theta}}_0.\\)\nles statistiques des tests de score de Rao, notées \\(S,\\) qui examinent le gradient repondéré de \\(\\ell,\\) évaluée uniquement à \\(\\widehat{\\boldsymbol{\\theta}}_0\\).\n\n\n\n\n\n\n\n\n\nFigure 3.2: Fonction de log vraisemblance et illustrations des éléments des statistique du score, de Wald et du rapport de vraisemblance.\n\n\n\n\n\nLes trois principales classes de statistiques permettant de tester une hypothèse nulle simple \\(\\mathscr{H}_0 : \\boldsymbol{\\theta}=\\boldsymbol{\\theta}_0\\) par rapport à l’hypothèse alternative \\(\\mathscr{H}_a : \\boldsymbol{\\theta} \\neq \\boldsymbol{\\theta}_0\\) sont \\[\\begin{align*}\nW(\\boldsymbol{\\theta}_0) &= (\\widehat{\\boldsymbol{\\theta}}-\\boldsymbol{\\theta}_0)^\\top j(\\widehat{\\boldsymbol{\\theta}})(\\widehat{\\boldsymbol{\\theta}}-\\boldsymbol{\\theta}_0), &&(\\text{Wald}) \\\\\nR(\\boldsymbol{\\theta}_0) &= 2 \\left\\{ \\ell(\\widehat{\\boldsymbol{\\theta}})-\\ell(\\boldsymbol{\\theta}_0)\\right\\}, &&(\\text{rapport de vraisemblance})\\\\\nS(\\boldsymbol{\\theta}_0) &= U^\\top(\\boldsymbol{\\theta}_0)i^{-1}(\\boldsymbol{\\theta}_0)U(\\boldsymbol{\\theta}_0), && (\\text{score})\n\\end{align*}\\] où \\(\\boldsymbol{\\theta}_0\\) est la valeur nulle postulée du paramètre avec \\(q\\) restrictions. Si \\(q \\neq p\\), alors on remplace \\(\\boldsymbol{\\theta}_0\\) par l’estimation contrainte \\(\\widehat{\\boldsymbol{\\theta}}_0\\).\nAsymptotiquement, toutes les statistiques de test sont équivalentes (dans le sens où elles conduisent aux mêmes conclusions sur \\(\\mathscr{H}_0\\)), mais elles ne sont pas identiques. Sous \\(\\mathscr{H}_0\\), les trois statistiques de test suivent une loi asymptotique \\(\\chi^2_q\\), où les degrés de liberté \\(q\\) indiquent le nombre de restrictions.\nSi \\(\\theta\\) est un scalaire (cas \\(q=1\\)), des versions directionnelles de ces statistiques existent, \\[\\begin{align*}\nw(\\theta_0)&=(\\widehat{\\theta}-\\theta_0)/\\mathsf{se}(\\widehat{\\theta}) &&(\\text{Wald}) \\\\\nr({\\theta_0}) &= \\mathrm{sign}(\\widehat{\\theta}-\\theta)\\left[2\n\\left\\{\\ell(\\widehat{\\theta})-\\ell(\\theta)\\right\\}\\right]^{1/2} &&(\\text{racine directionnelle de vraisemblance}) \\\\\ns(\\theta_0)&=i^{-1/2}(\\theta_0)U(\\theta_0) &&(\\text{score})\n\\end{align*}\\]\nSous cette forme, si l’hypothèse nulle \\(\\mathscr{H}_0: \\theta = \\theta_0\\) est vraie, alors \\(w(\\theta_0)\\stackrel{\\cdot}{\\sim} \\mathsf{normale}(0,1)\\), etc.\nLa statistique du test du rapport de vraisemblance est normalement la plus puissante des trois tests (et donc préférable selon ce critère); la statistique est aussi invariante aux reparamétrages. La statistique de score \\(S\\), moins utilisée, nécessite le calcul du score et de l’information de Fisher, mais n’est évaluée que sous \\(\\mathscr{H}_0\\) (car par définition \\(U(\\widehat{\\theta})=0\\)), elle peut donc être utile dans les problèmes où les calculs de l’estimateur du maximum de vraisemblance sous l’alternative sont coûteux ou impossibles. Le test de Wald est le plus facile à dériver, mais son taux de couverture empirique peut laisser à désirer si la loi d’échantillonnage de \\(\\widehat{\\boldsymbol{\\theta}}\\) est fortement asymétrique.\n\n\n\n\n\n\n\n\nFigure 3.3: Log-vraisemblance profilée pour \\(\\alpha\\), représentée par un trait gris traitillé (gauche) et par une coupe transversale (droite). Le panneau de gauche montre la surface de log-vraisemblance pour le modèle de Weibull avec des régions de confiance de 10%, 20%, , 90% du rapport de vraisemblance (courbes de contour blanches). Les valeurs de log vraisemblance les plus élevées sont indiquées par des couleurs plus foncées, et la valeur des estimations du maximum de vraisemblance par une croix. La vraisemblance profilée du panneau de droite a été décalée verticalement pour que sa valeur maximale soit zéro; les lignes horizontales traitillées indiquent les valeurs pour les intervalles de confiance à 95% et 99%.\n\n\n\n\n\nLa statistique de Wald \\(W\\) est la plus courante. Les intervalles de confiance bilatéraux de niveau \\((1-\\alpha)\\) de Wald pour les paramètres de \\(\\boldsymbol{\\theta}\\), où pour \\(\\theta_j\\) \\((j=1, \\ldots, p)\\), \\[\\begin{align*}\n\\widehat{\\theta}_j \\pm \\mathfrak{z}_{1-\\alpha/2}\\mathrm{se}(\\widehat{\\theta}_j),\n\\end{align*}\\] avec \\(\\mathfrak{z}_{1-\\alpha/2}\\) le quantile \\(1-\\alpha/2\\) d’une loi normale standard. Pour un intervalle à 95%, le \\(0.975\\) quantile vaut \\(\\mathfrak{z}_{0.975}=1.96.\\) Les intervalles de confiance de Wald bilatéraux sont, par construction, symmétriques. Parfois, cela donne des valeurs impossibles (par exemple, une variance négative).\n\nExemple 3.11 (Test de Wald pour comparer les modèles Weibull et exponentiel) Nous pouvons tester si la loi exponentielle est une simplification adéquate de la loi de Weibull en imposant la restriction \\(\\mathscr{H}_0: \\alpha=1\\). Nous comparons les statistiques de Wald \\(W\\) à un \\(\\chi^2_1\\). Puisque \\(\\alpha\\) est un paramètre de la loi Weibull, nous avons les erreurs-type gratuitement.\n\n# Calculer la statistique de Wald\nwald_exp &lt;- (mle_weibull[2] - 1)/se_weibull[2]\n# Calculer la valeur-p\npchisq(wald_exp^2, df = 1, lower.tail = FALSE)\n#&gt; [1] 3.61e-10\n# valeur-p inférieure à 5%, rejet de l'hypothèse nulle\n# Intervalles de confiance de niveau 95%\nmle_weibull[2] + qnorm(c(0.025, 0.975))*se_weibull[2]\n#&gt; [1] 2.1 3.1\n# La valeur 1 n'appartient pas à l'intervalle, rejeter H0\n\nNous rejetons l’hypothèse nulle, ce qui signifie que le sous-modèle exponentiel n’est pas une simplification adéquate du modèle de Weibull \\((\\alpha \\neq 1\\)).\nNous pouvons également vérifier l’ajustement des deux modèles à l’aide d’un diagramme quantile-quantile (cf. Définition 1.13). Il ressort de Figure 3.4 que le modèle exponentiel surestime les temps d’attente les plus importants, dont la dispersion dans l’échantillon est inférieure à celle impliquée par le modèle. En revanche, la ligne droite presque parfaite pour le modèle de Weibull dans le panneau de droite de Figure 3.4 suggère que l’ajustement du modèle est adéquat.\n\n\n\n\n\n\n\n\nFigure 3.4: Diagrammes quantile-quantile des modèles exponentiel (gauche) et Weibull (droite) avec intervalles de confiance ponctuels à 95% obtenus par autoamorçage.\n\n\n\n\n\n\n\nRemarque 3.1 (Absence d’invariance des intervalles de confiance de Wald). Puisque les erreurs-types de paramètres dépendent de la paramétrisation, les intervalles de confiance de Wald ne sont pas invariants à ces transformations. Par exemple, si on veut des intervalles de confiance pour une fonction \\(g(\\boldsymbol{\\theta})\\) qui n’est pas linéaire, alors en général. \\(\\mathsf{IC}_{W}\\{g(\\theta)\\} \\neq g\\{\\mathsf{IC}_{W}(\\theta)\\}.\\)\nPar exemple, considérons le modèle exponentiel. Nous pouvons inverser la statistique du test de Wald pour obtenir un intervalle de confiance symétrique à 95% pour \\(\\phi = g(\\lambda) = \\exp(-60/\\lambda),\\) $ [0.061,$ \\(0.191].\\) Si nous devions naïvement transformer l’intervalle de confiance pour \\(\\lambda\\) en un pour \\(\\phi\\) en appliquant la fonction \\(g(\\cdot)\\) à chaque borne, nous obtiendrions plutôt \\([0.063,\\) \\(0.19],\\) Bien que la différence soit minime ici, cela met en évidence l’invariance. L’approximation gaussienne qui sous-tend le test de Wald est fiable si la loi d’échantillonnage de la vraisemblance est presque quadratique, ce qui se produit lorsque la fonction de vraisemblance est à peu près symétrique de part et d’autre de l’estimateur du maximum de vraisemblance.\n\nLe test du rapport de vraisemblance est invariant par rapport aux reparamétrages préservant les intérêts, de sorte que la statistique de test pour \\(\\mathscr{H}_0: \\phi=\\phi_0\\) et \\(\\mathscr{H}_0: \\lambda = -60/\\ln(\\phi_0)\\) est la même. Les intervalles de confiance de Wald peuvent être comparées à celles (meilleures) obtenues à l’aide du test du rapport de vraisemblance. Ces dernières sont obtenues par une recherche numérique des limites de \\[\\begin{align*}\n\\left\\{\\theta: 2\\{\\ell(\\widehat{\\boldsymbol{\\theta}}) - \\ell(\\boldsymbol{\\theta})\\} \\leq \\chi^2_p(1-\\alpha)\\right\\},\n\\end{align*}\\] où \\(\\chi^2_p(1-\\alpha)\\) est le quantile de niveau \\((1-\\alpha)\\) de la loi \\(\\chi^2_p\\). De tels intervalles, pour \\(\\alpha = 0.1, \\ldots, 0.9\\), sont tracés sur la Figure 3.3 (courbes de contour). Si \\(\\boldsymbol{\\theta}\\) est un \\(p\\)-vecteur \\((p&gt; 1)\\), alors les intervalles de confiance pour \\(\\theta_i\\) sont dérivés à partir de la vraisemblance profilée. Les intervalles de confiance basés sur la statistique du rapport de vraisemblance sont invariants aux reparamétrages, donc \\(\\mathsf{IC}_{R}\\{g(\\theta)\\} = g\\{\\mathsf{IC}_{R}(\\theta)\\}.\\) Comme la vraisemblance est nulle si la valeur d’un paramètre se situe en dehors de l’espace des paramètres \\(\\boldsymbol{\\Theta}\\), les intervalles n’incluent que les valeurs plausibles de \\(\\theta.\\) En général, les intervalles sont asymétriques et présentent de meilleures taux de couverture.\n\n# Log vraisemblance exponentielle\nll_exp &lt;- function(lambda) {\n  sum(dexp(attente, rate = 1 / lambda, log = TRUE))\n}\n# EMV du paramètre d'échelle\nlambda_hat &lt;- mean(attente)\n# Recherche des zéros de la fonction pour obtenir\n# les limites des intervalles de confiance\nlrt_lb &lt;- uniroot(\n  # borne inférieure, en utilisant l'EMV\n  f = function(r) {\n    2 * (ll_exp(lambda_hat) - ll_exp(r)) - qchisq(0.95, 1)\n  },\n  interval = c(0.5 * min(attente), lambda_hat)\n)$root\nlrt_ub &lt;- uniroot(\n  # borne supérieure\n  f = function(r) {\n    2 * (ll_exp(lambda_hat) - ll_exp(r)) - qchisq(0.95, 1)\n  },\n  interval = c(lambda_hat, 2 * max(attente))\n)$root\n\nL’intervalle de confiance à 95% de la statistique du rapport de vraisemblance pour \\(\\lambda\\) peut être trouvé en utilisant un algorithme de recherche linéaire: l’intervalle de confiance à 95% pour \\(\\lambda\\) est \\(\\mathsf{IC}_R(\\lambda)[22.784,37.515].\\) Par invariance, l’intervalle de confiance à 95% pour \\(\\phi\\) est \\(\\mathsf{IC}_R(\\phi) = [0.072, 0.202] = g\\{\\mathsf{IC}_R(\\lambda)\\}.\\)",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Inférence basée sur la vraisemblance</span>"
    ]
  },
  {
    "objectID": "vraisemblance.html#vraisemblance-profilée",
    "href": "vraisemblance.html#vraisemblance-profilée",
    "title": "3  Inférence basée sur la vraisemblance",
    "section": "3.4 Vraisemblance profilée",
    "text": "3.4 Vraisemblance profilée\nParfois, nous pouvons vouloir effectuer des tests d’hypothèse ou dériver des intervalles de confiance pour un sous-ensemble spécifique des paramètres du modèle, ou une transformation de ces derniers. Dans ce cas, l’hypothèse nulle ne restreint qu’une partie de l’espace et les autres paramètres, dits de nuisance, ne sont pas spécifiés — la question est alors de savoir quelles valeurs utiliser pour la comparaison avec le modèle complet. Il s’avère que les valeurs qui maximisent la log-vraisemblance contrainte sont celles que l’on doit utiliser pour le test, et la fonction particulière dans laquelle ces paramètres de nuisance sont intégrés est appelée vraisemblance profilée.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDéfinition 3.5 (Log-vraisemblance profilée) Soit un modèle paramétrique avec log-vraisemblance \\(\\ell(\\boldsymbol{\\theta})\\), dont le vecteur de paramètres de dimension \\(p\\) \\(\\boldsymbol{\\theta}=(\\boldsymbol{\\psi}, \\boldsymbol{\\varphi})\\) peut être séparé en un sous-vecteur de longueur \\(q\\) contenant les paramètres d’intérêts, disons \\(\\boldsymbol{\\psi}\\) et un sous-vecteur de longueur \\((p-q)\\) contenant les paramètres de nuisance \\(\\boldsymbol{\\varphi}.\\)\nLa log-vraisemblance profilée \\(\\ell_{\\mathsf{p}}\\) est une fonction de \\(\\boldsymbol{\\psi}\\) qui est obtenue en maximisant la log-vraisemblance ponctuellement à chaque valeur fixe \\(\\boldsymbol{\\psi}_0\\) sur le vecteur de nuisance \\(\\boldsymbol{\\varphi}_{\\psi_0},\\) \\[\\begin{align*}\n\\ell_{\\mathsf{p}}(\\boldsymbol{\\psi})=\\max_{\\boldsymbol{\\varphi}}\\ell(\\boldsymbol{\\psi}, \\boldsymbol{\\varphi})=\\ell(\\boldsymbol{\\psi}, \\widehat{\\boldsymbol{\\varphi}}_{\\boldsymbol{\\psi}}).\n\\end{align*}\\]\n\n\nExemple 3.12 (Log-vraisemblance profilée pour le paramètre de forme d’une loi Weibull) Considérons le paramètre de forme \\(\\psi \\equiv\\alpha\\) comme paramètre d’intérêt, et le paramètre d’échelle \\(\\varphi\\equiv\\lambda\\) comme paramètre de nuisance. En utilisant le gradient dérivé dans l’Exemple 3.7, nous constatons que la valeur de l’échelle qui maximise la log-vraisemblance pour un \\(\\alpha\\) donné est \\[\\begin{align*}\n\\widehat{\\lambda}_\\alpha = \\left( \\frac{1}{n}\\sum_{i=1}^n y_i^\\alpha\\right)^{1/\\alpha}.\n\\end{align*}\\] Si on substitue cette valeur dans la log-vraisemblance, on obtient une fonction de \\(\\alpha\\) uniquement, ce qui réduit également le problème d’optimisation pour les EMV d’une loi Weibull à une recherche linéaire le long de \\(\\ell_{\\mathsf{p}}(\\alpha)\\). Le panneau de gauche de Figure 3.3 montre la crête le long de la direction de \\(\\alpha\\) correspondant à la surface de log-vraisemblance. Si l’on considère ces courbes de niveau comme celles d’une carte topographique, la log-vraisemblance profilée correspond dans ce cas à une marche le long de la crête des deux montagnes dans la direction \\(\\psi\\), le panneau de droite montrant le gain/la perte d’altitude. Le profil d’élévation correspondant à droite de Figure 3.3 avec les points de coupure pour les intervalles de confiance basés sur le rapport de vraisemblance&lt;. Nous devrions obtenir numériquement, à l’aide d’un algorithme de recherche lin/aire, les limites de l’intervalle de confiance de part et d’autre de \\(\\widehat{\\alpha}\\), mais il est clair que \\(\\alpha=1\\) n’est pas dans l’intervalle de 99%.\n\n# EMV conditionnels de lambda pour alpha donné\nlambda_alpha &lt;- function(alpha, y = attente) {\n  (mean(y^alpha))^(1 / alpha)\n}\n# Log vraisemblance profilée pour alpha\nprof_alpha_weibull &lt;- function(par, y = attente) {\n  sapply(par, function(a) {\n    nll_weibull(pars = c(lambda_alpha(a), a), y = y)\n  })\n}\n\n\n\nExemple 3.13 (Log-vraisemblance profilée pour l’espérance d’une loi Weibull) Nous pouvons également utiliser l’optimisation numérique pour calculer la log-vraisemblance profilée d’une fonction des paramètres. Supposons que nous soyons intéressés par le temps moyen d’attente théorique. Selon le modèle Weibull, cette valeur est \\(\\mu = \\mathsf{E}(Y) = \\lambda\\Gamma(1+1/\\alpha)\\). À cet effet, nous reparamétrons le modèle en termes de \\((\\mu, \\alpha)\\), où \\(\\lambda=\\mu/\\Gamma(1+1/\\alpha)\\). Nous créons ensuite une fonction qui optimise la log-vraisemblance pour une valeur fixe de \\(\\mu\\), puis renvoie \\(\\widehat{\\alpha}_{\\mu}\\), \\(\\mu\\) et \\(\\ell_{\\mathrm{p}}(\\mu)\\).\nPour obtenir les intervalles de confiance d’un paramètre scalaire, il existe une astuce qui permet de s’en tirer avec une évaluation sommaire, pour autant que la log-vraisemblance profilée soit relativement lisse. Nous calculons la racine directionnelle du rapport de vraisemblance, \\(r(\\psi) = \\mathrm{sign}(\\psi - \\widehat{\\psi})\\{2\\ell_{\\mathrm{p}}(\\widehat{\\psi}) -2 \\ell_{\\mathrm{p}}(\\psi)\\}^{1/2}\\) sur une grille fine de valeurs de \\(\\psi\\), puis nous ajustons une spline de lissage, une régression avec variable réponse \\(y=\\psi\\) et variable explicative \\(x=r(\\psi)\\). Nous prédisons ensuite la courbe aux quantiles normaux \\(\\mathfrak{z}_{\\alpha/2}\\) et \\(\\mathfrak{z}_{1-\\alpha/2}\\), et renvoyons ces valeurs sous forme d’intervalle de confiance. La Figure 3.5 montre comment ces valeurs correspondent aux points de coupure sur l’échelle du logarithme du rapport de vraisemblance, où la ligne verticale est donnée par \\(-\\mathfrak{c}(1-\\alpha)/2\\) où \\(\\mathfrak{c}\\) représente le quantile d’une variable aléatoire \\(\\chi^2_1\\).\n\n\nCode\n# Compute the MLE for the expected value via plug-in\nmu_hat &lt;- mle_weibull[1]*gamma(1+1/mle_weibull[2])\n# Create a profile function\nprof_weibull_mu &lt;- function(mu){\n  # For given value of mu\n  alpha_mu &lt;- function(mu){ \n  # Find the profile by optimizing (line search) for fixed mu and the best alpha\n     opt &lt;- optimize(f = function(alpha, mu){\n     # minimize the negative log likelihood\n      nll_weibull(c(mu/gamma(1+1/alpha), alpha), y = attente)}, \n   mu = mu, \n  interval = c(0.1,10) #search region\n  )\n  # Return the value of the negative log likelihood and alpha_mu\n  return(c(nll = opt$objective, alpha = opt$minimum))\n  }\n  # Create a data frame with mu and the other parameters\n  data.frame(mu = mu, t(sapply(mu, function(m){alpha_mu(m)})))\n}\n# Create a data frame with the profile  \nprof &lt;- prof_weibull_mu(seq(22, 35, length.out = 101L))\n# Compute signed likelihood root r\nprof$r &lt;- sign(prof$mu - mu_hat)*sqrt(2*(prof$nll - opt_weibull$value))\n\n# Trick: fit a spline to obtain the predictions with mu as a function of r\n# Then use this to predict the value at which we intersect the normal quantiles\nfit.r &lt;- stats::smooth.spline(x = cbind(prof$r, prof$mu), cv = FALSE)\npr &lt;- predict(fit.r, qnorm(c(0.025, 0.975)))$y\n# Plot the signed likelihood root - near linear indicates quadratic\ng1 &lt;- ggplot(data = prof,\n     mapping = aes(x = mu, y = r)) +\n  geom_abline(intercept = 0, slope = 1) +\n  geom_line() + \n  geom_hline(yintercept = qnorm(0.025, 0.975),\n            linetype = \"dashed\") + \n  labs(x = expression(paste(\"espérance \", mu)),\n       y = \"racine directionnelle de vraisemblance\")\n# Create a plot of the profile\ng2 &lt;- ggplot(data = prof,\n       mapping = aes(x = mu, y = opt_weibull$value - nll)) + \n  geom_line() +\n  geom_hline(yintercept = -qchisq(c(0.95), df = 1)/2,\n             linetype = \"dashed\") +\n  geom_vline(linetype = \"dotted\",\n  xintercept = pr) + \n  labs(x = expression(paste(\"espérance \", mu)),\n       y = \"log vraisemblance profilée\")\n\ng1 + g2\n\n\n\n\n\n\n\n\nFigure 3.5: Racine directionnelle du rapport de vraisemblance (gauche) et log vraisemblance profilée (droite) en fonction de l’espérance \\(\\mu\\) pour un modèle Weibull.\n\n\n\n\n\n\nL’estimateur du maximum de vraisemblance du profil se comporte comme une vraisemblance normale pour la plupart des quantités d’intérêt et nous pouvons dériver des statistiques de test et des intervalles de confiance de la manière habituelle. Un exemple célèbre de profil de vraisemblance est la fonction de risque proportionnel de Cox couvert dans le chapitre 7.\n\nExemple 3.14 (Transformation de Box–Cox) Parfois, le postulat de normalité de l’erreur dans une régression linéaire ne tient pas. Si les données sont strictement positives, on peut envisager une transformation de Box-Cox, \\[\\begin{align*}\ny(\\lambda)= \\begin{cases}\n(y^{\\lambda}-1)/\\lambda, & \\lambda \\neq 0\\\\\n\\ln(y), & \\lambda=0.\n\\end{cases}\n\\end{align*}\\]\nSi on postule que \\(\\boldsymbol{Y}(\\lambda) \\sim \\mathsf{normale}(\\mathbf{X}\\boldsymbol{\\beta}, \\sigma^2 \\mathbf{I}_n)\\), alors la log-vraisemblance s’écrit \\[\\begin{align*}\nL(\\lambda, \\boldsymbol{\\beta}, \\sigma; \\boldsymbol{y}, \\mathbf{X}) &= (2\\pi\\sigma^2)^{-n/2} J(\\lambda, \\boldsymbol{y}) \\times\\\\& \\quad \\exp \\left[ - \\frac{1}{2\\sigma^2}\\{\\boldsymbol{y}(\\lambda) - \\mathbf{X}\\boldsymbol{\\beta}\\}^\\top\\{\\boldsymbol{y}(\\lambda) - \\mathbf{X}\\boldsymbol{\\beta}\\}\\right],\n\\end{align*}\\] où \\(J\\) dénote le jacobien de la transformation de Box–Cox, \\(J(\\lambda, \\boldsymbol{y})=\\prod_{i=1}^n y_i^{\\lambda-1}\\). Pour chaque valeur de \\(\\lambda\\), l’estimateur du maximum de vraisemblance est le même que celle de la régression linéaire, mais où \\(\\boldsymbol{y}\\) est remplacée par \\(\\boldsymbol{y}(\\lambda)\\), soit \\(\\widehat{\\boldsymbol{\\beta}}_\\lambda = (\\mathbf{X}^\\top\\mathbf{X})^{-1}\\mathbf{X}^\\top \\boldsymbol{y}(\\lambda)\\) and \\(\\widehat{\\sigma}^2_\\lambda = n^{-1}\\{ \\boldsymbol{y}(\\lambda) - \\mathbf{X}\\widehat{\\boldsymbol{\\beta}}_\\lambda\\}^\\top\\{ \\boldsymbol{y}(\\lambda) - \\mathbf{X}\\widehat{\\boldsymbol{\\beta}}_\\lambda\\}\\).\nLa log-vraisemblance profilée est donc \\[\\begin{align*}\n\\ell_{\\mathsf{p}}(\\lambda) = -\\frac{n}{2}\\ln(2\\pi \\widehat{\\sigma}^2_\\lambda) - \\frac{n}{2} + (\\lambda - 1)\\sum_{i=1}^n \\ln(y_i)\n\\end{align*}\\] L’estimateur du maximum de vraisemblance profilée est la valeur \\(\\lambda\\) qui minimise la somme des carrés des résidus du modèle linéaire avec \\(\\boldsymbol{y}(\\lambda)\\) comme réponse.\nLa transformation de Box–Cox n’est pas une solution miracle et doit être réservée aux cas où la transformation réduit l’hétéroscédasticité (variance inégale) ou crée une relation linéaire entre les explications et la réponse. La théorie fournit une explication convaincante des données avec, par exemple, la fonction de production Cobb-Douglas utilisée en économie qui peut être linéarisée par une transformation logarithmique. Plutôt que de choisir une transformation ad hoc, on pourrait choisir une transformation logarithmique si la valeur 0$ est incluse dans l’intervalle de confiance à 95%, car cela améliore l’interprétabilité.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Inférence basée sur la vraisemblance</span>"
    ]
  },
  {
    "objectID": "vraisemblance.html#critères-dinformation",
    "href": "vraisemblance.html#critères-dinformation",
    "title": "3  Inférence basée sur la vraisemblance",
    "section": "3.5 Critères d’information",
    "text": "3.5 Critères d’information\nLa vraisemblance peut également servir d’élément de base pour la comparaison des modèles : plus \\(\\ell(\\boldsymbol{\\widehat{\\theta}})\\) est grand, meilleure est l’adéquation. Cependant, la vraisemblance ne tient pas compte de la complexité du modèle dans le sens où des modèles plus complexes avec plus de paramètres conduisent à une vraisemblance plus élevée. Cela ne pose pas de problème pour la comparaison de modèles emboîtés à l’aide du test du rapport de vraisemblance, car nous ne tenons compte que de l’amélioration relative de l’adéquation. Il existe un risque de surajustement si l’on ne tient compte que de la vraisemblance d’un modèle.\n\nLes critères d’information combinent la log vraisemblance, qui mesure l’adéquation du modèle aux données, avec une pénalité pour le nombre de paramètres. Les plus fréquents sont les critères d’information d’Akaike (AIC) et bayésien (BIC), \\[\\begin{align*}\n\\mathsf{AIC}&=-2\\ell(\\widehat{\\boldsymbol{\\theta}})+2p \\\\\n\\mathsf{BIC}&=-2\\ell(\\widehat{\\boldsymbol{\\theta}})+p\\ln(n),\n\\end{align*}\\] où \\(p\\) dénote le nombre de paramètres du modèle. Le plus petit la valeur du critère d’information, le meilleur le modèle.\nNotez que les critères d’information ne constituent pas des tests d’hypothèse formels sur les paramètres, mais qu’ils peuvent être utilisés pour comparer des modèles non imbriqués (mais ils sont alors très imprécis!) Ces outils fonctionnent sous des conditions de régularité et les critères d’information estimés sont assez bruyants, de sorte que les comparaisons pour les modèles non emboîtés sont hasardeuses bien que populaires. Si nous voulons comparer la vraisemblance de différents modèles de probabilité, nous devons nous assurer qu’ils incluent une constante de normalisation5. Le \\(\\mathsf{BIC}\\) est plus strict que le \\(\\mathsf{AIC}\\), car sa pénalité augmente avec la taille de l’échantillon, ce qui permet de sélectionner des modèles plus parsimonieux. Le \\(\\mathsf{BIC}\\) est un critère convergent, ce qui signifie qu’il choisira le vrai modèle parmi un ensemble de modèles avec une probabilité de 1 lorsque \\(n \\to \\infty\\) si ce dernier fait partie du catalogue de modèles à comparer. En pratique, cela présente peu d’intérêt si l’on suppose que tous les modèles sont des approximations de la réalité (il est peu probable que le vrai modèle soit inclus dans ceux que nous considérons). Pour sa part, \\(\\mathsf{AIC}\\) sélectionne souvent des modèles trop compliqués dans les grands échantillons, alors que \\(\\mathsf{BIC}\\) choisit des modèles trop simples.\nUne mise en garde s’impose: s’il est possible de comparer des modèles de régression non emboîtés à l’aide de critères d’information, ceux-ci ne peuvent être utilisés que lorsque la variable de réponse est la même. Vous pouvez comparer une régression de Poisson avec une régression linéaire pour une réponse \\(Y\\) en utilisant des critères d’information à condition d’inclure toutes les constantes de normalisation dans votre modèle. Les logiciels omettent souvent les termes constants; cela n’a pas d’impact lorsque vous comparez des modèles avec les mêmes facteurs constants, mais cela a de l’importance lorsque ceux-ci diffèrent. Cependant, on ne peut pas les comparer à un modèle log-linéaire avec une réponse \\(\\ln(Y)\\). Les comparaisons entre les modèles log-linéaires et linéaires ne sont valables que si vous utilisez la vraisemblance de Box–Cox, car elle inclut le jacobien de la transformation.\n\n\n\n\nDavison, A. C. 2003. Statistical Models. Cambridge University Press.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Inférence basée sur la vraisemblance</span>"
    ]
  },
  {
    "objectID": "vraisemblance.html#footnotes",
    "href": "vraisemblance.html#footnotes",
    "title": "3  Inférence basée sur la vraisemblance",
    "section": "",
    "text": "Si \\(A\\) et \\(B\\) sont des variables aléatoires indépendantes, leur probabilité conjointe est le produit des probabilités des événements individuels, \\(\\Pr(A \\cup B) = \\Pr(A)\\Pr(B).\\) La même factorisation tient pour la fonction de densité ou de masse, lesquelles sont les dérivées de la fonction de répartition.↩︎\nPuisque dans la plupart des cas on a un produit de densités, prendre le logarithme transforme un produit de termes potentiellement petits en une somme de log densités, ce qui est plus facile côté dérivation et plus stable du point de vue du calcul numérique.↩︎\nPar exemple, en utilisant une calculatrice symbolique.↩︎\nLa plupart des algorithmes d’optimisation minimisent les fonctions par rapport à leurs arguments, nous minimisons donc la log-vraisemblance négative, ce qui équivaut à maximiser la log-vraisemblance↩︎\nLes logiciels enlèvent parfois les termes ou constantes qui ne sont pas des fonctions des paramètres.↩︎",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Inférence basée sur la vraisemblance</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "Bibliographie",
    "section": "",
    "text": "Brodeur, Mathieu, Perrine Ruer, Pierre-Majorique Léger, and Sylvain\nSénécal. 2021. “Smartwatches Are More Distracting Than Mobile\nPhones While Driving: Results from an Experimental Study.”\nAccident Analysis & Prevention 149: 105846. https://doi.org/10.1016/j.aap.2020.105846.\n\n\nBrucks, Melanie S., and Jonathan Levav. 2022. “Virtual\nCommunication Curbs Creative Idea Generation.” Nature\n605 (7908): 108–12. https://doi.org/10.1038/s41586-022-04643-y.\n\n\nDavison, A. C. 2003. Statistical Models. Cambridge University\nPress.\n\n\nDuke, Kristen E., and On Amir. 2023. “The Importance of Selling\nFormats: When Integrating Purchase and Quantity Decisions Increases\nSales.” Marketing Science 42 (1): 87–109. https://doi.org/10.1287/mksc.2022.1364.\n\n\nGosset, William Sealy. 1908. “The Probable Error of a\nMean.” Biometrika 6 (1): 1–25. https://doi.org/10.1093/biomet/6.1.1.\n\n\nLee, Kiljae, and Jungsil Choi. 2019. “Image-Text Inconsistency\nEffect on Product Evaluation in Online Retailing.” Journal of\nRetailing and Consumer Services 49: 279–88. https://doi.org/10.1016/j.jretconser.2019.03.015.\n\n\nLiu, Peggy J., SoYon Rim, Lauren Min, and Kate E. Min. 2023. “The\nSurprise of Reaching Out: Appreciated More Than We Think.”\nJournal of Personality and Social Psychology 124 (4): 754–71.\nhttps://doi.org/10.1037/pspi0000402.\n\n\nMcCullagh, P., and J. A. Nelder. 1989. Generalized Linear\nModels. Second edition. London: Chapman & Hall.\n\n\nMoon, Alice, and Eric M VanEpps. 2023. “Giving Suggestions: Using\nQuantity Requests to Increase Donations.” Journal of Consumer\nResearch 50 (1): 190–210. https://doi.org/10.1093/jcr/ucac047.\n\n\nRosen, B., and T. H. Jerdee. 1974. “Influence of Sex Role\nStereotypes on Personnel Decisions.” Journal of Applied\nPsychology 59: 9–14.\n\n\nSokolova, Tatiana, Aradhna Krishna, and Tim Döring. 2023. “Paper\nMeets Plastic: The Perceived Environmental Friendliness of Product\nPackaging.” Journal of Consumer Research 50 (3): 468–91.\nhttps://doi.org/10.1093/jcr/ucad008.",
    "crumbs": [
      "Bibliographie"
    ]
  }
]