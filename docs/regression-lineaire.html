<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="fr" xml:lang="fr"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.5.56">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="description" content="Ces notes forment un complément web du cours MATH 60604 (Modélisation statistique) offert à la M.Sc. en gestion (science des données et analytique d’affaires) à HEC Montréal.">

<title>4&nbsp; Régression linéaire – MATH 60604 - Modélisation statistique</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./references.html" rel="next">
<link href="./vraisemblance.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "Pas de résultats",
    "search-matching-documents-text": "documents trouvés",
    "search-copy-link-title": "Copier le lien vers la recherche",
    "search-hide-matches-text": "Cacher les correspondances additionnelles",
    "search-more-match-text": "correspondance de plus dans ce document",
    "search-more-matches-text": "correspondances de plus dans ce document",
    "search-clear-button-title": "Effacer",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Annuler",
    "search-submit-button-title": "Envoyer",
    "search-label": "Recherche"
  }
}</script>
<link href="site_libs/htmltools-fill-0.5.8.1/fill.css" rel="stylesheet">
<script src="site_libs/htmlwidgets-1.6.4/htmlwidgets.js"></script>
<script src="site_libs/plotly-binding-4.10.4/plotly.js"></script>
<script src="site_libs/typedarray-0.1/typedarray.min.js"></script>
<script src="site_libs/jquery-3.5.1/jquery.min.js"></script>
<link href="site_libs/crosstalk-1.2.1/css/crosstalk.min.css" rel="stylesheet">
<script src="site_libs/crosstalk-1.2.1/js/crosstalk.min.js"></script>
<link href="site_libs/plotly-htmlwidgets-css-2.11.1/plotly-htmlwidgets.css" rel="stylesheet">
<script src="site_libs/plotly-main-2.11.1/plotly-latest.min.js"></script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="css/style.css">
</head>

<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Basculer la barre latérale" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./regression-lineaire.html"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Régression linéaire</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Basculer la barre latérale" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Recherche" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">MATH 60604 - Modélisation statistique</a> 
        <div class="sidebar-tools-main">
    <a href="https://github.com/lbelzile/math60604/" title="Code source" class="quarto-navigation-tool px-1" aria-label="Code source"><i class="bi bi-github"></i></a>
    <a href="./MATH60604.pdf" title="Download PDF" class="quarto-navigation-tool px-1" aria-label="Download PDF"><i class="bi bi-file-pdf"></i></a>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Recherche"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Bienvenue</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./introduction.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Introduction</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./inference.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Inférence statistique</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./vraisemblance.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Inférence basée sur la vraisemblance</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./regression-lineaire.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Régression linéaire</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Bibliographie</span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table des matières</h2>
   
  <ul>
  <li><a href="#introduction" id="toc-introduction" class="nav-link active" data-scroll-target="#introduction"><span class="header-section-number">4.1</span> Introduction</a>
  <ul class="collapse">
  <li><a href="#exemples" id="toc-exemples" class="nav-link" data-scroll-target="#exemples"><span class="header-section-number">4.1.1</span> Exemples</a></li>
  <li><a href="#analyse-exploratoire-des-données" id="toc-analyse-exploratoire-des-données" class="nav-link" data-scroll-target="#analyse-exploratoire-des-données"><span class="header-section-number">4.1.2</span> Analyse exploratoire des données</a></li>
  <li><a href="#spécification-du-modèle-pour-la-moyenne" id="toc-spécification-du-modèle-pour-la-moyenne" class="nav-link" data-scroll-target="#spécification-du-modèle-pour-la-moyenne"><span class="header-section-number">4.1.3</span> Spécification du modèle pour la moyenne</a></li>
  </ul></li>
  <li><a href="#interprétation-des-coefficients" id="toc-interprétation-des-coefficients" class="nav-link" data-scroll-target="#interprétation-des-coefficients"><span class="header-section-number">4.2</span> Interprétation des coefficients</a></li>
  <li><a href="#estimation-des-paramètres" id="toc-estimation-des-paramètres" class="nav-link" data-scroll-target="#estimation-des-paramètres"><span class="header-section-number">4.3</span> Estimation des paramètres</a>
  <ul class="collapse">
  <li><a href="#moindres-carrés-ordinaires" id="toc-moindres-carrés-ordinaires" class="nav-link" data-scroll-target="#moindres-carrés-ordinaires"><span class="header-section-number">4.3.1</span> Moindres carrés ordinaires</a></li>
  <li><a href="#maximum-de-vraisemblance" id="toc-maximum-de-vraisemblance" class="nav-link" data-scroll-target="#maximum-de-vraisemblance"><span class="header-section-number">4.3.2</span> Maximum de vraisemblance</a></li>
  <li><a href="#ajustement-des-modèles-linéaires-à-laide-dun-logiciel" id="toc-ajustement-des-modèles-linéaires-à-laide-dun-logiciel" class="nav-link" data-scroll-target="#ajustement-des-modèles-linéaires-à-laide-dun-logiciel"><span class="header-section-number">4.3.3</span> Ajustement des modèles linéaires à l’aide d’un logiciel</a></li>
  </ul></li>
  <li><a href="#coefR2" id="toc-coefR2" class="nav-link" data-scroll-target="#coefR2"><span class="header-section-number">4.4</span> Coefficient de détermination</a></li>
  </ul>
<div class="toc-actions"><ul><li><a href="https://github.com/lbelzile/math60604/edit/master/regression-lineaire.qmd" class="toc-action"><i class="bi bi-github"></i>Éditer cette page</a></li></ul></div></nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title"><span id="regression-lineaire" class="quarto-section-identifier"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Régression linéaire</span></span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<section id="introduction" class="level2" data-number="4.1">
<h2 data-number="4.1" class="anchored" data-anchor-id="introduction"><span class="header-section-number">4.1</span> Introduction</h2>
<p>Le modèle de régression linéaire, ou modèle linéaire, est l’un des outils les plus polyvalents pour l’inférence statistique. La régression linéaire est principalement utilisée pour évaluer les effets des variables explicatives (souvent l’effet d’une manipulation ou d’un traitement dans un cadre expérimental) sur la moyenne d’une variable réponse continue, ou pour la prédiction. Un modèle linéaire est un modèle qui décrit la moyenne d’une <strong>variable réponse</strong> continue <span class="math inline">\(Y_i\)</span> d’un échantillon aléatoire de taille <span class="math inline">\(n\)</span> comme <strong>fonction linéaire</strong> des <strong>variables explicatives</strong> (également appelés prédicteurs, régresseurs ou covariables) <span class="math inline">\(X_1, \ldots, X_p\)</span>.</p>
<p>Dénotons par <span class="math inline">\(Y_i\)</span> la valeur de <span class="math inline">\(Y\)</span> pour le sujet <span class="math inline">\(i\)</span>, et <span class="math inline">\(X_{ij}\)</span> la valeur de la <span class="math inline">\(j\)</span>e variable explicative du sujet <span class="math inline">\(i\)</span>. <span class="math display">\[\begin{align}
\underset{\text{moyenne conditionnelle}}{\mathsf{E}(Y_i \mid \boldsymbol{X}_i=\boldsymbol{x}_i)}=\mu_i=\underset{\substack{\text{combinaison linéaire (somme pondérée)}\\ \text{de variables explicatives}}}{\beta_0 + \beta_1x_{i1} + \cdots + \beta_p x_{ip}}\equiv \mathbf{x}_i\boldsymbol{\beta}.
\end{align}\]</span> où <span class="math inline">\(\mathbf{x}_i = (1, x_{i1}, \ldots, x_{ip})\)</span> est un vecteur ligne de taille <span class="math inline">\((p+1)\)</span> contenant les variables explicatives de l’observation <span class="math inline">\(i\)</span> et <span class="math inline">\(\boldsymbol{\beta} = (\beta_0, \ldots, \beta_p)^\top\)</span> est un vecteur colonne de longueur <span class="math inline">\(p+1\)</span> contenant les coefficients de la moyenne. Le fait que la moyenne est conditionnelle aux valeurs de <span class="math inline">\(\mathbf{X}\)</span> implique simplement que l’on considère les régresseurs comme constant, ou connus à l’avance. Les coefficients <span class="math inline">\(\boldsymbol{\beta}\)</span> sont les mêmes pour toutes les observations, mais le vecteurs de variables explicatives <span class="math inline">\(\mathbf{x}_i\)</span> peut différer d’une observation à l’autre. Le modèle est <strong>linéaire</strong> en <span class="math inline">\(\beta_0, \ldots, \beta_p\)</span>, pas nécessairement dans les variables explicatives.</p>
<p>Pour simplifier la notation, nous regroupons les observations dans un vecteur <span class="math inline">\(n\)</span> <span class="math inline">\(\boldsymbol{Y}\)</span> et les explications dans une matrice <span class="math inline">\(n \times (p+1)\)</span> <span class="math inline">\(\mathbf{X}\)</span> en concaténant une colonne de uns et les vecteurs de colonnes <span class="math inline">\(p\)</span> <span class="math inline">\(\boldsymbol{X}_1, \ldots, \boldsymbol{X}_p\)</span>, chacun contenant les <span class="math inline">\(n\)</span> observations des explications respectives. La matrice <span class="math inline">\(\mathbf{X}\)</span> est appelée <strong>matrice du modèle</strong> (ou parfois matrice de devis dans un contexte expérimental), et sa <span class="math inline">\(i\)</span>ème ligne est <span class="math inline">\(\mathbf{x}_i\)</span>.</p>
<p>En supposant que la variable réponse provient d’une famille de localisation, nous pouvons réécrire le modèle linéaire en termes de la moyenne plus un aléa, <span class="math display">\[\begin{align*}
\underset{\text{observation}\vphantom{\mu_i}}{Y_i} = \underset{\text{moyenne } \mu_i}{\vphantom{Y_i}\mathbf{x}_i\boldsymbol{\beta}} + \underset{\text{aléa}\vphantom{\mu_i}}{\vphantom{Y_i}\varepsilon_i},
\end{align*}\]</span> où <span class="math inline">\(\varepsilon_i\)</span> est le terme spécifique à l’observation <span class="math inline">\(i\)</span>. On assume que les aléas <span class="math inline">\(\varepsilon_1, \ldots \varepsilon_n\)</span> sont indépendants et identiquement distribués, avec <span class="math inline">\(\mathsf{E}(\varepsilon_i \mid \mathbf{x}_i) = 0\)</span> et <span class="math inline">\(\mathsf{Var}(\varepsilon_i \mid \mathbf{x}_i) = \sigma^2\)</span>. On fixe l’espérance de l’aléa à zéro car on postule qu’il n’y a pas d’erreur systématique. La variance <span class="math inline">\(\sigma^2\)</span> sert à tenir compte du fait qu’aucune relation linéaire exacte ne lie <span class="math inline">\(\mathbf{x}_i\)</span> et <span class="math inline">\(Y_i\)</span>, ou que les mesures de <span class="math inline">\(Y_i\)</span> sont variables.</p>
<p>Le modèle linéaire normal ou gaussien spécifie que les réponses suivent une loi normale, avec <span class="math inline">\(Y_i \mid \boldsymbol{X}_i=\boldsymbol{x}_i \sim \mathsf{normale}(\mathbf{x}_i\boldsymbol{\beta}, \sigma^2)\)</span>. La loi normale est une famille de localisation, de sorte que <span class="math inline">\(Y \sim \mathsf{normale}(\mu, \sigma^2)\)</span> équivaut à la décomposition additive <span class="math inline">\(\mu + \varepsilon\)</span> pour <span class="math inline">\(\varepsilon \sim \mathsf{normale}(0, \sigma^2)\)</span>.</p>
<section id="exemples" class="level3" data-number="4.1.1">
<h3 data-number="4.1.1" class="anchored" data-anchor-id="exemples"><span class="header-section-number">4.1.1</span> Exemples</h3>
<p>Considérons quelques exemples de jeux de données qui serviront à illustrer les méthodes par la suite.</p>
<div id="exm-lee-choi1" class="theorem example">
<p><span class="theorem-title"><strong>Exemple 4.1 (Cohérence de descriptions de produits)</strong></span> L’étude 1 de <span class="citation" data-cites="Lee.Choi:2019">Lee et Choi (<a href="references.html#ref-Lee.Choi:2019" role="doc-biblioref">2019</a>)</span> (base de données <code>LC19_S1</code>, paquet <code>hecedsm</code>) considère l’impact sur la perception d’un produit de la divergence entre la description textuelle et l’image. Dans leur première expérience, un paquet de six brosses à dents est vendu, mais l’image montre soit un paquet de six, soit une seule). Les auteurs ont également mesuré la familiarité préalable avec la marque de l’article. Les <span class="math inline">\(n=96\)</span> participants ont été recrutés à l’aide d’un panel en ligne. Nous pourrions ajuster un modèle linéaire pour le score moyen d’évaluation du produit, <code>prodeval</code>, en fonction de la familiarité de la marque <code>familiarity</code>, un nombre entier allant de 1 à 7, et une variable binaire pour le facteur expérimental <code>consistency</code>, codé <code>0</code> pour des descriptions d’image/texte cohérentes et <code>1</code> si elles sont incohérentes. La matrice du modèle qui en résulte est alors de dimension <span class="math inline">\(96\times 3\)</span>. La réponse <code>prodeval</code> est fortement discrétisée.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(LC19_S1, <span class="at">package =</span> <span class="st">"hecedsm"</span>)</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a>modmat <span class="ot">&lt;-</span> <span class="fu">model.matrix</span>( <span class="co"># Matrice du modèle</span></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a>     <span class="sc">~</span> familiarity <span class="sc">+</span> consistency,</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>     <span class="at">data =</span> LC19_S1)</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="fu">tail</span>(modmat, <span class="at">n =</span> <span class="dv">5</span>L) <span class="co"># Imprimer les premières 5 lignes</span></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;    (Intercept) familiarity consistencyinconsistent</span></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 92           1           6                       1</span></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 93           1           4                       1</span></span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 94           1           7                       1</span></span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 95           1           7                       1</span></span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 96           1           7                       1</span></span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a><span class="fu">dim</span>(modmat) <span class="co"># dimension de la matrice du modèle</span></span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [1] 96  3</span></span></code><button title="Copier vers le presse-papier" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
<div id="exm-teaching-baumann" class="theorem example">
<p><span class="theorem-title"><strong>Exemple 4.2 (Méthodes d’apprentissage de compréhension de lecture)</strong></span> La base de données <code>BSJ92</code> du paquet <code>hecedsm</code> contient les résultats d’une expérience de <span class="citation" data-cites="Baumann:1992">Baumann, Seifert-Kessell, et Jones (<a href="references.html#ref-Baumann:1992" role="doc-biblioref">1992</a>)</span> sur l’efficacité de différentes stratégies de lecture sur la compréhension d’enfants.</p>
<blockquote class="blockquote">
<p>Soixante-six élèves de quatrième année ont été assignés au hasard à l’un des trois groupes expérimentaux suivants : (a) un groupe « Think-Aloud » (TA), dans lequel les élèves ont appris diverses stratégies de contrôle de la compréhension pour la lecture d’histoires (par exemple : auto-questionnement, prédiction, relecture) par le biais de la réflexion à haute voix; (b) un groupe lecture dirigée-activité de réflexion (DRTA), dans lequel les élèves ont appris une stratégie de prédiction-vérification pour lire et répondre aux histoires; ou (c) un groupe activité de lecture dirigée (DRA), un groupe contrôle dans lequel les élèves se sont engagés dans une lecture guidée non interactive d’histoires.</p>
</blockquote>
<p>Les variables d’intérêt sont <code>group</code>, le facteur pour le groupe expérimental, soit <code>DRTA</code>, <code>TA</code> et <code>DR</code> ainsi que les variables numériques <code>pretest1</code> et <code>posttest1</code>, qui donnent le score (sur 16) sur le test pré-expérience pour la tâche de détection des erreurs.</p>
<p>Les données sont balancées puisqu’il y a 22 observations dans chacun des trois sous-groupes. Les chercheurs ont appliqué une série de trois évaluations: le test 1 de détection d’erreurs, le test 2 consistant en un questionnaire de suivi de compréhension, et le test 3 standardisé <em>Degrees of Reading Power</em>). Les tests 1 et 2 ont été administrés à la fois avant et après l’intervention: cela nous permet d’établir l’amélioration moyenne de l’élève en ajoutant le résultat du test pré-intervention comme covariable. Les tests 1 étaient sur 16, mais celui administré après l’expérience a été rendu plus difficile pour éviter les cas d’étudiants obtenant des scores presque complets. La corrélation entre le pré-test et le post-test 1 est <span class="math inline">\((\widehat{\rho}_1=0.57)\)</span>, beaucoup plus forte que celle du second test <span class="math inline">\((\widehat{\rho}_2=0.21)\)</span>.</p>
</div>
<div id="exm-college-salary-discrimination" class="theorem example">
<p><span class="theorem-title"><strong>Exemple 4.3 (Discrimination salariale dans un collège américain)</strong></span> On s’intéresse à la discrimination salariale dans un collège américain, au sein duquel une étude a été réalisée pour investiguer s’il existait des inégalités salariales entre hommes et femmes. Le jeu de données <code>college</code> contient les variables suivantes:</p>
<ul>
<li><code>salaire</code>: salaire de professeurs pendant l’année académique 2008–2009 (en milliers de dollars USD).</li>
<li><code>echelon</code>: échelon académique, soit adjoint (<code>adjoint</code>), aggrégé (<code>aggrege</code>) ou titulaire (<code>titulaire</code>).</li>
<li><code>domaine</code>: variable catégorielle indiquant le champ d’expertise du professeur, soit appliqué (<code>applique</code>) ou théorique (<code>theorique</code>).</li>
<li><code>sexe</code>: indicateur binaire pour le sexe, <code>homme</code> ou <code>femme</code>.</li>
<li><code>service</code>: nombre d’années de service.</li>
<li><code>annees</code>: nombre d’années depuis l’obtention du doctorat.</li>
</ul>
</div>
<div id="exm-moon-vanepps" class="theorem example">
<p><span class="theorem-title"><strong>Exemple 4.4 (Suggestion de montants de dons)</strong></span> L’étude 1 de <span class="citation" data-cites="Moon.VanEpps:2023">Moon et VanEpps (<a href="references.html#ref-Moon.VanEpps:2023" role="doc-biblioref">2023</a>)</span> (données <code>MV23_S1</code>, paquet <code>hecedsm</code>) porte sur la proportion de donateurs à un organisme de charité. Les participants au panel en ligne avaient la possibilité de gagner 25$ et de faire don d’une partie de cette somme à l’organisme de leur choix. Les données fournies incluent uniquement les personnes qui n’ont pas dépassé ce montant et qui ont indiqué avoir fait un don d’un montant non nul.</p>
</div>
</section>
<section id="analyse-exploratoire-des-données" class="level3" data-number="4.1.2">
<h3 data-number="4.1.2" class="anchored" data-anchor-id="analyse-exploratoire-des-données"><span class="header-section-number">4.1.2</span> Analyse exploratoire des données</h3>
<p>L’analyse exploratoire des données est une procédure itérative par laquelle nous interrogeons les données, en utilisant des informations auxiliaires, des statistiques descriptives et des graphiques, afin de mieux informer notre modélisation.</p>
<p>Elle est utile pour mieux comprendre les caractéristiques des données (plan d’échantillonnage, valeurs manquantes, valeurs aberrantes), la nature des observations, qu’il s’agisse de variables réponse ou explicatives et les interrelations entre variables.</p>
<p>Voir le <a href="https://tellingstorieswithdata.com/11-eda.html">Chapitre 11 de Alexander (2023)</a> pour des exemples. En particulier, il convient de vérifier</p>
<ul>
<li>que les variables catégorielles sont adéquatement traitées comme des facteurs (<code>factor</code>).</li>
<li>que les valeurs manquantes sont adéquatement déclarées comme telles (code d’erreur, 999, etc.)</li>
<li>s’il ne vaudrait mieux pas retirer certaines variables explicatives avec beaucoup de valeurs manquantes.</li>
<li>s’il ne vaudrait mieux pas fusionner des modalités de variables catégorielles si le nombre d’observation par modalité est trop faible.</li>
<li>qu’il n’y a pas de variable explicative dérivée de la variable réponse</li>
<li>que le sous-ensemble des observations employé pour l’analyse statistique est adéquat.</li>
<li>qu’il n’y a pas d’anomalies ou de valeurs aberrantes (par ex., 999 pour valeurs manquantes) qui viendraient fausser les résultats.</li>
</ul>
<div id="exm-college-aed" class="theorem example">
<p><span class="theorem-title"><strong>Exemple 4.5 (Analyse exploratoire des données <code>college</code>)</strong></span> Une analyse exploratoire des données est de mise avant d’ébaucher un modèle. Si le salaire augmente au fil des ans, on voit que l’hétérogénéité change en fonction de l’échelon et qu’il y a une relation claire entre ce dernier et le nombre d’années de service (les professeurs n’étant éligibles à des promotions qu’après un certain nombre d’années). Les professeurs adjoints qui ne sont pas promus sont généralement mis à la porte, aussi il y a moins d’occasions pour que les salaires varient sur cette échelle.</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div id="fig-edacollege" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-edacollege-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="regression-lineaire_files/figure-html/fig-edacollege-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:85.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-edacollege-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;4.1: Analyse exploratoire des données <code>college</code>: répartition des salaires en fonction de l’échelon et du nombre d’années de service
</figcaption>
</figure>
</div>
</div>
</div>
<p>Ainsi, le salaire augmente avec les années, mais la variabilité croît également. Les professeurs adjoints qui ne sont pas promus sont généralement mis à la porte, aussi il y a moins d’occasions pour que les salaires varient sur cette échelle. Il y a peu de femmes dans l’échantillon: moins d’information signifie moins de puissance pour détecter de petites différences de salaire. Si on fait un tableau de contingence de l’échelon et du sexe, on peut calculer la proportion relative homme/femme dans chaque échelon: 16% des profs adjoints, 16% pour les aggrégés, mais seulement 7% des titulaires alors que ces derniers sont mieux payés en moyenne.</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<table class="caption-top table table-sm table-striped small">
<caption>Tableau de contingence donnant le nombre de professeurs du collège par sexe et par échelon académique.</caption>
<thead>
<tr class="header">
<th style="text-align: left;"></th>
<th style="text-align: right;">adjoint</th>
<th style="text-align: right;">aggrege</th>
<th style="text-align: right;">titulaire</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">femme</td>
<td style="text-align: right;">11</td>
<td style="text-align: right;">10</td>
<td style="text-align: right;">18</td>
</tr>
<tr class="even">
<td style="text-align: left;">homme</td>
<td style="text-align: right;">56</td>
<td style="text-align: right;">54</td>
<td style="text-align: right;">248</td>
</tr>
</tbody>
</table>
</div>
</div>
<p>Plusieurs des variables explicatives potentielles des données <code>college</code> sont cat/gorielles (<code>echelon</code>, <code>sexe</code>, <code>discipline</code>), les deux dernières étant binaires. Les variables numériques <code>annees</code> et <code>service</code> sont fortement corrélées, avec une corrélation linéaire de 0.91.</p>
</div>
<div id="exm-donnees-manquantes-moon" class="theorem example">
<p><span class="theorem-title"><strong>Exemple 4.6 (Analyse exploratoire et données manquantes)</strong></span> Il convient de vérifier pour les données de <span class="citation" data-cites="Moon.VanEpps:2023">Moon et VanEpps (<a href="references.html#ref-Moon.VanEpps:2023" role="doc-biblioref">2023</a>)</span> que la description de la collecte coïncide avec la structure. Puisque les personnes qui n’ont pas donné ne remplissent pas le champ pour le montant, ce dernier indique une valeur manquante. Tous les montants des dons sont entre 0.25$ et 25$.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(MV23_S1, <span class="at">package =</span> <span class="st">"hecedsm"</span>)</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="fu">str</span>(MV23_S1)</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; tibble [869 × 4] (S3: tbl_df/tbl/data.frame)</span></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  $ before   : int [1:869] 0 1 0 1 1 1 1 0 1 0 ...</span></span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  $ donate   : int [1:869] 0 0 0 1 1 0 1 0 0 1 ...</span></span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  $ condition: Factor w/ 2 levels "open-ended","quantity": 1 1 1 1 2 2 2 1 1 1 ...</span></span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  $ amount   : num [1:869] NA NA NA 10 5 NA 20 NA NA 25 ...</span></span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(MV23_S1)</span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;      before          donate          condition       amount    </span></span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  Min.   :0.000   Min.   :0.00   open-ended:407   Min.   : 0.2  </span></span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  1st Qu.:0.000   1st Qu.:0.00   quantity  :462   1st Qu.: 5.0  </span></span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  Median :1.000   Median :1.00                    Median :10.0  </span></span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  Mean   :0.596   Mean   :0.73                    Mean   :10.7  </span></span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  3rd Qu.:1.000   3rd Qu.:1.00                    3rd Qu.:15.0  </span></span>
<span id="cb2-15"><a href="#cb2-15" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  Max.   :1.000   Max.   :1.00                    Max.   :25.0  </span></span>
<span id="cb2-16"><a href="#cb2-16" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  NA's   :1                                       NA's   :235</span></span></code><button title="Copier vers le presse-papier" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Si nous incluons <code>amount</code> comme variable réponse dans un modèle de régression, les 235 observations manquantes seront supprimées par défaut. Cela ne pose pas de problème si nous voulons comparer le montant moyen des personnes qui ont fait un don, mais dans le cas contraire, nous devons transformer les <code>NA</code> en zéros. La variable <code>donate</code> ne doit pas être incluse comme variable explicative dans le modèle, car elle permet de prédire exactement les personnes qui n’ont pas donné.</p>
</div>
</section>
<section id="spécification-du-modèle-pour-la-moyenne" class="level3" data-number="4.1.3">
<h3 data-number="4.1.3" class="anchored" data-anchor-id="spécification-du-modèle-pour-la-moyenne"><span class="header-section-number">4.1.3</span> Spécification du modèle pour la moyenne</h3>
<p>La première étape d’une analyse consiste à décider quelles variables explicatives doivent être ajoutées à l’équation de la moyenne, et sous quelle forme. Les modèles ne sont que des approximations de la réalité; la section 2.1 de <span class="citation" data-cites="Venables:2000">Venables (<a href="references.html#ref-Venables:2000" role="doc-biblioref">2000</a>)</span> affirme que, si nous pensons que la véritable fonction moyenne reliant les variables explicatives <span class="math inline">\(\boldsymbol{X}\)</span> et la réponse <span class="math inline">\(Y\)</span> est de la forme <span class="math inline">\(\mathsf{E}(Y \mid \boldsymbol{X}) = f(\boldsymbol{X})\)</span> pour <span class="math inline">\(f\)</span> suffisamment lisse, alors le modèle linéaire est une approximation du premier ordre. À des fins d’interprétation, il est logique de centrer sur la moyenne toute variable explicative continue, car cela facilite l’interprétation.</p>
<p>Dans un cadre expérimental, où la condition expérimentale est attribué de manière aléatoire, nous pouvons directement comparer les différents traitements et tirer des conclusions causales (puisque toutes les autres choses sont égales en moyenne constantes, toute différence détectable est due en moyenne à notre manipulation). Bien que nous nous abstenions généralement d’inclure d’autres variables explicatives afin de préserver la simplicité du modèle, il peut néanmoins être utile de prendre en compte certaines variables concomitantes qui expliquent une partie de la variabilité afin de filtrer le bruit de fond et d’augmenter la puissance de l’étude. Par exemple, pour les données de <span class="citation" data-cites="Baumann:1992">Baumann, Seifert-Kessell, et Jones (<a href="references.html#ref-Baumann:1992" role="doc-biblioref">1992</a>)</span>, l’objectif est de comparer les scores moyens en fonction de la méthode d’enseignement, nous inclurions <code>group</code>. Dans cet exemple, il serait également logique d’inclure le résultat <code>pretest1</code> en tant qu’élément explicatif pour <code>posttest1</code>. De cette façon, nous modéliserons la différence moyenne d’amélioration entre le pré-test et le post-test plutôt que le résultat final.</p>
<p>Dans un contexte observationnel, les participants dans différents groupes ont des caractéristiques différentes et nous devons donc tenir compte de ces différences. Les modèles linéaires utilisés en économie et en finance contiennent souvent des variables de contrôle au modèle pour tenir compte des différences potentielles dues aux variables sociodémographiques (âge, revenu, etc.) qui seraient corrélées à l’appartenance aux groupes. Tout test de coefficients ne prendrait en compte que la corrélation entre le résultat <span class="math inline">\(Y\)</span> et le facteur explicatif postulé d’intérêt.</p>
</section>
</section>
<section id="interprétation-des-coefficients" class="level2" data-number="4.2">
<h2 data-number="4.2" class="anchored" data-anchor-id="interprétation-des-coefficients"><span class="header-section-number">4.2</span> Interprétation des coefficients</h2>
<p>La spécification de la moyenne est <span class="math display">\[\begin{align*}
\mathsf{E}(Y_i \mid \boldsymbol{X}_i = \boldsymbol{x}_i) = \beta_0 + \beta_1 x_{i1} + \ldots + \beta_p x_{ip}.
\end{align*}\]</span> L’<strong>ordonnée à l’origine</strong> <span class="math inline">\(\beta_0\)</span> est la <strong>valeur moyenne de <span class="math inline">\(Y\)</span></strong> lorsque toutes les variables explicatives du modèles sont nulles, soit <span class="math inline">\(\boldsymbol{x}_i=\boldsymbol{0}_p\)</span>. <span class="math display">\[\begin{align*}
\beta_0 &amp;= \mathsf{E}(Y \mid X_1=0,X_2=0,\ldots,X_p=0) \\
&amp;= \beta_0 + \beta_1 \times 0 + \beta_2 \times 0 + \cdots + \beta_p \times 0
\end{align*}\]</span> Bien sur, il se peut que cette interprétation n’ait aucun sens dans le contexte étudié. Centrer les variables explicatives numériques (pour que leurs moyennes soit zéro) permet de rendre l’ordonnée à l’origine plus interprétable.</p>
<p>En régression linéaire, le paramètre <span class="math inline">\(\beta_j\)</span> mesure l’effet de la variable <span class="math inline">\(X_j\)</span> sur la variable <span class="math inline">\(Y\)</span> une fois que l’on tient compte des effets des autres variables explicatives. Pour chaque augmentation d’une unité de <span class="math inline">\(X_j\)</span>, la réponse <span class="math inline">\(Y\)</span> augmente en moyenne de <span class="math inline">\(\beta_j\)</span> lorsque les autres variables demeurent inchangées, <span class="math display">\[\begin{align*}
\beta_j &amp;= \mathsf{E}(Y \mid X_j= x_j+1, \boldsymbol{X}_{-j} = \boldsymbol{x}_{-j})  - \mathsf{E}(Y \mid \boldsymbol{X} = \boldsymbol{x}) \\
&amp;= \sum_{\substack{k=1\\k \neq j}}^p \beta_kx_k + \beta_j(x_j+1) - \sum_{k=1}^p \beta_k x_k
\end{align*}\]</span></p>
<div id="def-effet-marginal" class="theorem definition">
<p><span class="theorem-title"><strong>Définition 4.1 (Effet marginal)</strong></span> On définit l’effet marginal comme la dérivée première de la moyenne conditionnelle par rapport à <span class="math inline">\(X_j\)</span>, soit <span class="math display">\[\text{effet marginal de }X_j =  \frac{\partial \mathsf{E}(Y \mid \boldsymbol{X})}{ \partial X_j}.\]</span> Le coefficient <span class="math inline">\(\beta_j\)</span> est aussi l’<em>effet marginal</em> de la variable <span class="math inline">\(X_j\)</span>.</p>
</div>
<p>Les variables indicatrices, qui prennent typiquement des valeurs de <span class="math inline">\(-1\)</span>, <span class="math inline">\(0\)</span> et <span class="math inline">\(1\)</span>, servent à indiquer l’appartenance aux différentes modalités d’une variable catégorielle. Par exemple, pour une variable indicatrice binaire, nous pouvons créer une colonne dont les entrées sont <span class="math inline">\(1\)</span> pour le groupe de traitement et <span class="math inline">\(0\)</span> pour le groupe de contrôle.</p>
<div id="exm-moon" class="theorem example">
<p><span class="theorem-title"><strong>Exemple 4.7 (Modèle linéaire avec une seule variable binaire)</strong></span> Considérons par exemple un modèle linéaire pour les données de <span class="citation" data-cites="Moon.VanEpps:2023">Moon et VanEpps (<a href="references.html#ref-Moon.VanEpps:2023" role="doc-biblioref">2023</a>)</span> qui inclut le montant (<code>amount</code>) (en dollars, de 0 pour les personnes qui n’ont pas fait de don, jusqu’à 25 dollars).</p>
<p>L’équation du modèle linéaire simple qui inclut la variable binaire <code>condition</code> est <span class="math display">\[\begin{align*}
\mathsf{E}(\texttt{amount} \mid \texttt{condition})&amp;= \beta_0 + \beta_1 \mathbf{1}_{\texttt{condition}=\texttt{quantity}}.
\\&amp;= \begin{cases}
\beta_0, &amp; \texttt{condition}=0, \\
\beta_0 + \beta_1 &amp; \texttt{condition}=1.
\end{cases}
\end{align*}\]</span> Soit <span class="math inline">\(\mu_0\)</span> l’espérance du montant pour le groupe contrôle (<code>open-ended</code>) et <span class="math inline">\(\mu_1\)</span> celui des participants du groupe de traitement (<code>quantity</code>). Un modèle linéaire qui ne contient qu’une variable binaire <span class="math inline">\(X\)</span> comme régresseur revient à spécifier une moyenne différente pour chacun des deux groupes. L’ordonnée à l’origine <span class="math inline">\(\beta_0\)</span> est la moyenne du groupe contrôle. La moyenne du groupe traitement (<code>quantity</code>) est <span class="math inline">\(\beta_0 + \beta_1 = \mu_1\)</span> et donc <span class="math inline">\(\beta_1=\mu_1-\mu_0\)</span> est la différence du montant moyen de dons entre le groupe <code>open-ended</code> et le groupe <code>quantity</code>. Cette paramétrisation est commode si on veut tester s’il y a une différence moyenne entre les deux groupes, puisque cette hypothèse nulle correspond à <span class="math inline">\(\mathscr{H}_0: \beta_1=0\)</span>.</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div id="fig-donation-moon" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-donation-moon-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="regression-lineaire_files/figure-html/fig-donation-moon-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:85.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-donation-moon-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;4.2: Modèle linéaire simple pour les données <code>MV23_S1</code> avec <code>condition</code> comme variable explicative binaire, avec nuage de points décalés et un diagramme en demi-violin. Les cercles indiquent les moyennes de l’échantillon.
</figcaption>
</figure>
</div>
</div>
</div>
<p>Même si le modèle linéaire définit une droite, cette dernière ne peut être évaluée qu’à <span class="math inline">\(0\)</span> ou <span class="math inline">\(1\)</span>; la <a href="#fig-donation-moon" class="quarto-xref">Figure&nbsp;<span>4.2</span></a> montre cette droite avec en plus un nuage de points des montants, décalés horizontalement, et de la densité pour chaque condition. Le point coloré indique la moyenne empirique, qui correspond aux estimations.</p>
<p>Même s’il est clair que les données sont fortement discrétisées avec beaucoup de doublons et de zéros, l’échantillon a une taille de 869 observations, donc les conclusions quant aux moyennes de groupe seront fiables.</p>
</div>
<p>Considérons des variables catégorielles avec <span class="math inline">\(K &gt; 2\)</span> niveaux, qui dans <strong>R</strong> sont de la classe <code>factor</code>. La paramétrisation par défaut des facteurs se fait en termes de contraste de traitement: le niveau de référence du facteur (par défaut, la première valeur dans l’ordre alphanumérique) sera traité comme la catégorie de référence et assimilé à l’ordonnée à l’origine. Le logiciel créera alors un ensemble de <span class="math inline">\(K-1\)</span> variables indicatrices pour un facteur à <span class="math inline">\(K\)</span> niveaux, chacune d’entre elles ayant un pour la catégorie représentée et zéro dans le cas contraire.</p>
<div id="exm-baumann-dummies" class="theorem example">
<p><span class="theorem-title"><strong>Exemple 4.8 (Codage binaire pour les variables catégorielles)</strong></span> Considérons l’étude de <span class="citation" data-cites="Baumann:1992">Baumann, Seifert-Kessell, et Jones (<a href="references.html#ref-Baumann:1992" role="doc-biblioref">1992</a>)</span> et la seule variable <code>group</code>. Les données sont classées par groupe : les 22 premières observations concernent le groupe <code>DR</code>, les 22 suivantes le groupe <code>DRTA</code> et les 22 dernières le groupe <code>TA</code>. Si nous ajustons un modèle avec <code>groupe</code> comme variable catégorielle</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(BSJ92, <span class="at">package =</span> <span class="st">"hecedsm"</span>)</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="fu">class</span>(BSJ92<span class="sc">$</span>group) <span class="co"># Vérifier que group est un facteur</span></span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [1] "factor"</span></span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a><span class="fu">levels</span>(BSJ92<span class="sc">$</span>group) <span class="co"># première valeur est la catégorie de référence</span></span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [1] "DR"   "DRTA" "TA"</span></span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Imprimer trois lignes de la matrice du modèle</span></span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a><span class="co"># (trois enfants de groupes différents)</span></span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a><span class="fu">model.matrix</span>(<span class="sc">~</span> group, <span class="at">data =</span> BSJ92)[<span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">23</span>,<span class="dv">47</span>),]</span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;    (Intercept) groupDRTA groupTA</span></span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 1            1         0       0</span></span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 23           1         1       0</span></span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 47           1         0       1</span></span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Comparer avec les niveaux des facteurs</span></span>
<span id="cb3-14"><a href="#cb3-14" aria-hidden="true" tabindex="-1"></a>BSJ92<span class="sc">$</span>group[<span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">23</span>,<span class="dv">47</span>)]</span>
<span id="cb3-15"><a href="#cb3-15" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [1] DR   DRTA TA  </span></span>
<span id="cb3-16"><a href="#cb3-16" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Levels: DR DRTA TA</span></span></code><button title="Copier vers le presse-papier" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Si nous ajustons un modèle avec <code>groupe</code> comme variable catégorielle, la spécification de la moyenne du modèle est <span class="math display">\[\mathsf{E}(Y \mid \texttt{group})= \beta_0 + \beta_1\mathbf{1}_{\texttt{group}=\texttt{DRTA}} + \beta_2\mathbf{1}_{\texttt{group}=\texttt{TA}}.\]</span> Puisque la variable <code>group</code> est catégorielle avec <span class="math inline">\(K=3\)</span> niveaux, il nous faut mettre <span class="math inline">\(K-1 = 2\)</span> variables indicatrices.</p>
<p>Avec la paramétrisation en termes de <strong>traitements</strong> (option par défaut), on obtient</p>
<ul>
<li><span class="math inline">\(\mathbf{1}_{\texttt{group}=\texttt{DRTA}}=1\)</span> si <code>group=DRTA</code> et zéro sinon,</li>
<li><span class="math inline">\(\mathbf{1}_{\texttt{group}=\texttt{TA}}=1\)</span> si <code>group=TA</code> et zéro sinon.</li>
</ul>
<p>Étant donné que le modèle comprend une ordonnée à l’origine et que le modèle décrit en fin de compte trois moyennes de groupe, nous n’avons besoin que de deux variables supplémentaires. Avec la paramétrisation en termes de <strong>traitements</strong>, la moyenne du groupe de référence est l’ordonnée à l’origine. Si <code>group</code>=<code>DR</code> (référence), les deux variables indicatrices binaires <code>groupDRTA</code> et <code>groupTA</code> sont nulles. La moyenne de chaque groupe est</p>
<ul>
<li><span class="math inline">\(\mu_{\texttt{DR}} = \beta_0\)</span>,</li>
<li><span class="math inline">\(\mu_{\texttt{DRTA}}=\beta_0 + \beta_1\)</span> et</li>
<li><span class="math inline">\(\mu_{\texttt{TA}} = \beta_0 + \beta_2\)</span>.</li>
</ul>
<p>Ainsi, <span class="math inline">\(\beta_1\)</span> est la différence de moyenne entre les groupes <code>DRTA</code> et<code>DR</code>, et de la même façon <span class="math inline">\(\beta_2=\mu_{\texttt{TA}}- \mu_{\texttt{DR}}\)</span>.</p>
</div>
<div id="rem-sumtozero" class="proof remark">
<p><span class="proof-title"><em>Remarque 4.1</em> (Contrainte de somme nulle). </span>La paramétrisation discutée ci-dessus, qui est la valeur par défaut de la fonction <code>lm</code>, n’est pas la seule disponible. Plutôt que de comparer la moyenne de chaque groupe avec celle d’une catégorie de référence, la paramétrisation par défaut pour les modèles d’analyse de la variance est en termes de contraintes de somme nulle pour les coefficients, où l’ordonnée à l’origine est la moyenne équi-pondérée de chaque groupe, et les paramètres <span class="math inline">\(\beta_1, \ldots, \beta_{K-1}\)</span> sont des différences par rapport à cette moyenne.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="fu">model.matrix</span>(</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>    <span class="sc">~</span> group,</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>    <span class="at">data =</span> BSJ92,</span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a>    <span class="at">contrasts.arg =</span> <span class="fu">list</span>(<span class="at">group =</span> <span class="st">"contr.sum"</span>))</span></code><button title="Copier vers le presse-papier" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-layout-align="center">
<div id="tbl-sum2zero" class="cell quarto-float quarto-figure quarto-figure-center anchored" data-layout-align="center">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-sum2zero-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Tableau&nbsp;4.1: Paramétrisation des variables indicatrices pour la contrainte de somme nulle pour une variable catégorielle.
</figcaption>
<div aria-describedby="tbl-sum2zero-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="cell-output-display">
<table class="do-not-create-environment cell caption-top table table-sm table-striped small">
<thead>
<tr class="header">
<th style="text-align: left;"></th>
<th style="text-align: right;">(Intercept)</th>
<th style="text-align: right;">group1</th>
<th style="text-align: right;">group2</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">DR</td>
<td style="text-align: right;">1</td>
<td style="text-align: right;">1</td>
<td style="text-align: right;">0</td>
</tr>
<tr class="even">
<td style="text-align: left;">DRTA</td>
<td style="text-align: right;">1</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">1</td>
</tr>
<tr class="odd">
<td style="text-align: left;">TA</td>
<td style="text-align: right;">1</td>
<td style="text-align: right;">-1</td>
<td style="text-align: right;">-1</td>
</tr>
</tbody>
</table>
</div>
</div>
</figure>
</div>
</div>
<p>Dans la contrainte de somme nulle, nous obtenons à nouveau deux variables indicatrices, <code>group1</code> et <code>group2</code>, ainsi que l’ordonnée à l’origine. La valeur de <code>group1</code> est <span class="math inline">\(1\)</span> si <code>group=DR</code>, <span class="math inline">\(0\)</span> si <code>group=DRTA</code> et <span class="math inline">\(-1\)</span> si <code>group=TA</code>. ous trouvons <span class="math inline">\(\mu_{\texttt{DR}} = \beta_0 + \beta_1\)</span>, <span class="math inline">\(\mu_{\texttt{DRTA}}=\beta_0 + \beta_2\)</span> et <span class="math inline">\(\mu_{\texttt{TA}} = \beta_0 - \beta_1 - \beta_2\)</span>. Quelques manipulations algébriques révèlent que <span class="math inline">\(\beta_0 = (\mu_{\texttt{DR}} +\mu_{\texttt{DRTA}}+\mu_{\texttt{TA}})/3\)</span>, l’espérance équipondérée des différents niveaux. De manière générale, l’ordonnée à l’origine moins la somme de tous les autres coefficients liés aux facteurs.</p>
<p>En supprimant l’ordonnée à l’origine, on pourrait inclure trois variables indicatrices pour chaque niveau d’un facteur et chaque paramètre correspondrait alors à la moyenne. Ce n’est pas recommandé dans <strong>R</strong> car le logiciel traite différemment les modèles sans ordonnée à l’origine et certains résultats seront absurdes (par exemple, le coefficient de détermination sera erroné).</p>
</div>
<div id="exm-college-coeff" class="theorem example">
<p><span class="theorem-title"><strong>Exemple 4.9 (Interprétation des coefficients)</strong></span> On considère un modèle de régression pour les données <code>college</code> qui inclut le sexe, l’échelon académique, le nombre d’années de service et le domaine d’expertise (appliquée ou théorique).</p>
<p>Le modèle linéaire postulé s’écrit</p>
<p><span class="math display">\[\begin{align*}
\texttt{salaire} &amp;= \beta_0 + \beta_1 \mathbf{1}_{\texttt{sexe}=\texttt{femme}} +\beta_2 \mathbf{1}_{\texttt{domaine}=\texttt{theorique}} \\&amp;\quad +\beta_3 \mathbf{1}_{\texttt{echelon}=\texttt{aggrege}}
+\beta_4 \mathbf{1}_{\texttt{echelon}=\texttt{titulaire}}  +\beta_5 \texttt{service} + \varepsilon.
\end{align*}\]</span></p>
<div class="cell" data-layout-align="center">
<div id="tbl-collegecoefs" class="cell quarto-float quarto-figure quarto-figure-center anchored" data-layout-align="center">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-collegecoefs-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Tableau&nbsp;4.2: Estimations des coefficients du modèle linéaire pour les données <span class="math inline">\(\texttt{college}\)</span> (en dollars USD, arrondis à l’unité).
</figcaption>
<div aria-describedby="tbl-collegecoefs-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="cell-output-display">
<table class="do-not-create-environment cell caption-top table table-sm table-striped small">
<colgroup>
<col style="width: 16%">
<col style="width: 16%">
<col style="width: 16%">
<col style="width: 16%">
<col style="width: 16%">
<col style="width: 16%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: right;"><span class="math inline">\(\widehat{\beta}_0\)</span></th>
<th style="text-align: right;"><span class="math inline">\(\widehat{\beta}_1\)</span></th>
<th style="text-align: right;"><span class="math inline">\(\widehat{\beta}_2\)</span></th>
<th style="text-align: right;"><span class="math inline">\(\widehat{\beta}_3\)</span></th>
<th style="text-align: right;"><span class="math inline">\(\widehat{\beta}_4\)</span></th>
<th style="text-align: right;"><span class="math inline">\(\widehat{\beta}_5\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: right;">86596</td>
<td style="text-align: right;">-4771</td>
<td style="text-align: right;">-13473</td>
<td style="text-align: right;">14560</td>
<td style="text-align: right;">49160</td>
<td style="text-align: right;">-89</td>
</tr>
</tbody>
</table>
</div>
</div>
</figure>
</div>
</div>
<p>L’interprétation des coefficients est la suivante:</p>
<ul>
<li>L’ordonnée à l’origine <span class="math inline">\(\beta_0\)</span> correspond au salaire moyen d’un professeur adjoint (un homme) qui vient de compléter ses études et qui travaille dans un domaine appliqué: on estime ce salaire à <span class="math inline">\(\widehat{\beta}_0=86596\)</span> dollars.</li>
<li>toutes choses étant égales par ailleurs (même domaine, échelon et années depuis le dernier diplôme), l’écart de salaire entre un homme et un femme est estimé à <span class="math inline">\(\widehat{\beta}_1=-4771\)</span> dollars.</li>
<li><em>ceteris paribus</em>, un(e) professeur(e) qui oeuvre dans un domaine théorique gagne <span class="math inline">\(\beta_2\)</span> dollars de plus qu’une personne du même sexe dans un domaine appliqué; on estime cette différence à <span class="math inline">\(-13473\)</span> dollars.</li>
<li><em>ceteris paribus</em>, la différence moyenne de salaire entre professeurs adjoints et aggrégés est estimée à <span class="math inline">\(\widehat{\beta}_3=14560\)</span> dollars.</li>
<li><em>ceteris paribus</em>, la différence moyenne de salaire entre professeurs adjoints et titulaires est de <span class="math inline">\(\widehat{\beta}_4=49160\)</span> dollars.</li>
<li>au sein d’un même échelon, chaque année supplémentaire de service mène à une augmentation de salaire annuelle moyenne de <span class="math inline">\(\widehat{\beta}_5=-89\)</span> dollars.</li>
</ul>
</div>
<div id="rem-polynomes" class="proof remark">
<p><span class="proof-title"><em>Remarque 4.2</em> (Polynômes). </span>Il n’est pas toujours possible de fixer la valeur des autres colonnes de <span class="math inline">\(\mathbf{X}\)</span> si plusieurs colonnes contiennent des transformations ou des fonctions d’une même variable explicative. Par exemple, on pourrait par exemple considérer un polynôme d’ordre <span class="math inline">\(k\)</span> (ordinairement, on prendre <span class="math inline">\(k\leq 3\)</span>), <span class="math display">\[\begin{align*}
\mathsf{E}(Y \mid X=x)=\beta_0+ \beta_1 x+ \beta_2 x^2 + \ldots +\beta_k x^k.
\end{align*}\]</span> Si l’on inclut un terme d’ordre <span class="math inline">\(k\)</span>, <span class="math inline">\(x^k\)</span>, il faut <strong>toujours</strong> inclure les termes d’ordre inférieur <span class="math inline">\(1, x, \ldots, x^{k-1}\)</span> pour l’interprétabilité du modèle résultant (autrement, cela revient à choisir un polynôme en imposant que certains coefficients soient zéros). L’interprétation des effets des covariables nonlinéaires (même polynomiaux) est complexe parce qu’on ne peut pas « fixer la valeur des autres variables »: l’effet d’une augmentation d’une unité de <span class="math inline">\(x\)</span> <em>dépend de la valeur de cette dernière</em>. L’effet marginal de <span class="math inline">\(x\)</span> est <span class="math inline">\(\beta_1 + \sum_{j=1}^{k-1}j \beta_{j+1}x^j\)</span>.</p>
<p>L’utilisation de polynôme, plus flexibles, n’est généralement pas recommendée car ces derniers se généralisent mal hors de l’étendue observée des données. L’utilisation de splines avec une pénalité sur les coefficients, avec des modèles additifs, offre plus de flexibilité.</p>
</div>
<div id="exm-quadmod" class="theorem example">
<p><span class="theorem-title"><strong>Exemple 4.10 (Modèle quadratique pour les données automobile)</strong></span> Considérons un modèle de régression linéaire pour l’autonomie d’essence en fonction de la puissance du moteur pour différentes voitures dont les caractéristiques sont données dans le jeu de données <code>automobiles</code>. Le modèle postulé incluant un terme quadratique est <span class="math display">\[\begin{align*}
\texttt{autonomie}_i = \beta_0 + \beta_1 \texttt{puissance}_i + \beta_2 \texttt{puissance}_i^2 + \varepsilon_i
\end{align*}\]</span> Afin de comparer l’ajustement du modèle quadratique, on peut inclure également la droite ajustée du modèle de régression simple qui n’inclut que puissance.</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div id="fig-autoquad2d" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-autoquad2d-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="regression-lineaire_files/figure-html/fig-autoquad2d-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:85.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-autoquad2d-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;4.3: Modèle de régression avec terme quadratique pour la puissance (gris), versus spline cubique pénalisée (ligne traitillée).
</figcaption>
</figure>
</div>
</div>
</div>
<p>À vue d’oeil, l’ajustement quadratique est bon: nous verrons plus tard à l’aide de test si une simple droite aurait été suffisante. On voit aussi dans la <a href="#fig-autoquad2d" class="quarto-xref">Figure&nbsp;<span>4.3</span></a> que l’autonomie d’essence décroît rapidement quand la puissance croît entre <span class="math inline">\(0\)</span> et <span class="math inline">\(189.35\)</span>, mais semble remonter légèrement par la suite pour les voitures qui un moteur de plus de 200 chevaux-vapeurs, ce que le modèle quadratique capture. Prenez garde en revanche à l’extrapolation là où vous n’avez pas de données (comme l’illustre remarquablement bien <a href="https://web.archive.org/web/20210315050023/https://livefreeordichotomize.com/2020/05/05/model-detective/">le modèle cubique de Hassett pour le nombre de cas quotidiens de coronavirus</a>).</p>
<p>La représentation graphique du modèle polynomial de degré 2 présenté dans la <a href="#fig-autoquad2d" class="quarto-xref">Figure&nbsp;<span>4.3</span></a> peut sembler contre-intuitive, mais c’est une projection en 2D d’un plan 3D de coordonnées <span class="math inline">\(\beta_0 + \beta_1x-y +\beta_2z =0\)</span>, où <span class="math inline">\(x=\texttt{puissance}\)</span>, <span class="math inline">\(z=\texttt{puissance}^2\)</span> et <span class="math inline">\(y=\texttt{autonomie}\)</span>. La physique et le bon-sens imposent la contrainte <span class="math inline">\(z = x^2\)</span>, et donc les valeurs ajustées vivent sur une courbe dans un sous-espace du plan ajusté, représenté en gris dans la <a href="#fig-hyperplan" class="quarto-xref">Figure&nbsp;<span>4.4</span></a>.</p>
<div class="cell" data-layout-align="center">
<div id="fig-hyperplan" class="cell-output-display quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-hyperplan-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="plotly html-widget html-fill-item" id="htmlwidget-0748faf2f2c9924061cd" style="width:85%;height:474.624px;"></div>
<script type="application/json" data-for="htmlwidget-0748faf2f2c9924061cd">{"x":{"visdat":{"d39d216e8956":["function () ","plotlyVisDat"],"d39d55e62e98":["function () ","data"]},"cur_data":"d39d55e62e98","attrs":{"d39d216e8956":{"colors":"grey","alpha_stroke":1,"sizes":[10,100],"spans":[1,20],"x":{},"y":{},"z":{},"type":"scatter3d","mode":"markers","name":"data","opacity":0.80000000000000004,"marker":{"color":"black","size":4,"hoverinfo":"skip","opacity":0.80000000000000004},"inherit":true},"d39d216e8956.1":{"z":{},"type":"surface","x":[46,230],"y":[2116,52900],"name":"Relation entre puissance et autonomie","opacity":0.75,"cauto":false,"surfacecolor":[0,0,0],"inherit":false},"d39d55e62e98":{"colors":"grey","alpha_stroke":1,"sizes":[10,100],"spans":[1,20],"x":{},"y":{},"z":{},"type":"scatter3d","mode":"lines","color":"grey","inherit":true}},"layout":{"margin":{"b":40,"l":60,"t":25,"r":10},"scene":{"xaxis":{"title":"puissance (chevaux vapeurs)"},"yaxis":{"title":"puissance carré"},"zaxis":{"title":"autonomie d'essence (miles au gallon)"}},"hovermode":"closest","showlegend":false,"legend":{"yanchor":"top","y":0.5}},"source":"A","config":{"modeBarButtonsToAdd":["hoverclosest","hovercompare"],"showSendToCloud":false},"data":[{"x":[130,165,150,150,140,198,220,215,225,190,170,160,150,225,95,95,97,85,88,46,87,90,95,113,90,215,200,210,193,88,90,95,100,105,100,88,100,165,175,153,150,180,170,175,110,72,100,88,86,90,70,76,65,69,60,70,95,80,54,90,86,165,175,150,153,150,208,155,160,190,97,150,130,140,150,112,76,87,69,86,92,97,80,88,175,150,145,137,150,198,150,158,150,215,225,175,105,100,100,88,95,46,150,167,170,180,100,88,72,94,90,85,107,90,145,230,49,75,91,112,150,110,122,180,95,100,100,67,80,65,75,100,110,105,140,150,150,140,150,83,67,78,52,61,75,75,75,97,93,67,95,105,72,72,170,145,150,148,110,105,110,95,110,110,129,75,83,100,78,96,71,97,97,70,90,95,88,98,115,53,86,81,92,79,83,140,150,120,152,100,105,81,90,52,60,70,53,100,78,110,95,71,70,75,72,102,150,88,108,120,180,145,130,150,68,80,58,96,70,145,110,145,130,110,105,100,98,180,170,190,149,78,88,75,89,63,83,67,78,97,110,110,48,66,52,70,60,110,140,139,105,95,85,88,100,90,105,85,110,120,145,165,139,140,68,95,97,75,95,105,85,97,103,125,115,133,71,68,115,85,88,90,110,130,129,138,135,155,142,125,150,71,65,80,80,77,125,71,90,70,70,65,69,90,115,115,90,76,60,70,65,90,88,90,90,78,90,75,92,75,65,105,65,48,48,67,67,67,67,62,132,100,88,72,84,84,92,110,84,58,64,60,67,65,62,68,63,65,65,74,75,75,100,74,80,76,116,120,110,105,88,85,88,88,88,85,84,90,92,74,68,68,63,70,88,75,70,67,67,67,110,85,92,112,96,84,90,86,52,84,79,82],"y":[16900,27225,22500,22500,19600,39204,48400,46225,50625,36100,28900,25600,22500,50625,9025,9025,9409,7225,7744,2116,7569,8100,9025,12769,8100,46225,40000,44100,37249,7744,8100,9025,10000,11025,10000,7744,10000,27225,30625,23409,22500,32400,28900,30625,12100,5184,10000,7744,7396,8100,4900,5776,4225,4761,3600,4900,9025,6400,2916,8100,7396,27225,30625,22500,23409,22500,43264,24025,25600,36100,9409,22500,16900,19600,22500,12544,5776,7569,4761,7396,8464,9409,6400,7744,30625,22500,21025,18769,22500,39204,22500,24964,22500,46225,50625,30625,11025,10000,10000,7744,9025,2116,22500,27889,28900,32400,10000,7744,5184,8836,8100,7225,11449,8100,21025,52900,2401,5625,8281,12544,22500,12100,14884,32400,9025,10000,10000,4489,6400,4225,5625,10000,12100,11025,19600,22500,22500,19600,22500,6889,4489,6084,2704,3721,5625,5625,5625,9409,8649,4489,9025,11025,5184,5184,28900,21025,22500,21904,12100,11025,12100,9025,12100,12100,16641,5625,6889,10000,6084,9216,5041,9409,9409,4900,8100,9025,7744,9604,13225,2809,7396,6561,8464,6241,6889,19600,22500,14400,23104,10000,11025,6561,8100,2704,3600,4900,2809,10000,6084,12100,9025,5041,4900,5625,5184,10404,22500,7744,11664,14400,32400,21025,16900,22500,4624,6400,3364,9216,4900,21025,12100,21025,16900,12100,11025,10000,9604,32400,28900,36100,22201,6084,7744,5625,7921,3969,6889,4489,6084,9409,12100,12100,2304,4356,2704,4900,3600,12100,19600,19321,11025,9025,7225,7744,10000,8100,11025,7225,12100,14400,21025,27225,19321,19600,4624,9025,9409,5625,9025,11025,7225,9409,10609,15625,13225,17689,5041,4624,13225,7225,7744,8100,12100,16900,16641,19044,18225,24025,20164,15625,22500,5041,4225,6400,6400,5929,15625,5041,8100,4900,4900,4225,4761,8100,13225,13225,8100,5776,3600,4900,4225,8100,7744,8100,8100,6084,8100,5625,8464,5625,4225,11025,4225,2304,2304,4489,4489,4489,4489,3844,17424,10000,7744,5184,7056,7056,8464,12100,7056,3364,4096,3600,4489,4225,3844,4624,3969,4225,4225,5476,5625,5625,10000,5476,6400,5776,13456,14400,12100,11025,7744,7225,7744,7744,7744,7225,7056,8100,8464,5476,4624,4624,3969,4900,7744,5625,4900,4489,4489,4489,12100,7225,8464,12544,9216,7056,8100,7396,2704,7056,6241,6724],"z":[18,15,18,16,17,15,14,14,14,15,15,14,15,14,24,22,18,21,27,26,25,24,25,26,21,10,10,11,9,27,28,25,19,16,17,19,18,14,14,14,14,12,13,13,18,22,19,18,23,28,30,30,31,35,27,26,24,25,23,20,21,13,14,15,14,17,11,13,12,13,19,15,13,13,14,18,22,21,26,22,28,23,28,27,13,14,13,14,15,12,13,13,14,13,12,13,18,16,18,18,23,26,11,12,13,12,18,20,21,22,18,19,21,26,15,16,29,24,20,19,15,24,20,11,20,19,15,31,26,32,25,16,16,18,16,13,14,14,14,29,26,26,31,32,28,24,26,24,26,31,19,18,15,15,16,15,16,14,17,16,15,18,21,20,13,29,23,20,23,24,25,24,18,29,19,23,23,22,25,33,28,25,25,26,27,17.5,16,15.5,14.5,22,22,24,22.5,29,24.5,29,33,20,18,18.5,17.5,29.5,32,28,26.5,20,13,19,19,16.5,16.5,13,13,13,31.5,30,36,25.5,33.5,17.5,17,15.5,15,17.5,20.5,19,18.5,16,15.5,15.5,16,29,24.5,26,25.5,30.5,33.5,30,30.5,22,21.5,21.5,43.100000000000001,36.100000000000001,32.799999999999997,39.399999999999999,36.100000000000001,19.899999999999999,19.399999999999999,20.199999999999999,19.199999999999999,20.5,20.199999999999999,25.100000000000001,20.5,19.399999999999999,20.600000000000001,20.800000000000001,18.600000000000001,18.100000000000001,19.199999999999999,17.699999999999999,18.100000000000001,17.5,30,27.5,27.199999999999999,30.899999999999999,21.100000000000001,23.199999999999999,23.800000000000001,23.899999999999999,20.300000000000001,17,21.600000000000001,16.199999999999999,31.5,29.5,21.5,19.800000000000001,22.300000000000001,20.199999999999999,20.600000000000001,17,17.600000000000001,16.5,18.199999999999999,16.899999999999999,15.5,19.199999999999999,18.5,31.899999999999999,34.100000000000001,35.700000000000003,27.399999999999999,25.399999999999999,23,27.199999999999999,23.899999999999999,34.200000000000003,34.5,31.800000000000001,37.299999999999997,28.399999999999999,28.800000000000001,26.800000000000001,33.5,41.5,38.100000000000001,32.100000000000001,37.200000000000003,28,26.399999999999999,24.300000000000001,19.100000000000001,34.299999999999997,29.800000000000001,31.300000000000001,37,32.200000000000003,46.600000000000001,27.899999999999999,40.799999999999997,44.299999999999997,43.399999999999999,36.399999999999999,30,44.600000000000001,33.799999999999997,29.800000000000001,32.700000000000003,23.699999999999999,35,32.399999999999999,27.199999999999999,26.600000000000001,25.800000000000001,23.5,30,39.100000000000001,39,35.100000000000001,32.299999999999997,37,37.700000000000003,34.100000000000001,34.700000000000003,34.399999999999999,29.899999999999999,33,33.700000000000003,32.399999999999999,32.899999999999999,31.600000000000001,28.100000000000001,30.699999999999999,25.399999999999999,24.199999999999999,22.399999999999999,26.600000000000001,20.199999999999999,17.600000000000001,28,27,34,31,29,27,24,36,37,31,38,36,36,36,34,38,32,38,25,38,26,22,32,36,27,27,44,32,28,31],"type":"scatter3d","mode":"markers","name":"data","opacity":0.80000000000000004,"marker":{"color":"black","size":4,"hoverinfo":"skip","opacity":0.80000000000000004,"line":{"color":"rgba(31,119,180,1)"},"showscale":false},"error_y":{"color":"rgba(31,119,180,1)"},"error_x":{"color":"rgba(31,119,180,1)"},"line":{"color":"rgba(31,119,180,1)"},"frame":null},{"colorbar":{"title":"autonomie<br />surf","ticklen":2,"len":0.5,"lenmode":"fraction","y":1,"yanchor":"top"},"colorscale":[["0","rgba(190,190,190,1)"],["1","rgba(190,190,190,1)"]],"showscale":false,"z":[[38.059191113772343,-47.719700796540607],[100.55073645547486,14.771844545161919]],"type":"surface","x":[46,230],"y":[2116,52900],"name":"Relation entre puissance et autonomie","opacity":0.75,"cauto":false,"surfacecolor":[0,0,0],"frame":null},{"x":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250],"y":[0,1,4,9,16,25,36,49,64,81,100,121,144,169,196,225,256,289,324,361,400,441,484,529,576,625,676,729,784,841,900,961,1024,1089,1156,1225,1296,1369,1444,1521,1600,1681,1764,1849,1936,2025,2116,2209,2304,2401,2500,2601,2704,2809,2916,3025,3136,3249,3364,3481,3600,3721,3844,3969,4096,4225,4356,4489,4624,4761,4900,5041,5184,5329,5476,5625,5776,5929,6084,6241,6400,6561,6724,6889,7056,7225,7396,7569,7744,7921,8100,8281,8464,8649,8836,9025,9216,9409,9604,9801,10000,10201,10404,10609,10816,11025,11236,11449,11664,11881,12100,12321,12544,12769,12996,13225,13456,13689,13924,14161,14400,14641,14884,15129,15376,15625,15876,16129,16384,16641,16900,17161,17424,17689,17956,18225,18496,18769,19044,19321,19600,19881,20164,20449,20736,21025,21316,21609,21904,22201,22500,22801,23104,23409,23716,24025,24336,24649,24964,25281,25600,25921,26244,26569,26896,27225,27556,27889,28224,28561,28900,29241,29584,29929,30276,30625,30976,31329,31684,32041,32400,32761,33124,33489,33856,34225,34596,34969,35344,35721,36100,36481,36864,37249,37636,38025,38416,38809,39204,39601,40000,40401,40804,41209,41616,42025,42436,42849,43264,43681,44100,44521,44944,45369,45796,46225,46656,47089,47524,47961,48400,48841,49284,49729,50176,50625,51076,51529,51984,52441,52900,53361,53824,54289,54756,55225,55696,56169,56644,57121,57600,58081,58564,59049,59536,60025,60516,61009,61504,62001,62500],"z":[56.900099702112975,56.435140608266394,55.972642586621362,55.512605637177877,55.055029759935948,54.59991495489556,54.147261222056713,53.697068561419428,53.249336972983684,52.804066456749489,52.361257012716834,51.920908640885735,51.483021341256183,51.04759511382818,50.614629958601718,50.184125875576811,49.756082864753452,49.330500926131641,48.907380059711365,48.48672026549265,48.068521543475484,47.652783893659866,47.239507316045781,46.828691810633259,46.420337377422278,46.014444016412845,45.611011727604961,45.210040510998631,44.811530366593843,44.415481294390602,44.02189329438891,43.630766366588766,43.24210051099017,42.855895727593115,42.472152016397615,42.090869377403671,41.712047810611267,41.335687316020412,40.961787893631097,40.590349543443338,40.221372265457113,39.85485605967245,39.490800926089335,39.129206864707768,38.77007387552775,38.413401958549272,38.059191113772343,37.707441341196969,37.358152640823128,37.01132501265085,36.666958456680113,36.325052972910932,35.985608561343291,35.648625221977198,35.314102954812654,34.982041759849658,34.652441637088209,34.325302586528309,34.000624608169957,33.678407702013153,33.358651868057891,33.041357106304183,32.726523416752023,32.414150799401412,32.104239254252342,31.796788781304823,31.491799380558856,31.189271052014433,30.889203795671559,30.591597611530233,30.296452499590455,30.003768459852225,29.713545492315536,29.425783596980402,29.14048277384682,28.857643022914779,28.577264344184282,28.299346737655341,28.023890203327948,27.750894741202099,27.480360351277795,27.212287033555043,26.946674788033839,26.683523614714186,26.422833513596071,26.164604484679515,25.908836527964503,25.65552964345104,25.404683831139113,25.156299091028746,24.910375423119923,24.666912827412652,24.425911303906922,24.187370852602747,23.951291473500117,23.717673166599035,23.486515931899497,23.257819769401507,23.031584679105073,22.807810661010173,22.586497715116835,22.367645841425038,22.151255039934792,21.937325310646088,21.725856653558935,21.516849068673334,21.310302555989281,21.106217115506766,20.904592747225806,20.705429451146394,20.50872722726853,20.314486075592207,20.122705996117439,19.933386988844219,19.746529053772548,19.562132190902414,19.380196400233839,19.200721681766812,19.023708035501329,18.849155461437388,18.677063959575005,18.507433529914167,18.340264172454877,18.175555887197127,18.013308674140934,17.853522533286288,17.69619746463319,17.54133346818163,17.388930543931629,17.238988691883176,17.09150791203626,16.946488204390899,16.80392956894709,16.663832005704826,16.526195514664103,16.391020095824935,16.258305749187315,16.128052474751243,16.000260272516712,15.874929142483737,15.752059084652306,15.631650099022426,15.513702185594092,15.398215344367308,15.285189575342056,15.174624878518365,15.066521253896227,14.960878701475632,14.857697221256586,14.756976813239088,14.658717477423135,14.562919213808733,14.469582022395866,14.378705903184557,14.290290856174799,14.204336881366586,14.120843978759925,14.039812148354809,13.96124139015124,13.88513170414922,13.811483090348734,13.74029554874981,13.671569079352437,13.605303682156602,13.541499357162323,13.480156104369591,13.421273923778408,13.364852815388758,13.310892779200664,13.259393815214125,13.210355923429134,13.163779103845684,13.119663356463789,13.078008681283436,13.038815078304637,13.002082547527365,12.967811088951656,12.936000702577502,12.906651388404889,12.879763146433824,12.855335976664307,12.833369879096345,12.813864853729925,12.796820900565038,12.782238019601714,12.770116210839937,12.760455474279709,12.753255809921029,12.748517217763897,12.746239697808306,12.746423250054271,12.749067874501769,12.75417357115083,12.761740340001431,12.771768181053588,12.784257094307293,12.799207079762539,12.81661813741934,12.836490267277668,12.858823469337565,12.883617743599004,12.91087309006199,12.940589508726532,12.972766999592615,13.007405562660246,13.044505197929425,13.084065905400145,13.12608768507242,13.170570536946244,13.217514461021615,13.266919457298535,13.318785525777002,13.373112666457018,13.429900879338575,13.489150164421673,13.550860521706333,13.615031951192542,13.681664452880291,13.750758026769596,13.822312672860448,13.896328391152842,13.972805181646791,14.051743044342267,14.133141979239312,14.217001986337898,14.30332306563804,14.392105217139722,14.483348440842953,14.577052736747731,14.673218104854051,14.771844545161919,14.872932057671342,14.97648064238232,15.08249029929484,15.190961028408914,15.30189282972453,15.415285703241686,15.531139648960384,15.649454666880636,15.770230757002444,15.893467919325808,16.019166153850712,16.147325460577157,16.277945839505158,16.411027290634699,16.546569813965782,16.684573409498419,16.825038077232612,16.967963817168346,17.113350629305636,17.261198513644466],"type":"scatter3d","mode":"lines","name":"grey","marker":{"color":"rgba(190,190,190,1)","line":{"color":"rgba(190,190,190,1)"},"showscale":false},"textfont":{"color":"rgba(190,190,190,1)"},"error_y":{"color":"rgba(190,190,190,1)"},"error_x":{"color":"rgba(190,190,190,1)"},"line":{"color":"rgba(190,190,190,1)"},"frame":null}],"highlight":{"on":"plotly_click","persistent":false,"dynamic":false,"selectize":false,"opacityDim":0.20000000000000001,"selected":{"opacity":1},"debounce":0},"shinyEvents":["plotly_hover","plotly_click","plotly_selected","plotly_relayout","plotly_brushed","plotly_brushing","plotly_clickannotation","plotly_doubleclick","plotly_deselect","plotly_afterplot","plotly_sunburstclick"],"base_url":"https://plot.ly",".hideLegend":true},"evals":[],"jsHooks":[]}</script>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-hyperplan-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;4.4: Représentation graphique 3D du modèle de régression linéaire pour les données <span class="math inline">\(\texttt{automobile}\)</span>.
</figcaption>
</figure>
</div>
</div>
</div>
</section>
<section id="estimation-des-paramètres" class="level2" data-number="4.3">
<h2 data-number="4.3" class="anchored" data-anchor-id="estimation-des-paramètres"><span class="header-section-number">4.3</span> Estimation des paramètres</h2>
<p>Considérons un échantillon de <span class="math inline">\(n\)</span> observations. On n’observe ni les aléas <span class="math inline">\(\boldsymbol{\varepsilon}\)</span>, ni les paramètres <span class="math inline">\(\boldsymbol{\beta}\)</span>: il est donc impossible de recouvrer les (vrais) coefficients du modèle. Effectivement, le système d’équation spécifié par le modèle linéaire inclut <span class="math inline">\(n+p+1\)</span> inconnues, mais uniquement <span class="math inline">\(n\)</span> observations. Si on se concentre sur les <span class="math inline">\(p+1\)</span> paramètres de moyenne et sur la variance <span class="math inline">\(\sigma^2\)</span>, nous pourrons estimer les paramètres généralement si <span class="math inline">\(n&gt; p+2\)</span>, mais cela dépend de la spécification. Une infinité de plans pourraient passer dans le nuage de points; il faut donc choisir la meilleure droite (selon un critère donné). La section aborde le choix de ce critère et l’estimation des paramètres de la moyenne.</p>
<section id="moindres-carrés-ordinaires" class="level3" data-number="4.3.1">
<h3 data-number="4.3.1" class="anchored" data-anchor-id="moindres-carrés-ordinaires"><span class="header-section-number">4.3.1</span> Moindres carrés ordinaires</h3>
<p>Soit une matrice de modèle <span class="math inline">\(\mathbf{X}\)</span> et une formulation pour la moyenne avec <span class="math inline">\(\mathsf{E}(Y_i) = \mathbf{x}_i\boldsymbol{\beta}\)</span>. Les estimateurs des moindres carrés ordinaires <span class="math inline">\(\widehat{\boldsymbol{\beta}}=(\widehat{\beta}_0, \ldots, \widehat{\beta}_p)\)</span> sont les paramètres qui minimisent simultanément la distance euclidienne entre les observations <span class="math inline">\(y_i\)</span> et les <strong>valeurs ajustées</strong> <span class="math inline">\(\widehat{y}_i=\mathbf{x}_i\widehat{\boldsymbol{\beta}}\)</span>.</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div id="fig-vertdist" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-vertdist-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="regression-lineaire_files/figure-html/fig-vertdist-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:85.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-vertdist-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;4.5: Résidus ordinaires <span class="math inline">\(e_i\)</span> (vecteurs verticaux) ajoutés à la droit de régression dans l’espace <span class="math inline">\((x, y)\)</span> (gauche) et l’ajustement de la variable réponse <span class="math inline">\(y_i\)</span> en fonction des valeurs ajustées <span class="math inline">\(\widehat{y}_i\)</span>.
</figcaption>
</figure>
</div>
</div>
</div>
<p>En d’autres mots, les estimateurs des moindres carrés sont la solution du problème d’optimization convexe <span class="math display">\[\begin{align*}
\widehat{\boldsymbol{\beta}} &amp;=\min_{\boldsymbol{\beta} \in \mathbb{R}^{p+1}}\sum_{i=1}^n (Y_i-\widehat{Y}_i)^2= \min_{\boldsymbol{\beta}} \|\boldsymbol{Y}-\mathbf{X}\boldsymbol{\beta}\|^2
\end{align*}\]</span> Ce système d’équation a une solution explicite qui est plus facilement exprimée en notation matricielle. Soit les matrices et vecteurs <span class="math display">\[\begin{align*}
\boldsymbol{Y} =
\begin{pmatrix}
  Y_1 \\
  Y_2 \\
  \vdots \\
  Y_n
\end{pmatrix} ,
\;
\mathbf{X} = \begin{pmatrix}
1 &amp; x_{11} &amp; x_{12} &amp; \cdots &amp; x_{1p} \\
1 &amp; x_{21} &amp; x_{22} &amp; \cdots &amp; x_{2p} \\
\vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
1 &amp; x_{n1} &amp; x_{n2} &amp; \cdots &amp; x_{np}
\end{pmatrix} , \;
\boldsymbol{\beta} =
\begin{pmatrix}
  \beta_1 \\
  \beta_2 \\
  \vdots \\
  \beta_p
\end{pmatrix}
\end{align*}\]</span></p>
<div id="prp-ols-mle" class="theorem proposition">
<p><span class="theorem-title"><strong>Proposition 4.1 (Moindres carrés ordinaires)</strong></span> L’estimateur des moindres carrés ordinaires résoud le problème d’optimisation non-contraint <span class="math display">\[\begin{align*}
\widehat{\boldsymbol{\beta}}=\min_{\boldsymbol{\beta} \in \mathbb{R}^{p+1}}(\boldsymbol{y}-\mathbf{X}\boldsymbol{\beta})^\top(\boldsymbol{y}-\mathbf{X}\boldsymbol{\beta}).
\end{align*}\]</span> On peut calculer la dérivée première par rapport à <span class="math inline">\(\boldsymbol{\beta}\)</span>, égaler à zéro et isoler le maximum pour obtenir une formule explicite pour <span class="math inline">\(\widehat{\boldsymbol{\beta}}\)</span>, <span class="math display">\[\begin{align*}
\mathbf{0}_n&amp;=\frac{\partial}{\partial\boldsymbol{\beta}}(\boldsymbol{y}-\mathbf{X}\boldsymbol{\beta})^\top(\boldsymbol{y}-\mathbf{X}\boldsymbol{\beta})\\
\\&amp;=\frac{\partial (\boldsymbol{y}-\mathbf{X}\boldsymbol{\beta})}{\partial \boldsymbol{\beta}}\frac{\partial (\boldsymbol{y}-\mathbf{X}\boldsymbol{\beta})^\top(\boldsymbol{y}-\mathbf{X}\boldsymbol{\beta})}{\partial (\boldsymbol{y}-\mathbf{X}\boldsymbol{\beta})}\\
\\&amp;=\mathbf{X}^\top (\boldsymbol{y}-\mathbf{X}\boldsymbol{\beta})
\end{align*}\]</span> en utilisant la <a href="http://www.stat.rice.edu/~dobelman/notes_papers/math/Matrix.Calculus.AppD.pdf">règle de dérivation en chaîne</a>; on peut ainsi distribuer les termes pour obtenir l’<em>équation normale</em> <span class="math display">\[\begin{align*}
\mathbf{X}^\top \mathbf{X}\boldsymbol{\beta}&amp;=\mathbf{X}^\top \boldsymbol{y}.
\end{align*}\]</span> Si <span class="math inline">\(\mathbf{X}\)</span> est une matrice de rang <span class="math inline">\(p\)</span>, alors la forme quadratique <span class="math inline">\(\mathbf{X}^\top \mathbf{X}\)</span> est inversible et l’unique solution du problème d’optimisation est <span class="math display">\[\begin{align*}
\widehat{\boldsymbol{\beta}} = (\mathbf{X}^{\top} \mathbf{X})^{-1} \mathbf{X}^{\top} \boldsymbol{Y}.
\end{align*}\]</span> Si le rang de la matrice <span class="math inline">\(\mathbf{X}\)</span> est dimension <span class="math inline">\(n \times (p+1)\)</span> est de rang <span class="math inline">\(p+1\)</span>, l’unique solution du problème d’optimisation est <span id="eq-ols"><span class="math display">\[
\widehat{\boldsymbol{\beta}} = (\mathbf{X}^{\top} \mathbf{X})^{-1} \mathbf{X}^{\top} \boldsymbol{Y}.
\tag{4.1}\]</span></span> Cet estimateur dit des <strong>moindres carrés ordinaires</strong> (MCO) est explicite; il n’est donc pas nécessaire de procéder à l’optimisation à l’aide d’algorithmes numériques.</p>
</div>
</section>
<section id="maximum-de-vraisemblance" class="level3" data-number="4.3.2">
<h3 data-number="4.3.2" class="anchored" data-anchor-id="maximum-de-vraisemblance"><span class="header-section-number">4.3.2</span> Maximum de vraisemblance</h3>
<p>Nous pourrions également envisager l’estimation du maximum de vraisemblance. <a href="#prp-mle-normal-linmod" class="quarto-xref">Proposition&nbsp;<span>4.2</span></a> montre que, en supposant la normalité des aléas, les estimateurs des moindres carrés de <span class="math inline">\(\boldsymbol{\beta}\)</span> coïncident avec ceux du maximum de vraisemblance.</p>
<div id="prp-mle-normal-linmod" class="theorem proposition">
<p><span class="theorem-title"><strong>Proposition 4.2 (Estimation du maximum de vraisemblance du modèle linéaire normal)</strong></span> Le modèle de régression linéaire spécifie que les observations <span class="math inline">\(Y_i \sim \mathsf{normale}(\mathbf{x}_i\boldsymbol{\beta}, \sigma^2)\)</span> sont indépendantes. Le modèle linéaire a <span class="math inline">\(p+2\)</span> paramètres (<span class="math inline">\(\boldsymbol{\beta}\)</span> et <span class="math inline">\(\sigma^2\)</span>) et la log-vraisemblance est, abstraction faite des termes constants, <span class="math display">\[\begin{align*}
\ell(\boldsymbol{\beta}, \sigma)&amp;\propto-\frac{n}{2} \ln (\sigma^2) -\frac{1}{2\sigma^2}\left\{(\boldsymbol{y}-\mathbf{X}\boldsymbol{\beta})^\top(\boldsymbol{y}-\mathbf{X}\boldsymbol{\beta})\right\}^2.
\end{align*}\]</span> Maximiser la log-vraisemblance par rapport à <span class="math inline">\(\boldsymbol{\beta}\)</span> revient à minimiser la somme du carré des erreurs <span class="math inline">\(\sum_{i=1}^n (y_i - \mathbf{x}_i\boldsymbol{\beta})^2\)</span>, quelle que soit la valeur de <span class="math inline">\(\sigma\)</span>, et on recouvre <span class="math inline">\(\widehat{\boldsymbol{\beta}}\)</span>. L’estimateur du maximum de vraisemblance de la variance <span class="math inline">\(\widehat{\sigma}^2\)</span> est <span class="math display">\[\begin{align*}
\widehat{\sigma}^2=\mathrm{arg max}_{\sigma^2} \ell(\widehat{\boldsymbol{\beta}}, \sigma^2).
\end{align*}\]</span> La log-vraisemblance profilée de <span class="math inline">\(\sigma^2\)</span>, abstraction faite des constantes, est <span class="math display">\[\begin{align*}
\ell_{\mathrm{p}}(\sigma^2)
&amp;\propto-\frac{1}{2}\left\{n\ln\sigma^2+\frac{1}{\sigma^2}(\boldsymbol{y}-\mathbf{X}\hat{\boldsymbol{\beta}})^\top(\boldsymbol{y}-\mathbf{X}\hat{\boldsymbol{\beta}})\right\}.
\end{align*}\]</span> En différenciant chaque terme par rapport à <span class="math inline">\(\sigma^2\)</span> et en fixant le gradient à zéro, on obtient <span class="math display">\[\begin{align*}
\frac{\partial \ell_{\mathrm{p}}(\sigma^2)}{\partial \sigma^2} = -\frac{n}{2\sigma^2} + \frac{(\boldsymbol{y}-\mathbf{X}\hat{\boldsymbol{\beta}})^\top(\boldsymbol{y}-\mathbf{X}\hat{\boldsymbol{\beta}})}{2\sigma^4} = 0
\end{align*}\]</span></p>
<p>On déduit que l’estimateur du maximum de vraisemblance est la moyenne des carrés des résidus, <span class="math display">\[\begin{align*}
\widehat{\sigma}^2&amp;=\frac{1}{n}(\boldsymbol{Y}-\mathbf{X}\hat{\boldsymbol{\beta}})^\top(\boldsymbol{Y}-\mathbf{X}\hat{\boldsymbol{\beta}})\\&amp;= \frac{1}{n} \sum_{i=1}^n (y_i - \mathbf{x}_i\widehat{\boldsymbol{\beta}})^2= \frac{\mathsf{SC}_e}{n};
\end{align*}\]</span> L’estimateur sans biais habituel de <span class="math inline">\(\sigma^2\)</span> calculé par le logiciel est <span class="math display">\[S^2=\mathsf{SC}_e/(n-p-1),\]</span> où le dénominateur est la taille de l’échantillon <span class="math inline">\(n\)</span> moins le nombre de paramètres de la moyenne <span class="math inline">\(\boldsymbol{\beta}\)</span>, soit <span class="math inline">\(p+1\)</span>.</p>
</div>
<div id="rem-invariance" class="proof remark">
<p><span class="proof-title"><em>Remarque 4.3</em> (Invariance). </span>Une conséquence directe des propriétés des estimateurs du maximum de vraisemblance est que les valeurs ajustées <span class="math inline">\(\widehat{y}_i\)</span> pour deux matrices de modèle <span class="math inline">\(\mathbf{X}_a\)</span> et <span class="math inline">\(\mathbf{X}_b\)</span> sont les mêmes si elles engendrent le même espace linéaire, comme dans <a href="#exm-baumann-dummies" class="quarto-xref">Exemple&nbsp;<span>4.8</span></a>; seule l’’interprétation des coefficients change. Si nous incluons une ordonnée à l’origine, nous obtenons le même résultat si les colonnes explicatives sont centrées sur la moyenne.</p>
</div>
<p>La valeur de <span class="math inline">\(\widehat{\boldsymbol{\beta}}\)</span> est telle qu’elle maximise la corrélation entre <span class="math inline">\(\boldsymbol{y}\)</span> et <span class="math inline">\(\widehat{\boldsymbol{y}}\)</span>. Dans le cas d’une variable catégorielle unique, nous obtiendrons des valeurs ajustées <span class="math inline">\(\widehat{y}\)</span> qui correspondent à la moyenne de l’échantillon de chaque groupe.</p>
<div id="rem-geometry" class="proof remark">
<p><span class="proof-title"><em>Remarque 4.4</em> (Géométrie). </span>Le vecteur de valeurs ajustées <span class="math inline">\(\widehat{\boldsymbol{y}} =\mathbf{X} \widehat{\boldsymbol{\beta}} = \mathbf{H}_{\mathbf{X}}\boldsymbol{y}\)</span> est la projection du vecteur réponse <span class="math inline">\(\boldsymbol{y}\)</span> dans l’espace linéaire engendré par les colonnes de <span class="math inline">\(\mathbf{X}\)</span>. La matrice chapeau <span class="math inline">\(\mathbf{H}_{\mathbf{X}} = \mathbf{X}(\mathbf{X}^\top\mathbf{X})^{-1}\mathbf{X}^\top\)</span> est une matrice de projection orthogonale, car <span class="math inline">\(\mathbf{H}_{\mathbf{X}}=\mathbf{H}_{\mathbf{X}}^\top\)</span> et <span class="math inline">\(\mathbf{H}_{\mathbf{X}}\mathbf{H}_{\mathbf{X}} = \mathbf{H}_{\mathbf{X}}\)</span>. Ainsi, <span class="math inline">\(\mathbf{H}_{\mathbf{X}}\mathbf{X} = \mathbf{X}\)</span>. Puisque le vecteur de résidus ordinaires <span class="math inline">\(\boldsymbol{e} = (e_1, \ldots, e_n)^\top\)</span>, qui apparaît dans la somme des erreurs quadratiques, est définie comme <span class="math inline">\(\boldsymbol{y} - \widehat{\boldsymbol{y}}\)</span> et <span class="math inline">\(\widehat{\boldsymbol{y}}=\mathbf{X}\boldsymbol{\beta}\)</span>, de simples manipulations algébriques montrent que le produit scalaire entre les résidus ordinaires et les valeurs ajustées est nul, puisque <span class="math display">\[\begin{align*}
\widehat{\boldsymbol{y}}^\top\boldsymbol{e} &amp;= \widehat{\boldsymbol{\beta}}^\top \mathbf{X}^\top (\boldsymbol{y}- \mathbf{X} \widehat{\boldsymbol{\beta}})
\\&amp;= \boldsymbol{y}^\top\mathbf{X}(\mathbf{X}^\top\mathbf{X})^{-1}\mathbf{X}^\top(\boldsymbol{y} - \mathbf{X}(\mathbf{X}^\top\mathbf{X})^{-1}\mathbf{X}^\top \boldsymbol{y})\\&amp;=\boldsymbol{y}^\top\mathbf{H}_{\mathbf{X}}\boldsymbol{y} - \mathbf{X}(\mathbf{X}^\top\mathbf{X})^{-1}\mathbf{X}^\top\mathbf{X}(\mathbf{X}^\top\mathbf{X})^{-1}\mathbf{X}^\top \boldsymbol{y}
\\&amp;= 0
\end{align*}\]</span> où nous utilisons la définition de <span class="math inline">\(\widehat{\boldsymbol{y}}\)</span> et <span class="math inline">\(\boldsymbol{e} = \boldsymbol{y} - \widehat{\boldsymbol{y}}\)</span> sur la première ligne, puis on substitut l’estimateur des MCO <span class="math inline">\(\widehat{\boldsymbol{\beta}} = (\mathbf{X}^\top\mathbf{X})^{-1}\mathbf{X}^\top\boldsymbol{y}\)</span> avant de distribuer les termes du produit. Une dérivation similaire montre que <span class="math inline">\(\mathbf{X}^\top\boldsymbol{e}=\boldsymbol{0}_{p+1}\)</span>. Les résidus ordinaires sont donc orthogonaux à la fois à la matrice du modèle <span class="math inline">\(\mathbf{X}\)</span> et aux valeurs ajustées <span class="math inline">\(\widehat{\boldsymbol{y}}\)</span>.</p>
<p>Une conséquence directe de ces résultats est le fait que la corrélation linéaire entre <span class="math inline">\(\boldsymbol{e}\)</span> et <span class="math inline">\(\widehat{\boldsymbol{y}}\)</span> est nulle. Cette propriété servira lors de l’élaboration de diagnostics graphiques.</p>
<p>Puisque le produit scalaire est zéro, la moyenne de <span class="math inline">\(\boldsymbol{e}\)</span> doit être zéro pour autant que <span class="math inline">\(\mathbf{1}_n\)</span> est dans l’espace linéaire engendré par <span class="math inline">\(\mathbf{X}\)</span>.</p>
</div>
<div id="prp-info-normal" class="theorem proposition">
<p><span class="theorem-title"><strong>Proposition 4.3 (Matrices d’information pour modèles linéaires normaux.)</strong></span> Les entrées de la matrice d’information observée du modèle linéaire normal sont les suivantes <span class="math display">\[\begin{align*}
-\frac{\partial^2 \ell(\boldsymbol{\beta}, \sigma^2)}{\partial \boldsymbol{\beta}\partial \boldsymbol{\beta}^\top} &amp;= \frac{1}{\sigma^2} \frac{\partial \mathbf{X}^\top(\boldsymbol{y}-\mathbf{X}\boldsymbol{\beta})}{\partial \boldsymbol{\beta}^\top} =  \frac{\mathbf{X}^\top\mathbf{X}}{\sigma^2}\\
-\frac{\partial^2 \ell(\boldsymbol{\beta}, \sigma^2)}{\partial \boldsymbol{\beta}\partial \sigma^2} &amp;=- \frac{\mathbf{X}^\top(\boldsymbol{y}-\mathbf{X}\boldsymbol{\beta})}{\sigma^4}\\
-\frac{\partial^2 \ell(\boldsymbol{\beta}, \sigma^2)}{\partial (\sigma^2)^2} &amp;= -\frac{n}{2\sigma^4} + \frac{(\boldsymbol{y}-\mathbf{X}\boldsymbol{\beta})^\top(\boldsymbol{y}-\mathbf{X}\boldsymbol{\beta})}{\sigma^6}.
\end{align*}\]</span> Si on évalue l’information observée aux EMV, on obtient <span class="math display">\[\begin{align*}
j(\widehat{\boldsymbol{\beta}}, \widehat{\sigma^2}) =
\begin{pmatrix}
\frac{\mathbf{X}^\top\mathbf{X}}{\widehat{\sigma^2}} &amp; \boldsymbol{0}_{p+1} \\  \boldsymbol{0}_{p+1}^\top &amp; \frac{n}{2\widehat{\sigma^4}}
\end{pmatrix}
\end{align*}\]</span> puisque <span class="math inline">\(\widehat{\sigma}^2=\mathsf{SC}_e/n\)</span> et que les résidus sont orthogonaux à la matrice du modèle. Sachant que <span class="math inline">\(\mathsf{E}(Y \mid \mathbf{X})=\mathbf{X}\boldsymbol{\beta}\)</span>, la matrice d’information de Fisher est <span class="math display">\[\begin{align*}
i(\boldsymbol{\beta}, \sigma^2) =
\begin{pmatrix}
\frac{\mathbf{X}^\top\mathbf{X}}{\sigma^2} &amp; \boldsymbol{0}_{p+1} \\  \boldsymbol{0}_{p+1}^\top &amp; \frac{n}{2\sigma^4}
\end{pmatrix}
\end{align*}\]</span> Puisque la loi asymptotique de l’estimateur est normale, les EMV de <span class="math inline">\(\sigma^2\)</span> et <span class="math inline">\(\boldsymbol{\beta}\)</span> sont asymptotiquement indépendants car leur corrélation asymptotique est nulle.Pourvu que la matrice carrée <span class="math inline">\((p+1)\)</span>, <span class="math inline">\(\mathbf{X}^\top\mathbf{X}\)</span> soit inversible, la variance asymptotique des estimateurs est <span class="math inline">\(\mathsf{Var}(\widehat{\boldsymbol{\beta}})=\sigma^2(\mathbf{X}^\top\mathbf{X})^{-1}\)</span> et <span class="math inline">\(\mathsf{Var}(\widehat{\sigma}^2) = 2\sigma^4/n\)</span>.</p>
</div>
</section>
<section id="ajustement-des-modèles-linéaires-à-laide-dun-logiciel" class="level3" data-number="4.3.3">
<h3 data-number="4.3.3" class="anchored" data-anchor-id="ajustement-des-modèles-linéaires-à-laide-dun-logiciel"><span class="header-section-number">4.3.3</span> Ajustement des modèles linéaires à l’aide d’un logiciel</h3>
<p>Bien que nous puissions construire la matrice du modèle nous-mêmes et utiliser la formule des moindres carrés de l’<a href="#eq-ols" class="quarto-xref">Équation&nbsp;<span>4.1</span></a>, les routines numériques implémentées dans les logiciels sont préférables car plus stables. La fonction <code>lm</code> dans <strong>R</strong> ajuste <strong>les modèles linéaires</strong>, tout comme <code>glm</code> avec les arguments par défaut. Les objets de la classe <code>lm</code> ont plusieurs méthodes qui vous permettent d’extraire des objets spécifiques des objets <code>lm</code>. Par exemple, les fonctions <code>coef</code>, <code>resid</code>, <code>fitted</code>, <code>model.matrix</code> renvoient les estimations des coefficients <span class="math inline">\(\widehat{\boldsymbol{\beta}},\)</span> les résidus ordinaires <span class="math inline">\(\boldsymbol{e},\)</span> les valeurs ajustées <span class="math inline">\(\widehat{\boldsymbol{y}}\)</span> et la matrice du modèle <span class="math inline">\(\mathbf{X}\)</span>.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(BSJ92, <span class="at">package =</span> <span class="st">"hecedsm"</span>) <span class="co"># charger les données</span></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a><span class="fu">str</span>(BSJ92) <span class="co"># vérifier que les variables catégorielles sont "factor"</span></span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Ajustement de la régression linéaire</span></span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a>linmod <span class="ot">&lt;-</span> <span class="fu">lm</span>(posttest1 <span class="sc">~</span> pretest1 <span class="sc">+</span> group, </span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a>             <span class="at">data =</span> BSJ92)</span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a>est_beta <span class="ot">&lt;-</span> <span class="fu">coef</span>(linmod) <span class="co"># coefficients (betas)</span></span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a>vcov_beta <span class="ot">&lt;-</span> <span class="fu">vcov</span>(linmod) <span class="co"># matrice de covariance des betas</span></span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(linmod) <span class="co"># tableau résumé</span></span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a>beta_ic <span class="ot">&lt;-</span> <span class="fu">confint</span>(linmod) <span class="co"># IC de Wald pour betas</span></span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a>y_adj <span class="ot">&lt;-</span> <span class="fu">fitted</span>(linmod) <span class="co"># valeurs ajustées</span></span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a>e <span class="ot">&lt;-</span> <span class="fu">resid</span>(linmod) <span class="co"># résidus ordinaires</span></span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-13"><a href="#cb5-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Vérifier la formule des moindres carrés ordinaires</span></span>
<span id="cb5-14"><a href="#cb5-14" aria-hidden="true" tabindex="-1"></a>X <span class="ot">&lt;-</span> <span class="fu">model.matrix</span>(linmod) <span class="co"># matrice du modèle</span></span>
<span id="cb5-15"><a href="#cb5-15" aria-hidden="true" tabindex="-1"></a>y <span class="ot">&lt;-</span> college<span class="sc">$</span>salary</span>
<span id="cb5-16"><a href="#cb5-16" aria-hidden="true" tabindex="-1"></a><span class="fu">isTRUE</span>(<span class="fu">all.equal</span>(</span>
<span id="cb5-17"><a href="#cb5-17" aria-hidden="true" tabindex="-1"></a>  <span class="fu">c</span>(<span class="fu">solve</span>(<span class="fu">t</span>(X) <span class="sc">%*%</span> X) <span class="sc">%*%</span> <span class="fu">t</span>(X) <span class="sc">%*%</span> y),</span>
<span id="cb5-18"><a href="#cb5-18" aria-hidden="true" tabindex="-1"></a>  <span class="fu">as.numeric</span>(<span class="fu">coef</span>(linmod))</span>
<span id="cb5-19"><a href="#cb5-19" aria-hidden="true" tabindex="-1"></a>))</span></code><button title="Copier vers le presse-papier" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>La méthode <code>summary</code> est sans doute la plus utile: elle affiche les estimations des paramètres de la moyenne ainsi que leurs erreurs type, les valeurs <span class="math inline">\(t\)</span> pour le test de Wald de l’hypothèse <span class="math inline">\(\mathscr{H}_0 : \beta_i=0\)</span> et les valeurs-<span class="math inline">\(p\)</span> associées. D’autres statistiques descriptives, portant sur la taille de l’échantillon, les degrés de liberté, etc. sont données au bas du tableau. Notez que la fonction <code>lm</code> utilise l’estimateur sans biais de la variance <span class="math inline">\(\sigma^2\)</span>.</p>
</section>
</section>
<section id="coefR2" class="level2" data-number="4.4">
<h2 data-number="4.4" class="anchored" data-anchor-id="coefR2"><span class="header-section-number">4.4</span> Coefficient de détermination</h2>
<p>Lorsque nous spécifions un modèle, les aléas <span class="math inline">\(\boldsymbol{\varepsilon}\)</span> servent à tenir compte du fait qu’aucune relation linéaire exacte ne caractérise les données Une fois que nous avons ajusté un modèle, nous estimons la variance <span class="math inline">\(\sigma^2\)</span>; on peut alors se demander quelle part de la variance totale de l’échantillon est expliquée par le modèle.</p>
<p>La somme totale des carrés, définie comme la somme des carrés des résidus du modèle à ordonnée à l’origine uniquement, sert de comparaison — le modèle le plus simple que nous puissions trouver impliquerait chaque observation par la moyenne de l’échantillon de la réponse, ce qui donne la variance expliquée <span class="math inline">\(\mathsf{SC}_c = \sum_{i=1}^n (y_i - \overline{y})^2\)</span>. Nous pouvons ensuite comparer la variance des données originales avec celle des résidus du modèle avec la matrice de covariables <span class="math inline">\(\mathbf{X}\)</span>, définie comme <span class="math inline">\(\mathsf{SC}_e =\sum_{i=1}^n e_i^2\)</span> avec <span class="math inline">\(e_i = y_i - \widehat{\beta}_0 - \sum_{j=1}^p \widehat{\beta}_jX_j\)</span>. Nous définissons le coefficient de détermination <span class="math inline">\(R^2\)</span>, comme suit <span class="math display">\[\begin{align*}
R^2 &amp;=1- \frac{\mathsf{SC}_e}{\mathsf{SC}_c} = \frac{\sum_{i=1}^n (y_i - \overline{y})^2- \sum_{i=1}^n e_i^2}{\sum_{i=1}^n (y_i - \overline{y})^2}.
\end{align*}\]</span> Une autre décomposition montre que <span class="math inline">\(R^2 = \mathsf{cor}^2(\boldsymbol{y}, \widehat{\boldsymbol{y}})\)</span>, c’est-à-dire que le coefficient de détermination peut être interprété comme le carré de la corrélation linéaire de Pearson (<a href="introduction.html#def-correlation-Pearson" class="quarto-xref">Définition&nbsp;<span>1.3</span></a>) entre la réponse <span class="math inline">\(\boldsymbol{y}\)</span> et les valeurs ajustées <span class="math inline">\(\widehat{\boldsymbol{y}}\)</span>.</p>
<p>Il est important de noter que le <span class="math inline">\(R^2\)</span> n’est pas un critère de qualité de l’ajustement, tout comme la log-vraisemblance. En effet, certain phénomènes sont intrinsèquement complexes et même un bon modèle ne parviendra pas à rendre compte d’une grande partie de la variabilité de la réponse. Ce n’est pas non plus parce que le <span class="math inline">\(R^2\)</span> est faible que <span class="math inline">\(Y\)</span> et et les variables explicatives <span class="math inline">\(X_j\)</span> sont indépendantes, comme l’illustre la <a href="introduction.html#fig-datasaurus" class="quarto-xref">Figure&nbsp;<span>1.2</span></a>.</p>
<p>En outre, il est possible de gonfler la valeur de <span class="math inline">\(R^2\)</span> en incluant davantage de variables explicatives et en rendant le modèle plus complexe, ce qui améliore la vraisemblance et <span class="math inline">\(R^2\)</span>. En effet, le coefficient n’est pas décroissant dans la dimension de <span class="math inline">\(\mathbf{X}\)</span>, de sorte qu’un modèle comportant <span class="math inline">\(p+1\)</span> de covariables aura nécessairement des valeurs de <span class="math inline">\(R^2\)</span> plus élevées que si l’on n’incluait que <span class="math inline">\(p\)</span> de ces variables explicatives. Pour comparer les modèles, il est préférable d’utiliser des critères d’information ou de s’appuyer sur la performance prédictive si tel est l’objectif de la régression. Enfin, un modèle avec un <span class="math inline">\(R^2\)</span> élevé peut impliquer une corrélation élevée, mais <a href="http://www.tylervigen.com/spurious-correlations">la relation peut être fallacieuse</a>: la régression linéaire ne produit pas de modèles causaux!</p>


<div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list" style="display: none">
<div id="ref-Baumann:1992" class="csl-entry" role="listitem">
Baumann, James F., Nancy Seifert-Kessell, et Leah A. Jones. 1992. <span>«&nbsp;Effect of Think-Aloud Instruction on Elementary Students’ Comprehension Monitoring Abilities&nbsp;»</span>. <em>Journal of Reading Behavior</em> 24 (2): 143‑72. <a href="https://doi.org/10.1080/10862969209547770">https://doi.org/10.1080/10862969209547770</a>.
</div>
<div id="ref-Lee.Choi:2019" class="csl-entry" role="listitem">
Lee, Kiljae, et Jungsil Choi. 2019. <span>«&nbsp;Image-text inconsistency effect on product evaluation in online retailing&nbsp;»</span>. <em>Journal of Retailing and Consumer Services</em> 49: 279‑88. <a href="https://doi.org/10.1016/j.jretconser.2019.03.015">https://doi.org/10.1016/j.jretconser.2019.03.015</a>.
</div>
<div id="ref-Moon.VanEpps:2023" class="csl-entry" role="listitem">
Moon, Alice, et Eric M VanEpps. 2023. <span>«&nbsp;Giving Suggestions: Using Quantity Requests to Increase Donations&nbsp;»</span>. <em>Journal of Consumer Research</em> 50 (1): 190‑210. <a href="https://doi.org/10.1093/jcr/ucac047">https://doi.org/10.1093/jcr/ucac047</a>.
</div>
<div id="ref-Venables:2000" class="csl-entry" role="listitem">
Venables, William N. 2000. <span>«&nbsp;Exegeses on Linear Models&nbsp;»</span>. In <em>S-PLUS User’s Conference</em>. Washington, D.C. <a href="https://www.stats.ox.ac.uk/pub/MASS3/Exegeses.pdf">https://www.stats.ox.ac.uk/pub/MASS3/Exegeses.pdf</a>.
</div>
</div>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copié");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copié");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    // For code content inside modals, clipBoardJS needs to be initialized with a container option
    // TODO: Check when it could be a function (https://github.com/zenorocha/clipboard.js/issues/860)
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp("https:\/\/lbelzile\.github\.io\/math60604\/");
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./vraisemblance.html" class="pagination-link" aria-label="Inférence basée sur la vraisemblance">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Inférence basée sur la vraisemblance</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./references.html" class="pagination-link" aria-label="Bibliographie">
        <span class="nav-page-text">Bibliographie</span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
      &nbsp;
    </div>   
    <div class="nav-footer-center">
<p>Tous droits réservés (Léo Belzile)</p>
<div class="toc-actions d-sm-block d-md-none"><ul><li><a href="https://github.com/lbelzile/math60604/edit/master/regression-lineaire.qmd" class="toc-action"><i class="bi bi-github"></i>Éditer cette page</a></li></ul></div></div>
    <div class="nav-footer-right">
      &nbsp;
    </div>
  </div>
</footer>




</body></html>