<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="fr" xml:lang="fr"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.1">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="description" content="Ces notes forment un complément web du cours MATH 60604 (Modélisation statistique) offert à la M.Sc. en gestion (science des données et analytique d’affaires) à HEC Montréal.">

<title>4&nbsp; Régression linéaire – MATH 60604 - Modélisation statistique</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./references.html" rel="next">
<link href="./vraisemblance.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "Pas de résultats",
    "search-matching-documents-text": "documents trouvés",
    "search-copy-link-title": "Copier le lien vers la recherche",
    "search-hide-matches-text": "Cacher les correspondances additionnelles",
    "search-more-match-text": "correspondance de plus dans ce document",
    "search-more-matches-text": "correspondances de plus dans ce document",
    "search-clear-button-title": "Effacer",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Annuler",
    "search-submit-button-title": "Envoyer",
    "search-label": "Recherche"
  }
}</script>
<link href="site_libs/htmltools-fill-0.5.8.1/fill.css" rel="stylesheet">
<script src="site_libs/htmlwidgets-1.6.4/htmlwidgets.js"></script>
<script src="site_libs/plotly-binding-4.10.4/plotly.js"></script>
<script src="site_libs/typedarray-0.1/typedarray.min.js"></script>
<script src="site_libs/jquery-3.5.1/jquery.min.js"></script>
<link href="site_libs/crosstalk-1.2.1/css/crosstalk.min.css" rel="stylesheet">
<script src="site_libs/crosstalk-1.2.1/js/crosstalk.min.js"></script>
<link href="site_libs/plotly-htmlwidgets-css-2.11.1/plotly-htmlwidgets.css" rel="stylesheet">
<script src="site_libs/plotly-main-2.11.1/plotly-latest.min.js"></script>
<script src="site_libs/kePrint-0.0.1/kePrint.js"></script>
<link href="site_libs/lightable-0.0.1/lightable.css" rel="stylesheet">

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="css/style.css">
</head>

<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Basculer la barre latérale" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./regression-lineaire.html"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Régression linéaire</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Basculer la barre latérale" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Recherche" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">MATH 60604 - Modélisation statistique</a> 
        <div class="sidebar-tools-main">
    <a href="https://github.com/lbelzile/math60604/" title="Code source" class="quarto-navigation-tool px-1" aria-label="Code source"><i class="bi bi-github"></i></a>
    <a href="./MATH60604.pdf" title="Download PDF" class="quarto-navigation-tool px-1" aria-label="Download PDF"><i class="bi bi-file-pdf"></i></a>
</div>
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Recherche"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Bienvenue</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./introduction.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Introduction</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./inference.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Inférence statistique</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./vraisemblance.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Inférence basée sur la vraisemblance</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./regression-lineaire.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Régression linéaire</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Bibliographie</span></a>
  </div>
</li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table des matières</h2>
   
  <ul>
  <li><a href="#introduction" id="toc-introduction" class="nav-link active" data-scroll-target="#introduction"><span class="header-section-number">4.1</span> Introduction</a>
  <ul class="collapse">
  <li><a href="#exemples" id="toc-exemples" class="nav-link" data-scroll-target="#exemples"><span class="header-section-number">4.1.1</span> Exemples</a></li>
  <li><a href="#analyse-exploratoire-des-données" id="toc-analyse-exploratoire-des-données" class="nav-link" data-scroll-target="#analyse-exploratoire-des-données"><span class="header-section-number">4.1.2</span> Analyse exploratoire des données</a></li>
  <li><a href="#spécification-du-modèle-pour-la-moyenne" id="toc-spécification-du-modèle-pour-la-moyenne" class="nav-link" data-scroll-target="#spécification-du-modèle-pour-la-moyenne"><span class="header-section-number">4.1.3</span> Spécification du modèle pour la moyenne</a></li>
  </ul></li>
  <li><a href="#interprétation-des-coefficients" id="toc-interprétation-des-coefficients" class="nav-link" data-scroll-target="#interprétation-des-coefficients"><span class="header-section-number">4.2</span> Interprétation des coefficients</a></li>
  <li><a href="#estimation-des-paramètres" id="toc-estimation-des-paramètres" class="nav-link" data-scroll-target="#estimation-des-paramètres"><span class="header-section-number">4.3</span> Estimation des paramètres</a>
  <ul class="collapse">
  <li><a href="#moindres-carrés-ordinaires" id="toc-moindres-carrés-ordinaires" class="nav-link" data-scroll-target="#moindres-carrés-ordinaires"><span class="header-section-number">4.3.1</span> Moindres carrés ordinaires</a></li>
  <li><a href="#maximum-de-vraisemblance" id="toc-maximum-de-vraisemblance" class="nav-link" data-scroll-target="#maximum-de-vraisemblance"><span class="header-section-number">4.3.2</span> Maximum de vraisemblance</a></li>
  <li><a href="#ajustement-des-modèles-linéaires-à-laide-dun-logiciel" id="toc-ajustement-des-modèles-linéaires-à-laide-dun-logiciel" class="nav-link" data-scroll-target="#ajustement-des-modèles-linéaires-à-laide-dun-logiciel"><span class="header-section-number">4.3.3</span> Ajustement des modèles linéaires à l’aide d’un logiciel</a></li>
  </ul></li>
  <li><a href="#sec-predictions-lm" id="toc-sec-predictions-lm" class="nav-link" data-scroll-target="#sec-predictions-lm"><span class="header-section-number">4.4</span> Prédictions</a></li>
  <li><a href="#tests-dhypothèses" id="toc-tests-dhypothèses" class="nav-link" data-scroll-target="#tests-dhypothèses"><span class="header-section-number">4.5</span> Tests d’hypothèses</a>
  <ul class="collapse">
  <li><a href="#contrastes" id="toc-contrastes" class="nav-link" data-scroll-target="#contrastes"><span class="header-section-number">4.5.1</span> Contrastes</a></li>
  <li><a href="#exemples-de-tests" id="toc-exemples-de-tests" class="nav-link" data-scroll-target="#exemples-de-tests"><span class="header-section-number">4.5.2</span> Exemples de tests</a></li>
  </ul></li>
  <li><a href="#plans-factoriels-et-interactions" id="toc-plans-factoriels-et-interactions" class="nav-link" data-scroll-target="#plans-factoriels-et-interactions"><span class="header-section-number">4.6</span> Plans factoriels et interactions</a></li>
  <li><a href="#géométrie-des-moindres-carrés" id="toc-géométrie-des-moindres-carrés" class="nav-link" data-scroll-target="#géométrie-des-moindres-carrés"><span class="header-section-number">4.7</span> Géométrie des moindres carrés</a>
  <ul class="collapse">
  <li><a href="#résidus" id="toc-résidus" class="nav-link" data-scroll-target="#résidus"><span class="header-section-number">4.7.1</span> Résidus</a></li>
  <li><a href="#colinéarité" id="toc-colinéarité" class="nav-link" data-scroll-target="#colinéarité"><span class="header-section-number">4.7.2</span> Colinéarité</a></li>
  <li><a href="#levier-et-aberrances" id="toc-levier-et-aberrances" class="nav-link" data-scroll-target="#levier-et-aberrances"><span class="header-section-number">4.7.3</span> Levier et aberrances</a></li>
  </ul></li>
  <li><a href="#postulats-du-modèle-et-diagnostics" id="toc-postulats-du-modèle-et-diagnostics" class="nav-link" data-scroll-target="#postulats-du-modèle-et-diagnostics"><span class="header-section-number">4.8</span> Postulats du modèle et diagnostics</a>
  <ul class="collapse">
  <li><a href="#postulat-de-linéarité-et-dadditivité" id="toc-postulat-de-linéarité-et-dadditivité" class="nav-link" data-scroll-target="#postulat-de-linéarité-et-dadditivité"><span class="header-section-number">4.8.1</span> Postulat de linéarité et d’additivité</a></li>
  <li><a href="#postulat-dhomoscédasticité" id="toc-postulat-dhomoscédasticité" class="nav-link" data-scroll-target="#postulat-dhomoscédasticité"><span class="header-section-number">4.8.2</span> Postulat d’homoscédasticité</a></li>
  <li><a href="#postulat-dindépendance" id="toc-postulat-dindépendance" class="nav-link" data-scroll-target="#postulat-dindépendance"><span class="header-section-number">4.8.3</span> Postulat d’indépendance</a></li>
  <li><a href="#postulat-de-normalité" id="toc-postulat-de-normalité" class="nav-link" data-scroll-target="#postulat-de-normalité"><span class="header-section-number">4.8.4</span> Postulat de normalité</a></li>
  <li><a href="#sec-transfo" id="toc-sec-transfo" class="nav-link" data-scroll-target="#sec-transfo"><span class="header-section-number">4.8.5</span> Transformation de la variable réponse</a></li>
  </ul></li>
  <li><a href="#remarque-finale" id="toc-remarque-finale" class="nav-link" data-scroll-target="#remarque-finale"><span class="header-section-number">4.9</span> Remarque finale</a></li>
  </ul>
<div class="toc-actions"><ul><li><a href="https://github.com/lbelzile/math60604/edit/master/regression-lineaire.qmd" class="toc-action"><i class="bi bi-github"></i>Éditer cette page</a></li></ul></div></nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title"><span id="regression-lineaire" class="quarto-section-identifier"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Régression linéaire</span></span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<section id="introduction" class="level2" data-number="4.1">
<h2 data-number="4.1" class="anchored" data-anchor-id="introduction"><span class="header-section-number">4.1</span> Introduction</h2>
<p>Le modèle de régression linéaire, ou modèle linéaire, est l’un des outils les plus polyvalents pour l’inférence statistique. La régression linéaire est principalement utilisée pour évaluer les effets des variables explicatives (souvent l’effet d’une manipulation ou d’un traitement dans un cadre expérimental) sur la moyenne d’une variable réponse continue, ou pour la prédiction. Un modèle linéaire est un modèle qui décrit la moyenne d’une <strong>variable réponse</strong> continue <span class="math inline">\(Y_i\)</span> d’un échantillon aléatoire de taille <span class="math inline">\(n\)</span> comme <strong>fonction linéaire</strong> des <strong>variables explicatives</strong> (également appelés prédicteurs, régresseurs ou covariables) <span class="math inline">\(X_1, \ldots, X_p\)</span>.</p>
<p>Dénotons par <span class="math inline">\(Y_i\)</span> la valeur de <span class="math inline">\(Y\)</span> pour le sujet <span class="math inline">\(i\)</span>, et <span class="math inline">\(X_{ij}\)</span> la valeur de la <span class="math inline">\(j\)</span>e variable explicative du sujet <span class="math inline">\(i\)</span>. <span class="math display">\[\begin{align}
\underset{\text{moyenne conditionnelle}}{\mathsf{E}(Y_i \mid \boldsymbol{X}_i=\boldsymbol{x}_i)}=\mu_i=\underset{\substack{\text{combinaison linéaire (somme pondérée)}\\ \text{de variables explicatives}}}{\beta_0 + \beta_1x_{i1} + \cdots + \beta_p x_{ip}}\equiv \mathbf{x}_i\boldsymbol{\beta}.
\end{align}\]</span> où <span class="math inline">\(\mathbf{x}_i = (1, x_{i1}, \ldots, x_{ip})\)</span> est un vecteur ligne de taille <span class="math inline">\((p+1)\)</span> contenant les variables explicatives de l’observation <span class="math inline">\(i\)</span> et <span class="math inline">\(\boldsymbol{\beta} = (\beta_0, \ldots, \beta_p)^\top\)</span> est un vecteur colonne de longueur <span class="math inline">\(p+1\)</span> contenant les coefficients de la moyenne. Le fait que la moyenne est conditionnelle aux valeurs de <span class="math inline">\(\mathbf{X}\)</span> implique simplement que l’on considère les régresseurs comme constant, ou connus à l’avance. Les coefficients <span class="math inline">\(\boldsymbol{\beta}\)</span> sont les mêmes pour toutes les observations, mais le vecteurs de variables explicatives <span class="math inline">\(\mathbf{x}_i\)</span> peut différer d’une observation à l’autre. Le modèle est <strong>linéaire</strong> en <span class="math inline">\(\beta_0, \ldots, \beta_p\)</span>, pas nécessairement dans les variables explicatives.</p>
<p>Pour simplifier la notation, nous regroupons les observations dans un vecteur <span class="math inline">\(n\)</span> <span class="math inline">\(\boldsymbol{Y}\)</span> et les explications dans une matrice <span class="math inline">\(n \times (p+1)\)</span> <span class="math inline">\(\mathbf{X}\)</span> en concaténant une colonne de uns et les vecteurs de colonnes <span class="math inline">\(p\)</span> <span class="math inline">\(\boldsymbol{X}_1, \ldots, \boldsymbol{X}_p\)</span>, chacun contenant les <span class="math inline">\(n\)</span> observations des explications respectives. La matrice <span class="math inline">\(\mathbf{X}\)</span> est appelée <strong>matrice du modèle</strong> (ou parfois matrice de devis dans un contexte expérimental), et sa <span class="math inline">\(i\)</span>ème ligne est <span class="math inline">\(\mathbf{x}_i\)</span>.</p>
<p>En supposant que la variable réponse provient d’une famille de localisation, nous pouvons réécrire le modèle linéaire en termes de la moyenne plus un aléa, <span class="math display">\[\begin{align*}
\underset{\text{observation}\vphantom{\mu_i}}{Y_i} = \underset{\text{moyenne } \mu_i}{\vphantom{Y_i}\mathbf{x}_i\boldsymbol{\beta}} + \underset{\text{aléa}\vphantom{\mu_i}}{\vphantom{Y_i}\varepsilon_i},
\end{align*}\]</span> où <span class="math inline">\(\varepsilon_i\)</span> est le terme spécifique à l’observation <span class="math inline">\(i\)</span>. On assume que les aléas <span class="math inline">\(\varepsilon_1, \ldots \varepsilon_n\)</span> sont indépendants et identiquement distribués, avec <span class="math inline">\(\mathsf{E}(\varepsilon_i \mid \mathbf{x}_i) = 0\)</span> et <span class="math inline">\(\mathsf{Var}(\varepsilon_i \mid \mathbf{x}_i) = \sigma^2\)</span>. On fixe l’espérance de l’aléa à zéro car on postule qu’il n’y a pas d’erreur systématique. La variance <span class="math inline">\(\sigma^2\)</span> sert à tenir compte du fait qu’aucune relation linéaire exacte ne lie <span class="math inline">\(\mathbf{x}_i\)</span> et <span class="math inline">\(Y_i\)</span>, ou que les mesures de <span class="math inline">\(Y_i\)</span> sont variables.</p>
<p>Le modèle linéaire normal ou gaussien spécifie que les réponses suivent une loi normale, avec <span class="math inline">\(Y_i \mid \boldsymbol{X}_i=\boldsymbol{x}_i \sim \mathsf{normale}(\mathbf{x}_i\boldsymbol{\beta}, \sigma^2)\)</span>. La loi normale est une famille de localisation, de sorte que <span class="math inline">\(Y \sim \mathsf{normale}(\mu, \sigma^2)\)</span> équivaut à la décomposition additive <span class="math inline">\(\mu + \varepsilon\)</span> pour <span class="math inline">\(\varepsilon \sim \mathsf{normale}(0, \sigma^2)\)</span>.</p>
<section id="exemples" class="level3" data-number="4.1.1">
<h3 data-number="4.1.1" class="anchored" data-anchor-id="exemples"><span class="header-section-number">4.1.1</span> Exemples</h3>
<p>Considérons quelques exemples de jeux de données qui serviront à illustrer les méthodes par la suite.</p>
<div id="exm-lee-choi1" class="theorem example">
<p><span class="theorem-title"><strong>Exemple 4.1 (Cohérence de descriptions de produits)</strong></span> L’étude 1 de <span class="citation" data-cites="Lee.Choi:2019">Lee et Choi (<a href="references.html#ref-Lee.Choi:2019" role="doc-biblioref">2019</a>)</span> (base de données <code>LC19_S1</code>, paquet <code>hecedsm</code>) considère l’impact sur la perception d’un produit de la divergence entre la description textuelle et l’image. Dans leur première expérience, un paquet de six brosses à dents est vendu, mais l’image montre soit un paquet de six, soit une seule). Les auteurs ont également mesuré la familiarité préalable avec la marque de l’article. Les <span class="math inline">\(n=96\)</span> participants ont été recrutés à l’aide d’un panel en ligne. Nous pourrions ajuster un modèle linéaire pour le score moyen d’évaluation du produit, <code>prodeval</code>, en fonction de la familiarité de la marque <code>familiarity</code>, un nombre entier allant de 1 à 7, et une variable binaire pour le facteur expérimental <code>consistency</code>, codé <code>0</code> pour des descriptions d’image/texte cohérentes et <code>1</code> si elles sont incohérentes. La matrice du modèle qui en résulte est alors de dimension <span class="math inline">\(96\times 3\)</span>. La réponse <code>prodeval</code> est fortement discrétisée.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(LC19_S1, <span class="at">package =</span> <span class="st">"hecedsm"</span>)</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a>modmat <span class="ot">&lt;-</span> <span class="fu">model.matrix</span>( <span class="co"># Matrice du modèle</span></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a>     <span class="sc">~</span> familiarity <span class="sc">+</span> consistency,</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>     <span class="at">data =</span> LC19_S1)</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="fu">tail</span>(modmat, <span class="at">n =</span> <span class="dv">5</span>L) <span class="co"># Imprimer les premières 5 lignes</span></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;    (Intercept) familiarity consistencyinconsistent</span></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 92           1           6                       1</span></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 93           1           4                       1</span></span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 94           1           7                       1</span></span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 95           1           7                       1</span></span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 96           1           7                       1</span></span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a><span class="fu">dim</span>(modmat) <span class="co"># dimension de la matrice du modèle</span></span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [1] 96  3</span></span></code><button title="Copier vers le presse-papier" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
<div id="exm-teaching-baumann" class="theorem example">
<p><span class="theorem-title"><strong>Exemple 4.2 (Méthodes d’apprentissage de compréhension de lecture)</strong></span> La base de données <code>BSJ92</code> du paquet <code>hecedsm</code> contient les résultats d’une expérience de <span class="citation" data-cites="Baumann:1992">Baumann, Seifert-Kessell, et Jones (<a href="references.html#ref-Baumann:1992" role="doc-biblioref">1992</a>)</span> sur l’efficacité de différentes stratégies de lecture sur la compréhension d’enfants.</p>
<blockquote class="blockquote">
<p>Soixante-six élèves de quatrième année ont été assignés au hasard à l’un des trois groupes expérimentaux suivants : (a) un groupe « Think-Aloud » (TA), dans lequel les élèves ont appris diverses stratégies de contrôle de la compréhension pour la lecture d’histoires (par exemple : auto-questionnement, prédiction, relecture) par le biais de la réflexion à haute voix; (b) un groupe lecture dirigée-activité de réflexion (DRTA), dans lequel les élèves ont appris une stratégie de prédiction-vérification pour lire et répondre aux histoires; ou (c) un groupe activité de lecture dirigée (DRA), un groupe contrôle dans lequel les élèves se sont engagés dans une lecture guidée non interactive d’histoires.</p>
</blockquote>
<p>Les variables d’intérêt sont <code>group</code>, le facteur pour le groupe expérimental, soit <code>DRTA</code>, <code>TA</code> et <code>DR</code> ainsi que les variables numériques <code>pretest1</code> et <code>posttest1</code>, qui donnent le score (sur 16) sur le test pré-expérience pour la tâche de détection des erreurs.</p>
<p>Les données sont balancées puisqu’il y a 22 observations dans chacun des trois sous-groupes. Les chercheurs ont appliqué une série de trois évaluations: le test 1 de détection d’erreurs, le test 2 consistant en un questionnaire de suivi de compréhension, et le test 3 standardisé <em>Degrees of Reading Power</em>). Les tests 1 et 2 ont été administrés à la fois avant et après l’intervention: cela nous permet d’établir l’amélioration moyenne de l’élève en ajoutant le résultat du test pré-intervention comme covariable. Les tests 1 étaient sur 16, mais celui administré après l’expérience a été rendu plus difficile pour éviter les cas d’étudiants obtenant des scores presque complets. La corrélation entre le pré-test et le post-test 1 est <span class="math inline">\((\widehat{\rho}_1=0.57)\)</span>, beaucoup plus forte que celle du second test <span class="math inline">\((\widehat{\rho}_2=0.21)\)</span>.</p>
</div>
<div id="exm-college-salary-discrimination" class="theorem example">
<p><span class="theorem-title"><strong>Exemple 4.3 (Discrimination salariale dans un collège américain)</strong></span> On s’intéresse à la discrimination salariale dans un collège américain, au sein duquel une étude a été réalisée pour investiguer s’il existait des inégalités salariales entre hommes et femmes. Le jeu de données <code>college</code> contient les variables suivantes:</p>
<ul>
<li><code>salaire</code>: salaire de professeurs pendant l’année académique 2008–2009 (en milliers de dollars USD).</li>
<li><code>echelon</code>: échelon académique, soit adjoint (<code>adjoint</code>), aggrégé (<code>aggrege</code>) ou titulaire (<code>titulaire</code>).</li>
<li><code>domaine</code>: variable catégorielle indiquant le champ d’expertise du professeur, soit appliqué (<code>applique</code>) ou théorique (<code>theorique</code>).</li>
<li><code>sexe</code>: indicateur binaire pour le sexe, <code>homme</code> ou <code>femme</code>.</li>
<li><code>service</code>: nombre d’années de service.</li>
<li><code>annees</code>: nombre d’années depuis l’obtention du doctorat.</li>
</ul>
</div>
<div id="exm-moon-vanepps" class="theorem example">
<p><span class="theorem-title"><strong>Exemple 4.4 (Suggestion de montants de dons)</strong></span> L’étude 1 de <span class="citation" data-cites="Moon.VanEpps:2023">Moon et VanEpps (<a href="references.html#ref-Moon.VanEpps:2023" role="doc-biblioref">2023</a>)</span> (données <code>MV23_S1</code>, paquet <code>hecedsm</code>) porte sur la proportion de donateurs à un organisme de charité et le montant de leurs dons. Les participants au panel en ligne avaient la possibilité de gagner 25$ et de faire don d’une partie de cette somme à l’organisme de leur choix. Les données fournies incluent uniquement les personnes qui n’ont pas dépassé ce montant et qui ont indiqué avoir fait un don d’un montant non nul.</p>
</div>
<div id="exm-sokolova" class="theorem example">
<p><span class="theorem-title"><strong>Exemple 4.5 (Un emballage en carton supplémentaire est-il considéré comme plus écologique ?)</strong></span> <span class="citation" data-cites="Sokolova:2023">Sokolova, Krishna, et Döring (<a href="references.html#ref-Sokolova:2023" role="doc-biblioref">2023</a>)</span> tient compte des préjugés des consommateurs lorsqu’il s’agit d’évaluer le caractère écologique des emballages. Des produits tels que les céréales sont emballés dans des sacs en plastique, eux-mêmes recouverts d’une boîte. Ils supposent (et constatent) que, paradoxalement, les consommateurs ont tendance à considérer l’emballage comme plus écologique lorsque la quantité de carton ou de carton entourant la boîte est plus importante, ce qui n’est pas le cas. Nous examinons dans la suite les données de l’étude 2A, qui mesure la perception du respect de l’environnement (PEF, variable <code>pef</code>) en fonction de la <code>proportion</code> d’emballage en carton (soit aucun, soit la moitié de la surface du plastique, soit la même, soit le double).</p>
</div>
</section>
<section id="analyse-exploratoire-des-données" class="level3" data-number="4.1.2">
<h3 data-number="4.1.2" class="anchored" data-anchor-id="analyse-exploratoire-des-données"><span class="header-section-number">4.1.2</span> Analyse exploratoire des données</h3>
<p>L’analyse exploratoire des données est une procédure itérative par laquelle nous interrogeons les données, en utilisant des informations auxiliaires, des statistiques descriptives et des graphiques, afin de mieux informer notre modélisation.</p>
<p>Elle est utile pour mieux comprendre les caractéristiques des données (plan d’échantillonnage, valeurs manquantes, valeurs aberrantes), la nature des observations, qu’il s’agisse de variables réponse ou explicatives et les interrelations entre variables.</p>
<p>Voir le <a href="https://tellingstorieswithdata.com/11-eda.html">Chapitre 11 de Alexander (2023)</a> pour des exemples. En particulier, il convient de vérifier</p>
<ul>
<li>que les variables catégorielles sont adéquatement traitées comme des facteurs (<code>factor</code>).</li>
<li>que les valeurs manquantes sont adéquatement déclarées comme telles (code d’erreur, 999, etc.)</li>
<li>s’il ne vaudrait mieux pas retirer certaines variables explicatives avec beaucoup de valeurs manquantes.</li>
<li>s’il ne vaudrait mieux pas fusionner des modalités de variables catégorielles si le nombre d’observation par modalité est trop faible.</li>
<li>qu’il n’y a pas de variable explicative dérivée de la variable réponse</li>
<li>que le sous-ensemble des observations employé pour l’analyse statistique est adéquat.</li>
<li>qu’il n’y a pas d’anomalies ou de valeurs aberrantes (par ex., 999 pour valeurs manquantes) qui viendraient fausser les résultats.</li>
</ul>
<div id="exm-college-aed" class="theorem example">
<p><span class="theorem-title"><strong>Exemple 4.6 (Analyse exploratoire des données <code>college</code>)</strong></span> Une analyse exploratoire des données est de mise avant d’ébaucher un modèle. Si le salaire augmente au fil des ans, on voit que l’hétérogénéité change en fonction de l’échelon et qu’il y a une relation claire entre ce dernier et le nombre d’années de service (les professeurs n’étant éligibles à des promotions qu’après un certain nombre d’années). Les professeurs adjoints qui ne sont pas promus sont généralement mis à la porte, aussi il y a moins d’occasions pour que les salaires varient sur cette échelle.</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div id="fig-edacollege" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-edacollege-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="regression-lineaire_files/figure-html/fig-edacollege-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:85.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-edacollege-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;4.1: Analyse exploratoire des données <code>college</code>: répartition des salaires en fonction de l’échelon et du nombre d’années de service
</figcaption>
</figure>
</div>
</div>
</div>
<p>Ainsi, le salaire augmente avec les années, mais la variabilité croît également. Les professeurs adjoints qui ne sont pas promus sont généralement mis à la porte, aussi il y a moins d’occasions pour que les salaires varient sur cette échelle. Il y a peu de femmes dans l’échantillon: moins d’information signifie moins de puissance pour détecter de petites différences de salaire. Si on fait un tableau de contingence de l’échelon et du sexe, on peut calculer la proportion relative homme/femme dans chaque échelon: 16% des profs adjoints, 16% pour les aggrégés, mais seulement 7% des titulaires alors que ces derniers sont mieux payés en moyenne.</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<table class="caption-top table table-sm table-striped small">
<caption>Tableau de contingence donnant le nombre de professeurs du collège par sexe et par échelon académique.</caption>
<thead>
<tr class="header">
<th style="text-align: left;"></th>
<th style="text-align: right;">adjoint</th>
<th style="text-align: right;">aggrege</th>
<th style="text-align: right;">titulaire</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">femme</td>
<td style="text-align: right;">11</td>
<td style="text-align: right;">10</td>
<td style="text-align: right;">18</td>
</tr>
<tr class="even">
<td style="text-align: left;">homme</td>
<td style="text-align: right;">56</td>
<td style="text-align: right;">54</td>
<td style="text-align: right;">248</td>
</tr>
</tbody>
</table>
</div>
</div>
<p>Plusieurs des variables explicatives potentielles des données <code>college</code> sont cat/gorielles (<code>echelon</code>, <code>sexe</code>, <code>discipline</code>), les deux dernières étant binaires. Les variables numériques <code>annees</code> et <code>service</code> sont fortement corrélées, avec une corrélation linéaire de 0.91.</p>
</div>
<div id="exm-donnees-manquantes-moon" class="theorem example">
<p><span class="theorem-title"><strong>Exemple 4.7 (Analyse exploratoire et données manquantes)</strong></span> Il convient de vérifier pour les données de <span class="citation" data-cites="Moon.VanEpps:2023">Moon et VanEpps (<a href="references.html#ref-Moon.VanEpps:2023" role="doc-biblioref">2023</a>)</span> que la description de la collecte coïncide avec la structure. Puisque les personnes qui n’ont pas donné ne remplissent pas le champ pour le montant, ce dernier indique une valeur manquante. Tous les montants des dons sont entre 0.25$ et 25$.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(MV23_S1, <span class="at">package =</span> <span class="st">"hecedsm"</span>)</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="fu">str</span>(MV23_S1)</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; tibble [869 × 4] (S3: tbl_df/tbl/data.frame)</span></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  $ before   : int [1:869] 0 1 0 1 1 1 1 0 1 0 ...</span></span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  $ donate   : int [1:869] 0 0 0 1 1 0 1 0 0 1 ...</span></span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  $ condition: Factor w/ 2 levels "open-ended","quantity": 1 1 1 1 2 2 2 1 1 1 ...</span></span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  $ amount   : num [1:869] NA NA NA 10 5 NA 20 NA NA 25 ...</span></span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(MV23_S1)</span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;      before          donate          condition       amount    </span></span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  Min.   :0.000   Min.   :0.00   open-ended:407   Min.   : 0.2  </span></span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  1st Qu.:0.000   1st Qu.:0.00   quantity  :462   1st Qu.: 5.0  </span></span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  Median :1.000   Median :1.00                    Median :10.0  </span></span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  Mean   :0.596   Mean   :0.73                    Mean   :10.7  </span></span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  3rd Qu.:1.000   3rd Qu.:1.00                    3rd Qu.:15.0  </span></span>
<span id="cb2-15"><a href="#cb2-15" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  Max.   :1.000   Max.   :1.00                    Max.   :25.0  </span></span>
<span id="cb2-16"><a href="#cb2-16" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  NA's   :1                                       NA's   :235</span></span></code><button title="Copier vers le presse-papier" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Si nous incluons <code>amount</code> comme variable réponse dans un modèle de régression, les 235 observations manquantes seront supprimées par défaut. Cela ne pose pas de problème si nous voulons comparer le montant moyen des personnes qui ont fait un don, mais dans le cas contraire, nous devons transformer les <code>NA</code> en zéros. La variable <code>donate</code> ne doit pas être incluse comme variable explicative dans le modèle, car elle permet de prédire exactement les personnes qui n’ont pas donné.</p>
</div>
</section>
<section id="spécification-du-modèle-pour-la-moyenne" class="level3" data-number="4.1.3">
<h3 data-number="4.1.3" class="anchored" data-anchor-id="spécification-du-modèle-pour-la-moyenne"><span class="header-section-number">4.1.3</span> Spécification du modèle pour la moyenne</h3>
<p>La première étape d’une analyse consiste à décider quelles variables explicatives doivent être ajoutées à l’équation de la moyenne, et sous quelle forme. Les modèles ne sont que des approximations de la réalité; la section 2.1 de <span class="citation" data-cites="Venables:2000">Venables (<a href="references.html#ref-Venables:2000" role="doc-biblioref">2000</a>)</span> affirme que, si nous pensons que la véritable fonction moyenne reliant les variables explicatives <span class="math inline">\(\boldsymbol{X}\)</span> et la réponse <span class="math inline">\(Y\)</span> est de la forme <span class="math inline">\(\mathsf{E}(Y \mid \boldsymbol{X}) = f(\boldsymbol{X})\)</span> pour <span class="math inline">\(f\)</span> suffisamment lisse, alors le modèle linéaire est une approximation du premier ordre. À des fins d’interprétation, il est logique de centrer sur la moyenne toute variable explicative continue, car cela facilite l’interprétation.</p>
<p>Dans un cadre expérimental, où la condition expérimentale est attribué de manière aléatoire, nous pouvons directement comparer les différents traitements et tirer des conclusions causales (puisque toutes les autres choses sont égales en moyenne constantes, toute différence détectable est due en moyenne à notre manipulation). Bien que nous nous abstenions généralement d’inclure d’autres variables explicatives afin de préserver la simplicité du modèle, il peut néanmoins être utile de prendre en compte certaines variables concomitantes qui expliquent une partie de la variabilité afin de filtrer le bruit de fond et d’augmenter la puissance de l’étude. Par exemple, pour les données de <span class="citation" data-cites="Baumann:1992">Baumann, Seifert-Kessell, et Jones (<a href="references.html#ref-Baumann:1992" role="doc-biblioref">1992</a>)</span>, l’objectif est de comparer les scores moyens en fonction de la méthode d’enseignement, nous inclurions <code>group</code>. Dans cet exemple, il serait également logique d’inclure le résultat <code>pretest1</code> en tant qu’élément explicatif pour <code>posttest1</code>. De cette façon, nous modéliserons la différence moyenne d’amélioration entre le pré-test et le post-test plutôt que le résultat final.</p>
<p>Dans un contexte observationnel, les participants dans différents groupes ont des caractéristiques différentes et nous devons donc tenir compte de ces différences. Les modèles linéaires utilisés en économie et en finance contiennent souvent des variables de contrôle au modèle pour tenir compte des différences potentielles dues aux variables sociodémographiques (âge, revenu, etc.) qui seraient corrélées à l’appartenance aux groupes. Tout test de coefficients ne prendrait en compte que la corrélation entre le résultat <span class="math inline">\(Y\)</span> et le facteur explicatif postulé d’intérêt.</p>
</section>
</section>
<section id="interprétation-des-coefficients" class="level2" data-number="4.2">
<h2 data-number="4.2" class="anchored" data-anchor-id="interprétation-des-coefficients"><span class="header-section-number">4.2</span> Interprétation des coefficients</h2>
<p>La spécification de la moyenne est <span class="math display">\[\begin{align*}
\mathsf{E}(Y_i \mid \boldsymbol{X}_i = \boldsymbol{x}_i) = \beta_0 + \beta_1 x_{i1} + \cdots + \beta_p x_{ip}.
\end{align*}\]</span> L’<strong>ordonnée à l’origine</strong> <span class="math inline">\(\beta_0\)</span> est la <strong>valeur moyenne de <span class="math inline">\(Y\)</span></strong> lorsque toutes les variables explicatives du modèles sont nulles, soit <span class="math inline">\(\boldsymbol{x}_i=\boldsymbol{0}_p\)</span>. <span class="math display">\[\begin{align*}
\beta_0 &amp;= \mathsf{E}(Y \mid X_1=0,X_2=0,\ldots,X_p=0) \\
&amp;= \beta_0 + \beta_1 \times 0 + \beta_2 \times 0 + \cdots + \beta_p \times 0
\end{align*}\]</span> Bien sur, il se peut que cette interprétation n’ait aucun sens dans le contexte étudié. Centrer les variables explicatives numériques (pour que leurs moyennes soit zéro) permet de rendre l’ordonnée à l’origine plus interprétable.</p>
<p>En régression linéaire, le paramètre <span class="math inline">\(\beta_j\)</span> mesure l’effet de la variable <span class="math inline">\(X_j\)</span> sur la variable <span class="math inline">\(Y\)</span> une fois que l’on tient compte des effets des autres variables explicatives. Pour chaque augmentation d’une unité de <span class="math inline">\(X_j\)</span>, la réponse <span class="math inline">\(Y\)</span> augmente en moyenne de <span class="math inline">\(\beta_j\)</span> lorsque les autres variables demeurent inchangées, <span class="math display">\[\begin{align*}
\beta_j &amp;= \mathsf{E}(Y \mid X_j= x_j+1, \boldsymbol{X}_{-j} = \boldsymbol{x}_{-j})  - \mathsf{E}(Y \mid \boldsymbol{X} = \boldsymbol{x}) \\
&amp;= \sum_{\substack{k=1\\k \neq j}}^p \beta_kx_k + \beta_j(x_j+1) - \sum_{k=1}^p \beta_k x_k
\end{align*}\]</span></p>
<div id="def-effet-marginal" class="theorem definition">
<p><span class="theorem-title"><strong>Définition 4.1 (Effet marginal)</strong></span> On définit l’effet marginal comme la dérivée première de la moyenne conditionnelle par rapport à <span class="math inline">\(X_j\)</span>, soit <span class="math display">\[\text{effet marginal de }X_j =  \frac{\partial \mathsf{E}(Y \mid \boldsymbol{X})}{ \partial X_j}.\]</span> Le coefficient <span class="math inline">\(\beta_j\)</span> est aussi l’<em>effet marginal</em> de la variable <span class="math inline">\(X_j\)</span>.</p>
</div>
<p>Les variables indicatrices, qui prennent typiquement des valeurs de <span class="math inline">\(-1\)</span>, <span class="math inline">\(0\)</span> et <span class="math inline">\(1\)</span>, servent à indiquer l’appartenance aux différentes modalités d’une variable catégorielle. Par exemple, pour une variable indicatrice binaire, nous pouvons créer une colonne dont les entrées sont <span class="math inline">\(1\)</span> pour le groupe de traitement et <span class="math inline">\(0\)</span> pour le groupe de contrôle.</p>
<div id="exm-moon" class="theorem example">
<p><span class="theorem-title"><strong>Exemple 4.8 (Modèle linéaire avec une seule variable binaire)</strong></span> Considérons par exemple un modèle linéaire pour les données de <span class="citation" data-cites="Moon.VanEpps:2023">Moon et VanEpps (<a href="references.html#ref-Moon.VanEpps:2023" role="doc-biblioref">2023</a>)</span> qui inclut le montant (<code>amount</code>) (en dollars, de 0 pour les personnes qui n’ont pas fait de don, jusqu’à 25 dollars).</p>
<p>L’équation du modèle linéaire simple qui inclut la variable binaire <code>condition</code> est <span class="math display">\[\begin{align*}
\mathsf{E}(\texttt{amount} \mid \texttt{condition})&amp;= \beta_0 + \beta_1 \mathbf{1}_{\texttt{condition}=\texttt{quantity}}.
\\&amp;= \begin{cases}
\beta_0, &amp; \texttt{condition}=0, \\
\beta_0 + \beta_1 &amp; \texttt{condition}=1.
\end{cases}
\end{align*}\]</span> Soit <span class="math inline">\(\mu_0\)</span> l’espérance du montant pour le groupe contrôle (<code>open-ended</code>) et <span class="math inline">\(\mu_1\)</span> celui des participants du groupe de traitement (<code>quantity</code>). Un modèle linéaire qui ne contient qu’une variable binaire <span class="math inline">\(X\)</span> comme régresseur revient à spécifier une moyenne différente pour chacun des deux groupes. L’ordonnée à l’origine <span class="math inline">\(\beta_0\)</span> est la moyenne du groupe contrôle. La moyenne du groupe traitement (<code>quantity</code>) est <span class="math inline">\(\beta_0 + \beta_1 = \mu_1\)</span> et donc <span class="math inline">\(\beta_1=\mu_1-\mu_0\)</span> est la différence du montant moyen de dons entre le groupe <code>open-ended</code> et le groupe <code>quantity</code>. Cette paramétrisation est commode si on veut tester s’il y a une différence moyenne entre les deux groupes, puisque cette hypothèse nulle correspond à <span class="math inline">\(\mathscr{H}_0: \beta_1=0\)</span>.</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div id="fig-donation-moon" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-donation-moon-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="regression-lineaire_files/figure-html/fig-donation-moon-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:85.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-donation-moon-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;4.2: Modèle linéaire simple pour les données <code>MV23_S1</code> avec <code>condition</code> comme variable explicative binaire, avec nuage de points décalés et un diagramme en demi-violin. Les cercles indiquent les moyennes de l’échantillon.
</figcaption>
</figure>
</div>
</div>
</div>
<p>Même si le modèle linéaire définit une droite, cette dernière ne peut être évaluée qu’à <span class="math inline">\(0\)</span> ou <span class="math inline">\(1\)</span>; la <a href="#fig-donation-moon" class="quarto-xref">Figure&nbsp;<span>4.2</span></a> montre cette droite avec en plus un nuage de points des montants, décalés horizontalement, et de la densité pour chaque condition. Le point coloré indique la moyenne empirique, qui correspond aux estimations.</p>
<p>Même s’il est clair que les données sont fortement discrétisées avec beaucoup de doublons et de zéros, l’échantillon a une taille de 869 observations, donc les conclusions quant aux moyennes de groupe seront fiables.</p>
</div>
<p>Considérons des variables catégorielles avec <span class="math inline">\(K &gt; 2\)</span> niveaux, qui dans <strong>R</strong> sont de la classe <code>factor</code>. La paramétrisation par défaut des facteurs se fait en termes de contraste de traitement: le niveau de référence du facteur (par défaut, la première valeur dans l’ordre alphanumérique) sera traité comme la catégorie de référence et assimilé à l’ordonnée à l’origine. Le logiciel créera alors un ensemble de <span class="math inline">\(K-1\)</span> variables indicatrices pour un facteur à <span class="math inline">\(K\)</span> niveaux, chacune d’entre elles ayant un pour la catégorie représentée et zéro dans le cas contraire.</p>
<div id="exm-baumann-dummies" class="theorem example">
<p><span class="theorem-title"><strong>Exemple 4.9 (Codage binaire pour les variables catégorielles)</strong></span> Considérons l’étude de <span class="citation" data-cites="Baumann:1992">Baumann, Seifert-Kessell, et Jones (<a href="references.html#ref-Baumann:1992" role="doc-biblioref">1992</a>)</span> et la seule variable <code>group</code>. Les données sont classées par groupe : les 22 premières observations concernent le groupe <code>DR</code>, les 22 suivantes le groupe <code>DRTA</code> et les 22 dernières le groupe <code>TA</code>. Si nous ajustons un modèle avec <code>groupe</code> comme variable catégorielle</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(BSJ92, <span class="at">package =</span> <span class="st">"hecedsm"</span>)</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="fu">class</span>(BSJ92<span class="sc">$</span>group) <span class="co"># Vérifier que group est un facteur</span></span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [1] "factor"</span></span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a><span class="fu">levels</span>(BSJ92<span class="sc">$</span>group) <span class="co"># première valeur est la catégorie de référence</span></span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [1] "DR"   "DRTA" "TA"</span></span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Imprimer trois lignes de la matrice du modèle</span></span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a><span class="co"># (trois enfants de groupes différents)</span></span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a><span class="fu">model.matrix</span>(<span class="sc">~</span> group, <span class="at">data =</span> BSJ92)[<span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">23</span>,<span class="dv">47</span>),]</span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;    (Intercept) groupDRTA groupTA</span></span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 1            1         0       0</span></span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 23           1         1       0</span></span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 47           1         0       1</span></span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Comparer avec les niveaux des facteurs</span></span>
<span id="cb3-14"><a href="#cb3-14" aria-hidden="true" tabindex="-1"></a>BSJ92<span class="sc">$</span>group[<span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">23</span>,<span class="dv">47</span>)]</span>
<span id="cb3-15"><a href="#cb3-15" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [1] DR   DRTA TA  </span></span>
<span id="cb3-16"><a href="#cb3-16" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Levels: DR DRTA TA</span></span></code><button title="Copier vers le presse-papier" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Si nous ajustons un modèle avec <code>groupe</code> comme variable catégorielle, la spécification de la moyenne du modèle est <span class="math display">\[\mathsf{E}(Y \mid \texttt{group})= \beta_0 + \beta_1\mathbf{1}_{\texttt{group}=\texttt{DRTA}} + \beta_2\mathbf{1}_{\texttt{group}=\texttt{TA}}.\]</span> Puisque la variable <code>group</code> est catégorielle avec <span class="math inline">\(K=3\)</span> niveaux, il nous faut mettre <span class="math inline">\(K-1 = 2\)</span> variables indicatrices.</p>
<p>Avec la paramétrisation en termes de <strong>traitements</strong> (option par défaut), on obtient</p>
<ul>
<li><span class="math inline">\(\mathbf{1}_{\texttt{group}=\texttt{DRTA}}=1\)</span> si <code>group=DRTA</code> et zéro sinon,</li>
<li><span class="math inline">\(\mathbf{1}_{\texttt{group}=\texttt{TA}}=1\)</span> si <code>group=TA</code> et zéro sinon.</li>
</ul>
<p>Étant donné que le modèle comprend une ordonnée à l’origine et que le modèle décrit en fin de compte trois moyennes de groupe, nous n’avons besoin que de deux variables supplémentaires. Avec la paramétrisation en termes de <strong>traitements</strong>, la moyenne du groupe de référence est l’ordonnée à l’origine. Si <code>group</code>=<code>DR</code> (référence), les deux variables indicatrices binaires <code>groupDRTA</code> et <code>groupTA</code> sont nulles. La moyenne de chaque groupe est</p>
<ul>
<li><span class="math inline">\(\mu_{\texttt{DR}} = \beta_0\)</span>,</li>
<li><span class="math inline">\(\mu_{\texttt{DRTA}}=\beta_0 + \beta_1\)</span> et</li>
<li><span class="math inline">\(\mu_{\texttt{TA}} = \beta_0 + \beta_2\)</span>.</li>
</ul>
<p>Ainsi, <span class="math inline">\(\beta_1\)</span> est la différence de moyenne entre les groupes <code>DRTA</code> et<code>DR</code>, et de la même façon <span class="math inline">\(\beta_2=\mu_{\texttt{TA}}- \mu_{\texttt{DR}}\)</span>.</p>
</div>
<div id="rem-sumtozero" class="proof remark">
<p><span class="proof-title"><em>Remarque 4.1</em> (Contrainte de somme nulle). </span>La paramétrisation discutée ci-dessus, qui est la valeur par défaut de la fonction <code>lm</code>, n’est pas la seule disponible. Plutôt que de comparer la moyenne de chaque groupe avec celle d’une catégorie de référence, la paramétrisation par défaut pour les modèles d’analyse de la variance est en termes de contraintes de somme nulle pour les coefficients, où l’ordonnée à l’origine est la moyenne équi-pondérée de chaque groupe, et les paramètres <span class="math inline">\(\beta_1, \ldots, \beta_{K-1}\)</span> sont des différences par rapport à cette moyenne.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="fu">model.matrix</span>(</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>    <span class="sc">~</span> group,</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>    <span class="at">data =</span> BSJ92,</span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a>    <span class="at">contrasts.arg =</span> <span class="fu">list</span>(<span class="at">group =</span> <span class="st">"contr.sum"</span>))</span></code><button title="Copier vers le presse-papier" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-layout-align="center">
<div id="tbl-sum2zero" class="cell quarto-float quarto-figure quarto-figure-center anchored" data-layout-align="center">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-sum2zero-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Tableau&nbsp;4.1: Paramétrisation des variables indicatrices pour la contrainte de somme nulle pour une variable catégorielle.
</figcaption>
<div aria-describedby="tbl-sum2zero-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="cell-output-display">
<table class="do-not-create-environment cell caption-top table table-sm table-striped small">
<thead>
<tr class="header">
<th style="text-align: left;"></th>
<th style="text-align: right;">(Intercept)</th>
<th style="text-align: right;">group1</th>
<th style="text-align: right;">group2</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">DR</td>
<td style="text-align: right;">1</td>
<td style="text-align: right;">1</td>
<td style="text-align: right;">0</td>
</tr>
<tr class="even">
<td style="text-align: left;">DRTA</td>
<td style="text-align: right;">1</td>
<td style="text-align: right;">0</td>
<td style="text-align: right;">1</td>
</tr>
<tr class="odd">
<td style="text-align: left;">TA</td>
<td style="text-align: right;">1</td>
<td style="text-align: right;">-1</td>
<td style="text-align: right;">-1</td>
</tr>
</tbody>
</table>
</div>
</div>
</figure>
</div>
</div>
<p>Dans la contrainte de somme nulle, nous obtenons à nouveau deux variables indicatrices, <code>group1</code> et <code>group2</code>, ainsi que l’ordonnée à l’origine. La valeur de <code>group1</code> est <span class="math inline">\(1\)</span> si <code>group=DR</code>, <span class="math inline">\(0\)</span> si <code>group=DRTA</code> et <span class="math inline">\(-1\)</span> si <code>group=TA</code>. ous trouvons <span class="math inline">\(\mu_{\texttt{DR}} = \beta_0 + \beta_1\)</span>, <span class="math inline">\(\mu_{\texttt{DRTA}}=\beta_0 + \beta_2\)</span> et <span class="math inline">\(\mu_{\texttt{TA}} = \beta_0 - \beta_1 - \beta_2\)</span>. Quelques manipulations algébriques révèlent que <span class="math inline">\(\beta_0 = (\mu_{\texttt{DR}} +\mu_{\texttt{DRTA}}+\mu_{\texttt{TA}})/3\)</span>, l’espérance équipondérée des différents niveaux. De manière générale, l’ordonnée à l’origine moins la somme de tous les autres coefficients liés aux facteurs.</p>
<p>En supprimant l’ordonnée à l’origine, on pourrait inclure trois variables indicatrices pour chaque niveau d’un facteur et chaque paramètre correspondrait alors à la moyenne. Ce n’est pas recommandé dans <strong>R</strong> car le logiciel traite différemment les modèles sans ordonnée à l’origine et certains résultats seront absurdes (par exemple, le coefficient de détermination sera erroné).</p>
</div>
<div id="exm-college-coeff" class="theorem example">
<p><span class="theorem-title"><strong>Exemple 4.10 (Interprétation des coefficients)</strong></span> On considère un modèle de régression pour les données <code>college</code> qui inclut le sexe, l’échelon académique, le nombre d’années de service et le domaine d’expertise (appliquée ou théorique).</p>
<p>Le modèle linéaire postulé s’écrit</p>
<p><span class="math display">\[\begin{align*}
\texttt{salaire} &amp;= \beta_0 + \beta_1 \mathbf{1}_{\texttt{sexe}=\texttt{femme}} +\beta_2 \mathbf{1}_{\texttt{domaine}=\texttt{theorique}} \\&amp;\quad +\beta_3 \mathbf{1}_{\texttt{echelon}=\texttt{aggrege}}
+\beta_4 \mathbf{1}_{\texttt{echelon}=\texttt{titulaire}} \\&amp;\quad+\beta_5 \texttt{service} + \varepsilon.
\end{align*}\]</span></p>
<div class="cell" data-layout-align="center">
<div id="tbl-collegecoefs" class="cell quarto-float quarto-figure quarto-figure-center anchored" data-layout-align="center">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-collegecoefs-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Tableau&nbsp;4.2: Estimations des coefficients du modèle linéaire pour les données <span class="math inline">\(\texttt{college}\)</span> (en dollars USD, arrondis à l’unité).
</figcaption>
<div aria-describedby="tbl-collegecoefs-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="cell-output-display">
<table class="do-not-create-environment cell caption-top table table-sm table-striped small">
<colgroup>
<col style="width: 16%">
<col style="width: 16%">
<col style="width: 16%">
<col style="width: 16%">
<col style="width: 16%">
<col style="width: 16%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: right;"><span class="math inline">\(\widehat{\beta}_0\)</span></th>
<th style="text-align: right;"><span class="math inline">\(\widehat{\beta}_1\)</span></th>
<th style="text-align: right;"><span class="math inline">\(\widehat{\beta}_2\)</span></th>
<th style="text-align: right;"><span class="math inline">\(\widehat{\beta}_3\)</span></th>
<th style="text-align: right;"><span class="math inline">\(\widehat{\beta}_4\)</span></th>
<th style="text-align: right;"><span class="math inline">\(\widehat{\beta}_5\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: right;">86596</td>
<td style="text-align: right;">-4771</td>
<td style="text-align: right;">-13473</td>
<td style="text-align: right;">14560</td>
<td style="text-align: right;">49160</td>
<td style="text-align: right;">-89</td>
</tr>
</tbody>
</table>
</div>
</div>
</figure>
</div>
</div>
<p>L’interprétation des coefficients est la suivante:</p>
<ul>
<li>L’ordonnée à l’origine <span class="math inline">\(\beta_0\)</span> correspond au salaire moyen d’un professeur adjoint (un homme) qui vient de compléter ses études et qui travaille dans un domaine appliqué: on estime ce salaire à <span class="math inline">\(\widehat{\beta}_0=86596\)</span> dollars.</li>
<li>toutes choses étant égales par ailleurs (même domaine, échelon et années depuis le dernier diplôme), l’écart de salaire entre un homme et un femme est estimé à <span class="math inline">\(\widehat{\beta}_1=-4771\)</span> dollars.</li>
<li><em>ceteris paribus</em>, un(e) professeur(e) qui oeuvre dans un domaine théorique gagne <span class="math inline">\(\beta_2\)</span> dollars de plus qu’une personne du même sexe dans un domaine appliqué; on estime cette différence à <span class="math inline">\(-13473\)</span> dollars.</li>
<li><em>ceteris paribus</em>, la différence moyenne de salaire entre professeurs adjoints et aggrégés est estimée à <span class="math inline">\(\widehat{\beta}_3=14560\)</span> dollars.</li>
<li><em>ceteris paribus</em>, la différence moyenne de salaire entre professeurs adjoints et titulaires est de <span class="math inline">\(\widehat{\beta}_4=49160\)</span> dollars.</li>
<li>au sein d’un même échelon, chaque année supplémentaire de service mène à une augmentation de salaire annuelle moyenne de <span class="math inline">\(\widehat{\beta}_5=-89\)</span> dollars.</li>
</ul>
</div>
<div id="rem-polynomes" class="proof remark">
<p><span class="proof-title"><em>Remarque 4.2</em> (Polynômes). </span>Il n’est pas toujours possible de fixer la valeur des autres colonnes de <span class="math inline">\(\mathbf{X}\)</span> si plusieurs colonnes contiennent des transformations ou des fonctions d’une même variable explicative. Par exemple, on pourrait par exemple considérer un polynôme d’ordre <span class="math inline">\(k\)</span> (ordinairement, on va prendre <span class="math inline">\(k\leq 3\)</span>), <span class="math display">\[\begin{align*}
\mathsf{E}(Y \mid X=x)=\beta_0+ \beta_1 x+ \beta_2 x^2 + \cdots +\beta_k x^k.
\end{align*}\]</span> Si l’on inclut un terme d’ordre <span class="math inline">\(k\)</span>, <span class="math inline">\(x^k\)</span>, il faut <strong>toujours</strong> inclure les termes d’ordre inférieur <span class="math inline">\(1, x, \ldots, x^{k-1}\)</span> pour l’interprétabilité du modèle résultant (autrement, cela revient à choisir un polynôme en imposant que certains coefficients soient zéros). L’interprétation des effets des covariables nonlinéaires (même polynomiaux) est complexe parce qu’on ne peut pas « fixer la valeur des autres variables »: l’effet d’une augmentation d’une unité de <span class="math inline">\(x\)</span> <em>dépend de la valeur de cette dernière</em>. L’effet marginal de <span class="math inline">\(x\)</span> est <span class="math inline">\(\beta_1 + \sum_{j=1}^{k-1}j \beta_{j+1}x^j\)</span>.</p>
<p>L’utilisation de polynôme, plus flexibles, n’est généralement pas recommendée car ces derniers se généralisent mal hors de l’étendue observée des données. L’utilisation de splines avec une pénalité sur les coefficients, avec des modèles additifs, offre plus de flexibilité.</p>
</div>
<div id="exm-quadmod" class="theorem example">
<p><span class="theorem-title"><strong>Exemple 4.11 (Modèle quadratique pour les données automobile)</strong></span> Considérons un modèle de régression linéaire pour l’autonomie d’essence en fonction de la puissance du moteur pour différentes voitures dont les caractéristiques sont données dans le jeu de données <code>automobiles</code>. Le modèle postulé incluant un terme quadratique est <span class="math display">\[\begin{align*}
\texttt{autonomie}_i = \beta_0 + \beta_1 \texttt{puissance}_i + \beta_2 \texttt{puissance}_i^2 + \varepsilon_i
\end{align*}\]</span> Afin de comparer l’ajustement du modèle quadratique, on peut inclure également la droite ajustée du modèle de régression simple qui n’inclut que puissance.</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div id="fig-autoquad2d" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-autoquad2d-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="regression-lineaire_files/figure-html/fig-autoquad2d-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:85.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-autoquad2d-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;4.3: Modèle de régression avec terme quadratique pour la puissance (gris), versus spline cubique pénalisée (ligne traitillée).
</figcaption>
</figure>
</div>
</div>
</div>
<p>À vue d’oeil, l’ajustement quadratique est bon: nous verrons plus tard à l’aide de test si une simple droite aurait été suffisante. On voit aussi dans la <a href="#fig-autoquad2d" class="quarto-xref">Figure&nbsp;<span>4.3</span></a> que l’autonomie d’essence décroît rapidement quand la puissance croît entre <span class="math inline">\(0\)</span> et <span class="math inline">\(189.35\)</span>, mais semble remonter légèrement par la suite pour les voitures qui un moteur de plus de 200 chevaux-vapeurs, ce que le modèle quadratique capture. Prenez garde en revanche à l’extrapolation là où vous n’avez pas de données (comme l’illustre remarquablement bien <a href="https://web.archive.org/web/20210315050023/https://livefreeordichotomize.com/2020/05/05/model-detective/">le modèle cubique de Hassett pour le nombre de cas quotidiens de coronavirus</a>).</p>
<p>La représentation graphique du modèle polynomial de degré 2 présenté dans la <a href="#fig-autoquad2d" class="quarto-xref">Figure&nbsp;<span>4.3</span></a> peut sembler contre-intuitive, mais c’est une projection en 2D d’un plan 3D de coordonnées <span class="math inline">\(\beta_0 + \beta_1x-y +\beta_2z =0\)</span>, où <span class="math inline">\(x=\texttt{puissance}\)</span>, <span class="math inline">\(z=\texttt{puissance}^2\)</span> et <span class="math inline">\(y=\texttt{autonomie}\)</span>. La physique et le bon-sens imposent la contrainte <span class="math inline">\(z = x^2\)</span>, et donc les valeurs ajustées vivent sur une courbe dans un sous-espace du plan ajusté, représenté en gris dans la <a href="#fig-hyperplan" class="quarto-xref">Figure&nbsp;<span>4.4</span></a>.</p>
<div class="cell" data-layout-align="center">
<div id="fig-hyperplan" class="cell-output-display quarto-float quarto-figure quarto-figure-center anchored">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-hyperplan-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="plotly html-widget html-fill-item" id="htmlwidget-0748faf2f2c9924061cd" style="width:85%;height:474.624px;"></div>
<script type="application/json" data-for="htmlwidget-0748faf2f2c9924061cd">{"x":{"visdat":{"91125817ccd7":["function () ","plotlyVisDat"],"9112480fe2f4":["function () ","data"]},"cur_data":"9112480fe2f4","attrs":{"91125817ccd7":{"colors":"grey","alpha_stroke":1,"sizes":[10,100],"spans":[1,20],"x":{},"y":{},"z":{},"type":"scatter3d","mode":"markers","name":"data","opacity":0.80000000000000004,"marker":{"color":"black","size":4,"hoverinfo":"skip","opacity":0.80000000000000004},"inherit":true},"91125817ccd7.1":{"z":{},"type":"surface","x":[46,230],"y":[2116,52900],"name":"Relation entre puissance et autonomie","opacity":0.75,"cauto":false,"surfacecolor":[0,0,0],"inherit":false},"9112480fe2f4":{"colors":"grey","alpha_stroke":1,"sizes":[10,100],"spans":[1,20],"x":{},"y":{},"z":{},"type":"scatter3d","mode":"lines","color":"grey","inherit":true}},"layout":{"margin":{"b":40,"l":60,"t":25,"r":10},"scene":{"xaxis":{"title":"puissance (chevaux vapeurs)"},"yaxis":{"title":"puissance carré"},"zaxis":{"title":"autonomie d'essence (miles au gallon)"}},"hovermode":"closest","showlegend":false,"legend":{"yanchor":"top","y":0.5}},"source":"A","config":{"modeBarButtonsToAdd":["hoverclosest","hovercompare"],"showSendToCloud":false},"data":[{"x":[130,165,150,150,140,198,220,215,225,190,170,160,150,225,95,95,97,85,88,46,87,90,95,113,90,215,200,210,193,88,90,95,100,105,100,88,100,165,175,153,150,180,170,175,110,72,100,88,86,90,70,76,65,69,60,70,95,80,54,90,86,165,175,150,153,150,208,155,160,190,97,150,130,140,150,112,76,87,69,86,92,97,80,88,175,150,145,137,150,198,150,158,150,215,225,175,105,100,100,88,95,46,150,167,170,180,100,88,72,94,90,85,107,90,145,230,49,75,91,112,150,110,122,180,95,100,100,67,80,65,75,100,110,105,140,150,150,140,150,83,67,78,52,61,75,75,75,97,93,67,95,105,72,72,170,145,150,148,110,105,110,95,110,110,129,75,83,100,78,96,71,97,97,70,90,95,88,98,115,53,86,81,92,79,83,140,150,120,152,100,105,81,90,52,60,70,53,100,78,110,95,71,70,75,72,102,150,88,108,120,180,145,130,150,68,80,58,96,70,145,110,145,130,110,105,100,98,180,170,190,149,78,88,75,89,63,83,67,78,97,110,110,48,66,52,70,60,110,140,139,105,95,85,88,100,90,105,85,110,120,145,165,139,140,68,95,97,75,95,105,85,97,103,125,115,133,71,68,115,85,88,90,110,130,129,138,135,155,142,125,150,71,65,80,80,77,125,71,90,70,70,65,69,90,115,115,90,76,60,70,65,90,88,90,90,78,90,75,92,75,65,105,65,48,48,67,67,67,67,62,132,100,88,72,84,84,92,110,84,58,64,60,67,65,62,68,63,65,65,74,75,75,100,74,80,76,116,120,110,105,88,85,88,88,88,85,84,90,92,74,68,68,63,70,88,75,70,67,67,67,110,85,92,112,96,84,90,86,52,84,79,82],"y":[16900,27225,22500,22500,19600,39204,48400,46225,50625,36100,28900,25600,22500,50625,9025,9025,9409,7225,7744,2116,7569,8100,9025,12769,8100,46225,40000,44100,37249,7744,8100,9025,10000,11025,10000,7744,10000,27225,30625,23409,22500,32400,28900,30625,12100,5184,10000,7744,7396,8100,4900,5776,4225,4761,3600,4900,9025,6400,2916,8100,7396,27225,30625,22500,23409,22500,43264,24025,25600,36100,9409,22500,16900,19600,22500,12544,5776,7569,4761,7396,8464,9409,6400,7744,30625,22500,21025,18769,22500,39204,22500,24964,22500,46225,50625,30625,11025,10000,10000,7744,9025,2116,22500,27889,28900,32400,10000,7744,5184,8836,8100,7225,11449,8100,21025,52900,2401,5625,8281,12544,22500,12100,14884,32400,9025,10000,10000,4489,6400,4225,5625,10000,12100,11025,19600,22500,22500,19600,22500,6889,4489,6084,2704,3721,5625,5625,5625,9409,8649,4489,9025,11025,5184,5184,28900,21025,22500,21904,12100,11025,12100,9025,12100,12100,16641,5625,6889,10000,6084,9216,5041,9409,9409,4900,8100,9025,7744,9604,13225,2809,7396,6561,8464,6241,6889,19600,22500,14400,23104,10000,11025,6561,8100,2704,3600,4900,2809,10000,6084,12100,9025,5041,4900,5625,5184,10404,22500,7744,11664,14400,32400,21025,16900,22500,4624,6400,3364,9216,4900,21025,12100,21025,16900,12100,11025,10000,9604,32400,28900,36100,22201,6084,7744,5625,7921,3969,6889,4489,6084,9409,12100,12100,2304,4356,2704,4900,3600,12100,19600,19321,11025,9025,7225,7744,10000,8100,11025,7225,12100,14400,21025,27225,19321,19600,4624,9025,9409,5625,9025,11025,7225,9409,10609,15625,13225,17689,5041,4624,13225,7225,7744,8100,12100,16900,16641,19044,18225,24025,20164,15625,22500,5041,4225,6400,6400,5929,15625,5041,8100,4900,4900,4225,4761,8100,13225,13225,8100,5776,3600,4900,4225,8100,7744,8100,8100,6084,8100,5625,8464,5625,4225,11025,4225,2304,2304,4489,4489,4489,4489,3844,17424,10000,7744,5184,7056,7056,8464,12100,7056,3364,4096,3600,4489,4225,3844,4624,3969,4225,4225,5476,5625,5625,10000,5476,6400,5776,13456,14400,12100,11025,7744,7225,7744,7744,7744,7225,7056,8100,8464,5476,4624,4624,3969,4900,7744,5625,4900,4489,4489,4489,12100,7225,8464,12544,9216,7056,8100,7396,2704,7056,6241,6724],"z":[18,15,18,16,17,15,14,14,14,15,15,14,15,14,24,22,18,21,27,26,25,24,25,26,21,10,10,11,9,27,28,25,19,16,17,19,18,14,14,14,14,12,13,13,18,22,19,18,23,28,30,30,31,35,27,26,24,25,23,20,21,13,14,15,14,17,11,13,12,13,19,15,13,13,14,18,22,21,26,22,28,23,28,27,13,14,13,14,15,12,13,13,14,13,12,13,18,16,18,18,23,26,11,12,13,12,18,20,21,22,18,19,21,26,15,16,29,24,20,19,15,24,20,11,20,19,15,31,26,32,25,16,16,18,16,13,14,14,14,29,26,26,31,32,28,24,26,24,26,31,19,18,15,15,16,15,16,14,17,16,15,18,21,20,13,29,23,20,23,24,25,24,18,29,19,23,23,22,25,33,28,25,25,26,27,17.5,16,15.5,14.5,22,22,24,22.5,29,24.5,29,33,20,18,18.5,17.5,29.5,32,28,26.5,20,13,19,19,16.5,16.5,13,13,13,31.5,30,36,25.5,33.5,17.5,17,15.5,15,17.5,20.5,19,18.5,16,15.5,15.5,16,29,24.5,26,25.5,30.5,33.5,30,30.5,22,21.5,21.5,43.100000000000001,36.100000000000001,32.799999999999997,39.399999999999999,36.100000000000001,19.899999999999999,19.399999999999999,20.199999999999999,19.199999999999999,20.5,20.199999999999999,25.100000000000001,20.5,19.399999999999999,20.600000000000001,20.800000000000001,18.600000000000001,18.100000000000001,19.199999999999999,17.699999999999999,18.100000000000001,17.5,30,27.5,27.199999999999999,30.899999999999999,21.100000000000001,23.199999999999999,23.800000000000001,23.899999999999999,20.300000000000001,17,21.600000000000001,16.199999999999999,31.5,29.5,21.5,19.800000000000001,22.300000000000001,20.199999999999999,20.600000000000001,17,17.600000000000001,16.5,18.199999999999999,16.899999999999999,15.5,19.199999999999999,18.5,31.899999999999999,34.100000000000001,35.700000000000003,27.399999999999999,25.399999999999999,23,27.199999999999999,23.899999999999999,34.200000000000003,34.5,31.800000000000001,37.299999999999997,28.399999999999999,28.800000000000001,26.800000000000001,33.5,41.5,38.100000000000001,32.100000000000001,37.200000000000003,28,26.399999999999999,24.300000000000001,19.100000000000001,34.299999999999997,29.800000000000001,31.300000000000001,37,32.200000000000003,46.600000000000001,27.899999999999999,40.799999999999997,44.299999999999997,43.399999999999999,36.399999999999999,30,44.600000000000001,33.799999999999997,29.800000000000001,32.700000000000003,23.699999999999999,35,32.399999999999999,27.199999999999999,26.600000000000001,25.800000000000001,23.5,30,39.100000000000001,39,35.100000000000001,32.299999999999997,37,37.700000000000003,34.100000000000001,34.700000000000003,34.399999999999999,29.899999999999999,33,33.700000000000003,32.399999999999999,32.899999999999999,31.600000000000001,28.100000000000001,30.699999999999999,25.399999999999999,24.199999999999999,22.399999999999999,26.600000000000001,20.199999999999999,17.600000000000001,28,27,34,31,29,27,24,36,37,31,38,36,36,36,34,38,32,38,25,38,26,22,32,36,27,27,44,32,28,31],"type":"scatter3d","mode":"markers","name":"data","opacity":0.80000000000000004,"marker":{"color":"black","size":4,"hoverinfo":"skip","opacity":0.80000000000000004,"line":{"color":"rgba(31,119,180,1)"},"showscale":false},"error_y":{"color":"rgba(31,119,180,1)"},"error_x":{"color":"rgba(31,119,180,1)"},"line":{"color":"rgba(31,119,180,1)"},"frame":null},{"colorbar":{"title":"autonomie<br />surf","ticklen":2,"len":0.5,"lenmode":"fraction","y":1,"yanchor":"top"},"colorscale":[["0","rgba(190,190,190,1)"],["1","rgba(190,190,190,1)"]],"showscale":false,"z":[[38.059191113772343,-47.719700796540607],[100.55073645547486,14.771844545161919]],"type":"surface","x":[46,230],"y":[2116,52900],"name":"Relation entre puissance et autonomie","opacity":0.75,"cauto":false,"surfacecolor":[0,0,0],"frame":null},{"x":[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250],"y":[0,1,4,9,16,25,36,49,64,81,100,121,144,169,196,225,256,289,324,361,400,441,484,529,576,625,676,729,784,841,900,961,1024,1089,1156,1225,1296,1369,1444,1521,1600,1681,1764,1849,1936,2025,2116,2209,2304,2401,2500,2601,2704,2809,2916,3025,3136,3249,3364,3481,3600,3721,3844,3969,4096,4225,4356,4489,4624,4761,4900,5041,5184,5329,5476,5625,5776,5929,6084,6241,6400,6561,6724,6889,7056,7225,7396,7569,7744,7921,8100,8281,8464,8649,8836,9025,9216,9409,9604,9801,10000,10201,10404,10609,10816,11025,11236,11449,11664,11881,12100,12321,12544,12769,12996,13225,13456,13689,13924,14161,14400,14641,14884,15129,15376,15625,15876,16129,16384,16641,16900,17161,17424,17689,17956,18225,18496,18769,19044,19321,19600,19881,20164,20449,20736,21025,21316,21609,21904,22201,22500,22801,23104,23409,23716,24025,24336,24649,24964,25281,25600,25921,26244,26569,26896,27225,27556,27889,28224,28561,28900,29241,29584,29929,30276,30625,30976,31329,31684,32041,32400,32761,33124,33489,33856,34225,34596,34969,35344,35721,36100,36481,36864,37249,37636,38025,38416,38809,39204,39601,40000,40401,40804,41209,41616,42025,42436,42849,43264,43681,44100,44521,44944,45369,45796,46225,46656,47089,47524,47961,48400,48841,49284,49729,50176,50625,51076,51529,51984,52441,52900,53361,53824,54289,54756,55225,55696,56169,56644,57121,57600,58081,58564,59049,59536,60025,60516,61009,61504,62001,62500],"z":[56.900099702112975,56.435140608266394,55.972642586621362,55.512605637177877,55.055029759935948,54.59991495489556,54.147261222056713,53.697068561419428,53.249336972983684,52.804066456749489,52.361257012716834,51.920908640885735,51.483021341256183,51.04759511382818,50.614629958601718,50.184125875576811,49.756082864753452,49.330500926131641,48.907380059711365,48.48672026549265,48.068521543475484,47.652783893659866,47.239507316045781,46.828691810633259,46.420337377422278,46.014444016412845,45.611011727604961,45.210040510998631,44.811530366593843,44.415481294390602,44.02189329438891,43.630766366588766,43.24210051099017,42.855895727593115,42.472152016397615,42.090869377403671,41.712047810611267,41.335687316020412,40.961787893631097,40.590349543443338,40.221372265457113,39.85485605967245,39.490800926089335,39.129206864707768,38.77007387552775,38.413401958549272,38.059191113772343,37.707441341196969,37.358152640823128,37.01132501265085,36.666958456680113,36.325052972910932,35.985608561343291,35.648625221977198,35.314102954812654,34.982041759849658,34.652441637088209,34.325302586528309,34.000624608169957,33.678407702013153,33.358651868057891,33.041357106304183,32.726523416752023,32.414150799401412,32.104239254252342,31.796788781304823,31.491799380558856,31.189271052014433,30.889203795671559,30.591597611530233,30.296452499590455,30.003768459852225,29.713545492315536,29.425783596980402,29.14048277384682,28.857643022914779,28.577264344184282,28.299346737655341,28.023890203327948,27.750894741202099,27.480360351277795,27.212287033555043,26.946674788033839,26.683523614714186,26.422833513596071,26.164604484679515,25.908836527964503,25.65552964345104,25.404683831139113,25.156299091028746,24.910375423119923,24.666912827412652,24.425911303906922,24.187370852602747,23.951291473500117,23.717673166599035,23.486515931899497,23.257819769401507,23.031584679105073,22.807810661010173,22.586497715116835,22.367645841425038,22.151255039934792,21.937325310646088,21.725856653558935,21.516849068673334,21.310302555989281,21.106217115506766,20.904592747225806,20.705429451146394,20.50872722726853,20.314486075592207,20.122705996117439,19.933386988844219,19.746529053772548,19.562132190902414,19.380196400233839,19.200721681766812,19.023708035501329,18.849155461437388,18.677063959575005,18.507433529914167,18.340264172454877,18.175555887197127,18.013308674140934,17.853522533286288,17.69619746463319,17.54133346818163,17.388930543931629,17.238988691883176,17.09150791203626,16.946488204390899,16.80392956894709,16.663832005704826,16.526195514664103,16.391020095824935,16.258305749187315,16.128052474751243,16.000260272516712,15.874929142483737,15.752059084652306,15.631650099022426,15.513702185594092,15.398215344367308,15.285189575342056,15.174624878518365,15.066521253896227,14.960878701475632,14.857697221256586,14.756976813239088,14.658717477423135,14.562919213808733,14.469582022395866,14.378705903184557,14.290290856174799,14.204336881366586,14.120843978759925,14.039812148354809,13.96124139015124,13.88513170414922,13.811483090348734,13.74029554874981,13.671569079352437,13.605303682156602,13.541499357162323,13.480156104369591,13.421273923778408,13.364852815388758,13.310892779200664,13.259393815214125,13.210355923429134,13.163779103845684,13.119663356463789,13.078008681283436,13.038815078304637,13.002082547527365,12.967811088951656,12.936000702577502,12.906651388404889,12.879763146433824,12.855335976664307,12.833369879096345,12.813864853729925,12.796820900565038,12.782238019601714,12.770116210839937,12.760455474279709,12.753255809921029,12.748517217763897,12.746239697808306,12.746423250054271,12.749067874501769,12.75417357115083,12.761740340001431,12.771768181053588,12.784257094307293,12.799207079762539,12.81661813741934,12.836490267277668,12.858823469337565,12.883617743599004,12.91087309006199,12.940589508726532,12.972766999592615,13.007405562660246,13.044505197929425,13.084065905400145,13.12608768507242,13.170570536946244,13.217514461021615,13.266919457298535,13.318785525777002,13.373112666457018,13.429900879338575,13.489150164421673,13.550860521706333,13.615031951192542,13.681664452880291,13.750758026769596,13.822312672860448,13.896328391152842,13.972805181646791,14.051743044342267,14.133141979239312,14.217001986337898,14.30332306563804,14.392105217139722,14.483348440842953,14.577052736747731,14.673218104854051,14.771844545161919,14.872932057671342,14.97648064238232,15.08249029929484,15.190961028408914,15.30189282972453,15.415285703241686,15.531139648960384,15.649454666880636,15.770230757002444,15.893467919325808,16.019166153850712,16.147325460577157,16.277945839505158,16.411027290634699,16.546569813965782,16.684573409498419,16.825038077232612,16.967963817168346,17.113350629305636,17.261198513644466],"type":"scatter3d","mode":"lines","name":"grey","marker":{"color":"rgba(190,190,190,1)","line":{"color":"rgba(190,190,190,1)"},"showscale":false},"textfont":{"color":"rgba(190,190,190,1)"},"error_y":{"color":"rgba(190,190,190,1)"},"error_x":{"color":"rgba(190,190,190,1)"},"line":{"color":"rgba(190,190,190,1)"},"frame":null}],"highlight":{"on":"plotly_click","persistent":false,"dynamic":false,"selectize":false,"opacityDim":0.20000000000000001,"selected":{"opacity":1},"debounce":0},"shinyEvents":["plotly_hover","plotly_click","plotly_selected","plotly_relayout","plotly_brushed","plotly_brushing","plotly_clickannotation","plotly_doubleclick","plotly_deselect","plotly_afterplot","plotly_sunburstclick"],"base_url":"https://plot.ly",".hideLegend":true},"evals":[],"jsHooks":[]}</script>
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-hyperplan-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;4.4: Représentation graphique 3D du modèle de régression linéaire pour les données <span class="math inline">\(\texttt{automobile}\)</span>.
</figcaption>
</figure>
</div>
</div>
</div>
</section>
<section id="estimation-des-paramètres" class="level2" data-number="4.3">
<h2 data-number="4.3" class="anchored" data-anchor-id="estimation-des-paramètres"><span class="header-section-number">4.3</span> Estimation des paramètres</h2>
<p>Considérons un échantillon de <span class="math inline">\(n\)</span> observations. On n’observe ni les aléas <span class="math inline">\(\boldsymbol{\varepsilon}\)</span>, ni les paramètres <span class="math inline">\(\boldsymbol{\beta}\)</span>: il est donc impossible de recouvrer les (vrais) coefficients du modèle. Effectivement, le système d’équation spécifié par le modèle linéaire inclut <span class="math inline">\(n+p+1\)</span> inconnues, mais uniquement <span class="math inline">\(n\)</span> observations. Si on se concentre sur les <span class="math inline">\(p+1\)</span> paramètres de moyenne et sur la variance <span class="math inline">\(\sigma^2\)</span>, nous pourrons estimer les paramètres généralement si <span class="math inline">\(n&gt; p+2\)</span>, mais cela dépend de la spécification. Une infinité de plans pourraient passer dans le nuage de points; il faut donc choisir la meilleure droite (selon un critère donné). La section aborde le choix de ce critère et l’estimation des paramètres de la moyenne.</p>
<section id="moindres-carrés-ordinaires" class="level3" data-number="4.3.1">
<h3 data-number="4.3.1" class="anchored" data-anchor-id="moindres-carrés-ordinaires"><span class="header-section-number">4.3.1</span> Moindres carrés ordinaires</h3>
<p>Soit une matrice de modèle <span class="math inline">\(\mathbf{X}\)</span> et une formulation pour la moyenne avec <span class="math inline">\(\mathsf{E}(Y_i) = \mathbf{x}_i\boldsymbol{\beta}\)</span>. Les estimateurs des moindres carrés ordinaires <span class="math inline">\(\widehat{\boldsymbol{\beta}}=(\widehat{\beta}_0, \ldots, \widehat{\beta}_p)\)</span> sont les paramètres qui minimisent simultanément la distance euclidienne entre les observations <span class="math inline">\(y_i\)</span> et les <strong>valeurs ajustées</strong> <span class="math inline">\(\widehat{y}_i=\mathbf{x}_i\widehat{\boldsymbol{\beta}}\)</span>.</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div id="fig-vertdist" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-vertdist-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="regression-lineaire_files/figure-html/fig-vertdist-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:85.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-vertdist-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;4.5: Résidus ordinaires <span class="math inline">\(e_i\)</span> (vecteurs verticaux) ajoutés à la droit de régression dans l’espace <span class="math inline">\((x, y)\)</span> (gauche) et l’ajustement de la variable réponse <span class="math inline">\(y_i\)</span> en fonction des valeurs ajustées <span class="math inline">\(\widehat{y}_i\)</span>.
</figcaption>
</figure>
</div>
</div>
</div>
<p>En d’autres mots, les estimateurs des moindres carrés sont la solution du problème d’optimization convexe <span class="math display">\[\begin{align*}
\widehat{\boldsymbol{\beta}} &amp;=\min_{\boldsymbol{\beta} \in \mathbb{R}^{p+1}}\sum_{i=1}^n (Y_i-\widehat{Y}_i)^2= \min_{\boldsymbol{\beta}} \|\boldsymbol{Y}-\mathbf{X}\boldsymbol{\beta}\|^2
\end{align*}\]</span> Ce système d’équation a une solution explicite qui est plus facilement exprimée en notation matricielle. Soit les matrices et vecteurs <span class="math display">\[\begin{align*}
\boldsymbol{Y} =
\begin{pmatrix}
  Y_1 \\
  Y_2 \\
  \vdots \\
  Y_n
\end{pmatrix} ,
\;
\mathbf{X} = \begin{pmatrix}
1 &amp; x_{11} &amp; x_{12} &amp; \cdots &amp; x_{1p} \\
1 &amp; x_{21} &amp; x_{22} &amp; \cdots &amp; x_{2p} \\
\vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
1 &amp; x_{n1} &amp; x_{n2} &amp; \cdots &amp; x_{np}
\end{pmatrix} , \;
\boldsymbol{\beta} =
\begin{pmatrix}
  \beta_1 \\
  \beta_2 \\
  \vdots \\
  \beta_p
\end{pmatrix}
\end{align*}\]</span></p>
<div id="prp-ols-mle" class="theorem proposition">
<p><span class="theorem-title"><strong>Proposition 4.1 (Moindres carrés ordinaires)</strong></span> L’estimateur des moindres carrés ordinaires résoud le problème d’optimisation non-contraint <span class="math display">\[\begin{align*}
\widehat{\boldsymbol{\beta}}=\min_{\boldsymbol{\beta} \in \mathbb{R}^{p+1}}(\boldsymbol{y}-\mathbf{X}\boldsymbol{\beta})^\top(\boldsymbol{y}-\mathbf{X}\boldsymbol{\beta}).
\end{align*}\]</span> On peut calculer la dérivée première par rapport à <span class="math inline">\(\boldsymbol{\beta}\)</span>, égaler à zéro et isoler le maximum pour obtenir une formule explicite pour <span class="math inline">\(\widehat{\boldsymbol{\beta}}\)</span>, <span class="math display">\[\begin{align*}
\mathbf{0}_n&amp;=\frac{\partial}{\partial\boldsymbol{\beta}}(\boldsymbol{y}-\mathbf{X}\boldsymbol{\beta})^\top(\boldsymbol{y}-\mathbf{X}\boldsymbol{\beta})\\
\\&amp;=\frac{\partial (\boldsymbol{y}-\mathbf{X}\boldsymbol{\beta})}{\partial \boldsymbol{\beta}}\frac{\partial (\boldsymbol{y}-\mathbf{X}\boldsymbol{\beta})^\top(\boldsymbol{y}-\mathbf{X}\boldsymbol{\beta})}{\partial (\boldsymbol{y}-\mathbf{X}\boldsymbol{\beta})}\\
\\&amp;=\mathbf{X}^\top (\boldsymbol{y}-\mathbf{X}\boldsymbol{\beta})
\end{align*}\]</span> en utilisant la <a href="http://www.stat.rice.edu/~dobelman/notes_papers/math/Matrix.Calculus.AppD.pdf">règle de dérivation en chaîne</a>; on peut ainsi distribuer les termes pour obtenir l’<em>équation normale</em> <span class="math display">\[\begin{align*}
\mathbf{X}^\top \mathbf{X}\boldsymbol{\beta}&amp;=\mathbf{X}^\top \boldsymbol{y}.
\end{align*}\]</span> Si <span class="math inline">\(\mathbf{X}\)</span> est une matrice de rang <span class="math inline">\(p\)</span>, alors la forme quadratique <span class="math inline">\(\mathbf{X}^\top \mathbf{X}\)</span> est inversible et l’unique solution du problème d’optimisation est <span class="math display">\[\begin{align*}
\widehat{\boldsymbol{\beta}} = (\mathbf{X}^{\top} \mathbf{X})^{-1} \mathbf{X}^{\top} \boldsymbol{Y}.
\end{align*}\]</span> Si le rang de la matrice <span class="math inline">\(\mathbf{X}\)</span> est dimension <span class="math inline">\(n \times (p+1)\)</span> est de rang <span class="math inline">\(p+1\)</span>, l’unique solution du problème d’optimisation est <span id="eq-ols"><span class="math display">\[
\widehat{\boldsymbol{\beta}} = (\mathbf{X}^{\top} \mathbf{X})^{-1} \mathbf{X}^{\top} \boldsymbol{Y}.
\tag{4.1}\]</span></span> Cet estimateur dit des <strong>moindres carrés ordinaires</strong> (MCO) est explicite; il n’est donc pas nécessaire de procéder à l’optimisation à l’aide d’algorithmes numériques.</p>
</div>
</section>
<section id="maximum-de-vraisemblance" class="level3" data-number="4.3.2">
<h3 data-number="4.3.2" class="anchored" data-anchor-id="maximum-de-vraisemblance"><span class="header-section-number">4.3.2</span> Maximum de vraisemblance</h3>
<p>Nous pourrions également envisager l’estimation du maximum de vraisemblance. <a href="#prp-mle-normal-linmod" class="quarto-xref">Proposition&nbsp;<span>4.2</span></a> montre que, en supposant la normalité des aléas, les estimateurs des moindres carrés de <span class="math inline">\(\boldsymbol{\beta}\)</span> coïncident avec ceux du maximum de vraisemblance.</p>
<div id="prp-mle-normal-linmod" class="theorem proposition">
<p><span class="theorem-title"><strong>Proposition 4.2 (Estimation du maximum de vraisemblance du modèle linéaire normal)</strong></span> Le modèle de régression linéaire spécifie que les observations <span class="math inline">\(Y_i \sim \mathsf{normale}(\mathbf{x}_i\boldsymbol{\beta}, \sigma^2)\)</span> sont indépendantes. Le modèle linéaire a <span class="math inline">\(p+2\)</span> paramètres (<span class="math inline">\(\boldsymbol{\beta}\)</span> et <span class="math inline">\(\sigma^2\)</span>) et la log-vraisemblance est, abstraction faite des termes constants, <span class="math display">\[\begin{align*}
\ell(\boldsymbol{\beta}, \sigma)&amp;\propto-\frac{n}{2} \ln (\sigma^2) -\frac{1}{2\sigma^2}\left\{(\boldsymbol{y}-\mathbf{X}\boldsymbol{\beta})^\top(\boldsymbol{y}-\mathbf{X}\boldsymbol{\beta})\right\}^2.
\end{align*}\]</span> Maximiser la log-vraisemblance par rapport à <span class="math inline">\(\boldsymbol{\beta}\)</span> revient à minimiser la somme du carré des erreurs <span class="math inline">\(\sum_{i=1}^n (y_i - \mathbf{x}_i\boldsymbol{\beta})^2\)</span>, quelle que soit la valeur de <span class="math inline">\(\sigma\)</span>, et on recouvre <span class="math inline">\(\widehat{\boldsymbol{\beta}}\)</span>. L’estimateur du maximum de vraisemblance de la variance <span class="math inline">\(\widehat{\sigma}^2\)</span> est <span class="math display">\[\begin{align*}
\widehat{\sigma}^2=\mathrm{arg max}_{\sigma^2} \ell(\widehat{\boldsymbol{\beta}}, \sigma^2).
\end{align*}\]</span> La log-vraisemblance profilée de <span class="math inline">\(\sigma^2\)</span>, abstraction faite des constantes, est <span class="math display">\[\begin{align*}
\ell_{\mathrm{p}}(\sigma^2)
&amp;\propto-\frac{1}{2}\left\{n\ln\sigma^2+\frac{1}{\sigma^2}(\boldsymbol{y}-\mathbf{X}\hat{\boldsymbol{\beta}})^\top(\boldsymbol{y}-\mathbf{X}\hat{\boldsymbol{\beta}})\right\}.
\end{align*}\]</span> En différenciant chaque terme par rapport à <span class="math inline">\(\sigma^2\)</span> et en fixant le gradient à zéro, on obtient <span class="math display">\[\begin{align*}
\frac{\partial \ell_{\mathrm{p}}(\sigma^2)}{\partial \sigma^2} = -\frac{n}{2\sigma^2} + \frac{(\boldsymbol{y}-\mathbf{X}\hat{\boldsymbol{\beta}})^\top(\boldsymbol{y}-\mathbf{X}\hat{\boldsymbol{\beta}})}{2\sigma^4} = 0
\end{align*}\]</span></p>
<p>On déduit que l’estimateur du maximum de vraisemblance est la moyenne des carrés des résidus, <span class="math display">\[\begin{align*}
\widehat{\sigma}^2&amp;=\frac{1}{n}(\boldsymbol{Y}-\mathbf{X}\hat{\boldsymbol{\beta}})^\top(\boldsymbol{Y}-\mathbf{X}\hat{\boldsymbol{\beta}})\\&amp;= \frac{1}{n} \sum_{i=1}^n (y_i - \mathbf{x}_i\widehat{\boldsymbol{\beta}})^2= \frac{\mathsf{SC}_e}{n};
\end{align*}\]</span> L’estimateur sans biais habituel de <span class="math inline">\(\sigma^2\)</span> calculé par le logiciel est <span class="math display">\[S^2=\mathsf{SC}_e/(n-p-1),
\]</span> où le dénominateur est la taille de l’échantillon <span class="math inline">\(n\)</span> moins le nombre de paramètres de la moyenne <span class="math inline">\(\boldsymbol{\beta}\)</span>, soit <span class="math inline">\(p+1\)</span>.</p>
</div>
<div id="prp-info-normal" class="theorem proposition">
<p><span class="theorem-title"><strong>Proposition 4.3 (Matrices d’information pour modèles linéaires normaux.)</strong></span> Les entrées de la matrice d’information observée du modèle linéaire normal sont les suivantes <span class="math display">\[\begin{align*}
-\frac{\partial^2 \ell(\boldsymbol{\beta}, \sigma^2)}{\partial \boldsymbol{\beta}\partial \boldsymbol{\beta}^\top} &amp;= \frac{1}{\sigma^2} \frac{\partial \mathbf{X}^\top(\boldsymbol{y}-\mathbf{X}\boldsymbol{\beta})}{\partial \boldsymbol{\beta}^\top} =  \frac{\mathbf{X}^\top\mathbf{X}}{\sigma^2}\\
-\frac{\partial^2 \ell(\boldsymbol{\beta}, \sigma^2)}{\partial \boldsymbol{\beta}\partial \sigma^2} &amp;=- \frac{\mathbf{X}^\top(\boldsymbol{y}-\mathbf{X}\boldsymbol{\beta})}{\sigma^4}\\
-\frac{\partial^2 \ell(\boldsymbol{\beta}, \sigma^2)}{\partial (\sigma^2)^2} &amp;= -\frac{n}{2\sigma^4} + \frac{(\boldsymbol{y}-\mathbf{X}\boldsymbol{\beta})^\top(\boldsymbol{y}-\mathbf{X}\boldsymbol{\beta})}{\sigma^6}.
\end{align*}\]</span> Si on évalue l’information observée aux EMV, on obtient <span class="math display">\[\begin{align*}
j(\widehat{\boldsymbol{\beta}}, \widehat{\sigma^2}) =
\begin{pmatrix}
\frac{\mathbf{X}^\top\mathbf{X}}{\widehat{\sigma^2}} &amp; \boldsymbol{0}_{p+1} \\  \boldsymbol{0}_{p+1}^\top &amp; \frac{n}{2\widehat{\sigma^4}}
\end{pmatrix}
\end{align*}\]</span> puisque <span class="math inline">\(\widehat{\sigma}^2=\mathsf{SC}_e/n\)</span> et que les résidus sont orthogonaux à la matrice du modèle. Sachant que <span class="math inline">\(\mathsf{E}(Y \mid \mathbf{X})=\mathbf{X}\boldsymbol{\beta}\)</span>, la matrice d’information de Fisher est <span class="math display">\[\begin{align*}
i(\boldsymbol{\beta}, \sigma^2) =
\begin{pmatrix}
\frac{\mathbf{X}^\top\mathbf{X}}{\sigma^2} &amp; \boldsymbol{0}_{p+1} \\  \boldsymbol{0}_{p+1}^\top &amp; \frac{n}{2\sigma^4}
\end{pmatrix}
\end{align*}\]</span> Puisque la loi asymptotique de l’estimateur est normale, les EMV de <span class="math inline">\(\sigma^2\)</span> et <span class="math inline">\(\boldsymbol{\beta}\)</span> sont asymptotiquement indépendants car leur corrélation asymptotique est nulle.Pourvu que la matrice carrée <span class="math inline">\((p+1)\)</span>, <span class="math inline">\(\mathbf{X}^\top\mathbf{X}\)</span> soit inversible, la variance asymptotique des estimateurs est <span class="math inline">\(\mathsf{Var}(\widehat{\boldsymbol{\beta}})=\sigma^2(\mathbf{X}^\top\mathbf{X})^{-1}\)</span> et <span class="math inline">\(\mathsf{Var}(\widehat{\sigma}^2) = 2\sigma^4/n\)</span>.</p>
</div>
<div id="rem-independance" class="proof remark">
<p><span class="proof-title"><em>Remarque 4.3</em>. </span>Si on suppose que les observations sont normales, alors on peut montrer que <span class="math inline">\(\mathsf{SC}_e/\sigma^2 \sim \chi^2_{n-p-1}\)</span> et <span class="math inline">\(\widehat{\boldsymbol{\beta}} \sim \mathsf{normale}\{\boldsymbol{\beta}, \sigma^2(\mathbf{X}^\top\mathbf{X})^{-1}\}\)</span> sont indépendants et leurs lois sont connues. Cela nous permettra de construire des tests d’hypothèse.</p>
</div>
</section>
<section id="ajustement-des-modèles-linéaires-à-laide-dun-logiciel" class="level3" data-number="4.3.3">
<h3 data-number="4.3.3" class="anchored" data-anchor-id="ajustement-des-modèles-linéaires-à-laide-dun-logiciel"><span class="header-section-number">4.3.3</span> Ajustement des modèles linéaires à l’aide d’un logiciel</h3>
<p>Bien que nous puissions construire la matrice du modèle nous-mêmes et utiliser la formule des moindres carrés de l’<a href="#eq-ols" class="quarto-xref">Équation&nbsp;<span>4.1</span></a>, les routines numériques implémentées dans les logiciels sont préférables car plus stables. La fonction <code>lm</code> dans <strong>R</strong> ajuste <strong>les modèles linéaires</strong>, tout comme <code>glm</code> avec les arguments par défaut. Les objets de la classe <code>lm</code> ont plusieurs méthodes qui vous permettent d’extraire des objets spécifiques des objets <code>lm</code>. Par exemple, les fonctions <code>coef</code>, <code>resid</code>, <code>fitted</code>, <code>model.matrix</code> renvoient les estimations des coefficients <span class="math inline">\(\widehat{\boldsymbol{\beta}},\)</span> les résidus ordinaires <span class="math inline">\(\boldsymbol{e},\)</span> les valeurs ajustées <span class="math inline">\(\widehat{\boldsymbol{y}}\)</span> et la matrice du modèle <span class="math inline">\(\mathbf{X}\)</span>.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(BSJ92, <span class="at">package =</span> <span class="st">"hecedsm"</span>) <span class="co"># charger les données</span></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a><span class="fu">str</span>(BSJ92) <span class="co"># vérifier que les variables catégorielles sont "factor"</span></span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Ajustement de la régression linéaire</span></span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a>linmod <span class="ot">&lt;-</span> <span class="fu">lm</span>(posttest1 <span class="sc">~</span> pretest1 <span class="sc">+</span> group, </span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a>             <span class="at">data =</span> BSJ92)</span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a>est_beta <span class="ot">&lt;-</span> <span class="fu">coef</span>(linmod) <span class="co"># coefficients (betas)</span></span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a>vcov_beta <span class="ot">&lt;-</span> <span class="fu">vcov</span>(linmod) <span class="co"># matrice de covariance des betas</span></span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(linmod) <span class="co"># tableau résumé</span></span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a>beta_ic <span class="ot">&lt;-</span> <span class="fu">confint</span>(linmod) <span class="co"># IC de Wald pour betas</span></span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a>y_adj <span class="ot">&lt;-</span> <span class="fu">fitted</span>(linmod) <span class="co"># valeurs ajustées</span></span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a>e <span class="ot">&lt;-</span> <span class="fu">resid</span>(linmod) <span class="co"># résidus ordinaires</span></span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-13"><a href="#cb5-13" aria-hidden="true" tabindex="-1"></a><span class="co"># Vérifier la formule des moindres carrés ordinaires</span></span>
<span id="cb5-14"><a href="#cb5-14" aria-hidden="true" tabindex="-1"></a>X <span class="ot">&lt;-</span> <span class="fu">model.matrix</span>(linmod) <span class="co"># matrice du modèle</span></span>
<span id="cb5-15"><a href="#cb5-15" aria-hidden="true" tabindex="-1"></a>y <span class="ot">&lt;-</span> college<span class="sc">$</span>salary</span>
<span id="cb5-16"><a href="#cb5-16" aria-hidden="true" tabindex="-1"></a><span class="fu">isTRUE</span>(<span class="fu">all.equal</span>(</span>
<span id="cb5-17"><a href="#cb5-17" aria-hidden="true" tabindex="-1"></a>  <span class="fu">c</span>(<span class="fu">solve</span>(<span class="fu">t</span>(X) <span class="sc">%*%</span> X) <span class="sc">%*%</span> <span class="fu">t</span>(X) <span class="sc">%*%</span> y),</span>
<span id="cb5-18"><a href="#cb5-18" aria-hidden="true" tabindex="-1"></a>  <span class="fu">as.numeric</span>(<span class="fu">coef</span>(linmod))</span>
<span id="cb5-19"><a href="#cb5-19" aria-hidden="true" tabindex="-1"></a>))</span></code><button title="Copier vers le presse-papier" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>La méthode <code>summary</code> est sans doute la plus utile: elle affiche les estimations des paramètres de la moyenne ainsi que leurs erreurs type, les valeurs <span class="math inline">\(t\)</span> pour le test de Wald de l’hypothèse <span class="math inline">\(\mathscr{H}_0 : \beta_i=0\)</span> et les valeurs-<span class="math inline">\(p\)</span> associées. D’autres statistiques descriptives, portant sur la taille de l’échantillon, les degrés de liberté, etc. sont données au bas du tableau. Notez que la fonction <code>lm</code> utilise l’estimateur sans biais de la variance <span class="math inline">\(\sigma^2\)</span>.</p>
</section>
</section>
<section id="sec-predictions-lm" class="level2" data-number="4.4">
<h2 data-number="4.4" class="anchored" data-anchor-id="sec-predictions-lm"><span class="header-section-number">4.4</span> Prédictions</h2>
<p>Une fois les estimations des coefficients obtenues, on peut calculer les valeurs ajustées <span class="math inline">\(\widehat{\boldsymbol{y}}\)</span> avec <span class="math inline">\(\mathbf{X}\widehat{\boldsymbol{\beta}}\)</span>, où <span class="math inline">\(\mathbf{X}\)</span> dénote la matrice du modèle <span class="math inline">\(n \times (p+1)\)</span>. On peut aussi généraliser cette approche et obtenir une estimation de la moyenne pour n’importe quel vecteur lignes de covariables <span class="math inline">\(\mathbf{x}^* = (1, x^*_1, \ldots, x^*_p)\)</span>, sachant que <span class="math inline">\(\mathsf{E}(Y \mid \mathbf{x}^*)=\mathbf{x}^*\boldsymbol{\beta}\)</span>, en remplaçant les coefficients inconnus <span class="math inline">\(\boldsymbol{\beta}\)</span> par leurs estimations <span class="math inline">\(\widehat{\boldsymbol{\beta}}\)</span>. Pour le modèle postulé, c’est le meilleur prédicteur linéaire non-biaisé de la moyenne.</p>
<p>Si l’on veut prédire la valeur d’une nouvelle observation, disons <span class="math inline">\(Y^*\)</span>, dont le vecteur de variables explicatives <span class="math inline">\(\mathbf{x}^*\)</span> sont connues, la prédiction sera donc <span class="math inline">\(\widehat{y}^* = \mathbf{x}^*\widehat{\boldsymbol{\beta}}\)</span> parce que <span class="math display">\[\begin{align*}
\mathsf{E}(\widehat{Y}^* \mid \mathbf{X}, \mathbf{x}^*) = \mathsf{E}(\mathbf{x}^*\widehat{\boldsymbol{\beta}}\mid \mathbf{X}, \mathbf{x}^*) = \mathbf{x}^*\boldsymbol{\beta}.
\end{align*}\]</span> Cependant, les observations individuelles varient davantage que les moyennes (qui sont elles-mêmes basées sur plusieurs observations). Intuitivement, cela est dû à l’incertitude supplémentaire du terme d’erreur apparaissant dans l’équation du modèle: la variabilité des prédictions est la somme de l’incertitude due aux estimateurs (basés sur des données aléatoires) et de la variance intrinsèque des observations en supposant que la nouvelle observation est indépendante de celles utilisées pour estimer les coefficients, <span class="math display">\[\begin{align*}
\mathsf{Va}(Y^*-\widehat{Y}^* \mid \mathbf{X}, \mathbf{x}^*) &amp;= \mathsf{Va}(Y^*  - \mathbf{x}^*\widehat{\boldsymbol{\beta}} \mid \mathbf{X}, \mathbf{x}^*)
\\&amp;=\mathsf{Va}(Y^* \mid \mathbf{X}, \mathbf{x}^*) + \mathsf{Va}(\mathbf{x}^*\widehat{\boldsymbol{\beta}} \mid \mathbf{X}, \mathbf{x}^*)
\\&amp; = \sigma^2 + \sigma^2\mathbf{x}^{*\vphantom{\top}}(\mathbf{X}^\top\mathbf{X})^{-1}\mathbf{x}^{*\top}.
\end{align*}\]</span> On peut baser les intervalles de prédictions sur la loi Student-<span class="math inline">\(t\)</span>, à l’aide du pivot <span class="math display">\[\begin{align*}
\frac{Y^*-\mathrm{x}^*\widehat{\boldsymbol{\beta}}}{\sqrt{S^2\{1+\mathrm{x}^*(\mathbf{X}^\top\mathbf{X})^{-1}\mathrm{x}^{*\top}\}}}\sim \mathsf{Student}(n-p-1).
\end{align*}\]</span> On obtient l’<strong>intervalle de prédiction</strong> de niveau <span class="math inline">\(1-\alpha\)</span> pour <span class="math inline">\(Y^*\)</span> en inversant la statistique de test <span class="math display">\[\begin{align*}
\mathrm{x}^*\widehat{\boldsymbol{\beta}}\pm \mathfrak{t}_{n-p-1}(\alpha/2)\sqrt{S^2\{1+\mathrm{x}^*(\mathbf{X}^\top\mathbf{X})^{-1}\mathrm{x}^{*\top}\}}.
\end{align*}\]</span> Des calculs similaires pour les <strong>intervalles de confiance</strong> ponctuels pour la moyenne <span class="math inline">\(\mathrm{x}^*\boldsymbol{\beta}\)</span> donnent <span class="math display">\[\begin{align*}
\mathrm{x}^*\widehat{\boldsymbol{\beta}}\pm \mathfrak{t}_{n-p-1}(\alpha/2)\sqrt{S^2\mathrm{x}^*(\mathbf{X}^\top\mathbf{X})^{-1}\mathrm{x}^{*\top}}.
\end{align*}\]</span> Les deux formules diffèrent uniquement au niveau de la variabilité.</p>
<div id="exm-sokolova-pred" class="theorem example">
<p><span class="theorem-title"><strong>Exemple 4.12 (Prédiction pour une régression linéaire simple)</strong></span> Considérons les données de l’<a href="#exm-sokolova" class="quarto-xref">Exemple&nbsp;<span>4.5</span></a>. On ajuste un modèle de régression linéaire simple avec <span class="math inline">\(\texttt{pef} = \beta_0 + \beta_1 \texttt{proportion} + \varepsilon\)</span>, où <span class="math inline">\(\varepsilon \sim \mathsf{normale}(0,\sigma^2)\)</span> et on suppose les observations indépendantes.</p>
<p>La <a href="#fig-predinterval" class="quarto-xref">Figure&nbsp;<span>4.6</span></a> montre les bandes d’incertitude ponctuelles pour une simple régression linéaire des données de <span class="citation" data-cites="Sokolova:2023">Sokolova, Krishna, et Döring (<a href="references.html#ref-Sokolova:2023" role="doc-biblioref">2023</a>)</span> en fonction de la <code>proportion</code> de carton par rapport au plastique, les valeurs les plus élevées indiquant un emballage avec plus de carton superflu. Le modèle ne tient pas compte du fait que notre réponse provient d’une distribution discrète limitée avec des valeurs entières allant de 1 à 7, et que les ratios testés dans l’expérience sont 0 (pas de carton), 0.5, 1 et 2 uniquement. La droite centrale donne la prédiction des individus lorsque nous faisons varier la proportion carton/plastique. En examinant les formules des intervalles de confiance et de prédiction, il est clair que les bandes ne sont pas linéaires (nous considérons la racine carrée d’une fonction qui implique les prédicteurs), mais il n’est pas évident visuellement que l’incertitude augmente au fur et à mesure que l’on s’éloigne de la moyenne des prédicteurs.</p>
<p>Il est plus facile de s’en rendre compte en reproduisant les courbes potentielles qui auraient pu se produire avec des données différentes: la <a href="#fig-predinterval" class="quarto-xref">Figure&nbsp;<span>4.6</span></a> montre les nouvelles pentes potentielles générées à partir de la distribution normale asymptotique des estimateurs <span class="math inline">\(\widehat{\boldsymbol{\beta}}\)</span>. La forme hyperbolique n’est pas surprenante: nous pivotons essentiellement les courbes à partir de la <code>pef</code>/<code>proportion</code> moyenne, et leur potentiel de déviation est d’autant plus élevé que nous nous éloignons de la moyenne dans chaque direction. Les intervalles de prédiction (gris pâle) sont très larges et couvrent essentiellement l’ensemble des valeurs potentielles de l’échelle de Likert sur la perception du respect de l’environnement, à l’exception de quelques observations. En revanche, les intervalles de confiance pour la moyenne sont assez étroits, en raison de la taille importante de l’échantillon. On constate également que les courbes s’en écartent peu.</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div id="fig-predinterval" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-predinterval-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="regression-lineaire_files/figure-html/fig-predinterval-1.gif" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:85.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-predinterval-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;4.6: Prédictions avec intervalles de prédiction (à gauche) et intervalles de confiance pour la moyenne (à droite) pour la régression linéaire simple de la perception du respect de l’environnement (<code>pef</code>) en fonction de la <code>proportion</code> de carton par rapport au plastique, avec des observations décalées horizontalement. Le graphique montre les prédictions ainsi que les intervalles de confiance ponctuels à 95 % de la moyenne et des prédictions individuelles. L’axe des ordonnées a été tronqué.
</figcaption>
</figure>
</div>
</div>
</div>
<p>Dans <strong>R</strong>, la fonction générique <code>predict</code> prend comme arguments un modèle et une nouvelle base de données <code>newdata</code> contenant un tableau avec la même structure que les données qui ont servi à l’ajustement du modèle (à minima, les colonnes de variables explicatives utilisées dans le modèle).</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(SKD23_S2A, <span class="at">package =</span> <span class="st">"hecedsm"</span>) <span class="co"># charger les données</span></span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>lm_simple <span class="ot">&lt;-</span> <span class="fu">lm</span>(pef <span class="sc">~</span> proportion, <span class="at">data =</span> SKD23_S2A) <span class="co"># régression linéaire simple</span></span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a><span class="fu">predict</span>(lm_simple,</span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a>        <span class="at">newdata =</span> <span class="fu">data.frame</span>(<span class="at">proportion =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="fl">0.5</span>, <span class="dv">1</span>, <span class="dv">2</span>)),</span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a>        <span class="at">interval =</span> <span class="st">"prediction"</span>) <span class="co"># intervalles de prédiction</span></span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a><span class="fu">predict</span>(lm_simple,</span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a>        <span class="at">newdata =</span> <span class="fu">data.frame</span>(<span class="at">proportion =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="fl">0.5</span>, <span class="dv">1</span>, <span class="dv">2</span>)),</span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a>        <span class="at">interval =</span> <span class="st">"confidence"</span>) <span class="co"># IC de confiance pour la moyenne</span></span></code><button title="Copier vers le presse-papier" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div id="tbl-predints-soko" class="quarto-layout-panel anchored">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-predints-soko-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Tableau&nbsp;4.3: Prédictions avec intervalles de prédiction (gauche) et intervalles de confiance pour la moyenne (droite).
</figcaption>
<div aria-describedby="tbl-predints-soko-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="quarto-layout-row">
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: center;">
<table class="do-not-create-environment cell caption-top table">
<caption>Intervalles de prédiction</caption>
<thead>
<tr class="header">
<th style="text-align: center;"><code>proportion</code></th>
<th style="text-align: center;">prédiction</th>
<th style="text-align: center;">borne inf.</th>
<th style="text-align: center;">borne sup.</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">0.0</td>
<td style="text-align: center;">2.41</td>
<td style="text-align: center;">-0.168</td>
<td style="text-align: center;">4.98</td>
</tr>
<tr class="even">
<td style="text-align: center;">0.5</td>
<td style="text-align: center;">2.67</td>
<td style="text-align: center;">0.097</td>
<td style="text-align: center;">5.24</td>
</tr>
<tr class="odd">
<td style="text-align: center;">1.0</td>
<td style="text-align: center;">2.93</td>
<td style="text-align: center;">0.361</td>
<td style="text-align: center;">5.51</td>
</tr>
<tr class="even">
<td style="text-align: center;">2.0</td>
<td style="text-align: center;">3.46</td>
<td style="text-align: center;">0.884</td>
<td style="text-align: center;">6.04</td>
</tr>
</tbody>
</table>
</div>
<div class="quarto-layout-cell" style="flex-basis: 50.0%;justify-content: center;">
<table class="do-not-create-environment cell caption-top table">
<caption>Intervalles de confiance pour la moyenne</caption>
<thead>
<tr class="header">
<th style="text-align: center;">moyenne</th>
<th style="text-align: center;">borne inf.</th>
<th style="text-align: center;">borne sup.</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">2.41</td>
<td style="text-align: center;">2.27</td>
<td style="text-align: center;">2.55</td>
</tr>
<tr class="even">
<td style="text-align: center;">2.67</td>
<td style="text-align: center;">2.57</td>
<td style="text-align: center;">2.77</td>
</tr>
<tr class="odd">
<td style="text-align: center;">2.93</td>
<td style="text-align: center;">2.84</td>
<td style="text-align: center;">3.02</td>
</tr>
<tr class="even">
<td style="text-align: center;">3.46</td>
<td style="text-align: center;">3.30</td>
<td style="text-align: center;">3.62</td>
</tr>
</tbody>
</table>
</div>
</div>
</div>
</figure>
</div>
</div>
</section>
<section id="tests-dhypothèses" class="level2" data-number="4.5">
<h2 data-number="4.5" class="anchored" data-anchor-id="tests-dhypothèses"><span class="header-section-number">4.5</span> Tests d’hypothèses</h2>
<p>Les tests d’hypothèses dans les modèles linéaires et d’analyse de la variance suivent la procédure usuelle: nous comparons deux modèles emboîtés, dont l’un (le modèle nul) est une simplification d’un modèle plus complexe (modèle alternatif) obtenu en imposant des restrictions sur les coefficients de la moyenne.</p>
<p>Les tests de restrictions pour les composantes de <span class="math inline">\(\boldsymbol{\beta}\)</span> sont particulièrement intéressants. Les propriétés de l’estimateur du maximum de vraisemblance pour les grands échantillons impliquent que <span class="math display">\[\begin{align*}
\widehat{\boldsymbol{\beta}} \stackrel{\cdot}{\sim}\mathsf{normale}_{p+1}\left\{\boldsymbol{\beta}, \sigma^2(\mathbf{X}^\top\mathbf{X})^{-1}\right\}
\end{align*}\]</span> pour une taille d’échantillon suffisamment grande, et ce résultat est exact si les observations sont normales. On peut aisément obtenir les erreurs-type des coefficients en remplaçant <span class="math inline">\(\sigma^2\)</span> par un estimé; avec des données normales, on peut montrer que la somme du carré des erreurs <span class="math inline">\(\mathsf{SC}_e \sim \sigma^2\chi^2_{n-p-1}\)</span> et <span class="math inline">\(\mathsf{SC}_e\)</span> est indépendante de <span class="math inline">\(\widehat{\boldsymbol{\beta}}\)</span>.</p>
<p>Dans un contexte inférentiel, il est souvent important de tester si l’effet d’une variable explicative est significatif : si <span class="math inline">\(x_j\)</span> est binaire ou continu, le test pour <span class="math inline">\(\mathscr{H}_0 : \beta_j=0\)</span> correspond à un effet marginal nul pour <span class="math inline">\(x_j\)</span>. Le modèle nul est une régression linéaire dans laquelle nous supprimons la <span class="math inline">\((j+1)\)</span>ème colonne de <span class="math inline">\(\mathbf{X}\)</span>.</p>
<div id="prp-wald" class="theorem proposition">
<p><span class="theorem-title"><strong>Proposition 4.4 (Tests de Wald en régression linéaire)</strong></span> Rappelons que la statistique du test de Wald pour l’hypothèse <span class="math inline">\(\mathscr{H}_0: \beta_j=b\)</span> est <span class="math display">\[W = \frac{\widehat{\beta}_j - b}{\mathsf{se}(\widehat{\beta}_j)}.\]</span> La statistique du test de Wald est rapportée par la plupart des logiciels pour l’hypothèse <span class="math inline">\(b=0\)</span>. Puisque <span class="math inline">\(\mathsf{Var}(\widehat{\beta}_j) = \sigma^2 [(\mathbf{X}^\top\mathbf{X})^{-1}]_{j,j}\)</span>, nous pouvons estimer l’erreur type à partir de <span class="math inline">\(S^2\)</span> et en déduire que la distribution de <span class="math inline">\(W\)</span> sous l’hypothèse nulle est <span class="math inline">\(\mathsf{Student}(n-p-1)\)</span>. Cela explique la terminologie « <span class="math inline">\(t\)</span> values » dans le tableau <code>summary</code>. Outre les estimations des coefficients, il est possible d’obtenir des intervalles de confiance basés sur Wald pour <span class="math inline">\(\beta_j\)</span>, qui comme à l’accoutumée sont de la forme <span class="math inline">\(\widehat{\beta}_j \pm \mathfrak{t}_{n-p-1,\alpha/2} \mathsf{se}(\widehat{\beta}_j)\)</span>, avec <span class="math inline">\(\mathfrak{t}_{n-p-1,\alpha/2}\)</span> le quantile de niveau <span class="math inline">\(1-\alpha/2\)</span> d’une loi <span class="math inline">\(\mathsf{Student}({n-p-1})\)</span>.</p>
</div>
<div id="exm-sokolova-simple-ttest" class="theorem example">
<p><span class="theorem-title"><strong>Exemple 4.13</strong></span> Considérons les données de <a href="#exm-sokolova" class="quarto-xref">Exemple&nbsp;<span>4.5</span></a>. Si nous ajustons le modèle de régression linéaire simple, nous pouvons extraire les valeurs -<span class="math inline">\(p\)</span> pour les tests de Wald ou tests-<span class="math inline">\(t\)</span>. Le test pour l’ordonnée à l’origine est sans intérêt puisque les données sont mesurées sur une échelle de 1 à 7, de sorte que la réponse moyenne lorsque <code>proportion=0</code> ne peut être nulle. Le coefficient de <code>proportion</code> suggère une tendance de 0.5 point par unité de ratio, et il est significativement différent de zéro, ce qui indique que le score <code>pef</code> change avec le ratio carton/plastique.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="co"># tests-t (Wald) pour beta=0 avec valeurs-p</span></span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(lm_simple)<span class="sc">$</span>coefficients</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;             Estimate Std. Error t value  Pr(&gt;|t|)</span></span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; (Intercept)    2.407     0.0723   33.31 2.56e-153</span></span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; proportion     0.526     0.0618    8.51  8.40e-17</span></span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a><span class="fu">confint</span>(lm_simple) <span class="co"># intervalles de confiance pour betas</span></span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;             2.5 % 97.5 %</span></span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; (Intercept) 2.266  2.549</span></span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; proportion  0.405  0.648</span></span></code><button title="Copier vers le presse-papier" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
<p>Pour les variables catégorielles à plus de deux niveaux, tester si <span class="math inline">\(\beta_j=0\)</span> n’est généralement pas intéressant car le coefficient représente la différence entre la catégorie <span class="math inline">\(x_j\)</span> et la ligne de base avec la paramétrisation du modèle en terme de contrastes (traitements): ces deux catégories peuvent avoir une faible différence, mais la variable catégorielle dans son ensemble peut toujours être un prédicteur utile compte tenu des autres explications. L’hypothèse d’un contraste nul est spécifique car elle implique un modèle nul dans lequel les catégories sélectionnées sont fusionnées, ce qui dépend de la référence. Nous souhaitons plutôt comparer un modèle dans lequel toutes les variables sont présentes avec un modèle dans lequel la variable explicative catégorielle est omise.</p>
<div id="prp-ftest" class="theorem proposition">
<p><span class="theorem-title"><strong>Proposition 4.5 (Tests-<em>F</em> pour comparaison de modèles emboîtés)</strong></span> Considérons le modèle linéaire <em>complet</em> qui contient <span class="math inline">\(p\)</span> variables explicatives, <span class="math display">\[\begin{align*}
\mathbb{M}_1: Y=\beta_0+\beta_1 x_1 + \cdots + \beta_p x_p + \varepsilon.
\end{align*}\]</span> Supposons sans perte de généralité que nous voulions tester <span class="math inline">\(\mathscr{H}_0 : \beta_{k+1}=\beta_{k+2}=\cdots=\beta_p=0\)</span> pour <span class="math inline">\(k &lt; p\)</span> (on pourrait permuter les colonnes de la matrice du modèle pour obtenir cette configuration). L’hypothèse globale spécifie que <span class="math inline">\((p-k)\)</span> des paramètres <span class="math inline">\(\beta\)</span> sont nuls. Le <em>modèle restreint</em> correspondant à l’hypothèse nulle ne contient que les covariables pour lesquelles <span class="math inline">\(\beta_j \neq 0\)</span>, <span class="math display">\[\begin{align*}
\mathbb{M}_0: Y=\beta_0+\beta_1 x_1 + \cdots + \beta_k x_k + \varepsilon.
\end{align*}\]</span> Soit <span class="math inline">\(\mathsf{SC}_e(\mathbb{M}_1)\)</span> la somme du carré des résidus du modèle complet <span class="math inline">\(\mathbb{M}_1\)</span>, <span class="math display">\[\begin{align*}
\mathsf{SC}_e(\mathbb{M}_1)=\sum_{i=1}^n (Y_i-\widehat{Y}_i^{\mathbb{M}_1})^2,
\end{align*}\]</span> où <span class="math inline">\(\hat{Y}_i^{\mathbb{M}_1}\)</span> est la <span class="math inline">\(i\)</span>e valeur ajustée du modèle <span class="math inline">\(\mathbb{M}_1\)</span>. On définit de la même façon la somme du carré des résidus, <span class="math inline">\(\mathsf{SC}_e(\mathbb{M}_0)\)</span>, pour le modèle <span class="math inline">\(\mathbb{M}_0\)</span>. Logiquement, <span class="math inline">\(\mathsf{SC}_e(\mathbb{M}_0) \geq \mathsf{SC}_e(\mathbb{M}_1)\)</span>.</p>
<p>La statistique <span class="math inline">\(F\)</span> est <span class="math display">\[\begin{align*}
F=\frac{\{\mathsf{SC}_e(\mathbb{M}_0)-\mathsf{SC}_e(\mathbb{M}_1)\}/(p-k)}{\mathsf{SC}_e(\mathbb{M}_1)/(n-p-1)}.
\end{align*}\]</span> Sous <span class="math inline">\(\mathscr{H}_0\)</span>, la statistique <span class="math inline">\(F\)</span> suit une loi de Fisher (<a href="introduction.html#def-loiF" class="quarto-xref">Définition&nbsp;<span>1.12</span></a>) avec <span class="math inline">\((p-k)\)</span> et <span class="math inline">\((n-p-1)\)</span> degrés de liberté, <span class="math inline">\(\mathsf{Fisher}(p-k, n-p-1)\)</span>. Les degrés de libertés du numérateur, <span class="math inline">\(p-k\)</span>, indiquent le nombre de restrictions ou la différence du nombre de paramètres, tandis que celle du dénominateur, <span class="math inline">\(n-p-1\)</span> est la taille de l’échantillons moins le nombre de paramères pour la moyenne du modèle <span class="math inline">\(\mathbb{M}_1\)</span>.</p>
</div>
<p>Quand la <span class="math inline">\(j\)</span>e variable explicative est continue ou binaire, le test <span class="math inline">\(F\)</span> est équivalent au test <span class="math inline">\(t\)</span> pour <span class="math inline">\(\beta_j=0\)</span>. En effet, la statistique <span class="math inline">\(F\)</span> est le carré de la statistique de Wald, et ils mènent à la même inférence — les valeurs-<span class="math inline">\(p\)</span> sont identiques. Bien qu’il soit rapporté dans les tableaux, le test pour <span class="math inline">\(\beta_0=0\)</span> n’est pas intéressant; nous conservons l’ordonnée à l’origine uniquement pour centrer les résidus.</p>
<div id="rem-lrtvsF" class="proof remark">
<p><span class="proof-title"><em>Remarque 4.4</em> (Tests <em>F</em> versus test du rapport de vraisemblance). </span>Pour la régression linéaire normale, le test du rapport de vraisemblance pour comparer les modèles <span class="math inline">\(\mathbb{M}_1\)</span> et <span class="math inline">\(\mathbb{M}_0\)</span> est une fonction de la somme des carrés des résidus: la formule habituelle se simplifie à <span class="math display">\[\begin{align*}
R &amp;= 2( \ell_{\mathbb{M}_1} - \ell_{\mathbb{M}_0}) \\&amp;= n\ln\{\mathsf{SC}_e(\mathbb{M}_0)/\mathsf{SC}_e(\mathbb{M}_1)\}\\
&amp;= n \ln \left( 1+ \frac{p-k}{n-p-1}F\right)
\end{align*}\]</span> Le test du rapport de vraisemblance et les tests <span class="math inline">\(F\)</span> sont liés par une transformation monotone, et nous pouvons utiliser la distribution <span class="math inline">\(\mathsf{Fisher}\)</span> à des fins de comparaison, plutôt que l’approximation <span class="math inline">\(\chi^2\)</span> pour grand échantillon. Les tests <span class="math inline">\(t\)</span> et <span class="math inline">\(F\)</span> présentés ci-dessus pourraient donc tous deux être considérés comme des cas particuliers de <a href="@sec-testsvrais">tests de rapport de vraisemblance</a>, mais en utilisant Student-<span class="math inline">\(t\)</span> contre la distribution normale lorsque <span class="math inline">\(p-k=1\)</span>, et <span class="math inline">\(\mathsf{Fisher}\)</span> contre <span class="math inline">\(\chi^2\)</span> lorsque <span class="math inline">\(p-k \ge 1\)</span>. Lorsque <span class="math inline">\(n\)</span> est grand, les résultats sont à peu près les mêmes.</p>
</div>
<!-- ### Analysis of variance tables -->
<!-- In **R**, the generic `anova` can be used to compare two nested models by passing as arguments the simpler model and the complete model (in this order). Alternatively, we can call `anova` on the output of a linear regression model to produce an **analysis of variance** table, in which we compare the sum of square of the model with all variables, and the difference in sum of square when adding terms sequentially in the order in which they appear in the formula. The latter is typically not of interest, and we must be careful in models with interactions. -->
<section id="contrastes" class="level3" data-number="4.5.1">
<h3 data-number="4.5.1" class="anchored" data-anchor-id="contrastes"><span class="header-section-number">4.5.1</span> Contrastes</h3>
<p>Supposons que nous effectuions une analyse de la variance et que le test <span class="math inline">\(F\)</span> pour l’hypothèse nulle (globale) selon laquelle les moyennes de tous les groupes sont égales soit très élevé: nous rejetons l’hypothèse nulle en faveur de l’alternative, qui stipule qu’au moins une des moyennes du groupe est différente. La question suivante sera de savoir où se situent ces différences. En effet, dans un contexte expérimental, cela implique qu’une ou plusieurs manipulations ont un effet différent des autres sur la réponse moyenne. Souvent, cela n’est pas intéressant en soi: nous pourrions être intéressés par la comparaison de différentes options par rapport à un groupe de contrôle ou déterminer si des combinaisons spécifiques fonctionnent mieux que séparément, ou trouver le meilleur traitement en comparant toutes les paires.</p>
<p>La question scientifique qui a justifié l’expérience peut conduire à un ensemble spécifique d’hypothèses, qui peuvent être formulées par les chercheurs comme des comparaisons entre les moyennes de différents sous-groupes. Nous pouvons normalement les exprimer sous la forme de <strong>contrastes</strong>. Si le test global <span class="math inline">\(F\)</span> pour l’égalité des moyennes est équivalent à une pièce faiblement éclairée, les contrastes sont comparables à des projecteurs qui permettent de mettre l’accent sur des aspects particuliers des différences entre les traitements. Formellement, un contraste est une combinaison linéaire de moyennes: en clair, cela signifie que nous attribuons un poids à chaque moyenne de groupe et que nous les additionnons, puis que nous comparons ce résumé à une valeur postulée <span class="math inline">\(a\)</span>, généralement zéro.</p>
<p>Les contrastes encodent la question de recherche : si <span class="math inline">\(c_i\)</span> représente le poids de la moyenne du groupe <span class="math inline">\(\mu_i\)</span> <span class="math inline">\((i=1, \ldots, K)\)</span>, alors nous pouvons écrire le contraste comme <span class="math inline">\(C = c_1 \mu_1 + \cdots + c_K \mu_K\)</span> avec l’hypothèse nulle <span class="math inline">\(\mathscr{H}_0 : C=a\)</span> pour une alternative bilatérale. L’estimation du contraste linéaire est obtenue en remplaçant la moyenne inconnue de la population <span class="math inline">\(\mu_i\)</span> par la moyenne de l’échantillon de ce groupe, <span class="math inline">\(\widehat{\mu}_i = \overline{y}_{i}\)</span>. Nous pouvons facilement obtenir l’erreur type de la combinaison linéaire <span class="math inline">\(C\)</span>. La formule, l’erreur type, en supposant une taille de sous-échantillon de <span class="math inline">\(n_1, \ldots, n_K\)</span> et une variance commune <span class="math inline">\(\sigma^2\)</span>, est la racine carrée de <span class="math display">\[\begin{align*}
\mathsf{Va}(\widehat{C}) = \widehat{\sigma}^2\left(\frac{c_1^2}{n_1} + \cdots + \frac{c_K^2}{n_K}\right).
\end{align*}\]</span> Nous pouvons alors construire une statistique <span class="math inline">\(t\)</span> comme d’habitude en examinant la différence entre notre valeur postulée et la moyenne pondérée observée, convenablement normalisée. Si le test global <span class="math inline">\(F\)</span> conduit au rejet de la valeur nulle, il existe au moins un contraste significatif au même niveau. Lorsque les vecteurs de contraste sont orthogonaux, les tests ne sont pas corrélés. Mathématiquement, si nous laissons <span class="math inline">\(c_{i}\)</span> et <span class="math inline">\(c^{*}_{i}\)</span> désigner les poids attachés à la moyenne du groupe <span class="math inline">\(i\)</span> comprenant <span class="math inline">\(n_i\)</span> observations, les contrastes sont orthogonaux si <span class="math inline">\(c_{1}c^{*}_{1}/n_1 + \cdots + c_{K}c^{*}_K/n_K = 0\)</span> ; si l’échantillon est équilibré avec le même nombre d’observations dans chaque groupe, <span class="math inline">\(n/K = n_1 =\cdots = n_K\)</span>, nous pouvons considérer le produit scalaire des deux vecteurs de contrastes et négliger la taille des sous-échantillons.</p>
<p>Si nous avons <span class="math inline">\(K\)</span> groupes, il y a <span class="math inline">\(K-1\)</span> contrastes pour les différences deux à deux, le dernier étant capturé par la moyenne de l’échantillon pour l’effet global. Si nous nous intéressons uniquement à la différence entre groupes (par opposition à l’effet global de tous les traitements), nous imposons une contrainte de somme à zéro sur les poids, de sorte que <span class="math inline">\(c_1 + \cdots + c_K=0\)</span>.</p>
</section>
<section id="exemples-de-tests" class="level3" data-number="4.5.2">
<h3 data-number="4.5.2" class="anchored" data-anchor-id="exemples-de-tests"><span class="header-section-number">4.5.2</span> Exemples de tests</h3>
<div id="exm-moonvaepps-test" class="theorem example">
<p><span class="theorem-title"><strong>Exemple 4.14 (Test du montant des dons)</strong></span> Considérons l’<a href="#exm-moon" class="quarto-xref">Exemple&nbsp;<span>4.8</span></a>, dans lequel nous testons les différences entre les montants libres (<code>open-ended</code>) et les montants suggérés (<code>quantity</code>). Le test qui nous intéresse est <span class="math inline">\(\mathscr{H}_0 : \beta_1=0\)</span>, où <span class="math inline">\(\beta_1=\mu_{\texttt{oe}} - \mu_{\texttt{qty}}\)</span> est la différence moyenne entre les groupes. Outre le fait que la différence est statistiquement significative au niveau de 5 %, nous voulons également rapporter les <strong>moyennes marginales</strong>, qui, lorsque nous avons une seule variable explicative catégorielle dans le modèle linéaire, est la moyenne empirique de chaque sous-groupe.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(<span class="st">"MV23_S1"</span>, <span class="at">package =</span> <span class="st">"hecedsm"</span>)</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>MV23_S1 <span class="ot">&lt;-</span> MV23_S1 <span class="sc">|&gt;</span></span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a>    dplyr<span class="sc">::</span><span class="fu">mutate</span>(<span class="at">amount2 =</span> <span class="fu">ifelse</span>(<span class="fu">is.na</span>(amount), <span class="dv">0</span>, amount))</span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a>linmod_MV23 <span class="ot">&lt;-</span> <span class="fu">lm</span>(amount2 <span class="sc">~</span> condition, <span class="at">data =</span> MV23_S1)</span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Test Wald avec coefficients</span></span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(linmod_MV23)</span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Call:</span></span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; lm(formula = amount2 ~ condition, data = MV23_S1)</span></span>
<span id="cb8-10"><a href="#cb8-10" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb8-11"><a href="#cb8-11" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Residuals:</span></span>
<span id="cb8-12"><a href="#cb8-12" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;    Min     1Q Median     3Q    Max </span></span>
<span id="cb8-13"><a href="#cb8-13" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  -8.70  -6.77  -1.77   3.23  18.23 </span></span>
<span id="cb8-14"><a href="#cb8-14" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb8-15"><a href="#cb8-15" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Coefficients:</span></span>
<span id="cb8-16"><a href="#cb8-16" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;                   Estimate Std. Error t value Pr(&gt;|t|)    </span></span>
<span id="cb8-17"><a href="#cb8-17" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; (Intercept)          6.771      0.377   17.95   &lt;2e-16 ***</span></span>
<span id="cb8-18"><a href="#cb8-18" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; conditionquantity    1.929      0.517    3.73   0.0002 ***</span></span>
<span id="cb8-19"><a href="#cb8-19" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; ---</span></span>
<span id="cb8-20"><a href="#cb8-20" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</span></span>
<span id="cb8-21"><a href="#cb8-21" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb8-22"><a href="#cb8-22" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Residual standard error: 7.61 on 867 degrees of freedom</span></span>
<span id="cb8-23"><a href="#cb8-23" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Multiple R-squared:  0.0158, Adjusted R-squared:  0.0147 </span></span>
<span id="cb8-24"><a href="#cb8-24" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; F-statistic: 13.9 on 1 and 867 DF,  p-value: 0.000205</span></span>
<span id="cb8-25"><a href="#cb8-25" aria-hidden="true" tabindex="-1"></a><span class="co"># ANOVA avec tests F</span></span>
<span id="cb8-26"><a href="#cb8-26" aria-hidden="true" tabindex="-1"></a><span class="fu">anova</span>(linmod_MV23)</span>
<span id="cb8-27"><a href="#cb8-27" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Analysis of Variance Table</span></span>
<span id="cb8-28"><a href="#cb8-28" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb8-29"><a href="#cb8-29" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Response: amount2</span></span>
<span id="cb8-30"><a href="#cb8-30" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;            Df Sum Sq Mean Sq F value Pr(&gt;F)    </span></span>
<span id="cb8-31"><a href="#cb8-31" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; condition   1    805     805    13.9 0.0002 ***</span></span>
<span id="cb8-32"><a href="#cb8-32" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Residuals 867  50214      58                   </span></span>
<span id="cb8-33"><a href="#cb8-33" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; ---</span></span>
<span id="cb8-34"><a href="#cb8-34" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</span></span>
<span id="cb8-35"><a href="#cb8-35" aria-hidden="true" tabindex="-1"></a><span class="co"># Moyennes marginales</span></span>
<span id="cb8-36"><a href="#cb8-36" aria-hidden="true" tabindex="-1"></a>(emm <span class="ot">&lt;-</span> emmeans<span class="sc">::</span><span class="fu">emmeans</span>(linmod_MV23, <span class="at">spec =</span> <span class="st">"condition"</span>))</span>
<span id="cb8-37"><a href="#cb8-37" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  condition  emmean    SE  df lower.CL upper.CL</span></span>
<span id="cb8-38"><a href="#cb8-38" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  open-ended   6.77 0.377 867     6.03     7.51</span></span>
<span id="cb8-39"><a href="#cb8-39" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  quantity     8.70 0.354 867     8.01     9.40</span></span>
<span id="cb8-40"><a href="#cb8-40" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb8-41"><a href="#cb8-41" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Confidence level used: 0.95</span></span>
<span id="cb8-42"><a href="#cb8-42" aria-hidden="true" tabindex="-1"></a>emm <span class="sc">|&gt;</span> emmeans<span class="sc">::</span><span class="fu">contrast</span>(<span class="at">method =</span> <span class="st">"pairwise"</span>) <span class="co"># vecteur de contraste (1,-1)</span></span>
<span id="cb8-43"><a href="#cb8-43" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  contrast                estimate    SE  df t.ratio p.value</span></span>
<span id="cb8-44"><a href="#cb8-44" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  (open-ended) - quantity    -1.93 0.517 867  -3.730  0.0002</span></span></code><button title="Copier vers le presse-papier" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
<div id="exm-teachingtoread" class="theorem example">
<p><span class="theorem-title"><strong>Exemple 4.15 (Tests et contrastes pour les méthodes de compréhension de la lecture)</strong></span> Nous examinons maintenant les tests pour l’<a href="#exm-teaching-baumann" class="quarto-xref">Exemple&nbsp;<span>4.2</span></a> et l’<a href="#exm-baumann-dummies" class="quarto-xref">Exemple&nbsp;<span>4.9</span></a>, avec une covariable en plus. L’objectif de <span class="citation" data-cites="Baumann:1992">Baumann, Seifert-Kessell, et Jones (<a href="references.html#ref-Baumann:1992" role="doc-biblioref">1992</a>)</span> était de faire une comparaison particulière entre des groupes de traitement. Selon le résumé de l’article:</p>
<blockquote class="blockquote">
<p>Les analyses quantitatives principales comportaient deux contrastes orthogonaux planifiés: l’effet de l’enseignement (TA + DRTA vs.&nbsp;2 x DR) et l’intensité de l’enseignement (TA vs.&nbsp;DRTA).</p>
</blockquote>
<p>Avec un modèle pré-post, nous allons comparer les moyennes pour une valeur commune de <code>pretest1</code>, ci-dessous la moyenne globale du score <code>pretest1</code>.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(emmeans) <span class="co"># moyennes marginales</span></span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(BSJ92, <span class="at">package =</span> <span class="st">"hecedsm"</span>)</span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a>mod_post <span class="ot">&lt;-</span> <span class="fu">lm</span>(posttest1 <span class="sc">~</span> group <span class="sc">+</span> pretest1,</span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a>               <span class="at">data =</span> BSJ92)</span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a>mod_post0 <span class="ot">&lt;-</span> <span class="fu">lm</span>(posttest1 <span class="sc">~</span> pretest1,</span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a>               <span class="at">data =</span> BSJ92)</span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a><span class="fu">anova</span>(mod_post0, mod_post) <span class="co"># tests F</span></span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Analysis of Variance Table</span></span>
<span id="cb9-9"><a href="#cb9-9" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb9-10"><a href="#cb9-10" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Model 1: posttest1 ~ pretest1</span></span>
<span id="cb9-11"><a href="#cb9-11" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Model 2: posttest1 ~ group + pretest1</span></span>
<span id="cb9-12"><a href="#cb9-12" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;   Res.Df RSS Df Sum of Sq    F   Pr(&gt;F)    </span></span>
<span id="cb9-13"><a href="#cb9-13" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 1     64 509                               </span></span>
<span id="cb9-14"><a href="#cb9-14" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 2     62 365  2       143 12.2 0.000035 ***</span></span>
<span id="cb9-15"><a href="#cb9-15" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; ---</span></span>
<span id="cb9-16"><a href="#cb9-16" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</span></span>
<span id="cb9-17"><a href="#cb9-17" aria-hidden="true" tabindex="-1"></a>emmeans_post <span class="ot">&lt;-</span> <span class="fu">emmeans</span>(<span class="at">object =</span> mod_post,</span>
<span id="cb9-18"><a href="#cb9-18" aria-hidden="true" tabindex="-1"></a>                        <span class="at">specs =</span> <span class="st">"group"</span>)</span></code><button title="Copier vers le presse-papier" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Le résultat du tableau d’analyse de la variance montre qu’il y a bien des différences entre les groupes. On peut donc s’intéresser aux moyennes marginales estimées, qui sont la moyenne de chaque groupe.</p>
<div class="cell" data-layout-align="center">
<div id="tbl-print-pairwise-baumann" class="cell quarto-float quarto-figure quarto-figure-center anchored" data-layout-align="center">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-print-pairwise-baumann-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Tableau&nbsp;4.4: Moyennes estimées des groupes avec erreurs-types et intervalles de confiance à 95 % pour le post-test 1 pour un score moyen au pré-test 1.
</figcaption>
<div aria-describedby="tbl-print-pairwise-baumann-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="cell-output-display">
<table class="do-not-create-environment cell caption-top table table-sm table-striped small">
<thead>
<tr class="header">
<th style="text-align: left;">termes</th>
<th style="text-align: right;">moyennes</th>
<th style="text-align: right;">erreur-type</th>
<th style="text-align: right;">ddl</th>
<th style="text-align: right;">borne inf.</th>
<th style="text-align: right;">borne sup.</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">DR</td>
<td style="text-align: right;">6.19</td>
<td style="text-align: right;">0.52</td>
<td style="text-align: right;">62</td>
<td style="text-align: right;">5.14</td>
<td style="text-align: right;">7.23</td>
</tr>
<tr class="even">
<td style="text-align: left;">DRTA</td>
<td style="text-align: right;">9.81</td>
<td style="text-align: right;">0.52</td>
<td style="text-align: right;">62</td>
<td style="text-align: right;">8.78</td>
<td style="text-align: right;">10.85</td>
</tr>
<tr class="odd">
<td style="text-align: left;">TA</td>
<td style="text-align: right;">8.22</td>
<td style="text-align: right;">0.52</td>
<td style="text-align: right;">62</td>
<td style="text-align: right;">7.18</td>
<td style="text-align: right;">9.27</td>
</tr>
</tbody>
</table>
</div>
</div>
</figure>
</div>
</div>
<p>Les deux hypothèses et contrastes de <span class="citation" data-cites="Baumann:1992">Baumann, Seifert-Kessell, et Jones (<a href="references.html#ref-Baumann:1992" role="doc-biblioref">1992</a>)</span> sont <span class="math inline">\(\mathscr{H}_0: \mu_{\mathrm{TA}} + \mu_{\mathrm{DRTA}} = 2 \mu_{\mathrm{DRA}}\)</span> ou <span class="math display">\[\begin{align*}
\mathscr{H}_0: - 2 \mu_{\mathrm{DR}} + \mu_{\mathrm{DRTA}} + \mu_{\mathrm{TA}} = 0.
\end{align*}\]</span> avec poids <span class="math inline">\(c_1=(-2, 1, 1)\)</span>; l’ordre des niveaux de traitement est (<span class="math inline">\(\mathrm{DRA}\)</span>, <span class="math inline">\(\mathrm{DRTA}\)</span>, <span class="math inline">\(\mathrm{TA}\)</span>) et ce dernier doit correspond à celui des poids pour les contrastes. Ces derniers donnent les mêmes tests à multiple non-nul près, donc <span class="math inline">\(ac_1\)</span>, <span class="math inline">\(a \neq 0\)</span> donne un résultat équivalent, par exemple <span class="math inline">\((2, -1, -1)\)</span> ou <span class="math inline">\((1, -1/2, -1/2)\)</span> fonctionnent. Si les estimations changent, les erreurs-types sont ajustées d’autant. Un vecteur de contrastes pour <span class="math inline">\(\mathscr{H}_0:  \mu_{\mathrm{TA}} = \mu_{\mathrm{DRTA}}\)</span> est (<span class="math inline">\(0\)</span>, <span class="math inline">\(-1\)</span>, <span class="math inline">\(1\)</span>): le zéro apparaît parce que la première composante, <span class="math inline">\(\mathrm{DRA}\)</span> n’apparaît pas. Les deux contrastes sont orthogonaux puisque <span class="math inline">\((-2 \times 0) + (1 \times -1) + (1 \times 1) = 0\)</span>.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Identifier l'ordre de niveau du facteur</span></span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a><span class="fu">with</span>(BSJ92, <span class="fu">levels</span>(group))</span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [1] "DR"   "DRTA" "TA"</span></span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a><span class="co"># DR, DRTA, TA (alphabetical)</span></span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a>contrastes_list <span class="ot">&lt;-</span> <span class="fu">list</span>(</span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a>  <span class="co"># Contrastes: combo linéaire de moyennes,</span></span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true" tabindex="-1"></a>  <span class="co"># la somme des coefficients doit être nulle</span></span>
<span id="cb10-8"><a href="#cb10-8" aria-hidden="true" tabindex="-1"></a>  <span class="st">"C1: moy(DRTA+TA) vs DR"</span> <span class="ot">=</span> <span class="fu">c</span>(<span class="sc">-</span><span class="dv">1</span>, <span class="fl">0.5</span>, <span class="fl">0.5</span>),</span>
<span id="cb10-9"><a href="#cb10-9" aria-hidden="true" tabindex="-1"></a>  <span class="st">"C2: DRTA vs TA"</span> <span class="ot">=</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">1</span>, <span class="sc">-</span><span class="dv">1</span>)</span>
<span id="cb10-10"><a href="#cb10-10" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb10-11"><a href="#cb10-11" aria-hidden="true" tabindex="-1"></a>contrastes_post <span class="ot">&lt;-</span></span>
<span id="cb10-12"><a href="#cb10-12" aria-hidden="true" tabindex="-1"></a>  <span class="fu">contrast</span>(<span class="at">object =</span> emmeans_post,</span>
<span id="cb10-13"><a href="#cb10-13" aria-hidden="true" tabindex="-1"></a>           <span class="at">method =</span> contrastes_list)</span>
<span id="cb10-14"><a href="#cb10-14" aria-hidden="true" tabindex="-1"></a>contrastes_summary_post <span class="ot">&lt;-</span> <span class="fu">summary</span>(contrastes_post)</span></code><button title="Copier vers le presse-papier" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell" data-layout-align="center">
<div id="tbl-print-contrasts" class="cell quarto-float quarto-figure quarto-figure-center anchored" data-layout-align="center">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-print-contrasts-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Tableau&nbsp;4.5: Contrastes estimés pour le post-test 1.
</figcaption>
<div aria-describedby="tbl-print-contrasts-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="cell-output-display">
<table class="table do-not-create-environment cell caption-top table-sm table-striped small" data-quarto-postprocess="true">
<thead>
<tr class="header">
<th style="text-align: left;" data-quarto-table-cell-role="th">contraste</th>
<th style="text-align: right;" data-quarto-table-cell-role="th">estimation</th>
<th style="text-align: right;" data-quarto-table-cell-role="th">erreur-type</th>
<th style="text-align: right;" data-quarto-table-cell-role="th">ddl</th>
<th style="text-align: right;" data-quarto-table-cell-role="th">stat</th>
<th style="text-align: right;" data-quarto-table-cell-role="th">valeur-p</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">C1: moy(DRTA+TA) vs DR</td>
<td style="text-align: right;">2.83</td>
<td style="text-align: right;">0.64</td>
<td style="text-align: right;">62</td>
<td style="text-align: right;">4.40</td>
<td style="text-align: right;">0.00</td>
</tr>
<tr class="even">
<td style="text-align: left;">C2: DRTA vs TA</td>
<td style="text-align: right;">1.59</td>
<td style="text-align: right;">0.73</td>
<td style="text-align: right;">62</td>
<td style="text-align: right;">2.17</td>
<td style="text-align: right;">0.03</td>
</tr>
</tbody>
</table>


</div>
</div>
</figure>
</div>
</div>
<p>Nous pouvons examiner ces différences: puisque <code>DRTA</code> contre <code>TA</code> est une différence par paire, nous aurions pu obtenir la statistique <span class="math inline">\(t\)</span> directement à partir des contrastes deux à deux en utilisant <code>pairs(emmeans_post)</code>.</p>
<p>Quelle est la conclusion de notre analyse des contrastes? Il semble que les méthodes impliquant la réflexion à haute voix aient un impact important sur la compréhension de la lecture par rapport à la seule lecture dirigée. Les preuves ne sont pas aussi solides lorsque nous comparons la méthode qui combine la lecture dirigée, l’activité de réflexion et la réflexion à haute voix, mais la différence est néanmoins significative à niveau 5%.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Extraire les coefficients et les erreurs-type</span></span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a>beta_pre <span class="ot">&lt;-</span> <span class="fu">coefficients</span>(mod_post)[<span class="st">'pretest1'</span>]</span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a>se_pre <span class="ot">&lt;-</span> <span class="fu">sqrt</span>(<span class="fu">c</span>(<span class="fu">vcov</span>(mod_post)[<span class="st">'pretest1'</span>, <span class="st">'pretest1'</span>]))</span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a>wald <span class="ot">&lt;-</span> (beta_pre <span class="sc">-</span> <span class="dv">1</span>)<span class="sc">/</span>se_pre <span class="co"># test de Wald directionnel</span></span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Valeur-p basée sur la référence nulle Student-t avec n-p-1 ddl</span></span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a>pval <span class="ot">&lt;-</span> <span class="dv">2</span><span class="sc">*</span><span class="fu">pt</span>(<span class="fu">abs</span>(wald), <span class="at">df =</span> mod_post<span class="sc">$</span>df.residual, <span class="at">lower.tail =</span> <span class="cn">FALSE</span>)</span>
<span id="cb11-7"><a href="#cb11-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Comparaison de modèles emboîtés avec appel à 'anova'</span></span>
<span id="cb11-8"><a href="#cb11-8" aria-hidden="true" tabindex="-1"></a>mod0 <span class="ot">&lt;-</span> <span class="fu">lm</span>(posttest1 <span class="sc">~</span> <span class="fu">offset</span>(pretest1) <span class="sc">+</span> group, <span class="at">data =</span> BSJ92)</span>
<span id="cb11-9"><a href="#cb11-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Le décalage (`offset`) fixe le terme, ce qui équivaut à un coefficient de 1.</span></span>
<span id="cb11-10"><a href="#cb11-10" aria-hidden="true" tabindex="-1"></a>aov_tab <span class="ot">&lt;-</span> <span class="fu">anova</span>(mod0, mod_post)</span></code><button title="Copier vers le presse-papier" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Une autre hypothèse potentielle intéressante consiste à tester si le coefficient de <code>pretest1</code> est égal à l’unité. Cela équivaut à l’hypothèse <span class="math inline">\(b=1\)</span> pour le test de Wald, <span class="math inline">\(w = (\widehat{\beta}_{\texttt{pretest1}}-1)/\mathsf{se}(\widehat{\beta}_{\texttt{pretest1}})= -3.024\)</span>, ou bien une comparaison de modèles avec le test <span class="math inline">\(F\)</span> via <code>anova</code>, qui donne une statistique de test de <span class="math inline">\(F=9.143.\)</span> On peut montrer que si <span class="math inline">\(Z \sim \mathsf{Student}(\nu)\)</span>, alors <span class="math inline">\(Z^2 \sim \mathsf{Fisher}(1, \nu)\)</span>, il s’ensuit que les deux tests sont équivalents et que les valeurs-<span class="math inline">\(p\)</span> sont exactement les mêmes.</p>
</div>
<div id="exm-paperorplastic" class="theorem example">
<p><span class="theorem-title"><strong>Exemple 4.16 (Tests et contrastes pour l’effet de l’emballage carton sur la perception)</strong></span> Soit <span class="math inline">\(\mu_{0}, \mu_{0.5}, \mu_{1}, \mu_2\)</span> la vraie moyenne du score PEF en fonction de la proportion de carton pour les données de <a href="#exm-sokolova" class="quarto-xref">Exemple&nbsp;<span>4.5</span></a>. Plusieurs tests pourraient être intéressants ici, mais nous nous concentrons sur les contrastes effectués par les auteurs et sur un test d’hypothèse de linéarité en fonction de la proportion de plastique. Pour ce dernier, nous pouvons comparer le modèle de régression linéaire (dans lequel le score PEF augmente linéairement avec la proportion de carton par rapport au plastique), <span class="math display">\[\begin{align*}
\mathsf{E}(\texttt{pef} \mid \texttt{proportion}) = \beta_0 + \beta_1\texttt{proportion},
\end{align*}\]</span> au modèle d’analyse de variance qui permet à chacun des quatre groupes d’avoir des moyennes différentes. <span class="math display">\[\begin{align*}
&amp;\mathsf{E}(\texttt{pef} \mid \texttt{proportion}) = \alpha_0 + \alpha_1 \mathbf{1}_{\texttt{proportion}=0.5} \\&amp;\quad + \alpha_2 \mathbf{1}_{\texttt{proportion}=1} + \alpha_3\mathbf{1}_{\texttt{proportion}=2}.
\end{align*}\]</span> Si on veut obtenir l’hypothèse nulle en terme de contraintes sur les paramètres <span class="math inline">\(\boldsymbol{\alpha}\)</span>, on trouve <span class="math display">\[\begin{align*}
\mu_0 &amp;= \beta_0=\alpha_0 \\
\mu_{0.5} &amp;= \beta_0 + 0.5 \beta_1 = \alpha_0 + \alpha_1\\
\mu_1 &amp;= \beta_0 + \beta_1 = \alpha_0 + \alpha_2 \\
\mu_2 &amp;= \beta_0 + 2 \beta_1= \alpha_0 + \alpha_3.
\end{align*}\]</span> Le test comparant la régression linéaire simple à l’analyse de la variance impose deux restrictions simultanées, avec <span class="math inline">\(\mathscr{H}_0 : \alpha_3 = 2\alpha_2= 4\alpha_1\)</span>, de sorte que la distribution nulle est <span class="math inline">\(\mathsf{Fisher}(2, 798)\)</span> ou approximativement <span class="math inline">\(\chi^2_2\)</span>.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(SKD23_S2A, <span class="at">package =</span> <span class="st">"hecedsm"</span>)</span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a>linmod <span class="ot">&lt;-</span> <span class="fu">lm</span>(pef <span class="sc">~</span> proportion, <span class="at">data =</span> SKD23_S2A)</span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a><span class="fu">coef</span>(linmod) <span class="co"># extraire coefficients</span></span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; (Intercept)  proportion </span></span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;       2.407       0.526</span></span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a><span class="co"># ANOVA à un facteur</span></span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a>anovamod <span class="ot">&lt;-</span> <span class="fu">lm</span>(pef <span class="sc">~</span> <span class="fu">factor</span>(proportion),</span>
<span id="cb12-8"><a href="#cb12-8" aria-hidden="true" tabindex="-1"></a>               <span class="at">data =</span> SKD23_S2A)</span>
<span id="cb12-9"><a href="#cb12-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Comparer les deux modèles emboîtés</span></span>
<span id="cb12-10"><a href="#cb12-10" aria-hidden="true" tabindex="-1"></a><span class="fu">anova</span>(linmod, anovamod) <span class="co"># est-ce que l'effet est linéaire?</span></span>
<span id="cb12-11"><a href="#cb12-11" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Analysis of Variance Table</span></span>
<span id="cb12-12"><a href="#cb12-12" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb12-13"><a href="#cb12-13" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Model 1: pef ~ proportion</span></span>
<span id="cb12-14"><a href="#cb12-14" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Model 2: pef ~ factor(proportion)</span></span>
<span id="cb12-15"><a href="#cb12-15" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;   Res.Df  RSS Df Sum of Sq    F  Pr(&gt;F)    </span></span>
<span id="cb12-16"><a href="#cb12-16" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 1    800 1373                              </span></span>
<span id="cb12-17"><a href="#cb12-17" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 2    798 1343  2      29.3 8.69 0.00018 ***</span></span>
<span id="cb12-18"><a href="#cb12-18" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; ---</span></span>
<span id="cb12-19"><a href="#cb12-19" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</span></span>
<span id="cb12-20"><a href="#cb12-20" aria-hidden="true" tabindex="-1"></a><span class="co"># Test avec code alternatif (poids pour chaque coefficient)</span></span>
<span id="cb12-21"><a href="#cb12-21" aria-hidden="true" tabindex="-1"></a>car<span class="sc">::</span><span class="fu">linearHypothesis</span>(<span class="at">model =</span> anovamod,</span>
<span id="cb12-22"><a href="#cb12-22" aria-hidden="true" tabindex="-1"></a>   <span class="at">hypothesis =</span> <span class="fu">rbind</span>(<span class="fu">c</span>(<span class="dv">0</span>, <span class="sc">-</span><span class="dv">2</span>, <span class="dv">1</span>, <span class="dv">0</span>),</span>
<span id="cb12-23"><a href="#cb12-23" aria-hidden="true" tabindex="-1"></a>                      <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">0</span>, <span class="sc">-</span><span class="dv">2</span>, <span class="dv">1</span>)))</span>
<span id="cb12-24"><a href="#cb12-24" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Linear hypothesis test</span></span>
<span id="cb12-25"><a href="#cb12-25" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb12-26"><a href="#cb12-26" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Hypothesis:</span></span>
<span id="cb12-27"><a href="#cb12-27" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; - 2 factor(proportion)0.5  + factor(proportion)1 = 0</span></span>
<span id="cb12-28"><a href="#cb12-28" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; - 2 factor(proportion)1  + factor(proportion)2 = 0</span></span>
<span id="cb12-29"><a href="#cb12-29" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb12-30"><a href="#cb12-30" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Model 1: restricted model</span></span>
<span id="cb12-31"><a href="#cb12-31" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Model 2: pef ~ factor(proportion)</span></span>
<span id="cb12-32"><a href="#cb12-32" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb12-33"><a href="#cb12-33" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;   Res.Df  RSS Df Sum of Sq    F  Pr(&gt;F)    </span></span>
<span id="cb12-34"><a href="#cb12-34" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 1    800 1373                              </span></span>
<span id="cb12-35"><a href="#cb12-35" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 2    798 1343  2      29.3 8.69 0.00018 ***</span></span>
<span id="cb12-36"><a href="#cb12-36" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; ---</span></span>
<span id="cb12-37"><a href="#cb12-37" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</span></span></code><button title="Copier vers le presse-papier" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Le résultat montre que les tests <span class="math inline">\(F\)</span> et les valeurs-<span class="math inline">\(p\)</span> sont identiques, que l’on impose les contraintes manuellement ou que l’on soumette simplement les deux modèles imbriqués à la méthode <code>anova</code>.</p>
<p>Les auteurs souhaitaient comparer zéro carton avec d’autres choix: nous nous intéressons aux différences par paire, mais uniquement par rapport à la référence <span class="math inline">\(\mu_{0}\)</span>: <span class="math display">\[\begin{align*}
\mu_0 = \mu_{0.5}  &amp; \iff 1\mu_0 - 1\mu_{0.5} + 0\mu_{1} + 0 \mu_{2} = 0\\
\mu_0 = \mu_{1} &amp; \iff 1\mu_0 + 0\mu_{0.5} -1\mu_{1} + 0 \mu_{2} = 0\\
\mu_0 = \mu_{2} &amp; \iff 1\mu_0 + 0\mu_{0.5} + 0\mu_{1} -1 \mu_{2} = 0.
\end{align*}\]</span> Les vecteurs de poids pour les contrastes linéaires sont <span class="math inline">\((1, -1, 0, 0)\)</span>, <span class="math inline">\((1, 0, -1, 0)\)</span> et <span class="math inline">\((1, 0, 0, -1)\)</span> pour les moyennes marginales.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a>moymarg <span class="ot">&lt;-</span> anovamod <span class="sc">|&gt;</span></span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a>  emmeans<span class="sc">::</span><span class="fu">emmeans</span>(<span class="at">specs =</span> <span class="st">"proportion"</span>) <span class="co"># moyennes de groupes</span></span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a>contrastlist <span class="ot">&lt;-</span> <span class="fu">list</span>( <span class="co"># liste de vecteurs de contrastes</span></span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a>   <span class="at">refvsdemi =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="sc">-</span><span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">0</span>),</span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a>   <span class="at">refvsun =</span>  <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">0</span>, <span class="sc">-</span><span class="dv">1</span>, <span class="dv">0</span>),</span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a>   <span class="at">refvsdeux =</span>  <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">0</span>, <span class="sc">-</span><span class="dv">1</span>))</span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true" tabindex="-1"></a><span class="co"># calculer différences relativement à la référence</span></span>
<span id="cb13-8"><a href="#cb13-8" aria-hidden="true" tabindex="-1"></a>moymarg <span class="sc">|&gt;</span> emmeans<span class="sc">::</span><span class="fu">contrast</span>(<span class="at">method =</span> contrastlist)</span>
<span id="cb13-9"><a href="#cb13-9" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  contrast  estimate    SE  df t.ratio p.value</span></span>
<span id="cb13-10"><a href="#cb13-10" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  refvsdemi   -0.749 0.131 798  -5.710  &lt;.0001</span></span>
<span id="cb13-11"><a href="#cb13-11" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  refvsun     -0.901 0.131 798  -6.890  &lt;.0001</span></span>
<span id="cb13-12"><a href="#cb13-12" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  refvsdeux   -1.182 0.129 798  -9.200  &lt;.0001</span></span></code><button title="Copier vers le presse-papier" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Les moyennes des groupes rapportées dans le <a href="#tbl-print-groupmeans-PEF" class="quarto-xref">Tableau&nbsp;<span>4.6</span></a> correspondent à celles indiquées par les auteurs dans l’article. Elles suggèrent que la perception du respect de l’environnement augmente avec la quantité de carton utilisée dans l’emballage. Nous avons pu ajuster un modèle de régression simple pour évaluer le changement moyen, en traitant la proportion comme une variable explicative continue. La pente estimée pour le changement du score PEF, qui va de 1 à 7 par incréments de 0.25, est 0.53 point par rapport au carton/plastique. Il y a cependant de fortes indications, compte tenu des données, que le changement n’est pas tout à fait linéaire, puisque l’ajustement du modèle de régression linéaire est significativement plus mauvais que le modèle linéaire correspondant.</p>
<div class="cell" data-layout-align="center">
<div id="tbl-print-groupmeans-PEF" class="cell quarto-float quarto-figure quarto-figure-center anchored" data-layout-align="center">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-print-groupmeans-PEF-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Tableau&nbsp;4.6: Moyennes estimées du DEP par proportion pour les groupes, avec erreurs-types
</figcaption>
<div aria-describedby="tbl-print-groupmeans-PEF-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="cell-output-display">
<table class="table do-not-create-environment cell caption-top table-sm table-striped small" data-quarto-postprocess="true">
<thead>
<tr class="header">
<th style="text-align: right;" data-quarto-table-cell-role="th">proportion</th>
<th style="text-align: right;" data-quarto-table-cell-role="th">moyenne</th>
<th style="text-align: right;" data-quarto-table-cell-role="th">erreur-type</th>
<th style="text-align: right;" data-quarto-table-cell-role="th">ddl</th>
<th style="text-align: right;" data-quarto-table-cell-role="th">borne inf.</th>
<th style="text-align: right;" data-quarto-table-cell-role="th">borne sup.</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: right;">0.0</td>
<td style="text-align: right;">2.16</td>
<td style="text-align: right;">0.093</td>
<td style="text-align: right;">798</td>
<td style="text-align: right;">1.98</td>
<td style="text-align: right;">2.34</td>
</tr>
<tr class="even">
<td style="text-align: right;">0.5</td>
<td style="text-align: right;">2.91</td>
<td style="text-align: right;">0.093</td>
<td style="text-align: right;">798</td>
<td style="text-align: right;">2.73</td>
<td style="text-align: right;">3.09</td>
</tr>
<tr class="odd">
<td style="text-align: right;">1.0</td>
<td style="text-align: right;">3.06</td>
<td style="text-align: right;">0.092</td>
<td style="text-align: right;">798</td>
<td style="text-align: right;">2.88</td>
<td style="text-align: right;">3.24</td>
</tr>
<tr class="even">
<td style="text-align: right;">2.0</td>
<td style="text-align: right;">3.34</td>
<td style="text-align: right;">0.089</td>
<td style="text-align: right;">798</td>
<td style="text-align: right;">3.17</td>
<td style="text-align: right;">3.52</td>
</tr>
</tbody>
</table>


</div>
</div>
</figure>
</div>
</div>
<div class="cell" data-layout-align="center">
<div id="tbl-print-contrast-PEF" class="cell quarto-float quarto-figure quarto-figure-center anchored" data-layout-align="center">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-print-contrast-PEF-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Tableau&nbsp;4.7: Estimations des contrastes pour les différences de PEF relativement à plastique seulement.
</figcaption>
<div aria-describedby="tbl-print-contrast-PEF-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="cell-output-display">
<table class="table do-not-create-environment cell caption-top table-sm table-striped small" data-quarto-postprocess="true">
<thead>
<tr class="header">
<th style="text-align: left;" data-quarto-table-cell-role="th">contraste</th>
<th style="text-align: right;" data-quarto-table-cell-role="th">estimation</th>
<th style="text-align: right;" data-quarto-table-cell-role="th">erreur-type</th>
<th style="text-align: right;" data-quarto-table-cell-role="th">ddl</th>
<th style="text-align: right;" data-quarto-table-cell-role="th">stat</th>
<th style="text-align: left;" data-quarto-table-cell-role="th">valeur-p</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">refvsdemi</td>
<td style="text-align: right;">-0.75</td>
<td style="text-align: right;">0.13</td>
<td style="text-align: right;">798</td>
<td style="text-align: right;">-5.71</td>
<td style="text-align: left;">&lt; 0.001</td>
</tr>
<tr class="even">
<td style="text-align: left;">refvsun</td>
<td style="text-align: right;">-0.90</td>
<td style="text-align: right;">0.13</td>
<td style="text-align: right;">798</td>
<td style="text-align: right;">-6.89</td>
<td style="text-align: left;">&lt; 0.001</td>
</tr>
<tr class="odd">
<td style="text-align: left;">refvsdeux</td>
<td style="text-align: right;">-1.18</td>
<td style="text-align: right;">0.13</td>
<td style="text-align: right;">798</td>
<td style="text-align: right;">-9.20</td>
<td style="text-align: left;">&lt; 0.001</td>
</tr>
</tbody>
</table>


</div>
</div>
</figure>
</div>
</div>
<p>Toutes les différences dans le <a href="#tbl-print-contrast-PEF" class="quarto-xref">Tableau&nbsp;<span>4.7</span></a> sont significatives et positives, conformément à l’hypothèse des chercheurs.</p>
</div>
<div id="exm-tests-college" class="theorem example">
<p><span class="theorem-title"><strong>Exemple 4.17 (Tester la discrimination salariale dans l’enseignement supérieur)</strong></span> Considérons l’exemple des données <code>college</code> et le modèle linéaire associé avec <code>echelon</code>, <code>sexe</code>, années de <code>service</code> et <code>domaine</code> comme variables explicatives.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(college, <span class="at">package =</span> <span class="st">"hecmodstat"</span>)</span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a>mod1_college <span class="ot">&lt;-</span> <span class="fu">lm</span>(salaire <span class="sc">~</span> sexe <span class="sc">+</span> domaine <span class="sc">+</span> echelon <span class="sc">+</span> service, <span class="at">data =</span> college)</span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a>mod0_college <span class="ot">&lt;-</span> <span class="fu">lm</span>(salaire <span class="sc">~</span> domaine <span class="sc">+</span> echelon <span class="sc">+</span> service, <span class="at">data =</span> college)</span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a><span class="co"># F-test avec "anova" comparant les modèles emboîtés</span></span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a>aov_tab_college <span class="ot">&lt;-</span> <span class="fu">anova</span>(mod0_college, mod1_college)</span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Test t de Wald</span></span>
<span id="cb14-7"><a href="#cb14-7" aria-hidden="true" tabindex="-1"></a>wald_college <span class="ot">&lt;-</span> <span class="fu">summary</span>(mod1_college)<span class="sc">$</span>coefficients[<span class="dv">2</span>,]</span>
<span id="cb14-8"><a href="#cb14-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Test du rapport de vraisemblance avec approx khi-deux</span></span>
<span id="cb14-9"><a href="#cb14-9" aria-hidden="true" tabindex="-1"></a>pval_lrt <span class="ot">&lt;-</span> <span class="fu">pchisq</span>(<span class="at">q =</span> <span class="fu">as.numeric</span>(<span class="dv">2</span><span class="sc">*</span>(<span class="fu">logLik</span>(mod1_college) <span class="sc">-</span> <span class="fu">logLik</span>(mod0_college))),</span>
<span id="cb14-10"><a href="#cb14-10" aria-hidden="true" tabindex="-1"></a>       <span class="at">df =</span> <span class="dv">1</span>, <span class="at">lower.tail =</span> <span class="cn">FALSE</span>)</span></code><button title="Copier vers le presse-papier" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Le seul test qui nous intéresse ici est <span class="math inline">\(\mathscr{H}_0 : \beta_{\texttt{sexe}} = 0\)</span> contre l’alternative bilatérale <span class="math inline">\(\mathscr{H}_a : \beta_{\texttt{sexe}} \neq 0\)</span>. La statistique du test de Wald est <span class="math inline">\(1.23\)</span>, avec une valeur-<span class="math inline">\(p\)</span> de <span class="math inline">\(0.219\)</span> basée sur une distribution Student-<span class="math inline">\(t\)</span> avec <span class="math inline">\(391\)</span> degrés de liberté. La valeur-<span class="math inline">\(p\)</span> dans la sortie du test <span class="math inline">\(F\)</span> est la même, et celle obtenue par le test du rapport de vraisemblance est la même jusqu’à la deuxième décimale.</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<table class="caption-top table table-sm table-striped small">
<caption>Tableau des estimations des coefficients de régression linéaire avec les erreurs-type associées, les tests de Wald et les valeurs <span class="math inline">\(p\)</span> basées sur la distribution Student-<span class="math inline">\(t\)</span>.</caption>
<thead>
<tr class="header">
<th style="text-align: left;">term</th>
<th style="text-align: right;">estimation</th>
<th style="text-align: right;">erreur-type</th>
<th style="text-align: right;">stat de Wald</th>
<th style="text-align: right;">valeur-p</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">(Intercept)</td>
<td style="text-align: right;">86.596</td>
<td style="text-align: right;">2.96</td>
<td style="text-align: right;">29.25</td>
<td style="text-align: right;">&lt; 0.001</td>
</tr>
<tr class="even">
<td style="text-align: left;">sexe [femme]</td>
<td style="text-align: right;">-4.771</td>
<td style="text-align: right;">3.878</td>
<td style="text-align: right;">-1.23</td>
<td style="text-align: right;">0.22</td>
</tr>
<tr class="odd">
<td style="text-align: left;">domaine [théorique]</td>
<td style="text-align: right;">-13.473</td>
<td style="text-align: right;">2.315</td>
<td style="text-align: right;">-5.82</td>
<td style="text-align: right;">&lt; 0.001</td>
</tr>
<tr class="even">
<td style="text-align: left;">échelon [agrégé]</td>
<td style="text-align: right;">14.56</td>
<td style="text-align: right;">4.098</td>
<td style="text-align: right;">3.55</td>
<td style="text-align: right;">&lt; 0.001</td>
</tr>
<tr class="odd">
<td style="text-align: left;">échelon [titulaire]</td>
<td style="text-align: right;">49.16</td>
<td style="text-align: right;">3.834</td>
<td style="text-align: right;">12.82</td>
<td style="text-align: right;">&lt; 0.001</td>
</tr>
<tr class="even">
<td style="text-align: left;">service</td>
<td style="text-align: right;">-0.089</td>
<td style="text-align: right;">0.112</td>
<td style="text-align: right;">-0.8</td>
<td style="text-align: right;">0.43</td>
</tr>
</tbody>
</table>
</div>
</div>
</div>
</section>
</section>
<section id="plans-factoriels-et-interactions" class="level2" data-number="4.6">
<h2 data-number="4.6" class="anchored" data-anchor-id="plans-factoriels-et-interactions"><span class="header-section-number">4.6</span> Plans factoriels et interactions</h2>
<p>Le modèle additif pour la moyenne spécifie que l’effet marginal d’une variable ( y compris pour les variables catégorielles) est indépendant des autres. Nous pouvons souhaiter assouplir cette hypothèse en incluant des <strong>termes d’interaction</strong>.</p>
<div id="def-interaction" class="theorem definition">
<p><span class="theorem-title"><strong>Définition 4.2 (Interaction)</strong></span> On parle d’<strong>interaction</strong> lorsque des combinaisons de variables explicatives affectent la variable réponse différemment que lorsqu’elles sont considérées individuellement. Si <span class="math inline">\(X_j\)</span> et <span class="math inline">\(X_k\)</span> interagissent, l’effet marginal de <span class="math inline">\(\mathsf{E}(Y \mid \boldsymbol{X})\)</span> par rapport à <span class="math inline">\(X_j\)</span> est une fonction de <span class="math inline">\(X_k\)</span>, et vice-versa.</p>
</div>
<p>On s’attarde au cas où au moins une des variables est catégorielle (facteur).</p>
<div id="exm-assurance-interaction" class="theorem example">
<p><span class="theorem-title"><strong>Exemple 4.18 (Primes d’assurances et interactions)</strong></span> On considère la relation entre <code>fumeur</code> et l’indice de masse corporel pour la détermination de primes d’assurance. Les fumeurs dont l’indice de masse corporelle (IMC) est égal ou supérieur à 30 paient une prime élevée, mais il semble que le montant de la prime augmente de façon linéaire en fonction de l’IMC. Cette tarification ne semble pas s’appliquer aux non-fumeurs.</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div id="fig-insuranceinter1" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-insuranceinter1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="regression-lineaire_files/figure-html/fig-insuranceinter1-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:85.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-insuranceinter1-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;4.7: Nuage de points des données <code>assurance</code> avec les frais en fonction de l’<code>imc</code>, selon le status <code>fumeur</code>.
</figcaption>
</figure>
</div>
</div>
</div>
</div>
<div id="exm-intention" class="theorem example">
<p><span class="theorem-title"><strong>Exemple 4.19 (Intention d’achat)</strong></span> On considère un exemple avec des données bidons <code>interaction</code>. Le modèle additif (sans interaction) a pour moyenne <span class="math display">\[\begin{align*}
\mathsf{E}(\texttt{intention} \mid \cdot)=\beta_0 + \beta_1 \texttt{sexe} + \beta_2 \texttt{fixation},
\end{align*}\]</span> où <span class="math inline">\(\texttt{sexe=1}\)</span> pour les femmes et <span class="math inline">\(\texttt{sexe=0}\)</span> pour les hommes</p>
<p>L’effet de la variable continue <code>fixation</code> est identique pour les deux sexes. De même, l’effet de la variable binaire est supposé être le même pour toutes les valeurs possibles de la variable continue. Nous pouvons le voir sur le graphique, car la différence entre les lignes représente l’effet de <span class="math inline">\(\texttt{sexe}\)</span>, est le même pour toutes les valeurs de <span class="math inline">\(\texttt{fixation}\)</span>; les lignes sont <em>parallèles</em> : voir le panneau gauche de <a href="#fig-interaction-slope" class="quarto-xref">Figure&nbsp;<span>4.8</span></a>.</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div id="fig-interaction-slope" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-interaction-slope-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="regression-lineaire_files/figure-html/fig-interaction-slope-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:85.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-interaction-slope-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;4.8: Nuages de points et droites ajustées pour un modèle sans interaction (gauche) et avec interaction (droite).
</figcaption>
</figure>
</div>
</div>
</div>
<p>Pour ajuster une pente différente par sexe, on crée une nouvelle variable égale au produit <span class="math inline">\(\texttt{fixation}\times\texttt{sexe}\)</span> et on l’ajoute à notre modèle, <span class="math display">\[\begin{align*}
\mathsf{E}(\texttt{intention} \mid \cdot)= \beta_0 + \beta_1 \texttt{sexe} + \beta_2\texttt{fixation}  + \beta_3 \texttt{fixation}\cdot \texttt{sexe}.
\end{align*}\]</span></p>
<p>Selon la valeur de <span class="math inline">\(\texttt{sexe}\)</span>, on obtient <span class="math display">\[\begin{align*}
\mathsf{E}(\texttt{intention} \mid \cdot) =
\begin{cases}
(\beta_0 + \beta_1) + (\beta_2 + \beta_3)\texttt{fixation}, &amp; \texttt{sexe}=1 \text{ (femme)},\\
  \beta_0 + \beta_2 \texttt{fixation}, &amp; \texttt{sexe}=0 \text{ (homme)}.
\end{cases}
\end{align*}\]</span> L’interprétation des coefficients du modèle se fait comme d’habitude avec la paramétrisation (traitement):</p>
<ul>
<li><span class="math inline">\(\beta_0\)</span> est l’intention d’achat moyenne lorsque le temps de fixation est nul pour les hommes,</li>
<li><span class="math inline">\(\beta_1\)</span> est la différence d’ordonnée à l’origine entre les femmes et les hommes (différence d’intention d’achat moyenne entre femmes et hommes quand le temps de fixation est nul),</li>
<li><span class="math inline">\(\beta_2\)</span> est l’augmentation unitaire de l’intention d’achat par seconde de fixation pour les hommes,</li>
<li><span class="math inline">\(\beta_3\)</span> est la différence de pente entre les femmes et les hommes (différence d’intention d’achat moyenne femmes vs hommes pour une augmentation d’une seconde de fixation).</li>
</ul>
<p>Tester la significativité de l’interaction revient à vérifier si <span class="math inline">\(\mathscr{H}_0: \beta_3=0\)</span>.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(interaction, <span class="at">package =</span> <span class="st">"hecmodstat"</span>)</span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Pour spécifier une interaction, utiliser :</span></span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a>mod <span class="ot">&lt;-</span> <span class="fu">lm</span>(intention <span class="sc">~</span> sexe <span class="sc">+</span> fixation <span class="sc">+</span>  sexe<span class="sc">:</span>fixation, </span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a>          <span class="at">data =</span> interaction)</span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Un raccourci est sexe*fixation, qui donne la même chose</span></span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(mod)<span class="sc">$</span>coefficients</span>
<span id="cb15-7"><a href="#cb15-7" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;               Estimate Std. Error t value Pr(&gt;|t|)</span></span>
<span id="cb15-8"><a href="#cb15-8" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; (Intercept)      2.741      0.282    9.73 1.02e-16</span></span>
<span id="cb15-9"><a href="#cb15-9" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; sexe             1.312      0.380    3.45 7.74e-04</span></span>
<span id="cb15-10"><a href="#cb15-10" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; fixation         0.504      0.153    3.29 1.33e-03</span></span>
<span id="cb15-11"><a href="#cb15-11" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; sexe:fixation    2.135      0.200   10.69 5.61e-19</span></span></code><button title="Copier vers le presse-papier" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Le modèle avec interaction est significativement meilleur, ce qui signifie que l’effet du temps de fixation sur l’intention d’achat varie en fonction du sexe.</p>
</div>
<div id="rem-marginalite" class="proof remark">
<p><span class="proof-title"><em>Remarque 4.5</em> (Principe de marginalité). </span>Tous les termes d’ordre inférieurs devraient être inclus si l’interaction est présente.</p>
<p>Par exemple, on ne retirera pas <span class="math inline">\(\texttt{fixation}\)</span> tout en conservant le terme d’interaction <span class="math inline">\(\texttt{fixation*sexe}\)</span>, même si on ne rejette pas <span class="math inline">\(\mathscr{H}_0:\beta_2=0\)</span>, puisqu’autrement <span class="math display">\[\begin{align*}
&amp;\mathsf{E}(\texttt{intention} \mid \cdot) =
\begin{cases}
(\beta_0 + \beta_1) + \beta_3\texttt{fixation}, &amp; \texttt{sexe}=1 \text{ (femme)},\\
  \beta_0, &amp;\texttt{sexe}=0 \text{ (homme)};                 
\end{cases}
\end{align*}\]</span> cela implique que l’intention d’achat est constante pour les hommes, quel que soit le temps de fixation.</p>
<p>Comme le choix de catégorie de référence est arbitraire, changer la variable indicatrice pour <span class="math inline">\(\texttt{0}\)</span> pour les femmes, <span class="math inline">\(\texttt{1}\)</span> pour les hommes, donnerait un autre modèle et potentiellement des inférences différentes. De ce fait, on ne considère jamais le retrait d’un effet principal si la variable est incluse dans une interaction. Le principe de <strong>marginalité</strong> suppose que tous les termes d’ordre inférieurs devraient être inclus.</p>
</div>
<p>Le concept d’interaction se généralise à des variables catégorielles avec plus de deux niveaux. Dans ce cas, on doit considérer la statistique <span class="math inline">\(F\)</span> pour l’ajout/l’élimination afin de vérifier la significativité de l’interaction dans son ensemble.</p>
<div id="def-anova" class="theorem definition">
<p><span class="theorem-title"><strong>Définition 4.3 (Analyse de variance)</strong></span> Une analyse de variance est un modèle linéaire dans lequel la moyenne est une fonction de variables explicatives catégorielles. Si nous disposons de données pour toutes les combinaisons différentes de facteurs, les facteurs sont <strong>croisés</strong> et nous pouvons envisager d’inclure leurs interactions.</p>
</div>
<p>Considérons un modèle d’analyse de variance à deux facteurs, disons <span class="math inline">\(A\)</span> et <span class="math inline">\(B\)</span>, lesquels ont respectivement <span class="math inline">\(n_a\)</span> et <span class="math inline">\(n_b\)</span> niveaux. Le modèle avec interaction s’écrit</p>
<p><span id="eq-twowayasoneway"><span class="math display">\[
\underset{\text{réponse}\vphantom{b}}{Y_{ijk}} = \underset{\text{moyenne de sous-groupe}}{\mu_{ij}} + \underset{\text{aléa}}{\varepsilon_{ijk}}
\tag{4.2}\]</span></span> où</p>
<ul>
<li><span class="math inline">\(Y_{ijk}\)</span> est le <span class="math inline">\(k\)</span>e mesure du <span class="math inline">\(i\)</span>e niveau du facteur <span class="math inline">\(A\)</span> et du <span class="math inline">\(j\)</span>e niveau du facteur <span class="math inline">\(B\)</span>, disons <span class="math inline">\((a_i, b_j)\)</span></li>
<li><span class="math inline">\(\mu_{ij}\)</span> est la moyenne théorique du sous-groupe <span class="math inline">\((a_i, b_j)\)</span></li>
<li><span class="math inline">\(\varepsilon_{ijk}\)</span> sont des termes d’aléas indépendants de moyenne zéro et d’écart-type <span class="math inline">\(\sigma\)</span>.</li>
</ul>
<p>Dans un devis factoriel complet avec interaction, on peut écrire l’espérance de la variable réponse <span class="math inline">\(\mathsf{E}(Y \mid A=a_i, B=b_j) = \mu_{ij}\)</span>. Ce modèle peut être vu comme une analyse de variance à un facteur doté de <span class="math inline">\(n_an_b\)</span> niveaux. Cette observation peut être utile pour spécifier les poids de contrastes linéaires ou lorsqu’il existe un groupe de contrôle supplémentaire dans un cadre expérimental. Toutefois, la structure permet de spécifier les hypothèses d’intérêt.</p>
<p>Nous pouvons l’exprimer de manière équivalente en termes d’ordonnée à l’origine, d’effets principaux de l’une ou l’autre variable et de termes d’interaction. Le modèle additif, sans interaction, a une moyenne pour la cellule <span class="math inline">\((i,j)\)</span> de</p>
<p><span class="math display">\[\begin{align*}
\mathsf{E}(Y_{ij} \mid A = a_i, B=b_j) = \mu + \alpha_i + \beta_j.
\end{align*}\]</span> <!--
- $\mu$ is the average of all subgroup averages, termed overall mean.
- $\alpha_i = \mu_{i.} - \mu$ is the mean of level $A_i$ minus the overall mean.
- $\beta_j  = \mu_{.j} - \mu$ is the mean of level $B_j$ minus the overall mean.
- $(\alpha\beta)_{ij} = \mu_{ij} - \mu_{i.} - \mu_{.j} + \mu$ is the interaction term for $A_i$ and $B_j$ which encodes the effect of both variable not already captured by the main effects.
--></p>
<!--
The model formulation in terms of difference from the global average or main effect ensures that we can test for main effects for factor $A$ by setting $\mathscr{H}_0: \alpha_1 = \cdots = \alpha_{n_a-1}=0$. The $1 +  n_a + n_b$ **sum to zero** constraints,
$$\sum_{i=1}^{n_a} \alpha_i=0, \quad \sum_{j=1}^{n_b} \beta_j=0, \quad  \sum_{j=1}^{n_b} (\alpha\beta)_{ij}=0, \quad \sum_{i=1}^{n_a} (\alpha\beta)_{ij}=0.$$
-->
<p>Nous pouvons envisager des simplifications de modèle de bas en haut. La suppression de l’interaction conduit à un modèle avec <span class="math inline">\(1 + (n_a-1) + (n_b-1)\)</span> paramètres, par rapport à <span class="math inline">\(n_a \times n_b\)</span> pour le modèle avec l’interaction. Nous pouvons utiliser un test <span class="math inline">\(F\)</span> pour vérifier la significativité de ce dernier. Si les facteurs n’interagissent pas, la moyenne dans la cellule est donnée par la somme des effets principaux. Ce n’est qu’après avoir supprimé ce terme que nous pouvons déterminer si toutes les moyennes des lignes ou des colonnes sont identiques.</p>
<p>Bien que des tests formels soient nécessaires pour vérifier les interactions, le concept peut être mieux compris en examinant des graphiques.</p>
<div id="def-interactionplot" class="theorem definition">
<p><span class="theorem-title"><strong>Définition 4.4 (Diagramme d’interaction)</strong></span> Nous pouvons essayer de détecter visuellement les interactions en traçant la réponse (moyenne) en fonction de l’une des covariables, en utilisant ce que l’on appelle un <strong>diagramme d’interaction</strong>. Lorsqu’il y a plus de deux variables catégorielles, nous pouvons utiliser des couleurs, des symboles ou des panneaux pour représenter les catégories. L’absence d’interaction dans ces diagrammes implique des lignes parallèles, mais il faut tenir compte de l’incertitude.</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div id="fig-2by2" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-2by2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="regression-lineaire_files/figure-html/fig-2by2-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:100.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-2by2-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;4.9: Diagramme d’interactions pour un devis 2 par 2. Image adaptée de la Figure 10.2 de <span class="citation" data-cites="Crump.Navarro.Suzuki:2019">Crump, Navarro, et Suzuki (<a href="references.html#ref-Crump.Navarro.Suzuki:2019" role="doc-biblioref">2019</a>)</span> par Matthew Crump (licence CC BY-SA 4.0).
</figcaption>
</figure>
</div>
</div>
</div>
</div>
<div id="def-simple" class="theorem definition">
<p><span class="theorem-title"><strong>Définition 4.5 (Effets simples et effets principaux)</strong></span> Lorsqu’il n’y a pas d’interactions, il est logique de faire abstraction d’une ou plusieurs variables et de considérer les <strong>effets marginaux</strong>, obtenus en regroupant les données des facteurs omis, en calculant la moyenne équipondérée des sous-groupes. Supposons, par exemple, que nous soyons intéressés par la comparaison des niveaux de <span class="math inline">\(A\)</span>. Lorsque les interactions entre <span class="math inline">\(A\)</span> et <span class="math inline">\(B\)</span> ne sont pas significatives, nous pouvons considérer des termes d’ordre inférieur et rapporter les <strong>moyennes marginales estimées</strong> et les contrastes entre les moyennes de <span class="math inline">\(A\)</span>. Si l’interaction avec <span class="math inline">\(B\)</span> a un impact, nous pouvons plutôt calculer la moyenne de la sous-cellule <span class="math inline">\(A \mid B=b_j\)</span>, et de la même manière pour les contrastes. Nous distinguons donc les cas suivants :</p>
<ul>
<li><strong>effets simples</strong>: différences entre les niveaux d’un élément dans une combinaison fixe d’autres éléments. Les effets simples consistent à comparer les moyennes des cellules dans une ligne ou une colonne donnée.</li>
<li><strong>effets principaux</strong> : différences par rapport à la moyenne pour chaque condition d’un facteur. Les effets principaux sont des moyennes de lignes ou de colonnes.</li>
</ul>
</div>
<div id="exm-STC21-twoway" class="theorem example">
<p><span class="theorem-title"><strong>Exemple 4.20 (Effet psychologique d’emprunt)</strong></span> L’étude complémentaire 5 de <span class="citation" data-cites="Sharma.Tully.Cryder:2021">Sharma, Tully, et Cryder (<a href="references.html#ref-Sharma.Tully.Cryder:2021" role="doc-biblioref">2021</a>)</span> vérifie la perception psychologique de l’emprunt en fonction du terme employé pour désigner le montant monétaire. Les auteurs ont effectué une comparaison deux par deux inter-sujets (ANOVA à deux facteurs) en faisant varier le type de dette (si l’argent était proposé sous forme de crédit (<code>credit</code>) ou prêt (<code>loan</code>), de même que le type d’achat pour lequel l’argent serait utilisé, soit dépenses discrétionnaires (<code>discretionary</code>) ou pour combler à des besoins essentiels (<code>need</code>). La réponse est la moyenne de (a) la probabilité et de (b) l’intérêt pour le produit, toutes deux mesurés à l’aide d’une échelle de Likert allant de 1 à 9.</p>
<p>Le modèle pour la moyenne avec interaction peut être écrit en utilisant la paramétrisation usuelle comme suit <span class="math display">\[\begin{align*}
\texttt{likelihood} &amp;= \beta_0 + \beta_1\mathbf{1}_{\texttt{purchase=need}} + \beta_2\mathbf{1}_{\texttt{debttype=loan}} \\&amp;\quad+ \beta_3\mathbf{1}_{\texttt{purchase=need}}\mathbf{1}_{\texttt{debttype=loan}} + \varepsilon
\end{align*}\]</span></p>
<p>On peut calculer la moyenne de chaque groupe et déduire l’interprétation des coefficients:</p>
<ul>
<li><span class="math inline">\(\mu_1 = \beta_0\)</span> pour <code>purchase=discretionnary</code> et <code>debttype=credit</code></li>
<li><span class="math inline">\(\mu_2 = \beta_0 + \beta_1\)</span> pour <code>purchase=need</code> et <code>debttype=credit</code></li>
<li><span class="math inline">\(\mu_1 = \beta_0 + \beta_2\)</span> pour <code>purchase=discretionnary</code> et <code>debttype=loan</code></li>
<li><span class="math inline">\(\mu_2 = \beta_0 + \beta_1 + \beta_2 + \beta_3\)</span> pour <code>purchase=need</code> et <code>debttype=loan</code></li>
</ul>
<p>Ainsi, <span class="math inline">\(\beta_3\)</span> représente la différence des moyennes <span class="math inline">\(\mu_1 + \mu_4 - \mu_2 - \mu_3\)</span>.</p>
<p><span class="citation" data-cites="Sharma.Tully.Cryder:2021">Sharma, Tully, et Cryder (<a href="references.html#ref-Sharma.Tully.Cryder:2021" role="doc-biblioref">2021</a>)</span> a ajusté un modèle avec deux facteurs, chacun avec deux niveaux, et leur interaction. Comme il y a une moyenne globale et deux effets principaux (différence supplémentaire de moyenne pour les deux facteurs <code>debttype</code> et <code>purchase</code>), l’interaction a un degré de liberté puisque nous passons d’un modèle avec trois paramètres à un modèle qui a une moyenne différente pour chacun des quatre sous-groupes.</p>
<p>La raison pour laquelle on teste d’abord la présence d’interaction est que, si l’effet d’un facteur dépend du niveau de l’autre, comme le montre <a href="#fig-2by2" class="quarto-xref">Figure&nbsp;<span>4.9</span></a>, il faut alors comparer l’étiquette du type de dette séparément pour chaque type d’achat et vice-versa à l’aide d’effets simples. Si l’interaction n’est pas significative, nous pouvons regrouper les observations pour obtenir une ANOVA à un facteur, ce qui donne les comparaisons marginales avec les effets principaux.</p>
<p>L’ajustement du modèle incluant l’interaction entre les facteurs garantit que nous conservons l’hypothèse d’additivité et que nos conclusions ne sont pas trompeuses: le prix à payer est l’estimation de paramètres moyens supplémentaires, ce qui n’est pas un problème si vous recueillez suffisamment de données, mais peut être critique lorsque la collecte de données est extrêmement coûteuse et que seules quelques observations sont disponibles pour chaque sous-groupe.</p>
<p>Dans <strong>R</strong>, on inclut les deux facteurs et leurs interactions avec <code>reponse ~ facteurA * facteurB</code>, le symbole <code>*</code> indiquant que les deux interagissent, un raccourci pour <code>facteuA + facteurB + facteurA:facteurB</code>; dans un modèle avec seulement les effets principaux, on sépare les facteurs par un <code>+</code> pour obtenir le modèle additif.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Données de l'étude supp. 5</span></span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a><span class="co"># de Sharma, Tully, et Cryder (2021)</span></span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(STC21_SS5, <span class="at">package =</span> <span class="st">"hecedsm"</span>)</span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a><span class="co"># La fonction 'aov' sert à ajuste des ANOVA</span></span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Équivalent à "lm" avec variables catégorielles, contrasts somme nulle</span></span>
<span id="cb16-6"><a href="#cb16-6" aria-hidden="true" tabindex="-1"></a>modlin_STC21 <span class="ot">&lt;-</span> <span class="fu">aov</span>(</span>
<span id="cb16-7"><a href="#cb16-7" aria-hidden="true" tabindex="-1"></a>    likelihood <span class="sc">~</span> purchase<span class="sc">*</span>debttype, </span>
<span id="cb16-8"><a href="#cb16-8" aria-hidden="true" tabindex="-1"></a>    <span class="at">data =</span> STC21_SS5)</span>
<span id="cb16-9"><a href="#cb16-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculer le décompte par sous-catégorie (données débalancées)</span></span>
<span id="cb16-10"><a href="#cb16-10" aria-hidden="true" tabindex="-1"></a><span class="fu">xtabs</span>(<span class="sc">~</span> purchase <span class="sc">+</span> debttype, <span class="at">data =</span> STC21_SS5)</span>
<span id="cb16-11"><a href="#cb16-11" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;                debttype</span></span>
<span id="cb16-12"><a href="#cb16-12" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; purchase        credit loan</span></span>
<span id="cb16-13"><a href="#cb16-13" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;   discretionary    392  359</span></span>
<span id="cb16-14"><a href="#cb16-14" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;   need             361  389</span></span>
<span id="cb16-15"><a href="#cb16-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Calcul de la moyenne globale/lignes/colonnes/cellules</span></span>
<span id="cb16-16"><a href="#cb16-16" aria-hidden="true" tabindex="-1"></a>moy_groupes <span class="ot">&lt;-</span> <span class="fu">model.tables</span>(modlin_STC21, <span class="at">type =</span> <span class="st">"means"</span>)</span>
<span id="cb16-17"><a href="#cb16-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-18"><a href="#cb16-18" aria-hidden="true" tabindex="-1"></a><span class="co"># Tableau d'ANOVA avec effets de type 2</span></span>
<span id="cb16-19"><a href="#cb16-19" aria-hidden="true" tabindex="-1"></a>car<span class="sc">::</span><span class="fu">Anova</span>(modlin_STC21, <span class="at">type =</span> <span class="dv">2</span>)</span>
<span id="cb16-20"><a href="#cb16-20" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Anova Table (Type II tests)</span></span>
<span id="cb16-21"><a href="#cb16-21" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb16-22"><a href="#cb16-22" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Response: likelihood</span></span>
<span id="cb16-23"><a href="#cb16-23" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;                   Sum Sq   Df F value  Pr(&gt;F)    </span></span>
<span id="cb16-24"><a href="#cb16-24" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; purchase             752    1   98.21 &lt; 2e-16 ***</span></span>
<span id="cb16-25"><a href="#cb16-25" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; debttype              92    1   12.04 0.00054 ***</span></span>
<span id="cb16-26"><a href="#cb16-26" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; purchase:debttype     14    1    1.79 0.18171    </span></span>
<span id="cb16-27"><a href="#cb16-27" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Residuals          11467 1497                    </span></span>
<span id="cb16-28"><a href="#cb16-28" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; ---</span></span>
<span id="cb16-29"><a href="#cb16-29" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</span></span></code><button title="Copier vers le presse-papier" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>L’interaction n’étant pas significative, nous pouvons n’interpréter que l’effet principal de la fixation.</p>
<p>Cette différence de moyenne conditionnelle est appelée effet marginal, car elle est obtenue en calculant la moyenne de toutes les sous-catégories pour un même niveau du facteur. Le modèle estime cependant la variance sur la base des résidus du modèle d’interaction complet avec quatre moyennes de cellules, et diffère donc de celui obtenu en exécutant (à tort) un modèle avec seulement <code>purchase</code> comme variable explicative.</p>
<p>Dans le tableau d’analyse de la variance, nous nous concentrons exclusivement sur la dernière ligne avec la somme des carrés pour l’interaction <code>purchase:debttype</code>. La statistique <span class="math inline">\(F\)</span> est 1.79; avec la loi de référence <span class="math inline">\(\mathsf{Fisher}\)</span> (1, 1497), on obtient une valeur-<span class="math inline">\(p\)</span> de 0.18 alors il n’y a pas de preuve que l’effet du libellé pour l’achat dépende du type de dette.</p>
<p>On peut donc regrouper les données et étudier uniquement l’effet du libellé (prêt <code>loan</code> ou <code>credit</code>) en combinant les données pour les types d’achats, une des comparaisons planifiées des annexes en ligne. Pour ce faire, on utilise la fonction <code>emmeans</code> du paquet éponyme en spécifiant le nom du ou des facteurs d’intérêts (ceux que l’on veut conserver) avec l’argument <code>specs</code>. Par défaut, on calcule les moyennes marginales estimées, l’argument <code>contr = "pairwise"</code> indique que l’on veut en plus les différences deux à deux, ici le seul contraste possible pour des différences entre deux facteurs.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Comparisons deux à deux au sein des niveaux de "purchase"</span></span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Effets simples</span></span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a>emmeans<span class="sc">::</span><span class="fu">emmeans</span>(modlin_STC21, </span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a>                 <span class="at">specs =</span> <span class="st">"purchase"</span>,</span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a>                 <span class="at">contr =</span> <span class="st">"pairwise"</span>)</span>
<span id="cb17-6"><a href="#cb17-6" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; $emmeans</span></span>
<span id="cb17-7"><a href="#cb17-7" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  purchase      emmean    SE   df lower.CL upper.CL</span></span>
<span id="cb17-8"><a href="#cb17-8" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  discretionary   4.17 0.101 1497     3.97     4.36</span></span>
<span id="cb17-9"><a href="#cb17-9" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  need            5.58 0.101 1497     5.39     5.78</span></span>
<span id="cb17-10"><a href="#cb17-10" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb17-11"><a href="#cb17-11" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Results are averaged over the levels of: debttype </span></span>
<span id="cb17-12"><a href="#cb17-12" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Confidence level used: 0.95 </span></span>
<span id="cb17-13"><a href="#cb17-13" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb17-14"><a href="#cb17-14" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; $contrasts</span></span>
<span id="cb17-15"><a href="#cb17-15" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  contrast             estimate    SE   df t.ratio p.value</span></span>
<span id="cb17-16"><a href="#cb17-16" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  discretionary - need    -1.42 0.143 1497  -9.910  &lt;.0001</span></span>
<span id="cb17-17"><a href="#cb17-17" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb17-18"><a href="#cb17-18" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Results are averaged over the levels of: debttype</span></span>
<span id="cb17-19"><a href="#cb17-19" aria-hidden="true" tabindex="-1"></a><span class="co"># Diagramme d'interaction</span></span>
<span id="cb17-20"><a href="#cb17-20" aria-hidden="true" tabindex="-1"></a>emmeans<span class="sc">::</span><span class="fu">emmip</span>(modlin_STC21, </span>
<span id="cb17-21"><a href="#cb17-21" aria-hidden="true" tabindex="-1"></a>               purchase <span class="sc">~</span> debttype, </span>
<span id="cb17-22"><a href="#cb17-22" aria-hidden="true" tabindex="-1"></a>               <span class="at">CIs =</span> <span class="cn">TRUE</span>) <span class="sc">+</span></span>
<span id="cb17-23"><a href="#cb17-23" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme_minimal</span>()</span></code><button title="Copier vers le presse-papier" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div id="fig-interaction-ST" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-interaction-ST-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="regression-lineaire_files/figure-html/fig-interaction-ST-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:85.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-interaction-ST-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;4.10: Diagramme d’interaction pour les données de l’étude S5 de <span class="citation" data-cites="Sharma.Tully.Cryder:2021">Sharma, Tully, et Cryder (<a href="references.html#ref-Sharma.Tully.Cryder:2021" role="doc-biblioref">2021</a>)</span>.
</figcaption>
</figure>
</div>
</div>
</div>
</div>
<div id="rem-sumofsquare" class="proof remark">
<p><span class="proof-title"><em>Remarque 4.6</em> (Décomposition de sommes des carrés). </span>Il existe différentes décompositions de la somme des carrés (type I, II et III) pour la comparaison des modèles emboîtés dans les tableaux d’analyse de la variance.</p>
<p>Ces décompositions testent différents modèles à l’aide des statistiques <span class="math inline">\(F\)</span>, avec le même dénominateur basé sur l’estimation de l’écart-type, mesuré avec <span class="math inline">\(S_2\)</span>, de la sortie du modèle complet. Le numérateur est la différence dans la somme des carrés. Toutes les décompositions concordent lorsque le plan d’expérience est <strong>équilibré</strong>, ce qui signifie que chaque cellule a le même nombre de réplications <span class="math inline">\(n_r\)</span>, de sorte que le nombre total d’observations est <span class="math inline">\(n = n_an_bn_r\)</span>.</p>
<div class="cell" data-layout-align="center">
<div id="tbl-ssdecompo" class="cell quarto-float quarto-figure quarto-figure-center anchored" data-layout-align="center">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-ssdecompo-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Tableau&nbsp;4.8: Décomposition de la somme des carrés dans les tableaux d’ANOVA (termes de l’hypothèse nulle vs l’alternative).
</figcaption>
<div aria-describedby="tbl-ssdecompo-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="cell-output-display">
<table class="do-not-create-environment cell caption-top table table-sm table-striped small">
<colgroup>
<col style="width: 20%">
<col style="width: 25%">
<col style="width: 25%">
<col style="width: 29%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;"></th>
<th style="text-align: left;">type I</th>
<th style="text-align: left;">type II</th>
<th style="text-align: left;">type III</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;"><span class="math inline">\(\boldsymbol{A}\)</span></td>
<td style="text-align: left;">intercept vs <span class="math inline">\(A\)</span></td>
<td style="text-align: left;"><span class="math inline">\(B\)</span> vs <span class="math inline">\((A,B)\)</span></td>
<td style="text-align: left;"><span class="math inline">\((B, A:B)\)</span> vs <span class="math inline">\((A,B, A:B)\)</span></td>
</tr>
<tr class="even">
<td style="text-align: left;"><span class="math inline">\(\boldsymbol{B}\)</span></td>
<td style="text-align: left;"><span class="math inline">\(A\)</span> vs <span class="math inline">\((A,B)\)</span></td>
<td style="text-align: left;"><span class="math inline">\(A\)</span> vs <span class="math inline">\((A,B)\)</span></td>
<td style="text-align: left;"><span class="math inline">\((A, A:B)\)</span> vs <span class="math inline">\((A,B,A:B)\)</span></td>
</tr>
<tr class="odd">
<td style="text-align: left;"><span class="math inline">\(\boldsymbol{A:B}\)</span></td>
<td style="text-align: left;"><span class="math inline">\((A,B)\)</span> vs <span class="math inline">\((A,B,A:B)\)</span></td>
<td style="text-align: left;"><span class="math inline">\((A,B)\)</span> vs <span class="math inline">\((A,B,A:B)\)</span></td>
<td style="text-align: left;"><span class="math inline">\((A,B)\)</span> vs <span class="math inline">\((A,B,A:B)\)</span></td>
</tr>
</tbody>
</table>
</div>
</div>
</figure>
</div>
</div>
<p><a href="#tbl-ssdecompo" class="quarto-xref">Tableau&nbsp;<span>4.8</span></a> montre les différentes sommes des erreurs quadratiques des modèles, avec les termes entre parenthèses indiquant quels termes sont inclus (<span class="math inline">\(A:B\)</span> désigne l’interaction).</p>
<p>La décomposition de type I, la valeur par défaut du générique <code>anova</code>, utilise l’ordre dans lequel les termes sont spécifiés, disons <span class="math inline">\(A\)</span>, <span class="math inline">\(B\)</span>, <span class="math inline">\(AB\)</span>, et compare donc sur la première ligne l’amélioration dans le modèle de la moyenne seule avec <span class="math inline">\(A\)</span>, puis sur la deuxième ligne le test pour <span class="math inline">\(B\)</span> compare le modèle avec les deux effets principaux <span class="math inline">\(A\)</span> et <span class="math inline">\(B\)</span> avec seulement <span class="math inline">\(A\)</span>. Étant donné que l’ordre dans lequel les facteurs sont spécifiés est arbitraire, cette décomposition est arbitraire et donc non pertinente.</p>
<p>La décomposition de type II considère les termes de même niveau dans la hiérarchie, de sorte que les tests pour les effets principaux sont <span class="math inline">\(A + B\)</span> vs <span class="math inline">\(A\)</span>, <span class="math inline">\(A+B\)</span> vs <span class="math inline">\(B\)</span> et celui de l’interaction est <span class="math inline">\(A\times B\)</span> vs <span class="math inline">\(A, B\)</span>. Il s’agit de l’option par défaut si l’on souhaite considérer les effets principaux lorsque l’interaction n’est pas significative.</p>
<p>La décomposition de type III, popularisée par SAS et souvent choisie par défaut dans les logiciels, prend en compte tous les autres termes, et testerait donc les effets principaux comme <span class="math inline">\(A + B + A\times B\)</span> vs <span class="math inline">\(B + A\times B\)</span>. Cette méthode ne respecte pas le principe de marginalité et doit donc être évitée. Les tests pour <span class="math inline">\(A\)</span> ou <span class="math inline">\(B\)</span> ne doivent pas être utilisés.</p>
<p>Les trois méthodes donnent le même résultat et la même comparaison pour le dernier niveau avec l’interaction.</p>
</div>
<p>Toutes les discussions relatives à une ANOVA à deux voies s’appliquent à des plans d’expérience à <span class="math inline">\(K\)</span> facteurs. Cependant, le fléau de la dimensionnalité rend plus difficile la collecte d’observations dans chaque cellule. Toute ANOVA à plusieurs facteurs peut être ramenée à une ANOVA à un facteur: ceci est particulièrement utile lorsqu’il y a un groupe de contrôle qui n’est pas lié aux niveaux des facteurs, étant donné qu’il n’y a pas de manipulation. L’utilisation des contrastes devient critique puisque nous pouvons écrire n’importe quel test pour les effets principaux, les interactions, etc.</p>
<div id="exm-LKUK24" class="theorem example">
<p><span class="theorem-title"><strong>Exemple 4.21 (Perception d’appropriation culturelle par idéologie politique)</strong></span> On considère un modèle d’ANOVA à trois facteurs de <span class="citation" data-cites="Lin.Kim.Uduehi.Keinan:2024">Lin et al. (<a href="references.html#ref-Lin.Kim.Uduehi.Keinan:2024" role="doc-biblioref">2024</a>)</span>. Leur étude 4 s’intéresse à l’appropriation culturelle pour une recette de <em>soul food</em>, un courant afro-américain, parue dans le livre du “Chef Dax”. Les auteurs manipulent l’ethnicité du chef, afro-Américain ou pas, et la façon dont la recette a été obtenue (furtivement, en demandant la permission ou sans mention dans le cas du groupe contrôle). Les auteurs ont postulé que la perception de l’appropriation varie selon l’idéologie politique. L’étude utilise un devis expérimental <span class="math inline">\(3 \times 2 \times 2\)</span>.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(LKUK24_S4, <span class="at">package =</span> <span class="st">"hecedsm"</span>)</span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Vérifier la répartition d'observations en sous-groupes</span></span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a><span class="fu">xtabs</span>(<span class="sc">~</span>politideo <span class="sc">+</span> chefdax <span class="sc">+</span> brandaction,</span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a>          <span class="at">data =</span> LKUK24_S4)</span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; , , brandaction = peeking</span></span>
<span id="cb18-6"><a href="#cb18-6" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb18-7"><a href="#cb18-7" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;               chefdax</span></span>
<span id="cb18-8"><a href="#cb18-8" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; politideo      not black black</span></span>
<span id="cb18-9"><a href="#cb18-9" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;   conservative        33    36</span></span>
<span id="cb18-10"><a href="#cb18-10" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;   liberal             87    84</span></span>
<span id="cb18-11"><a href="#cb18-11" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb18-12"><a href="#cb18-12" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; , , brandaction = permission</span></span>
<span id="cb18-13"><a href="#cb18-13" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb18-14"><a href="#cb18-14" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;               chefdax</span></span>
<span id="cb18-15"><a href="#cb18-15" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; politideo      not black black</span></span>
<span id="cb18-16"><a href="#cb18-16" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;   conservative        42    34</span></span>
<span id="cb18-17"><a href="#cb18-17" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;   liberal             77    84</span></span>
<span id="cb18-18"><a href="#cb18-18" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb18-19"><a href="#cb18-19" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; , , brandaction = control</span></span>
<span id="cb18-20"><a href="#cb18-20" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb18-21"><a href="#cb18-21" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;               chefdax</span></span>
<span id="cb18-22"><a href="#cb18-22" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; politideo      not black black</span></span>
<span id="cb18-23"><a href="#cb18-23" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;   conservative        38    32</span></span>
<span id="cb18-24"><a href="#cb18-24" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;   liberal             79    85</span></span>
<span id="cb18-25"><a href="#cb18-25" aria-hidden="true" tabindex="-1"></a><span class="co"># Les facteurs sont croisés et il y a des réplications</span></span>
<span id="cb18-26"><a href="#cb18-26" aria-hidden="true" tabindex="-1"></a><span class="co"># On ajuste un modèle d'ANOVA à trois facteurs (avec toutes les interactions)</span></span>
<span id="cb18-27"><a href="#cb18-27" aria-hidden="true" tabindex="-1"></a>mod <span class="ot">&lt;-</span> <span class="fu">lm</span>(appropriation <span class="sc">~</span> politideo <span class="sc">*</span> chefdax <span class="sc">*</span> brandaction,</span>
<span id="cb18-28"><a href="#cb18-28" aria-hidden="true" tabindex="-1"></a>          <span class="at">data =</span> LKUK24_S4)</span>
<span id="cb18-29"><a href="#cb18-29" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculer les estimations des moyennes marginales </span></span>
<span id="cb18-30"><a href="#cb18-30" aria-hidden="true" tabindex="-1"></a><span class="co"># pour chacun des 12 sous-groupes</span></span>
<span id="cb18-31"><a href="#cb18-31" aria-hidden="true" tabindex="-1"></a>emm <span class="ot">&lt;-</span> <span class="fu">emmeans</span>(mod, </span>
<span id="cb18-32"><a href="#cb18-32" aria-hidden="true" tabindex="-1"></a>        <span class="at">specs =</span> <span class="fu">c</span>(<span class="st">"chefdax"</span>, <span class="st">"brandaction"</span>, <span class="st">"politideo"</span>))</span>
<span id="cb18-33"><a href="#cb18-33" aria-hidden="true" tabindex="-1"></a><span class="co"># Créer un diagramme d'interaction</span></span>
<span id="cb18-34"><a href="#cb18-34" aria-hidden="true" tabindex="-1"></a><span class="fu">emmip</span>(<span class="at">object =</span> emm, </span>
<span id="cb18-35"><a href="#cb18-35" aria-hidden="true" tabindex="-1"></a>        <span class="at">formula =</span> brandaction <span class="sc">~</span> chefdax <span class="sc">|</span> politideo, </span>
<span id="cb18-36"><a href="#cb18-36" aria-hidden="true" tabindex="-1"></a>        <span class="at">CIs =</span> <span class="cn">TRUE</span>) <span class="sc">+</span> </span>
<span id="cb18-37"><a href="#cb18-37" aria-hidden="true" tabindex="-1"></a>  MetBrewer<span class="sc">::</span><span class="fu">scale_color_met_d</span>(<span class="at">name =</span> <span class="st">"Hiroshige"</span>) <span class="sc">+</span></span>
<span id="cb18-38"><a href="#cb18-38" aria-hidden="true" tabindex="-1"></a>  <span class="fu">labs</span>(<span class="at">y =</span> <span class="st">"prédicteur linéaire"</span>,</span>
<span id="cb18-39"><a href="#cb18-39" aria-hidden="true" tabindex="-1"></a>       <span class="at">x =</span> <span class="st">"niveaux de chefdax"</span>)</span>
<span id="cb18-40"><a href="#cb18-40" aria-hidden="true" tabindex="-1"></a><span class="co"># Tableau d'ANOVA (type 2)</span></span>
<span id="cb18-41"><a href="#cb18-41" aria-hidden="true" tabindex="-1"></a>anova_tab <span class="ot">&lt;-</span> car<span class="sc">::</span><span class="fu">Anova</span>(mod, <span class="at">type =</span> <span class="dv">2</span>)</span></code><button title="Copier vers le presse-papier" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="regression-lineaire_files/figure-html/unnamed-chunk-39-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:85.0%"></p>
</figure>
</div>
</div>
</div>
<p>Pour l’ANOVA à <span class="math inline">\(K\)</span> facteurs, nous commençons toujours par estimer le modèle complet avec toutes les interactions (à condition qu’il y ait suffisamment de données pour estimer ces dernières, ce qui implique qu’il y ait des répétitions). Si cette dernière est significative, nous pouvons fixer un ou plusieurs niveaux de facteurs et comparer les autres.</p>
<div class="cell" data-layout-align="center">
<div id="tbl-anova-LKUK24" class="cell quarto-float quarto-figure quarto-figure-center anchored" data-layout-align="center">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-anova-LKUK24-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Tableau&nbsp;4.9: Tableau d’analyse de variance (décomposition de type 2) pour l’étude 4 de <span class="citation" data-cites="Lin.Kim.Uduehi.Keinan:2024">Lin et al. (<a href="references.html#ref-Lin.Kim.Uduehi.Keinan:2024" role="doc-biblioref">2024</a>)</span>.
</figcaption>
<div aria-describedby="tbl-anova-LKUK24-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="cell-output-display">
<table class="do-not-create-environment cell caption-top table table-sm table-striped small">
<colgroup>
<col style="width: 44%">
<col style="width: 25%">
<col style="width: 5%">
<col style="width: 10%">
<col style="width: 13%">
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;">terme</th>
<th style="text-align: right;">somme des carrés</th>
<th style="text-align: right;">ddl</th>
<th style="text-align: right;">stat</th>
<th style="text-align: left;">valeur-p</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">politideo</td>
<td style="text-align: right;">48.49</td>
<td style="text-align: right;">1</td>
<td style="text-align: right;">21.35</td>
<td style="text-align: left;">&lt;0.001</td>
</tr>
<tr class="even">
<td style="text-align: left;">chefdax</td>
<td style="text-align: right;">473.72</td>
<td style="text-align: right;">1</td>
<td style="text-align: right;">208.61</td>
<td style="text-align: left;">&lt;0.001</td>
</tr>
<tr class="odd">
<td style="text-align: left;">brandaction</td>
<td style="text-align: right;">34.24</td>
<td style="text-align: right;">2</td>
<td style="text-align: right;">7.54</td>
<td style="text-align: left;">&lt;0.001</td>
</tr>
<tr class="even">
<td style="text-align: left;">politideo:chefdax</td>
<td style="text-align: right;">65.00</td>
<td style="text-align: right;">1</td>
<td style="text-align: right;">28.63</td>
<td style="text-align: left;">&lt;0.001</td>
</tr>
<tr class="odd">
<td style="text-align: left;">politideo:brandaction</td>
<td style="text-align: right;">1.56</td>
<td style="text-align: right;">2</td>
<td style="text-align: right;">0.34</td>
<td style="text-align: left;">0.71</td>
</tr>
<tr class="even">
<td style="text-align: left;">chefdax:brandaction</td>
<td style="text-align: right;">0.62</td>
<td style="text-align: right;">2</td>
<td style="text-align: right;">0.14</td>
<td style="text-align: left;">0.87</td>
</tr>
<tr class="odd">
<td style="text-align: left;">politideo:chefdax:brandaction</td>
<td style="text-align: right;">0.66</td>
<td style="text-align: right;">2</td>
<td style="text-align: right;">0.15</td>
<td style="text-align: left;">0.86</td>
</tr>
<tr class="even">
<td style="text-align: left;">Residuals</td>
<td style="text-align: right;">1587.33</td>
<td style="text-align: right;">699</td>
<td style="text-align: right;"></td>
<td style="text-align: left;"></td>
</tr>
</tbody>
</table>
</div>
</div>
</figure>
</div>
</div>
<p>Si on considère le <a href="#tbl-anova-LKUK24" class="quarto-xref">Tableau&nbsp;<span>4.9</span></a>, nous constatons qu’il n’y a pas d’interaction à trois voies et, si l’on omet cette dernière et que l’on se concentre sur les niveaux inférieurs, une seule interaction à deux voies entre l’idéologie politique et la race du chef Dax.Nous ne pouvons pas interpréter la valeur <span class="math inline">\(p\)</span> pour l’effet principal de <code>brandaction</code>, mais nous pouvons examiner les moyennes marginales.</p>
<p>Sur la base des données, nous réduirons les données à une ANOVA à une voie comparant les trois niveaux de <code>brandaction</code> et à une ANOVA à deux facteurs, <span class="math inline">\(2 \times 2\)</span> pour <code>chefdax</code> et <code>politideo</code>. Les résultats sont obtenus en calculant la moyenne pour le facteur manquant, mais en estimant l’écart-type du modèle complet.</p>
<p>Nous souhaitons comparer la perception de la race du chef Dax (noir ou non), car la cuisine <em>soul</em> est plus susceptible d’être associée à l’appropriation culturelle si le chef Dax n’est pas noir. Nous procédons avec <code>emmeans</code> en calculant les moyennes marginales séparément pour chacune des quatre sous-catégories, mais nous comparons la race du chef Dax séparément pour les libéraux et les conservateurs en raison de la présence de l’interaction.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(LKUK24_S4, <span class="at">package =</span> <span class="st">"hecedsm"</span>)</span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(emmeans)</span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a>mod <span class="ot">&lt;-</span> <span class="fu">lm</span>(appropriation <span class="sc">~</span> politideo <span class="sc">*</span> chefdax <span class="sc">*</span> brandaction,</span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a>   <span class="at">data =</span> LKUK24_S4)</span>
<span id="cb19-5"><a href="#cb19-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Moyennes marginales pour </span></span>
<span id="cb19-6"><a href="#cb19-6" aria-hidden="true" tabindex="-1"></a><span class="co"># idéologie politique/ethnicité du Chef Dax</span></span>
<span id="cb19-7"><a href="#cb19-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculer les effets simples séparément</span></span>
<span id="cb19-8"><a href="#cb19-8" aria-hidden="true" tabindex="-1"></a><span class="co">#  pour chaque idéologie politique</span></span>
<span id="cb19-9"><a href="#cb19-9" aria-hidden="true" tabindex="-1"></a><span class="fu">emmeans</span>(mod, </span>
<span id="cb19-10"><a href="#cb19-10" aria-hidden="true" tabindex="-1"></a>         <span class="at">specs =</span> <span class="st">"chefdax"</span>, </span>
<span id="cb19-11"><a href="#cb19-11" aria-hidden="true" tabindex="-1"></a>         <span class="at">by =</span> <span class="st">"politideo"</span>,</span>
<span id="cb19-12"><a href="#cb19-12" aria-hidden="true" tabindex="-1"></a>         <span class="at">contrast =</span> <span class="st">"pairwise"</span>)</span>
<span id="cb19-13"><a href="#cb19-13" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; politideo = conservative:</span></span>
<span id="cb19-14"><a href="#cb19-14" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  chefdax   emmean     SE  df lower.CL upper.CL</span></span>
<span id="cb19-15"><a href="#cb19-15" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  not black   2.38 0.1425 699     2.11     2.66</span></span>
<span id="cb19-16"><a href="#cb19-16" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  black       1.68 0.1494 699     1.38     1.97</span></span>
<span id="cb19-17"><a href="#cb19-17" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb19-18"><a href="#cb19-18" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; politideo = liberal:</span></span>
<span id="cb19-19"><a href="#cb19-19" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  chefdax   emmean     SE  df lower.CL upper.CL</span></span>
<span id="cb19-20"><a href="#cb19-20" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  not black   3.60 0.0968 699     3.41     3.79</span></span>
<span id="cb19-21"><a href="#cb19-21" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  black       1.57 0.0947 699     1.38     1.75</span></span>
<span id="cb19-22"><a href="#cb19-22" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb19-23"><a href="#cb19-23" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Results are averaged over the levels of: brandaction </span></span>
<span id="cb19-24"><a href="#cb19-24" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Confidence level used: 0.95</span></span></code><button title="Copier vers le presse-papier" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Nous constatons que les libéraux sont beaucoup plus susceptibles de considérer le livre de cuisine du chef Dax comme un exemple d’appropriation culturelle s’il n’est pas noir; il y a peu de preuves d’une différence entre les conservateurs et les libéraux lorsque le chef Dax est noir. On peut calculer les effets marginaux pour idéologie (afro-Américain ou pas). Les deux différences sont statistiquement significatives, mais la différence est beaucoup plus marquée pour les répondants de gauche.</p>
<p>Pour <code>brandaction</code>, nous supposons que les participants verront le fait de copier furtivement moins favorablement que si le chef Dax demandait l’autorisation de publier la recette. Il est difficile de connaître l’effet du groupe contrôle, car on ne mentionne pas comment la recette a été acquise.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Effet marginal (effet principal) pour brandaction</span></span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a>emm_brand <span class="ot">&lt;-</span> <span class="fu">emmeans</span>(mod, <span class="at">specs =</span> <span class="fu">c</span>(<span class="st">"brandaction"</span>)) </span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a>emm_brand</span>
<span id="cb20-4"><a href="#cb20-4" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  brandaction emmean    SE  df lower.CL upper.CL</span></span>
<span id="cb20-5"><a href="#cb20-5" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  peeking       2.56 0.107 699     2.35     2.77</span></span>
<span id="cb20-6"><a href="#cb20-6" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  permission    2.29 0.105 699     2.09     2.50</span></span>
<span id="cb20-7"><a href="#cb20-7" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  control       2.07 0.108 699     1.86     2.28</span></span>
<span id="cb20-8"><a href="#cb20-8" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb20-9"><a href="#cb20-9" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Results are averaged over the levels of: politideo, chefdax </span></span>
<span id="cb20-10"><a href="#cb20-10" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Confidence level used: 0.95</span></span>
<span id="cb20-11"><a href="#cb20-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Test F conjoint pour l'effet principale de brandaction</span></span>
<span id="cb20-12"><a href="#cb20-12" aria-hidden="true" tabindex="-1"></a>emm_brand <span class="sc">|&gt;</span> <span class="fu">pairs</span>() <span class="sc">|&gt;</span> <span class="fu">joint_tests</span>()</span>
<span id="cb20-13"><a href="#cb20-13" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  model term df1 df2 F.ratio p.value</span></span>
<span id="cb20-14"><a href="#cb20-14" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  contrast     2 699   5.090  0.0064</span></span></code><button title="Copier vers le presse-papier" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Un test <span class="math inline">\(F\)</span> conjoint, obtenu en ramenant le devis à une ANOVA à un facteur, montre qu’il existe effectivement des différences. C’est le groupe contrôle qui a la moyenne la plus basse.</p>
</div>
</section>
<section id="géométrie-des-moindres-carrés" class="level2" data-number="4.7">
<h2 data-number="4.7" class="anchored" data-anchor-id="géométrie-des-moindres-carrés"><span class="header-section-number">4.7</span> Géométrie des moindres carrés</h2>
<div id="rem-geometry" class="proof remark">
<p><span class="proof-title"><em>Remarque 4.9</em>. </span></p>
<div id="rem-geometry" class="proof remark">
<p><span class="proof-title"><em>Remarque 4.9</em> (Géométrie). </span>Le vecteur de valeurs ajustées <span class="math inline">\(\widehat{\boldsymbol{y}} =\mathbf{X} \widehat{\boldsymbol{\beta}} = \mathbf{H}_{\mathbf{X}}\boldsymbol{y}\)</span> est la projection du vecteur réponse <span class="math inline">\(\boldsymbol{y}\)</span> dans l’espace linéaire engendré par les colonnes de <span class="math inline">\(\mathbf{X}\)</span>. La matrice chapeau <span class="math inline">\(\mathbf{H}_{\mathbf{X}} = \mathbf{X}(\mathbf{X}^\top\mathbf{X})^{-1}\mathbf{X}^\top\)</span> est une matrice de projection orthogonale, car <span class="math inline">\(\mathbf{H}_{\mathbf{X}}=\mathbf{H}_{\mathbf{X}}^\top\)</span> et <span class="math inline">\(\mathbf{H}_{\mathbf{X}}\mathbf{H}_{\mathbf{X}} = \mathbf{H}_{\mathbf{X}}\)</span>. Ainsi, <span class="math inline">\(\mathbf{H}_{\mathbf{X}}\mathbf{X} = \mathbf{X}\)</span>. Puisque le vecteur de résidus ordinaires <span class="math inline">\(\boldsymbol{e} = (e_1, \ldots, e_n)^\top\)</span>, qui apparaît dans la somme des erreurs quadratiques, est définie comme <span class="math inline">\(\boldsymbol{y} - \widehat{\boldsymbol{y}}\)</span> et <span class="math inline">\(\widehat{\boldsymbol{y}}=\mathbf{X}\boldsymbol{\beta}\)</span>, de simples manipulations algébriques montrent que le produit scalaire entre les résidus ordinaires et les valeurs ajustées est nul, puisque <span class="math display">\[\begin{align*}
\widehat{\boldsymbol{y}}^\top\boldsymbol{e} &amp;= \widehat{\boldsymbol{\beta}}^\top \mathbf{X}^\top (\boldsymbol{y}- \mathbf{X} \widehat{\boldsymbol{\beta}})
\\&amp;= \boldsymbol{y}^\top\mathbf{X}(\mathbf{X}^\top\mathbf{X})^{-1}\mathbf{X}^\top(\boldsymbol{y} - \mathbf{X}(\mathbf{X}^\top\mathbf{X})^{-1}\mathbf{X}^\top \boldsymbol{y})\\&amp;=\boldsymbol{y}^\top\mathbf{H}_{\mathbf{X}}\boldsymbol{y} - \mathbf{X}(\mathbf{X}^\top\mathbf{X})^{-1}\mathbf{X}^\top\mathbf{X}(\mathbf{X}^\top\mathbf{X})^{-1}\mathbf{X}^\top \boldsymbol{y}
\\&amp;= 0
\end{align*}\]</span> où nous utilisons la définition de <span class="math inline">\(\widehat{\boldsymbol{y}}\)</span> et <span class="math inline">\(\boldsymbol{e} = \boldsymbol{y} - \widehat{\boldsymbol{y}}\)</span> sur la première ligne, puis on substitut l’estimateur des MCO <span class="math inline">\(\widehat{\boldsymbol{\beta}} = (\mathbf{X}^\top\mathbf{X})^{-1}\mathbf{X}^\top\boldsymbol{y}\)</span> avant de distribuer les termes du produit. Une dérivation similaire montre que <span class="math inline">\(\mathbf{X}^\top\boldsymbol{e}=\boldsymbol{0}_{p+1}\)</span>. Les résidus ordinaires sont donc orthogonaux à la fois à la matrice du modèle <span class="math inline">\(\mathbf{X}\)</span> et aux valeurs ajustées <span class="math inline">\(\widehat{\boldsymbol{y}}\)</span>.</p>
</div>
<div id="cor-cor" class="theorem corollary">
<p><span class="theorem-title"><strong>Corollaire 4.1 (Orthogonalité des résidus et des valeurs ajustées)</strong></span> Une conséquence directe de ces résultats est le fait que la corrélation linéaire entre <span class="math inline">\(\boldsymbol{e}\)</span> et <span class="math inline">\(\widehat{\boldsymbol{y}}\)</span> est nulle. Cette propriété servira lors de l’élaboration de diagnostics graphiques.</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div id="fig-zerocor" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-zerocor-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="regression-lineaire_files/figure-html/fig-zerocor-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:85.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-zerocor-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;4.11: Diagramme des résidus en fonction des valeurs ajustées (à gauche) et de la variable explicative <code>service</code> (à droite) pour la régression linéaire des données <code>college</code>. L’ordonnée à l’origine et la pente des régressions linéaires simples sont nulles.
</figcaption>
</figure>
</div>
</div>
</div>
</div>
<div id="cor-zeromean" class="theorem corollary">
<p><span class="theorem-title"><strong>Corollaire 4.2 (Moyenne des résidus nulle)</strong></span> Puisque le produit scalaire est zéro, la moyenne de <span class="math inline">\(\boldsymbol{e}\)</span> doit être zéro pour autant que <span class="math inline">\(\mathbf{1}_n\)</span> est dans l’espace linéaire engendré par <span class="math inline">\(\mathbf{X}\)</span>.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a>mod <span class="ot">&lt;-</span> <span class="fu">lm</span>(salaire <span class="sc">~</span> sexe <span class="sc">+</span> echelon <span class="sc">+</span> domaine <span class="sc">+</span> service, <span class="at">data =</span> college)</span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Corrélation nulle</span></span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a><span class="fu">with</span>(college, <span class="fu">cor</span>(<span class="fu">resid</span>(mod), service))</span>
<span id="cb21-4"><a href="#cb21-4" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [1] 1.26e-17</span></span>
<span id="cb21-5"><a href="#cb21-5" aria-hidden="true" tabindex="-1"></a><span class="fu">cor</span>(<span class="fu">resid</span>(mod), <span class="fu">fitted</span>(mod))</span>
<span id="cb21-6"><a href="#cb21-6" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [1] 2.32e-17</span></span>
<span id="cb21-7"><a href="#cb21-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Moyenne des résidus ordinaires est nulle</span></span>
<span id="cb21-8"><a href="#cb21-8" aria-hidden="true" tabindex="-1"></a><span class="fu">mean</span>(<span class="fu">resid</span>(mod))</span>
<span id="cb21-9"><a href="#cb21-9" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [1] -5.6e-16</span></span></code><button title="Copier vers le presse-papier" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Puisque les aléas avaient moyenne théorique de zéro, on veut forcer les résidus ordinaires à avoir une moyenne empirique de zéro en incluant l’ordonnée à l’origine.</p>
</div>
<div id="rem-invariance" class="proof remark">
<p><span class="proof-title"><em>Remarque 4.8</em> (Invariance). </span>Une conséquence directe de l’expression de l’estimateur des MCO en terme de matrice de projection est que les valeurs ajustées <span class="math inline">\(\widehat{y}_i\)</span> pour deux matrices de modèle <span class="math inline">\(\mathbf{X}_a\)</span> et <span class="math inline">\(\mathbf{X}_b\)</span> sont les mêmes si elles engendrent le même espace linéaire, comme dans <a href="#exm-baumann-dummies" class="quarto-xref">Exemple&nbsp;<span>4.9</span></a>; seule l’interprétation des coefficients change. Si nous incluons une ordonnée à l’origine, nous obtenons le même résultat si les colonnes explicatives sont centrées sur la moyenne.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a>modA <span class="ot">&lt;-</span> <span class="fu">lm</span>(salaire <span class="sc">~</span> sexe <span class="sc">+</span> echelon <span class="sc">+</span> service, <span class="at">data =</span> college)</span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a>modB <span class="ot">&lt;-</span> <span class="fu">lm</span>(salaire <span class="sc">~</span> <span class="dv">0</span> <span class="sc">+</span> sexe <span class="sc">+</span> echelon <span class="sc">+</span> service, <span class="co"># Enlever l'ordonnée à l'origine</span></span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a>           <span class="at">data =</span> college <span class="sc">|&gt;</span> </span>
<span id="cb22-4"><a href="#cb22-4" aria-hidden="true" tabindex="-1"></a>            dplyr<span class="sc">::</span><span class="fu">mutate</span>(<span class="at">service =</span> <span class="fu">scale</span>(service)), <span class="co"># Centrer-réduire une variable</span></span>
<span id="cb22-5"><a href="#cb22-5" aria-hidden="true" tabindex="-1"></a>           <span class="at">contrasts =</span> <span class="fu">list</span>(<span class="at">echelon =</span> contr.sum)) <span class="co"># changer la paramétrisation</span></span>
<span id="cb22-6"><a href="#cb22-6" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(<span class="fu">model.matrix</span>(modA), <span class="at">n =</span> <span class="dv">3</span>L)</span>
<span id="cb22-7"><a href="#cb22-7" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;   (Intercept) sexefemme echelonaggrege echelontitulaire service</span></span>
<span id="cb22-8"><a href="#cb22-8" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 1           1         0              0                1      18</span></span>
<span id="cb22-9"><a href="#cb22-9" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 2           1         0              0                1      16</span></span>
<span id="cb22-10"><a href="#cb22-10" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 3           1         0              0                0       3</span></span>
<span id="cb22-11"><a href="#cb22-11" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(<span class="fu">model.matrix</span>(modB), <span class="at">n =</span> <span class="dv">3</span>L)</span>
<span id="cb22-12"><a href="#cb22-12" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;   sexehomme sexefemme echelon1 echelon2 service</span></span>
<span id="cb22-13"><a href="#cb22-13" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 1         1         0       -1       -1  0.0296</span></span>
<span id="cb22-14"><a href="#cb22-14" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 2         1         0       -1       -1 -0.1241</span></span>
<span id="cb22-15"><a href="#cb22-15" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 3         1         0        1        0 -1.1237</span></span>
<span id="cb22-16"><a href="#cb22-16" aria-hidden="true" tabindex="-1"></a><span class="co"># Invariance du modèle</span></span>
<span id="cb22-17"><a href="#cb22-17" aria-hidden="true" tabindex="-1"></a><span class="fu">isTRUE</span>(<span class="fu">all.equal</span>(<span class="fu">fitted</span>(modA), <span class="fu">fitted</span>(modB)))</span>
<span id="cb22-18"><a href="#cb22-18" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [1] TRUE</span></span></code><button title="Copier vers le presse-papier" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
<p>La valeur de <span class="math inline">\(\widehat{\boldsymbol{\beta}}\)</span> est telle qu’elle maximise la corrélation entre <span class="math inline">\(\boldsymbol{y}\)</span> et <span class="math inline">\(\widehat{\boldsymbol{y}}\)</span>. Dans le cas d’une variable catégorielle unique, nous obtiendrons des valeurs ajustées <span class="math inline">\(\widehat{y}\)</span> qui correspondent à la moyenne de l’échantillon de chaque groupe.</p>
</div>
<section id="résidus" class="level3" data-number="4.7.1">
<h3 data-number="4.7.1" class="anchored" data-anchor-id="résidus"><span class="header-section-number">4.7.1</span> Résidus</h3>
<p>Les résidus sont les prédictions des aléas <span class="math inline">\(\varepsilon\)</span>, et représentent la différence entre la valeur observée de la réponse <span class="math inline">\(Y_i\)</span> et sa prédiction. Les résidus ordinaires sont définis comme <span class="math display">\[\begin{align*}
e_i=Y_i-\widehat{Y}_i, \qquad i =1, \ldots, n.
\end{align*}\]</span> La somme des résidus ordinaire est toujours zéro par construction si on inclut une ordonnée à l’origine, ce qui donne que <span class="math inline">\(\overline{e} = 0\)</span>.</p>
<p>Toutes les observations ne contribuent pas de la même manière à l’ajustement de l’hyperplan ajusté. La géométrie des moindres carrés montre que les résidus sont orthogonaux aux valeurs ajustées, et que <span class="math inline">\(\boldsymbol{e} = (\mathbf{I}_n-\mathbf{H}_{\mathbf{X}})\boldsymbol{Y}\)</span>, où <span class="math inline">\(\mathbf{H}_{\mathbf{X}}=\mathbf{X}(\mathbf{X}^\top\mathbf{X})^{-1}\mathbf{X}^\top\)</span> est une matrice de projection de dimension <span class="math inline">\(n \times n\)</span> qui génère un sous-espace vectoriel de dimension <span class="math inline">\((p+1)\)</span> décrouvrant toutes les combinaisons linéaires des colonnes de <span class="math inline">\(\mathbf{X}\)</span>, dénoté <span class="math inline">\(\mathscr{S}(\mathbf{X})\)</span>. Si <span class="math inline">\(\mathsf{Va}(\boldsymbol{Y}) = \sigma^2\mathbf{I}_n\)</span>, il en découle que <span class="math inline">\(\mathsf{Va}(\boldsymbol{e})=\sigma^2(\mathbf{I}_n-\mathbf{H}_{\mathbf{X}})\)</span> parce que <span class="math inline">\(\mathbf{I}_n-\mathbf{H}_{\mathbf{X}}\)</span> est une matrice de projection orthogonale, donc idempotente et symmérique. Puisque la matrice <span class="math inline">\(\mathbf{I}_n-\mathbf{H}_{\mathbf{X}}\)</span> a rang <span class="math inline">\(n-p-1\)</span>, les résidus ordinaires ne sont pas indépendants les uns des autres.</p>
<p>Si les aléas sont indépendants et homoscédastiques, les résidus ordinaires <span class="math inline">\(e_i\)</span> ont une variance de <span class="math inline">\(\sigma^2(1-h_{i})\)</span>, où le terme de levier <span class="math inline">\(h_i =(\mathbf{H}_{\mathbf{X}})_{ii} = \mathbf{x}_i (\mathbf{X}^\top\mathbf{X})^{-1}\mathbf{x}_i\)</span> est le <span class="math inline">\(i\)</span>e élément de la diagonale de la matrice de projection <span class="math inline">\(\mathbf{H}_{\mathbf{X}}\)</span> et <span class="math inline">\(\mathbf{x}_i\)</span> est comme à l’accoutumée la <span class="math inline">\(i\)</span>e ligne de la matrice du modèle qui correspond à l’observation <span class="math inline">\(i\)</span>.</p>
<p>Nous concluons donc que les résidus ordinaires n’ont pas tous le même écart-type et qu’ils ne sont pas indépendants. Ceci est problématique, car nous ne pouvons pas faire de comparaisons de leurs lois: les points ayant un faible effet de levier s’écartent davantage du modèle ajusté que les autres. Pour pallier ce problème, nous pouvons normaliser les résidus de façon à ce que chacun ait la même variance sous l’hypothèse nulle d’erreurs homoscédastiques indépendantes — les termes d’effet de levier <span class="math inline">\(h_i\)</span> sont facilement calculés à partir de la matrice du modèle <span class="math inline">\(\mathbf{X}\)</span>.</p>
<p>La seule question qui subsiste est celle de l’estimation de la variance. Si nous utilisons la <span class="math inline">\(i\)</span>e observation pour estimer à la fois le résidu et la variance, nous introduisons une dépendance supplémentaire. Une meilleure solution consiste à supprimer la <span class="math inline">\(i\)</span>e observation et à réajuster le modèle avec les <span class="math inline">\(n-1\)</span> observations restantes pour obtenir <span class="math inline">\(S^2_{(-i)}\)</span> (il existe des formules explicites qui font qu’il n’est pas nécessaire d’ajuster <span class="math inline">\(n\)</span> modèles linéaires). Les résidus studentisés externes <span class="math inline">\(r_i = e_i/\{s_{(-i)}(1-h_i)\}\)</span>, également appelés résidus studentisés par la méthode du canif, ne sont pas indépendants, mais ils sont une loi marginale identique de Student avec <span class="math inline">\(n-p-2\)</span> degrés de liberté. Ils peuvent être obtenus dans <strong>R</strong> avec la commande <code>rstudent</code>.</p>
<p>Quand utiliser quels résidus? Par construction, le vecteur des résidus ordinaires <span class="math inline">\(\boldsymbol{e}\)</span> est orthogonal aux valeurs ajustées <span class="math inline">\(\widehat{\boldsymbol{y}}\)</span> et également à chaque colonne de la matrice du modèle <span class="math inline">\(\mathbf{X}\)</span>: cela signifie qu’une simple régression linéaire de <span class="math inline">\(\boldsymbol{e}\)</span> avec n’importe laquelle de ces covariables donne une ordonnée à l’origine et une pente toutes deux nulles. Ainsi, les modèles résiduels dus à des interactions oubliées, à des termes non linéaires, etc. pourraient être détectés à partir de diagrammes de paires de résidus ordinaires en fonction des variables explicatives.</p>
<p>Bien que les résidus studentisés externes <span class="math inline">\(r_i\)</span> ne soient pas orthogonaux, ils ne sont pas très différents quand <span class="math inline">\(n\)</span> est grand par rapport à <span class="math inline">\(p\)</span>. On peut utiliser les résidus <span class="math inline">\(\boldsymbol{r}\)</span> pour vérifier l’égalité de la variance et les hypothèses de distribution (par exemple, à l’aide d’un diagramme quantile-quantile).</p>
<div id="def-r2" class="theorem definition">
<p><span class="theorem-title"><strong>Définition 4.6 (Coefficient de détermination)</strong></span> Lorsque nous spécifions un modèle, les aléas <span class="math inline">\(\boldsymbol{\varepsilon}\)</span> servent à tenir compte du fait qu’aucune relation linéaire exacte ne caractérise les données Une fois que nous avons ajusté un modèle, nous estimons la variance <span class="math inline">\(\sigma^2\)</span>; on peut alors se demander quelle part de la variance totale de l’échantillon est expliquée par le modèle.</p>
<p>La somme totale des carrés, définie comme la somme des carrés des résidus du modèle à ordonnée à l’origine uniquement, sert de comparaison — le modèle le plus simple que nous puissions trouver impliquerait chaque observation par la moyenne de l’échantillon de la réponse, ce qui donne la variance expliquée <span class="math inline">\(\mathsf{SC}_c = \sum_{i=1}^n (y_i - \overline{y})^2\)</span>. Nous pouvons ensuite comparer la variance des données originales avec celle des résidus du modèle avec la matrice de covariables <span class="math inline">\(\mathbf{X}\)</span>, définie comme <span class="math inline">\(\mathsf{SC}_e =\sum_{i=1}^n e_i^2\)</span> avec <span class="math inline">\(e_i = y_i - \widehat{\beta}_0 - \sum_{j=1}^p \widehat{\beta}_jX_j\)</span>. Nous définissons le coefficient de détermination <span class="math inline">\(R^2\)</span>, comme suit <span class="math display">\[\begin{align*}
R^2 &amp;=1- \frac{\mathsf{SC}_e}{\mathsf{SC}_c} = \frac{\sum_{i=1}^n (y_i - \overline{y})^2- \sum_{i=1}^n e_i^2}{\sum_{i=1}^n (y_i - \overline{y})^2}.
\end{align*}\]</span> Une autre décomposition montre que <span class="math inline">\(R^2 = \mathsf{cor}^2(\boldsymbol{y}, \widehat{\boldsymbol{y}})\)</span>, c’est-à-dire que le coefficient de détermination peut être interprété comme le carré de la corrélation linéaire de Pearson (<a href="introduction.html#def-correlation-Pearson" class="quarto-xref">Définition&nbsp;<span>1.3</span></a>) entre la réponse <span class="math inline">\(\boldsymbol{y}\)</span> et les valeurs ajustées <span class="math inline">\(\widehat{\boldsymbol{y}}\)</span>.</p>
</div>
<p>Il est important de noter que le <span class="math inline">\(R^2\)</span> n’est pas un critère de qualité de l’ajustement, tout comme la log-vraisemblance. En effet, certain phénomènes sont intrinsèquement complexes et même un bon modèle ne parviendra pas à rendre compte d’une grande partie de la variabilité de la réponse. Ce n’est pas non plus parce que le <span class="math inline">\(R^2\)</span> est faible que <span class="math inline">\(Y\)</span> et et les variables explicatives <span class="math inline">\(X_j\)</span> sont indépendantes, comme l’illustre la <a href="introduction.html#fig-datasaurus" class="quarto-xref">Figure&nbsp;<span>1.2</span></a>.</p>
<p>En outre, il est possible de gonfler la valeur de <span class="math inline">\(R^2\)</span> en incluant davantage de variables explicatives et en rendant le modèle plus complexe, ce qui améliore la vraisemblance et <span class="math inline">\(R^2\)</span>. En effet, le coefficient n’est pas décroissant dans la dimension de <span class="math inline">\(\mathbf{X}\)</span>, de sorte qu’un modèle comportant <span class="math inline">\(p+1\)</span> de covariables aura nécessairement des valeurs de <span class="math inline">\(R^2\)</span> plus élevées que si l’on n’incluait que <span class="math inline">\(p\)</span> de ces variables explicatives. Pour comparer les modèles, il est préférable d’utiliser des critères d’information ou de s’appuyer sur la performance prédictive si tel est l’objectif de la régression. Enfin, un modèle avec un <span class="math inline">\(R^2\)</span> élevé peut impliquer une corrélation élevée, mais <a href="http://www.tylervigen.com/spurious-correlations">la relation peut être fallacieuse</a> : la régression linéaire ne produit pas de modèles causaux!</p>
</section>
<section id="colinéarité" class="level3" data-number="4.7.2">
<h3 data-number="4.7.2" class="anchored" data-anchor-id="colinéarité"><span class="header-section-number">4.7.2</span> Colinéarité</h3>
<p>Le postulat de linéarité peut être interprétée au sens large comme signifiant que toutes les covariables pertinentes ont été incluses et que leur effet est correctement spécifié dans l’équation de la moyenne. L’ajout de covariables superflues à un modèle a un impact limité: si la corrélation (partielle) entre un vecteur colonne <span class="math inline">\(\boldsymbol{X}_k\)</span> et la variable réponse <span class="math inline">\(\boldsymbol{Y}\)</span> est nulle, alors <span class="math inline">\(\beta_k=0\)</span> et le coefficient estimé <span class="math inline">\(\widehat{\beta}_k \approx 0\)</span> parce que les estimateurs des moindres carrés sont sans biais. Si nous incluons de nombreuses variables inutiles, disons <span class="math inline">\(k\)</span>, le manque de parcimonie peut toutefois rendre l’interprétation plus difficile. Le prix à payer pour inclure <span class="math inline">\(k\)</span> de variables explicatives supplémentaires est une augmentation de la variance des estimateurs <span class="math inline">\(\widehat{\boldsymbol{\beta}}\)</span>.</p>
<p>Dans les études observationnelles, il est néanmoins préférable d’inclure davantage de variables que d’oublier des variables explicatives clés: si nous omettons une variable prédictive importante, son effet peut être capturé par d’autres <strong>variables confondantes</strong>, qui sont corréléws avec à la fois les variables omises et la réponse et qui causent les deux. Par exemple, le modèle linéaire simple (ou le test <span class="math inline">\(t\)</span> à deux échantillons) pour le salaire en fonction du sexe pour les données de salaires dans un collège n’est pas valide parce que l’échelon académique est un facteur confondant pour les différences selon le sexe. Comme il y a plus d’hommes que de femmes professeurs titulaires, la différence de salaire moyen entre les hommes et les femmes est plus élevée de l’échantillon qu’elle ne l’est réellement. Une façon d’en tenir compte est d’inclure des variables de contrôle (telles que l’échelon), dont l’effet ne nous intéresse pas forcément, mais qui sont nécessaires pour que le modèle soit adéquat. Nous aurions également pu utiliser la stratification, c’est-à-dire tester la discrimination salariale au sein de chaque échelon académique. C’est la raison pour laquelle des variables sociodémographiques (sexe, âge, niveau d’éducation, etc.) sont collectées dans le cadre des études.</p>
<p>Un modèle linéaire n’est pas un [modèle causal] (https://xkcd.com/552/): il ne fait que capturer la corrélation linéaire entre une variable explicative et la réponse. Lorsqu’il y a plus d’une variable explicative, l’effet de <span class="math inline">\(X_j\)</span> est fonction de ce qui n’a pas déjà été expliqué par les autres variables explicatives, disons <span class="math inline">\(\boldsymbol{X}_{-j}\)</span>. Ainsi, si nous ne parvenons pas à rejeter <span class="math inline">\(\mathscr{H}_0:\beta_j=0\)</span> en faveur de l’alternative <span class="math inline">\(\mathscr{H}_1 : \beta_j \neq 0\)</span>, nous pouvons seulement dire qu’il n’y a pas d’association <em>linéaire</em> significative entre <span class="math inline">\(X_j\)</span> et <span class="math inline">\(Y\)</span> une fois que l’effet des autres variables incluses dans le modèle a été pris en compte. Il existe donc deux scénarios: soit la réponse n’est pas corrélée à <span class="math inline">\(X_j\)</span> (cas inintéressant, mais facile à repérer en traçant les deux ou en calculant la corrélation linéaire), soit il existe une forte corrélation entre <span class="math inline">\(X_j\)</span> et à la fois la réponse <span class="math inline">\(Y\)</span> et (certaines) des autres variables explicatives <span class="math inline">\(X_1, \ldots, X_p\)</span>. Ce problème est appelé (multi)<strong>colinéarité</strong>.</p>
<p>L’un des inconvénients de la colinéarité est la diminution de la précision des estimateurs de paramètres. En présence de variables explicatives colinéaires, de nombreuses combinaisons linéaires des covariables représentent presque aussi bien la réponse. En raison du manque (ou presque) d’identifiabilité, les coefficients estimés deviennent numériquement instables, ce qui entraîne une augmentation des erreurs-type des paramètres. Les valeurs prédites ou ajustées ne sont pas affectées. En général, les coefficients de régression peuvent changer radicalement lorsque de nouvelles observations sont incluses dans le modèle, ou lorsque nous incluons ou supprimons des variables explicatives. Les coefficients <span class="math inline">\(\beta\)</span> individuels peuvent ne pas être statistiquement significatifs, mais le test <span class="math inline">\(F\)</span> global indiquera que certaines covariables sont pertinentes pour expliquer la réponse. Toutefois, ce serait également le cas s’il y avait des prédicteurs avec un signal fort, de sorte que ni l’un ni l’autre n’est susceptible d’être utile pour détecter les problèmes.</p>
<p>Le <strong>diagramme de régression partielle</strong> montre à l’aide d’un nuage de points la relation entre la réponse <span class="math inline">\(Y\)</span> et une variable explicative <span class="math inline">\(X_j\)</span> après la prise en compte de l’effet linéaire des autres variables. Il est obtenu en faisant une régressant à tour de rôle <span class="math inline">\(X_j\)</span> et <span class="math inline">\(Y\)</span> sur les autres colonnes de la matrice du modèle, et en calculant les résidus. Le théorème de Frisch–Waugh–Lovell montre que la pente <span class="math inline">\(\widehat{\beta}_j\)</span> de la régression linéaire simple entre les résidus <span class="math inline">\(\boldsymbol{e}_{Y}^{-j}\)</span> et <span class="math inline">\(\boldsymbol{e}_{X_j}^{-j}\)</span> est la même que celle du modèle complet. Si on ne voit pas de relation linéaire dans le graphique (pente presque nulle) et que la corrélation entre <span class="math inline">\(X_j\)</span> et <span class="math inline">\(Y\)</span> était très forte, cela est typiquement indicateur de colinéarité.</p>
<p>Une idée similaire peut être utilisée pour voir quelle part de <span class="math inline">\(X_j\)</span> est déjà expliquée par les autres variables. Nous définissons le facteur <strong>facteur d’inflation de la variance</strong> comme <span class="math inline">\(\mathsf{FIV}(j)=(1-R^2(j))^{-1}\)</span>, où <span class="math inline">\(R^2(j)\)</span> est le coefficient de détermination du modèle obtenu en régressant <span class="math inline">\(X_j\)</span> sur toutes les autres variables explicatives, c’est-à-dire, <span class="math display">\[\begin{align*}
X_j = \beta^{\star}_0 + \beta^{\star}_1 X_1 + \cdots + \beta^{\star}_{j-1} X_{j-1} + \beta^{\star}_{j+1} X_{j+1} + \cdots + \beta^{\star}_pX_p + \varepsilon^{\star}
\end{align*}\]</span> Par définition, <span class="math inline">\(R^2(j)\)</span> donne la proportion de la variance de <span class="math inline">\(X_j\)</span> expliquée par les autres variables explicatives. Un facteur d’inflation de la variance élevé est un indicateur de colinéarité: typiquement les valeurs avec une corrélation de plus de 90%, ou <span class="math inline">\(\mathsf{FIV}&gt;10\)</span>, nécessitent une attention particulière. Les valeurs dans les centaines ou les milliers représentent des cas pathologiques. Pour les variables catégorielles, la définition du facteur d’inflation de la variance donnerait normalement une valeur différente pour chaque niveau; une alternative est le facteur d’inflation de la variance généralisée <span class="citation" data-cites="Fox:1992">(<a href="references.html#ref-Fox:1992" role="doc-biblioref">Fox et Monette 1992</a>)</span>.</p>
<p>Que doit-on faire s’il y a de la colinéarité ? Si l’objectif de l’étude est de développer un modèle prédictif et que nous ne sommes pas intéressés par les paramètres eux-mêmes, alors nous n’avons rien à faire. La colinéarité n’est pas un problème pour le modèle global: c’est seulement un problème pour les effets individuels des variables. Leur effet conjoint est toujours présent dans le modèle, quelle que soit la manière dont les effets individuels sont combinés.</p>
<p>Si nous nous intéressons aux estimations des paramètres individuels, par exemple pour voir comment (et dans quelle mesure) les variables prédictives expliquent le comportement de <span class="math inline">\(Y\)</span>, les choses se compliquent. La colinéarité n’affecte que les variables qui sont fortement corrélées les unes aux autres, de sorte que nous ne nous préoccupons que si elle affecte une ou plusieurs des variables qui nous intéressent. Il n’y a malheureusement pas de bonne solution à ce problème. On pourrait</p>
<ul>
<li>essayer d’obtenir plus de données, afin de réduire les effets de colinéarité apparaissant dans des échantillons spécifiques ou dus à la petite taille de l’échantillon.</li>
<li>créer un score composite en combinant d’une manière ou d’une autre les variables présentant une colinéarité.</li>
<li>supprimer une ou plusieurs des variables colinéaires. Vous devez en revanche faire attention à ne pas vous retrouver avec un modèle mal spécifié.</li>
<li>utiliser la régression pénalisée si <span class="math inline">\(\mathbf{X}^\top\mathbf{X}\)</span> n’est (presque) pas inversible, cela peut restaurer l’unicité de la solution. Les pénalités introduisent un biais, mais peuvent réduire la variance des estimateurs <span class="math inline">\(\boldsymbol{\beta}\)</span>. Les choix populaires incluent la régression en crête (avec une pénalité de <span class="math inline">\(l_2\)</span>), lasso (pénalité de <span class="math inline">\(l_1\)</span>), mais ceux-ci requièrent un ajustement pour l’inférence post-sélection</li>
</ul>
<p>Quelle que soit la méthode utilisée, il est important de comprendre qu’il peut être très difficile (et parfois impossible) d’isoler l’effet individuel d’une variable explicative fortement corrélée avec d’autres.</p>
<div id="exm-collegedatcollineaire" class="theorem example">
<p><span class="theorem-title"><strong>Exemple 4.22 (Colinéarité des données de <code>college</code>)</strong></span> On considère l’analyse des données sur l’inéquité salariale dans un college, en incluant cette fois <code>annees</code>, le nombre d’années depuis l’obtiention du doctorat. On peut penser que, à moins qu’un(e) professeur(e) ait entamé sa carrière dans une autre institution d’enseignement, le nombre d’années de service sera fortement lié à ces derniers. De fait, la corrélation linéaire entre <code>service</code> et <code>annees</code> est 0.91. Cette corrélation n’est pas problématique puisque le <span class="math inline">\(\mathsf{FIV}\)</span> pour <span class="math inline">\(\texttt{sexe}\)</span> (voir le <a href="#tbl-vif-college" class="quarto-xref">Tableau&nbsp;<span>4.10</span></a>) n’est pas élevé et l’inclusion sert à éviter les variables confondantes et réduire l’incertitude.</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div id="fig-addedvariableplots" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-addedvariableplots-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="regression-lineaire_files/figure-html/fig-addedvariableplots-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:100.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-addedvariableplots-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;4.12: Diagramme de régression partielle pour le nombre d’années de service et le nombre d’années depuis le doctorat.
</figcaption>
</figure>
</div>
</div>
</div>
<div class="cell" data-layout-align="center">
<div id="tbl-vif-college" class="cell quarto-float quarto-figure quarto-figure-center anchored" data-layout-align="center">
<figure class="quarto-float quarto-float-tbl figure">
<figcaption class="quarto-float-caption-top quarto-float-caption quarto-float-tbl" id="tbl-vif-college-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Tableau&nbsp;4.10: Facteur d’inflation de la variance généralisés pour les données <code>college</code>.
</figcaption>
<div aria-describedby="tbl-vif-college-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<div class="cell-output-display">
<table class="do-not-create-environment cell caption-top table table-sm table-striped small">
<thead>
<tr class="header">
<th style="text-align: right;">echelon</th>
<th style="text-align: right;">domaine</th>
<th style="text-align: right;">sexe</th>
<th style="text-align: right;">service</th>
<th style="text-align: right;">annees</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: right;">2.01</td>
<td style="text-align: right;">1.06</td>
<td style="text-align: right;">1.03</td>
<td style="text-align: right;">5.92</td>
<td style="text-align: right;">7.52</td>
</tr>
</tbody>
</table>
</div>
</div>
</figure>
</div>
</div>
</div>
</section>
<section id="levier-et-aberrances" class="level3" data-number="4.7.3">
<h3 data-number="4.7.3" class="anchored" data-anchor-id="levier-et-aberrances"><span class="header-section-number">4.7.3</span> Levier et aberrances</h3>
<p>L’effet de levier <span class="math inline">\(h_i\)</span> de l’observation <span class="math inline">\(i\)</span> mesure son impact sur l’ajustement par les moindres carrés, puisque nous pouvons écrire <span class="math inline">\(h_i = \partial \widehat{y}_i/\partial y_i\)</span>. Les valeurs de l’effet de levier nous indiquent l’impact de chaque point sur l’ajustement : elles sont strictement positives, avec une borne inférieure de <span class="math inline">\(1/n\)</span> et une borne supérieure de <span class="math inline">\(1\)</span>. La somme des leviers est <span class="math inline">\(\sum_{i=1}^n h_i=p+1\)</span> : dans un bon modèle, chaque point a approximativement la même contribution, avec un poids moyen de <span class="math inline">\((p+1)/n\)</span>.</p>
<p>Les points à fort effet de levier sont ceux qui présentent des combinaisons inhabituelles de variables explicatives. Une observation <strong>influente</strong> (<span class="math inline">\(h_i\approx 1\)</span>) tire l’hyperplan ajusté vers elle-même de sorte que <span class="math inline">\(\hat{y}_i \approx y_i\)</span>. En règle générale, les points avec <span class="math inline">\(h_i&gt; 2(p+1)/n\)</span> doivent être examinés de près.</p>
<p>Il est important de faire la distinction entre les observations <strong>influentes</strong> (qui ont une valeur <span class="math inline">\(\mathbf{x}\)</span> inhabituelle, c’est-à-dire éloignée de la moyenne générale) et les <strong>aberrances</strong> (valeur inhabituelle de la réponse <span class="math inline">\(y\)</span>). Si une observation est à la fois une valeur aberrante et a un effet de levier élevé, elle est problématique.</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div id="fig-outliers" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-outliers-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="regression-lineaire_files/figure-html/fig-outliers-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:85.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-outliers-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;4.13: Valeur aberrante (gauche) et observation influente (droite, valeur de <span class="math inline">\(x\)</span> la plus à droite).
</figcaption>
</figure>
</div>
</div>
</div>
<p>Si les observations influentes peuvent être détectées en inspectant le levier de chaque observation, les valeurs aberrantes sont plus difficiles à diagnostiquer. Une valeur aberrante se distingue du reste des observations, soit parce qu’elle a une valeur de réponse habituelle, soit parce qu’elle se situe loin de la surface de régression. En gros, une valeur aberrante est une valeur inhabituelle de <span class="math inline">\(Y\)</span> pour une combinaison donnée de <span class="math inline">\(\mathbf{X}\)</span> qui se distingue des autres. Les valeurs aberrantes peuvent être détectées au cours de l’analyse exploratoire des données ou dans les diagrammes de résidus (valeurs élevées de <span class="math inline">\(|e_i|\)</span> dans les diagrammes des valeurs ajustées par rapport aux valeurs résiduelles) ou dans les diagrammes de régression partielle. On pourrait éventuellement tester si un résidu studentisé externe est une valeur aberrante (en tenant compte du fait que nous ne prendrions en considération que les valeurs les plus élevées). On peut également considérer la distance de Cook, <span class="math inline">\(C_j\)</span>, une statistique donnant la distance à l’échelle entre les valeurs ajustées <span class="math inline">\(\hat{\boldsymbol{y}}\)</span> et les valeurs ajustées pour le modèle avec toutes les observations sauf la <span class="math inline">\(j\)</span>e, <span class="math inline">\(\hat{\boldsymbol{y}}^{(-j)}\)</span>, <span class="math display">\[\begin{align*}
C_j = \frac{1}{(p+1)S^2} \sum_{i=1}^n \left\{\hat{y}_i - \hat{y}_{i}^{(-j)}\right\}^2
\end{align*}\]</span> Des valeurs élevées de <span class="math inline">\(C_j\)</span> indiquent que son résidu ordinaire <span class="math inline">\(e_j\)</span> est important par rapport aux autres observations ou que son effet de levier <span class="math inline">\(h_j\)</span> est élevé. Une règle empirique consiste à considérer les points pour lesquels <span class="math inline">\(C_j &gt; 4/(n-p-1)\)</span>. En pratique, si deux observations sont aberrantes et se situent dans la même région, leur distance de Cook sera réduite de moitié.</p>
<p>Les observations aberrantes et influentes ne doivent pas être négligées parce qu’elles ne sont pas conformes au modèle, mais doivent faire l’objet d’un examen plus approfondi. Elles peuvent motiver une modélisation plus poussée des caractéristiques non prises en compte. Il est également utile de vérifier les erreurs d’enregistrement dans les données (qui peuvent être écartées sans risque). Dans les très grands échantillons, l’impact d’une seule valeur aberrante est, espérons-le, limité. Les transformations de la réponse peuvent contribuer à réduire le caractère aberrant. Sinon, il est possible d’utiliser d’autres fonctions objectives que le critère des moindres carrés ordinaires (telles que celles employées dans la régression robuste); celles-ci pondèrent les observations extrêmes, au détriment de l’efficacité.</p>
</section>
</section>
<section id="postulats-du-modèle-et-diagnostics" class="level2" data-number="4.8">
<h2 data-number="4.8" class="anchored" data-anchor-id="postulats-du-modèle-et-diagnostics"><span class="header-section-number">4.8</span> Postulats du modèle et diagnostics</h2>
<p>Cette section passe en revue les postulats du modèle énoncés pour permettre l’inférence statistique à l’aide du modèle linéaire et des différents résidus qui servent d’éléments de base pour les diagnostics graphiques. Nous étudions les conséquences de la violation de ces postulats et décrivons des stratégies d’atténuation potentielles, dont beaucoup sont abordées dans d’autres chapitres.</p>
<p>Jusqu’à présent, nous avons ajusté des modèles et testé la significativité des coefficients sans valider notre modèle. La fiabilité des valeurs <span class="math inline">\(p\)</span> et des intervalles de confiance dépend de la validité (approximative) des postulats du modèle, qui découlent toutes de l’hypothèse sur les alés, supposée indépendantes et identiquement distribuées avec <span class="math inline">\(\varepsilon_i \stackrel{\cdot}{\sim} \mathsf{normale}(0, \sigma^2)\)</span>. Cette description mathématique compacte peut être décomposée en quatre postulats principaux: Il y a quatre postulats principaux du modèle linéaire de la forme <span class="math display">\[Y_i \mid \mathbf{x}_i \sim \mathsf{normale}(\mathbf{x}_i\boldsymbol{\beta}, \sigma^2)\]</span></p>
<ul>
<li>linéarité et additivité: la moyenne de <span class="math inline">\(Y_i \mid \mathbf{x}_i\)</span> est <span class="math inline">\(\beta_0 + \beta_1x_{i1} + \cdots + \beta_p x_{ip}\)</span>,</li>
<li>homoscédasticité: la variance des observations <span class="math inline">\(\sigma^2\)</span> est constante,</li>
<li>indépendence des observations (conditionnellement aux covariables),</li>
<li>normalité.</li>
</ul>
<p>Lorsque nous effectuons un test d’hypothèse et que nous ne rejetons pas l’hypothèse nulle, c’est soit parce qu’elle est vraie, soit par manque de preuves. Il en va de même pour la vérification de la validité des postulats du modèle: le raisonnement scientifique veut que nous ne puissions pas savoir avec certitude si ces derniers sont vrais. Notre stratégie consiste donc à utiliser les implications des hypothèses du modèle linéaire pour créer des outils de diagnostics graphiques, afin de s’assurer qu’il n’y a pas de violation flagrante des postulats. Toutefois, il est important de se garder de surinterpréter les diagnostics graphiques: l’oeil humain est très doué pour trouver des schémas inexistants.</p>
<section id="postulat-de-linéarité-et-dadditivité" class="level3" data-number="4.8.1">
<h3 data-number="4.8.1" class="anchored" data-anchor-id="postulat-de-linéarité-et-dadditivité"><span class="header-section-number">4.8.1</span> Postulat de linéarité et d’additivité</h3>
<p>Le postulat de linéarité signifie que le modèle moyen est correctement spécifié, que toutes les covariables pertinentes ont été incluses et que leur effet est correctement spécifié (y compris les effets non linéaires et les interactions). L’additivité sous-tend que le modèle peut être exprimé comme la somme de moyenne plus aléa. Pour vérifier que la surface de réponse du modèle linéaire est adéquate, nous dessinons un nuage de points de <span class="math inline">\(e_i\)</span> en fonction de <span class="math inline">\(\widehat{y}_i\)</span> ou <span class="math inline">\(x_{ij}\)</span> (pour <span class="math inline">\(j=1, \ldots, p\)</span>). Étant donné que la corrélation linéaire entre <span class="math inline">\(\boldsymbol{e}\)</span> et <span class="math inline">\(\widehat{\boldsymbol{y}}\)</span> (ou <span class="math inline">\(\boldsymbol{e}\)</span> et <span class="math inline">\(\mathbf{X}_j\)</span>) est nulle par construction, les modèles (par exemple, tendance quadratique, cycles, points de changement) sont indicatifs d’une mauvaise spécification du modèle pour la moyenne. Il est possible d’ajouter une courbe de lissage de tels effets. La <a href="#fig-regdiaglin" class="quarto-xref">Figure&nbsp;<span>4.14</span></a> montre trois diagrammes de résidus. On cherche une tendance locale dans l’axe des ordonnées <span class="math inline">\(y\)</span>, pas sur l’axe des abcisses.</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div id="fig-regdiaglin" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-regdiaglin-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="regression-lineaire_files/figure-html/fig-regdiaglin-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:85.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-regdiaglin-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;4.14: Diagrammes des résidus par rapport aux valeurs ajustées. Les deux premiers diagrammes ne montrent aucun écart par rapport à la linéarité (moyenne locale nulle). Le troisième diagramme montre une tendance quadratique évidente, ce qui suggère que le modèle moyen est mal spécifié. Notez que la distribution de la valeur ajustée n’est pas nécessairement uniforme, comme dans le deuxième panneau.
</figcaption>
</figure>
</div>
</div>
</div>
<p>S’il existe une structure résiduelle dans les graphiques des résidus ordinaires en fonction (a) des valeurs ajustées ou (b) des variables explicatives, un modèle plus complexe peut être ajusté, y compris un contenant des interactions, des fonctions non linéaires, etc. Si l’effet d’une variable explicative est clairement non linéaire et compliqué, des termes de lissage peuvent être ajoutés (nous ne couvrirons pas les modèles additifs généralisés dans ce cours).</p>
<p>La représentation graphique des résidus en fonction des variables explicatives omises peut également servir à vérifier que tout le pouvoir explicatif de la covariable omise est déjà expliqué par les colonnes de <span class="math inline">\(\mathbf{X}\)</span>.</p>
<p>Si une variable importante a été omise et n’est pas disponible dans l’ensemble de données, l’effet de cette variable est capturé à la fois par les erreurs (la partie orthogonale à la matrice du modèle <span class="math inline">\(\mathbf{X}\)</span>, c’est-à-dire inexpliquée par les covariables incluses dans le modèle) et la partie restante est capturée par d’autres variables explicatives du modèle qui sont corrélées avec la variable omise. Ces variables peuvent agir comme des facteurs de confusion. Dans les deux cas, il n’y a pas grand-chose à faire si les données relatives à la variable omise ne sont pas disponibles, mais des connaissances spécifiques au sujet peuvent aider à donner un sens aux résultats.</p>
</section>
<section id="postulat-dhomoscédasticité" class="level3" data-number="4.8.2">
<h3 data-number="4.8.2" class="anchored" data-anchor-id="postulat-dhomoscédasticité"><span class="header-section-number">4.8.2</span> Postulat d’homoscédasticité</h3>
<p>Si la variance des aléas est la même pour toutes les observations (homoscédasticité), celle des observations <span class="math inline">\(Y\)</span> est également constante. Les scénarios les plus courants d’hétéroscédasticité sont des augmentations de la variance avec la réponse, ou bien une variance qui dépend de variables explicatives <span class="math inline">\(\mathbf{X}\)</span>, notamment des variables catégorielles.</p>
<p>Si les aléas (ou variables réponses) sont hétéroscédastiques (variance non constante), les effets estimés des variables (les paramètres <span class="math inline">\(\beta\)</span>) sont toujours valables dans le sens où l’estimateur des moindres carrés ordinaires <span class="math inline">\(\widehat{\boldsymbol{\beta}}\)</span> est sans biais. Cependant, les erreurs types estimées des <span class="math inline">\(\widehat{\beta}\)</span> ne sont plus fiables et, par conséquent, les intervalles de confiance et les tests d’hypothèse pour les paramètres du modèle seront incorrects. En effet, si la variance des erreurs diffère d’une observation à l’autre, nous allons estimer une moyenne des différents termes de variance. Les erreurs types de chaque terme sont incorrectes (trop petites ou trop grandes) et les conclusions des tests (valeurs <span class="math inline">\(p\)</span>) seront erronées car les formules des statistiques des tests <span class="math inline">\(t\)</span> et <span class="math inline">\(F\)</span> incluent des estimations de <span class="math inline">\(hat{\sigma}^2\)</span>.</p>
<p>L’examen de nuages de points des résidus studentisés externes en fonction des régresseurs (ou des valeurs ajustées), appelé diagrammes de niveau et de dispersion, est instructif — par exemple, nous voyons souvent un modèle en entonnoir lorsqu’il y a une augmentation de la variance dans le tracé des résidus studentisés externes en fonction de la valeur ajustée, ou encore dans les boîtes à moustache pour une variable catégorielle comme dans la <a href="#fig-diagfitvalhomosce" class="quarto-xref">Figure&nbsp;<span>4.15</span></a>. Cependant, si nous voulons ajuster un lissage local pour observer les tendances, il est préférable de tracer la valeur absolue des résidus <span class="math inline">\(r\)</span> en fonction des régresseurs ou du nombre d’observations.</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div id="fig-diagfitvalhomosce" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-diagfitvalhomosce-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="regression-lineaire_files/figure-html/fig-diagfitvalhomosce-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:85.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-diagfitvalhomosce-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;4.15: Diagrammes des résidus studentisés externes en fonction des valeurs ajustées (gauche) et d’une variable catégorielle (droite).
</figcaption>
</figure>
</div>
</div>
</div>
<p>Une extension évidente du modèle linéaire consiste à permettre à la variance de varier en fonction des variables explicatives, généralement des covariables catégorielles. Cela est facile à faire en modifiant la vraisemblance et nous couvrirons cette approche plus en détail.</p>
<p>Nous pouvons effectuer des tests d’hypothèse pour l’hypothèse d’homogénéité (égalité) de la variance. Les tests les plus couramment utilisés sont le test de Bartlett, un test du rapport de vraisemblance sous l’hypothèse que les données sont tirées d’une loi normale, avec une correction de Bartlett pour améliorer l’approximation <span class="math inline">\(\chi^2\)</span> de la distribution nulle. Ce test est cependant sensible aux écarts à la normalité, et tend à rejeter même quand la variance est constante. Le deuxième test le plus répandu est le test de Levene (une alternative plus robuste, moins sensible aux valeurs aberrantes). Pour les deux tests, la distribution nulle est <span class="math inline">\(\mathscr{H}_0 : \sigma^2_1 = \cdots = \sigma^2_K\)</span> contre l’alternative qu’au moins deux diffèrent. La statistique du test de Bartlett a une distribution nulle <span class="math inline">\(\chi^2\)</span> avec <span class="math inline">\(K-1\)</span> degrés de liberté, alors que le test de Levene a une distribution <span class="math inline">\(F\)</span> avec (<span class="math inline">\(K-1\)</span>, <span class="math inline">\(n-K\)</span>) degrés de liberté: il est équivalent au calcul de la statistique <span class="math inline">\(F\)</span> de l’ANOVA à un facteur avec la valeur absolue des résidus centrés, <span class="math inline">\(|y_{ik} - \widehat{\mu}_k|\)</span>, comme observations. Un test populaire plus général est le test de <span class="citation" data-cites="Breusch.Pagan:1979">Breusch et Pagan (<a href="references.html#ref-Breusch.Pagan:1979" role="doc-biblioref">1979</a>)</span>, qui est un test du score pour un modèle de régression linéaire pour le carré des résidus ordinaires <span class="math inline">\(e_i^2\)</span>. Comme les autres tests de score, ce dernier ne nécessite pas d’ajustement du modèle avec des variances inégales, mais on doit choisir quelles variables explicatives mettre dans le modèle.</p>
<div id="exm-heterogeneity" class="theorem example">
<p><span class="theorem-title"><strong>Exemple 4.23 (Violation du postulat d’homoscédasticité)</strong></span> &nbsp;</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div id="fig-simuWelchnull" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-simuWelchnull-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="regression-lineaire_files/figure-html/fig-simuWelchnull-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:85.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-simuWelchnull-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;4.16: Histogramme de la loi nulle des valeurs-<span class="math inline">\(p\)</span> obtenues par simulation à l’aide du test-<span class="math inline">\(t\)</span> à deux échantillons (à gauche) et du test-<span class="math inline">\(t\)</span> de Welch (à droite), sur la base de 10 000 simulations. Chaque échantillon simulé se compose de 50 observations provenant d’une distribution <span class="math inline">\(\mathsf{normale}(0, 1)\)</span> et de 10 observations provenant d’une distribution <span class="math inline">\(\mathsf{normale}(0, 9)\)</span>. La loi uniforme sous <span class="math inline">\(\mathscr{H}_0\)</span> aurait 5 % dans chacune des 20 cases utilisées pour l’affichage.
</figcaption>
</figure>
</div>
</div>
</div>
<p>Qu’arrive-t-il si la variance est inégale? Considérons un problème simple de comparaison de moyennes entre deux groupes, qui revient à effectuer un <span class="math inline">\(t\)</span>-test pour deux échantillons. Nous avons simulé 50 observations à partir d’une loi <span class="math inline">\(\mathsf{normale}(0, 1)\)</span> et 10 observations à partir d’une loi <span class="math inline">\(\mathsf{normale}(0, 9)\)</span>, en comparant la distribution des valeurs <span class="math inline">\(p\)</span> pour les statistiques du test de Welch et du test <span class="math inline">\(t\)</span>. En revanche, nous rejetons 0% du temps avec le test-<span class="math inline">\(t\)</span> : il s’agit d’une grande proportion de prémisses erronées Bien que la distorsion du niveau du test ne soit pas toujours aussi frappante, l’hétérogénéité doit être prise en compte dans l’élaboration du modèle en exigeant des tailles d’échantillon suffisantes (lorsque les coûts le permettent) dans chaque groupe pour pouvoir estimer la variance de manière fiable dans chaque sous-groupe et à l’aide d’une statistique adéquate.</p>
</div>
<p>Souvent, une variance inégale se produit parce que le modèle n’est pas additif. Vous pouvez utiliser des transformations stabilisant la variance (par exemple, pour des effets multiplicatifs) afin de garantir une variance à peu près égale dans chaque groupe. Dans ce cas de figure, une transformation logarithmique (ou une transformation de Box–Cox) peut aider à stabiliser la variance, mais il faut que la réponse soit positive. Une autre option consiste à utiliser un modèle adapté au type de réponse que vous avez (y compris les données de décompte et les données binaires). Enfin, il peut être nécessaire de modéliser explicitement la variance dans des modèles plus complexes (y compris les mesures répétées) lorsqu’il y a un effet d’apprentissage au fil du temps et que la variabilité diminue en conséquence. Consultez un expert si nécessaire.</p>
<p>Les économistes utilisent fréquemment des estimateurs <strong>sandwich</strong> <span class="citation" data-cites="White:1980">(<a href="references.html#ref-White:1980" role="doc-biblioref">White 1980</a>)</span>, en remplaçant l’estimateur usuel de la matrice de covariance des <span class="math inline">\(\widehat{\boldsymbol{\beta}}\)</span>, d’ordinaire <span class="math inline">\(S^2(\mathbf{X}^\top\mathbf{X})^{-1}\)</span>, par un estimateur sandwich de la forme <span class="math display">\[\widehat{\mathsf{Va}}_{\mathsf{HCE}}(\boldsymbol{\widehat{\beta}}) = (\mathbf{X}^\top\mathbf{X})^{-1}\mathbf{X}^\top\boldsymbol{\Omega}\mathbf{X}(\mathbf{X}^\top\mathbf{X})^{-1}\]</span> avec <span class="math inline">\(\boldsymbol{\Omega}\)</span> une matrice diagonale. Les choix populaires pour des matrices convergente en cas d’hétéroscédasticité matrices <span class="citation" data-cites="McKinnon.White:1985">(<a href="references.html#ref-McKinnon.White:1985" role="doc-biblioref">MacKinnon et White 1985</a>)</span>, utilisent <span class="math inline">\(\mathrm{diag}(\boldsymbol{\Omega})_i = e_i^2/(1-h_{ii})^2\)</span>, dans le cas de la matrice <span class="math inline">\(\mathrm{HC}_3\)</span>.</p>
</section>
<section id="postulat-dindépendance" class="level3" data-number="4.8.3">
<h3 data-number="4.8.3" class="anchored" data-anchor-id="postulat-dindépendance"><span class="header-section-number">4.8.3</span> Postulat d’indépendance</h3>
<p>Habituellement, l’indépendance des observations découle directement du type d’échantillonnage utilisé — cette hypothèse est implicitement vraie si les observations représentent un <em>échantillon aléatoire</em> de la population. Ce n’est généralement pas le cas pour les données longitudinales, qui contiennent des mesures répétées des mêmes individus au fil du temps. De même, les séries temporelles ne sont pas constituées d’observations indépendantes. Si nous voulons inclure tous les points temporels dans l’analyse, nous devons tenir compte de l’éventuelle dépendance (corrélation) entre les observations.</p>
<p>Quel est l’impact de la dépendance entre les mesures? D’un point de vue heuristique, les mesures corrélées contiennent moins d’informations que les mesures indépendantes. Dans le cas le plus extrême, il n’y a pas d’information supplémentaire et les mesures sont identiques, mais le fait de les ajouter plusieurs fois gonfle indûment la la taille de l’échantillon. Si nous ignorons la corrélation, les erreurs-type estimées sont trop petites, car la taille effective de l’échantillon est inférieure au nombre d’observations. Cela enfle la statistique et conduit à des rejets plus fréquents des hypothèses nulles, par erreur.</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div id="fig-plotLevelIndep" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-plotLevelIndep-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="regression-lineaire_files/figure-html/fig-plotLevelIndep-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:85.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-plotLevelIndep-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;4.17: Taux de rejet de l’hypothèse nulle pour le test <span class="math inline">\(F\)</span> d’égalité des moyennes pour une ANOVA à une voie avec des données générées en groupes de cinq avec une moyenne et une variance constantes, à partir d’un modèle d’équicorrélation (les observations à l’intérieur d’un groupe sont corrélées, les observations entre les groupes sont indépendantes). Le niveau nominal du test est de 5%.
</figcaption>
</figure>
</div>
</div>
</div>
<p>Le manque d’indépendance peut également avoir des conséquences dramatiques sur l’inférence et conduire à de fausses conclusions: la <a href="#fig-plotLevelIndep" class="quarto-xref">Figure&nbsp;<span>4.17</span></a> montre un exemple avec des échantillons corrélés au sein d’un groupe (ou, de manière équivalente, des mesures répétées d’individus) avec cinq observations par groupe. L’axe des ordonnées montre la proportion de fois où l’hypothèse nulle est rejetée alors qu’elle ne devrait l’être en principe que 5% du temps. Ici, comme les données sont générées à partir du modèle nul (moyenne égale) avec une variance égale, l’inflation du nombre d’erreurs de type I est alarmante et l’inflation du niveau du test est substantielle même avec une corrélation très limitée entre les mesures.</p>
<p>La première source de dépendance est constituée par les données groupées, c’est-à-dire les mesures prises sur des sujets qui ne sont pas indépendants les uns des autres (famille, groupes, etc.) On distingue entre <strong>données longitudinales</strong>, qui sont des mesures répétées sont effectuées sur les mêmes sujets (quelques points temporels) et <strong>séries chronologiques</strong>, dont la longueur et la fréquence d’échantillonage est plus élevée. Les séries temporelles nécessitent des modèles spécifiques qui ne sont pas abordés dans ce cours. En raison de l’autocorrélation, les erreurs positives ont tendance à être suivies d’erreurs positives, etc. Nous pouvons tracer les résidus en fonction du temps et un nuage de points des résidus retardés <span class="math inline">\(e_i\)</span> par rapport à <span class="math inline">\(e_{i-1}\)</span> (<span class="math inline">\(i=2, \ldots, n\)</span>).</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div id="fig-timeresidplot" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-timeresidplot-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="regression-lineaire_files/figure-html/fig-timeresidplot-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:85.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-timeresidplot-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;4.18: Nuage de point de résidus versus les résidus décalés d’une observation: il n’y a aucune preuve d’indépendance dans le panneau de gauche, alors que le panneau de droite montre des résidus positivement corrélés.
</figcaption>
</figure>
</div>
</div>
</div>
<p>Toutefois, les diagrammes de résidus décalés ne montrent que la dépendance au premier décalage entre les observations. Pour les séries temporelles, nous pouvons utiliser un corrélogramme, c’est-à-dire un diagramme à bandes de la corrélation entre deux observations distantes de <span class="math inline">\(h\)</span> unités en fonction du décalage <span class="math inline">\(h\)</span>.<span class="citation" data-cites="Brockwell.Davis:2016">(<a href="references.html#ref-Brockwell.Davis:2016" role="doc-biblioref">Brockwell et Davis 2016</a>, Definition 1.4.4)</span>.</p>
<p>Pour <span class="math inline">\(y_1, \ldots, y_n\)</span> et des pas de décalages <span class="math inline">\(h=0, 1, \ldots\)</span>, l’autocorrélation au pas de temps <span class="math inline">\(h\)</span> est <span class="math display">\[\begin{align*}
r(h) = \frac{\gamma(h)}{\gamma(0)}, \qquad \gamma(h) = \frac{1}{n}\sum_{i=1}^{n-|h|} (y_i-\overline{y})(y_{i+h} - \overline{y})
\end{align*}\]</span></p>
<p>Si la série est corrélée, l’autocorrélation de l’échantillon se situera probablement en dehors des intervalles de confiance ponctuels, comme le montre la <a href="#fig-correlogram" class="quarto-xref">Figure&nbsp;<span>4.19</span></a>. La présence d’autocorrélation nécessite de modéliser la corrélation entre les observations de manière explicite à l’aide d’outils spécifiques issus de la littérature sur les séries temporelles. Nous examinerons toutefois les modèles <span class="math inline">\(\mathsf{AR}(1)\)</span> dans le cadre du chapitre sur les données longitudinales. Voir <a href="https://otexts.com/fpp2/regression-evaluation.html">Forecasting : Principles and Practice, section 5.3</a> pour plus de détails.</p>
<p>Lorsque les observations sont positivement corrélées, les erreurs-types estimées indiquées par le logiciel sont trop petites. Cela signifie que nous sommes trop confiants et que nous rejetterons l’hypothèse nulle plus souvent que nous ne le devrions si l’hypothèse nulle était vraie (erreur de type I gonflée, plus de faux positifs).</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div id="fig-correlogram" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-correlogram-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="regression-lineaire_files/figure-html/fig-correlogram-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:85.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-correlogram-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;4.19: Corrélogramme d’observations indépendantes (à gauche) et des résidus ordinaires du modèle log-linéaire ajusté aux données sur le traffic aérien (à droite). Alors que le modèle moyen de ce dernier est apparemment correctement spécifié, il existe une dépendance résiduelle entre les observations mensuelles et annuelles (décalage de <span class="math inline">\(h=12\)</span> mois). Les lignes traitillées en bleu indiquent un intervalle de confiance ponctuels approximatifs à 95 % pour un bruit blanc (observations non corrélées).
</figcaption>
</figure>
</div>
</div>
</div>
<p>Comment prendre en compte la dépendance entre observations? L’idée principale est de modéliser la corrélation et la variance, en partant du vecteur complet d’observations et en supposant que <span class="math display">\[\boldsymbol{Y} \mid \mathbf{X} \sim \mathsf{normale}_n(\mathbf{X}\boldsymbol{\beta}, \boldsymbol{\Sigma})\]</span> avec un modèle pour la matrice de variance de dimension <span class="math inline">\(n \times n\)</span>, disons <span class="math inline">\(\boldsymbol{\Sigma}\)</span>, qui sera paramétré en fonction de <span class="math inline">\(\boldsymbol{\psi}\)</span>.</p>
</section>
<section id="postulat-de-normalité" class="level3" data-number="4.8.4">
<h3 data-number="4.8.4" class="anchored" data-anchor-id="postulat-de-normalité"><span class="header-section-number">4.8.4</span> Postulat de normalité</h3>
<p>Le postulat de normalité des aléas est commode, mais pas strictement nécessaire dans la majorité des cas pour la validité des tests sur les coefficients ou les énoncés reliés à la moyenne prédite. Si les aléas suivent une loi normale, les estimateurs des moindres carrés et du maximum de vraisemblance de <span class="math inline">\(\boldsymbol{\beta}\)</span> coïncident. Les estimateurs du maximum de vraisemblance de <span class="math inline">\(\boldsymbol{\beta}\)</span> sont asymptotiquement normaux sous de faibles conditions sur la matrice du modèle et les <span class="math inline">\(t\)</span>-tests sont étonnamment robustes et ne sont pas affectés par un écart par rapport au postulat de normalité. Cela signifie que l’inférence est valable avec de grands échantillons, quelle que soit la distribution des erreurs/résidus (même si la loi nulle n’est pas exacte). L’inférence sera valable avec de grands échantillons même si les aléas ne sont pas normaux à cause du théorème de la limite centrale. Il est important de garder à l’esprit que, pour les variables explicatives catégorielles, la taille de l’échantillon dans chaque sous-groupe doit être suffisamment importante pour que le théorème de la limite centrale s’applique, puisque les coefficients représentent la moyenne du sous-groupe. En revanche, les résultats et tests qui capitalisent sur la loi des aléas (par exemple, les tests pour les aberrances basés sur le maximum des résidus studentisés, ou les intervalles de prédictions) seront probablement trompeurs.</p>
<p>Parfois, des transformations peuvent améliorer la normalité : si les données sont asymétriques à droite et que la variable réponse est strictement positive, un modèle log-linéaire peut être plus adéquat <a href="#sec-transfo" class="quarto-xref"><span>Section 4.8.5</span></a>. Ceci peut être évalué en regardant le diagramme quantile-quantile des résidus studentisés externes. Si la réponse <span class="math inline">\(Y\)</span> n’est pas continue (y compris les données binaires, proportionnelles ou de dénombrement), les modèles linéaires généralisés sont plus appropriés.</p>
<p>Si l’aléa <span class="math inline">\(\varepsilon_i \sim \mathsf{normale}(0, \sigma^2)\)</span>, alors les résidus studentisés externes devraient suivre une distribution de Student, avec <span class="math inline">\(r_i \sim \mathsf{Student}(n-p-2)\)</span> (identiquement distribués, mais non indépendants). Un diagramme quantile-quantile de Student peut donc être utilisé pour vérifier le postulat. Gardez à l’esprit que si le modèle de la moyenne ou de la variance n’est pas correctement spécifié, certains résidus peuvent incorporer les effets résiduels.</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div id="fig-qqplotresid" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-qqplotresid-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="regression-lineaire_files/figure-html/fig-qqplotresid-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:85.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-qqplotresid-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;4.20: Histogramme et estimation de densité par lissage de noyau (gauche) et diagramme quantile-quantile Student (droite). Le panneau de gauche montre la loi théorique Student (en bleu) pour comparaison. Le panneau de droite présente des intervalles de confiance ponctuels à 95% calculés à l’aide d’un autoamorçage paramétrique.
</figcaption>
</figure>
</div>
</div>
</div>
<p>Les graphiques quantile-quantile sont abordés dans la <a href="introduction.html#def-diagramme-qq" class="quarto-xref">Définition&nbsp;<span>1.14</span></a>, mais leur interprétation nécessite de la pratique. Par exemple, la <a href="#fig-qqplotsbad" class="quarto-xref">Figure&nbsp;<span>4.21</span></a> montre de nombreux scénarios courants qui peuvent être détectés à l’aide de diagrammes quantile-quantile. Les données discrètes sont responsables des motifs en escalier, les données asymétriques à droite ont des quantiles bas trop élevés et des quantiles hauts trop bas par rapport aux positions de tracé, les données à ailes lourdes ont des observations élevées de part et d’autre et les données bimodales conduisent à des sauts dans le tracé.</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div id="fig-qqplotsbad" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-qqplotsbad-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="regression-lineaire_files/figure-html/fig-qqplotsbad-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:85.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-qqplotsbad-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;4.21: Diagrammes quantiles-quantiles de données discrète (coin supérieur gauche), à ailes lourdes (coin supérieur droit), asymmétrique à droite (coin inférieur gauche) et bimodales (coin inférieur droit).
</figcaption>
</figure>
</div>
</div>
</div>
<div id="exm-diagplotcollege" class="theorem example">
<p><span class="theorem-title"><strong>Exemple 4.24 (Diagnostics graphiques pour l’inéquité salariale)</strong></span> On considère le modèle pour les données <code>college</code> avec toutes les observations (sans interaction) pour voir si les postulats tiennent la route.</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div id="fig-diagplotscollege" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-diagplotscollege-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="regression-lineaire_files/figure-html/fig-diagplotscollege-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:85.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-diagplotscollege-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;4.22: Diagnostic plots for the college data example: ordinary residuals against fitted values (top left), absolute value of the jacknnife studentized residuals against fitted values (top right), box and whiskers plot of jacknnife studentized residuals (bottom left) and detrended Student quantile-quantile plot (bottom right). There is clear group heteroscedasticity.
</figcaption>
</figure>
</div>
</div>
</div>
<p>Sur la base des graphiques de <a href="#fig-diagplotscollege" class="quarto-xref">Figure&nbsp;<span>4.22</span></a>, nous constatons qu’il existe une hétéroscédasticité au sein des échelons. Comme le nombre d’années pour les adjoint(e)s est limité et que tous les professeurs assistants ont été embauchés au cours des six dernières années, il y a moins de disparité dans leurs revenus. Il est important de ne pas confondre le modèle sur l’axe <span class="math inline">\(x\)</span> pour la valeur ajustée (en raison de l’effet important du rang et du domaine, tous deux variables catégorielles) avec les modèles dans les résidus (aucun n’est apparent). La correction de l’hétéroscédasticité permettrait de corriger les résidus et d’améliorer l’aspect du graphique quantile-quantile.</p>
<p>On effectue quelques tests avec les résidus studentisés externes pour les données <code>college</code> pour valider ce que les diagnostics graphiques indiquent.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a>r <span class="ot">&lt;-</span> <span class="fu">rstudent</span>(modlin1_college)</span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Test F de Levene</span></span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a>car<span class="sc">::</span><span class="fu">leveneTest</span>(r <span class="sc">~</span> echelon, <span class="at">center =</span> <span class="st">"mean"</span>, <span class="at">data =</span> college)</span>
<span id="cb23-4"><a href="#cb23-4" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Levene's Test for Homogeneity of Variance (center = "mean")</span></span>
<span id="cb23-5"><a href="#cb23-5" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;        Df F value Pr(&gt;F)    </span></span>
<span id="cb23-6"><a href="#cb23-6" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; group   2      50 &lt;2e-16 ***</span></span>
<span id="cb23-7"><a href="#cb23-7" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;       394                   </span></span>
<span id="cb23-8"><a href="#cb23-8" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; ---</span></span>
<span id="cb23-9"><a href="#cb23-9" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</span></span>
<span id="cb23-10"><a href="#cb23-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Test du score avec Breusch-Pagan</span></span>
<span id="cb23-11"><a href="#cb23-11" aria-hidden="true" tabindex="-1"></a>car<span class="sc">::</span><span class="fu">ncvTest</span>(modlin1_college, <span class="at">var.formula =</span>  <span class="sc">~</span> echelon)</span>
<span id="cb23-12"><a href="#cb23-12" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Non-constant Variance Score Test </span></span>
<span id="cb23-13"><a href="#cb23-13" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Variance formula: ~ echelon </span></span>
<span id="cb23-14"><a href="#cb23-14" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Chisquare = 70.2, Df = 2, p = 6e-16</span></span></code><button title="Copier vers le presse-papier" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Pour les données de collège, on spécifie donc plutôt <span class="math inline">\(Y_i \sim \mathsf{normale}(\mathbf{x}_i\boldsymbol{\beta}, \sigma^2_{\texttt{echelon}_i})\)</span> avec un paramètre de variance spécifique à l’échelon. Cela semble corriger l’hétéroscédasticité.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(nlme) <span class="co"># modèles mixtes et structures de corrélation</span></span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a>modlin.college2 <span class="ot">&lt;-</span> nlme<span class="sc">::</span><span class="fu">gls</span>(</span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">model =</span> salaire <span class="sc">~</span> echelon <span class="sc">+</span> domaine <span class="sc">+</span> sexe <span class="sc">+</span> service, <span class="co"># spécification de la moyenne</span></span>
<span id="cb24-4"><a href="#cb24-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">weights =</span> nlme<span class="sc">::</span><span class="fu">varIdent</span>(<span class="at">form =</span> <span class="sc">~</span><span class="dv">1</span> <span class="sc">|</span> echelon), <span class="co"># variance constante par échelon</span></span>
<span id="cb24-5"><a href="#cb24-5" aria-hidden="true" tabindex="-1"></a>  <span class="at">data =</span> college)</span>
<span id="cb24-6"><a href="#cb24-6" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(modlin.college2)</span>
<span id="cb24-7"><a href="#cb24-7" aria-hidden="true" tabindex="-1"></a>car<span class="sc">::</span><span class="fu">Anova</span>(modlin.college2)</span>
<span id="cb24-8"><a href="#cb24-8" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Analysis of Deviance Table (Type II tests)</span></span>
<span id="cb24-9"><a href="#cb24-9" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; </span></span>
<span id="cb24-10"><a href="#cb24-10" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Response: salaire</span></span>
<span id="cb24-11"><a href="#cb24-11" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;         Df  Chisq Pr(&gt;Chisq)    </span></span>
<span id="cb24-12"><a href="#cb24-12" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; echelon  2 363.50     &lt;2e-16 ***</span></span>
<span id="cb24-13"><a href="#cb24-13" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; domaine  1  91.04     &lt;2e-16 ***</span></span>
<span id="cb24-14"><a href="#cb24-14" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; sexe     1   1.80      0.180    </span></span>
<span id="cb24-15"><a href="#cb24-15" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; service  1   2.97      0.085 .  </span></span>
<span id="cb24-16"><a href="#cb24-16" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; ---</span></span>
<span id="cb24-17"><a href="#cb24-17" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</span></span></code><button title="Copier vers le presse-papier" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="regression-lineaire_files/figure-html/unnamed-chunk-59-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:85.0%"></p>
</figure>
</div>
</div>
</div>
<p>Le modèle est ajusté par maximum de vraisemblance restreint avec la fonction <code>gls</code> du paquet <code>nlme</code>. La modification semble suffisante pour capturer l’hétéroscédasticité dans le diagramme des résidus standardisés vs valeurs ajustées.</p>
<p>On pourrait aussi essayer d’utiliser la matrice sandwich, en remplaçant l’estimateur de <span class="math inline">\(\mathsf{Va}(\widehat{\boldsymbol{\beta}})\)</span> par <span class="math inline">\(\widehat{\mathsf{Va}}_{\mathsf{HCE}}(\boldsymbol{\widehat{\beta}})\)</span> dans la formule des tests de Wald. Ici, c’est option n’est pas recommandée car moins efficace.</p>
<div class="cell" data-layout-align="center">
<div class="sourceCode cell-code" id="cb25"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Matrice de covariance sandwich</span></span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a>vcov_HCE <span class="ot">&lt;-</span> car<span class="sc">::</span><span class="fu">hccm</span>(modlin1_college)</span>
<span id="cb25-3"><a href="#cb25-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Statistiques de Wald</span></span>
<span id="cb25-4"><a href="#cb25-4" aria-hidden="true" tabindex="-1"></a>lmtest<span class="sc">::</span><span class="fu">coeftest</span>(modlin1_college, <span class="at">vcov. =</span> vcov_HCE)</span></code><button title="Copier vers le presse-papier" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</div>
</section>
<section id="sec-transfo" class="level3" data-number="4.8.5">
<h3 data-number="4.8.5" class="anchored" data-anchor-id="sec-transfo"><span class="header-section-number">4.8.5</span> Transformation de la variable réponse</h3>
<p>Si la réponse est strictement positive, certaines options peuvent atténuer le manque d’additivité, plus particulièrement les relations multiplicatives entre la moyenne et la variance. Si les données sont asymétriques et que la réponse est strictement positive, un modèle log-linéaire peut être plus approprié et les paramètres peuvent être interprétés.</p>
<p>Écrivons le modèle log-linéaire <span class="math display">\[\begin{align*}
\ln Y = \beta_0+ \beta_1 X_1 +\cdots + \beta_pX_p + \varepsilon;
\end{align*}\]</span> à l’échelle originale de la variable réponse, cela représente <span class="math display">\[\begin{align*}
Y &amp;= \exp\left(\beta_0 +\beta_1 X_1 +\cdots + \beta_pX_p\right)\cdot \exp(\varepsilon),
\end{align*}\]</span> et donc <span class="math display">\[\begin{align*}
\mathsf{E}(Y \mid \mathbf{X}) = \exp(\beta_0 +\beta_1 X_1 +\cdots + \beta_pX_p) \times \mathsf{E}\{\exp(\varepsilon) \mid \mathbf{X}\}.
\end{align*}\]</span> Si <span class="math inline">\(\varepsilon \mid \mathbf{x} \sim \mathsf{normale}(\mu,\sigma^2)\)</span>, alors <span class="math inline">\(\mathsf{E}\{\exp(\varepsilon) \mid \mathbf{x}\}= \exp(\mu+\sigma^2/2)\)</span> et <span class="math inline">\(\exp(\varepsilon)\)</span> suit une loi lognormale. Une augmentation d’une unité de <span class="math inline">\(X_j\)</span> mène à une augmentation moyenne de <span class="math inline">\(\beta_j\)</span> de <span class="math inline">\(\ln Y\)</span> sans interaction ni terme nonlinéaire pour <span class="math inline">\(X_j\)</span>, et cela se traduit par un facteur multiplicatif de <span class="math inline">\(\exp(\beta_j)\)</span> à l’échelle de <span class="math inline">\(Y\)</span>. Si <span class="math inline">\(\beta_j=0\)</span>, <span class="math inline">\(\exp(\beta_j)=1\)</span> et il n’y a pas de changement, si <span class="math inline">\(\beta_j &lt; 0\)</span>, <span class="math inline">\(\exp(\beta_j)&lt;1\)</span> et la moyenne décroît avec <span class="math inline">\(X_j\)</span>, et si <span class="math inline">\(\beta_j &gt; 0\)</span>, <span class="math inline">\(\exp(\beta_j)&gt;1\)</span> et la moyenne augmente avec <span class="math inline">\(X_j\)</span>.</p>
<p>Comparez le rapport <span class="math display">\[\begin{align*}
\frac{\mathsf{E}(Y \mid X_1=x+1, X_2, \ldots, X_p)}{\mathsf{E}(Y \mid X_1=x,  X_2, \ldots, X_p)} = \frac{\exp\{\beta_1(x+1)\}}{\exp(\beta_1 x)} = \exp(\beta_1).
\end{align*}\]</span> Ainsi, <span class="math inline">\(\exp(\beta_1)\)</span> donne le rapport des moyennes de <span class="math inline">\(Y\)</span> quand <span class="math inline">\(X_1=x+1\)</span> par rapport à <span class="math inline">\(X_1=x\)</span>, <em>ceteris paribus</em> (avec les restrictions habituelles). L’interprétation (par rapport à la référence, dépend du signe de <span class="math inline">\(\beta_j\)</span>: le pourcentage de diminution est <span class="math inline">\(1-\exp(\beta_j)\)</span> si <span class="math inline">\(\beta_j &lt;0\)</span> et le pourcentage d’augmentation est <span class="math inline">\(\exp(\beta_j)-1\)</span> si <span class="math inline">\(\beta_j&gt;0\)</span>.</p>
<p>Parfois, on veut considérer une transformation à la fois de la réponse et d’une variable explicative positive continue, un modèle log-log. Considérons le cas où on prend le logarithme de <span class="math inline">\(Y\)</span> et <span class="math inline">\(X_1\)</span>, avec <span class="math display">\[\begin{align*}
Y= X_1^{\beta_1}\exp(\beta_0 + \beta_2X_2 + \cdots + \beta_pX_p + \varepsilon)
\end{align*}\]</span> En prenant la dérivée par rapport à <span class="math inline">\(X_1&gt;0\)</span>, on obtient <span class="math display">\[\begin{align*}
\frac{\partial Y}{\partial X_1}&amp;= \beta_1 X_1^{\beta_1-1}\exp(\beta_0 + \beta_2X_2 + \cdots + \beta_pX_p + \varepsilon)\\&amp;= \frac{\beta_1 Y}{X_1}
\end{align*}\]</span> et réarranger cette expression nous donne <span class="math display">\[\begin{align*}
\frac{\partial X_1}{X_1}\beta_1 = \frac{\partial Y}{Y};
\end{align*}\]</span> une mesure <strong>d’élasticité partielle</strong>: le coefficient <span class="math inline">\(\beta_1\)</span> est un pourcentage de changement de <span class="math inline">\(Y\)</span> pour chaque pourcentage d’augmentation de <span class="math inline">\(X_1\)</span>, <em>ceteris paribus</em>.</p>
<div id="exm-loglog" class="theorem example">
<p><span class="theorem-title"><strong>Exemple 4.25 (Modèle de Cobb-Douglas)</strong></span> Considérons par exemple la fonction de production Cobb–Douglas <span class="citation" data-cites="Douglas:1976">(<a href="references.html#ref-Douglas:1976" role="doc-biblioref">Douglas 1976</a>)</span>, qui spécifie que la production économique <span class="math inline">\(Y\)</span> est liée au travail <span class="math inline">\(L\)</span> et au capital <span class="math inline">\(C\)</span> par l’intermédiaire de <span class="math inline">\(\mathsf{E}(Y \mid L, C) = \beta_0C^{\beta}L^{1-\beta}\)</span> avec <span class="math inline">\(\beta \ dans (0,1)\)</span>.Si nous prenons les logarithmes des deux côtés (puisque tous les arguments sont positifs), alors <span class="math inline">\(\mathsf{E}(\ln Y \mid L, C) = \beta_0^* + \beta_1 \ln C + (1-\beta_1)\ln L\)</span>. Nous pourrions ajuster un modèle linéaire avec la réponse <span class="math inline">\(\ln Y - \ln L\)</span> et la variable explicative <span class="math inline">\(\ln C - \ln L\)</span>, pour obtenir une estimation du coefficient <span class="math inline">\(\beta_1\)</span>, tandis que <span class="math inline">\(\beta_0^*=\ln \beta_0\)</span>. Une optimisation sous contrainte serait potentiellement nécessaire pour estimer les paramètres du modèle linéaire résultant si les estimations se situent en dehors de l’espace des paramètres.</p>
</div>
<div id="prp-boxcox" class="theorem proposition">
<p><span class="theorem-title"><strong>Proposition 4.6 (Transformation de Box–Cox)</strong></span> Parfois, le postulat de normalité de l’erreur dans une régression linéaire ne tient pas. Avec des données strictement positives, on peut envisager une transformation de Box–Cox <span class="citation" data-cites="Box.Cox:1964">(<a href="references.html#ref-Box.Cox:1964" role="doc-biblioref">Box et Cox 1964</a>)</span>, <span class="math display">\[\begin{align*}
y(\lambda)= \begin{cases}
(y^{\lambda}-1)/\lambda, &amp; \lambda \neq 0\\
\ln(y), &amp; \lambda=0.
\end{cases}
\end{align*}\]</span> Les cas de figure <span class="math inline">\(\lambda=-1\)</span> (inverse), <span class="math inline">\(\lambda=1\)</span> (identité) et <span class="math inline">\(\lambda=0\)</span> (logarithme) sont les plus importants car les modèles résultants sont interprétables.</p>
<p>Si on suppose que <span class="math inline">\(\boldsymbol{Y}(\lambda) \sim \mathsf{normale}(\mathbf{X}\boldsymbol{\beta}, \sigma^2 \mathbf{I}_n)\)</span>, alors la vraisemblance est <span class="math display">\[\begin{align*}
L(\lambda, \boldsymbol{\beta}, \sigma; \boldsymbol{y}, \mathbf{X}) &amp;= (2\pi\sigma^2)^{-n/2} J(\lambda, \boldsymbol{y}) \times\\&amp; \quad \exp \left[ - \frac{1}{2\sigma^2}\{\boldsymbol{y}(\lambda) - \mathbf{X}\boldsymbol{\beta}\}^\top\{\boldsymbol{y}(\lambda) - \mathbf{X}\boldsymbol{\beta}\}\right],
\end{align*}\]</span> où <span class="math inline">\(J\)</span> dénote le Jacobien de la transformation Box–Cox, <span class="math inline">\(J(\lambda, \boldsymbol{y})=\prod_{i=1}^n y_i^{\lambda-1}\)</span>. Pour chaque valeur de <span class="math inline">\(\lambda\)</span>, l’estimateur du maximum de vraisemblance est le même que celle de la régression linéaire, mais où <span class="math inline">\(\boldsymbol{y}\)</span> est remplacée par <span class="math inline">\(\boldsymbol{y}(\lambda)\)</span>, soit <span class="math inline">\(\widehat{\boldsymbol{\beta}}_\lambda = (\mathbf{X}^\top\mathbf{X})^{-1}\mathbf{X}^\top \boldsymbol{y}(\lambda)\)</span> and <span class="math inline">\(\widehat{\sigma}^2_\lambda = n^{-1}\{ \boldsymbol{y}(\lambda) - \mathbf{X}\widehat{\boldsymbol{\beta}}_\lambda\}^\top\{ \boldsymbol{y}(\lambda) - \mathbf{X}\widehat{\boldsymbol{\beta}}_\lambda\}\)</span>.</p>
<p>La log-vraisemblance profilée est donc <span class="math display">\[\begin{align*}
\ell_{\mathsf{p}}(\lambda) = -\frac{n}{2}\ln(2\pi \widehat{\sigma}^2_\lambda) - \frac{n}{2} + (\lambda - 1)\sum_{i=1}^n \ln(y_i)
\end{align*}\]</span> L’estimateur du maximum de vraisemblance profilée est la valeur <span class="math inline">\(\lambda\)</span> qui minimise la somme des carrés des résidus du modèle linéaire avec <span class="math inline">\(\boldsymbol{y}(\lambda)\)</span> comme réponse.</p>
<p>Nous ne pouvons pas comparer les modèles ajustés à <span class="math inline">\(Y_i\)</span> par rapport à <span class="math inline">\(\ln Y_i\)</span> en utilisant, par exemple, des critères d’information ou des tests, parce que les modèles ont des réponses différentes. Nous pouvons toutefois utiliser la vraisemblance de Box–Cox, qui inclut le <strong>Jacobien</strong> de la transformation, pour évaluer la qualité de l’ajustement et comparer le modèle avec <span class="math inline">\(\lambda=1\)</span> par rapport à <span class="math inline">\(\lambda=0\)</span>.</p>
<p>La transformation de Box–Cox n’est pas une solution miracle et doit être réservée aux cas où la transformation réduit l’hétéroscédasticité (variance inégale) ou crée une relation linéaire entre les explications et la réponse. La théorie fournit une explication convaincante des données avec, par exemple, la fonction de production Cobb-Douglas utilisée en économie qui peut être linéarisée par une transformation logarithmique. Plutôt que de choisir une transformation <em>ad hoc</em>, on pourrait choisir une transformation logarithmique si la valeur 0$ est incluse dans l’intervalle de confiance à 95%, car cela améliore l’interprétabilité.</p>
</div>
<div id="exm-poisonboxcox" class="theorem example">
<p><span class="theorem-title"><strong>Exemple 4.26 (Transformation de Box–Cox pour données sur les poisons)</strong></span> <span class="citation" data-cites="Box.Cox:1964">Box et Cox (<a href="references.html#ref-Box.Cox:1964" role="doc-biblioref">1964</a>)</span> modélisent le temps de survie de 48 animaux sur la base d’un essai aléatoire. Les données sur les <code>poisons</code> sont équilibrées, 3 poisons ayant été administrés avec 4 traitements à 4 animaux chacun. Nous pourrions envisager une ANOVA à deux facteurs sans interaction, étant donné le peu d’observations pour chaque combinaison. Le modèle s’écrit alors <span class="math display">\[\begin{align*}
Y &amp;= \beta_0 + \beta_1 \texttt{poison}_2 + \beta_2\texttt{poison}_3  +\beta_3\texttt{treatment}_2 \\ &amp;\qquad+ \beta_4\texttt{treatment}_3
+\beta_5\texttt{treatment}_4 + \varepsilon
\end{align*}\]</span></p>
<p>Le tracé des valeurs ajustées par rapport aux résidus montre que le modèle n’est pas additif (panneau du milieu de la <a href="#fig-poisonplots" class="quarto-xref">Figure&nbsp;<span>4.23</span></a>); il y a également des indications que la variance augmente avec la réponse moyenne. Le modèle est inadéquat: les temps de survie les plus faibles sont sous-estimés, ce qui signifie que les résidus sont positifs, de même que les réponses moyennes. Un test formel de non-additivité indique également la non-additivité <span class="citation" data-cites="Davison:2003">(<a href="references.html#ref-Davison:2003" role="doc-biblioref">Davison 2003</a>, Exemple 8.24)</span>. Dans l’ensemble, l’ajustement du modèle est médiocre et toute conclusion tirée de celui-ci est douteuse.</p>
<p>On pourrait envisager d’utiliser un Box–Cox pour trouver une transformation appropriée des résidus afin d’améliorer la normalité. Une analyse des résidus dans les quatre premiers graphiques de <a href="#fig-poisonplots" class="quarto-xref">Figure&nbsp;<span>4.23</span></a> montre des signes d’hétéroscédasticité en fonction du poison et du traitement. Ceci est évident en regardant le graphique des résidus ordinaires, qui montre une augmentation de la variance avec le temps de survie. Le tracé quantile-quantile dans le tracé du milieu à droite montre quelques signes d’écart par rapport à la normalité, mais la non-linéarité et l’hétéroscédasticité le masquent.</p>
<div class="cell" data-layout-align="center">
<div class="cell-output-display">
<div id="fig-poisonplots" class="quarto-float quarto-figure quarto-figure-center anchored" data-fig-align="center">
<figure class="quarto-float quarto-float-fig figure">
<div aria-describedby="fig-poisonplots-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
<img src="regression-lineaire_files/figure-html/fig-poisonplots-1.png" class="img-fluid quarto-figure quarto-figure-center figure-img" style="width:85.0%">
</div>
<figcaption class="quarto-float-caption-bottom quarto-float-caption quarto-float-fig" id="fig-poisonplots-caption-0ceaefa1-69ba-4598-a22c-09a6ac19f8ca">
Figure&nbsp;4.23: Diagnostics graphiques pour les données de poisons. Panneau du haut: vraisemblance profilée pour <span class="math inline">\(\lambda\)</span>. Panneau du milieu: (<span class="math inline">\(\lambda=1\)</span>, temps de survie) et du bas <span class="math inline">\((\lambda=-1\)</span>, vitesse d’absorption). Les diagnostics pour les modèles représentent les résidus ordinaires versus valeurs ajustées et diagramme quantile-quantile des résidus studentisés.
</figcaption>
</figure>
</div>
</div>
</div>
<p>L’intervalle de confiance à 95% basé sur la log-vraisemblance profilée pour le paramètre du modèle Box–Cox contient <span class="math inline">\(\lambda=-1\)</span>. La réciproque de la variable réponse <span class="math inline">\(Y^{-1}\)</span> indique la vitesse d’action du poison, selon le type et le traitement. Les diagnostics graphiques de ce modèles, présentés dans le panneau du bas de la <a href="#fig-poisonplots" class="quarto-xref">Figure&nbsp;<span>4.23</span></a> ne montrent aucune structure résiduelle.</p>
</div>
</section>
</section>
<section id="remarque-finale" class="level2" data-number="4.9">
<h2 data-number="4.9" class="anchored" data-anchor-id="remarque-finale"><span class="header-section-number">4.9</span> Remarque finale</h2>
<p>La régression linéaire est le modèle statistique le plus connu et le plus utilisé. Le nom peut sembler réducteur, mais de nombreux tests statistiques (<em>t</em>-tests, ANOVA, Wilcoxon, Kruskal–Wallis) [peuvent être formulés à l’aide d’une régression linéaire] (https://lindeloev.github.io/tests-as-linear/linear_tests_cheat_sheet.pdf), tandis que [des modèles aussi divers que les arbres, les composantes principales et les réseaux neuronaux profonds ne sont que des modèles de régression linéaire déguisés] (https://threadreaderapp.com/thread/1286420597505892352.html). Ce qui change sous le capot d’un modèle à l’autre, c’est la méthode d’optimisation (par exemple, les moindres carrés ordinaires, l’optimisation sous contrainte ou la descente de gradient stochastique) et le choix des variables explicatives entrant dans le modèle (bases de splines pour la régression non paramétrique, variable indicatrice sélectionnée via une recherche glouton pour les arbres, fonctions d’activation pour les réseaux neuronaux).</p>


<div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list" style="display: none">
<div id="ref-Baumann:1992" class="csl-entry" role="listitem">
Baumann, James F., Nancy Seifert-Kessell, et Leah A. Jones. 1992. <span>«&nbsp;Effect of Think-Aloud Instruction on Elementary Students’ Comprehension Monitoring Abilities&nbsp;»</span>. <em>Journal of Reading Behavior</em> 24 (2): 143‑72. <a href="https://doi.org/10.1080/10862969209547770">https://doi.org/10.1080/10862969209547770</a>.
</div>
<div id="ref-Box.Cox:1964" class="csl-entry" role="listitem">
Box, G. E. P., et D. R. Cox. 1964. <span>«&nbsp;An Analysis of Transformations&nbsp;»</span>. <em>Journal of the Royal Statistical Society: Series B (Methodological)</em> 26 (2): 211‑43. <a href="https://doi.org/10.1111/j.2517-6161.1964.tb00553.x">https://doi.org/10.1111/j.2517-6161.1964.tb00553.x</a>.
</div>
<div id="ref-Breusch.Pagan:1979" class="csl-entry" role="listitem">
Breusch, T. S., et A. R. Pagan. 1979. <span>«&nbsp;A Simple Test for Heteroscedasticity and Random Coefficient Variation&nbsp;»</span>. <em>Econometrica</em> 47 (5): 1287‑94. <a href="http://www.jstor.org/stable/1911963">http://www.jstor.org/stable/1911963</a>.
</div>
<div id="ref-Brockwell.Davis:2016" class="csl-entry" role="listitem">
Brockwell, P. J., et R. A. Davis. 2016. <em>Introduction to Time Series and Forecasting</em>. Springer Texts in Statistics. Springer.
</div>
<div id="ref-Crump.Navarro.Suzuki:2019" class="csl-entry" role="listitem">
Crump, M. J. C., D. J. Navarro, et J. Suzuki. 2019. <em>Answering Questions with Data: Introductory Statistics for Psychology Students</em>. <a href="https://doi.org/10.17605/OSF.IO/JZE52">https://doi.org/10.17605/OSF.IO/JZE52</a>.
</div>
<div id="ref-Davison:2003" class="csl-entry" role="listitem">
Davison, A. C. 2003. <em>Statistical Models</em>. Cambridge University Press.
</div>
<div id="ref-Douglas:1976" class="csl-entry" role="listitem">
Douglas, Paul H. 1976. <span>«&nbsp;The <span>Cobb–Douglas</span> Production Function Once Again: Its History, Its Testing, and Some New Empirical Values&nbsp;»</span>. <em>Journal of Political Economy</em> 84 (5): 903‑15. <a href="http://www.jstor.org/stable/1830435">http://www.jstor.org/stable/1830435</a>.
</div>
<div id="ref-Fox:1992" class="csl-entry" role="listitem">
Fox, John, et Georges Monette. 1992. <span>«&nbsp;Generalized Collinearity Diagnostics&nbsp;»</span>. <em>Journal of the American Statistical Association</em> 87 (417): 178‑83. <a href="https://doi.org/10.1080/01621459.1992.10475190">https://doi.org/10.1080/01621459.1992.10475190</a>.
</div>
<div id="ref-Lee.Choi:2019" class="csl-entry" role="listitem">
Lee, Kiljae, et Jungsil Choi. 2019. <span>«&nbsp;Image-text inconsistency effect on product evaluation in online retailing&nbsp;»</span>. <em>Journal of Retailing and Consumer Services</em> 49: 279‑88. <a href="https://doi.org/10.1016/j.jretconser.2019.03.015">https://doi.org/10.1016/j.jretconser.2019.03.015</a>.
</div>
<div id="ref-Lin.Kim.Uduehi.Keinan:2024" class="csl-entry" role="listitem">
Lin, Jason D, Nicole You Jeung Kim, Esther Uduehi, et Anat Keinan. 2024. <span>«&nbsp;Culture for Sale: Unpacking Consumer Perceptions of Cultural Appropriation&nbsp;»</span>. <em>Journal of Consumer Research</em>. <a href="https://doi.org/10.1093/jcr/ucad076">https://doi.org/10.1093/jcr/ucad076</a>.
</div>
<div id="ref-McKinnon.White:1985" class="csl-entry" role="listitem">
MacKinnon, James G, et Halbert White. 1985. <span>«&nbsp;Some heteroskedasticity-consistent covariance matrix estimators with improved finite sample properties&nbsp;»</span>. <em>Journal of Econometrics</em> 29 (3): 305‑25. <a href="https://doi.org/10.1016/0304-4076(85)90158-7">https://doi.org/10.1016/0304-4076(85)90158-7</a>.
</div>
<div id="ref-Moon.VanEpps:2023" class="csl-entry" role="listitem">
Moon, Alice, et Eric M VanEpps. 2023. <span>«&nbsp;Giving Suggestions: Using Quantity Requests to Increase Donations&nbsp;»</span>. <em>Journal of Consumer Research</em> 50 (1): 190‑210. <a href="https://doi.org/10.1093/jcr/ucac047">https://doi.org/10.1093/jcr/ucac047</a>.
</div>
<div id="ref-Sharma.Tully.Cryder:2021" class="csl-entry" role="listitem">
Sharma, Eesha, Stephanie Tully, et Cynthia Cryder. 2021. <span>«&nbsp;Psychological Ownership of (Borrowed) Money&nbsp;»</span>. <em>Journal of Marketing Research</em> 58 (3): 497‑514. <a href="https://doi.org/10.1177/0022243721993816">https://doi.org/10.1177/0022243721993816</a>.
</div>
<div id="ref-Sokolova:2023" class="csl-entry" role="listitem">
Sokolova, Tatiana, Aradhna Krishna, et Tim Döring. 2023. <span>«&nbsp;Paper Meets Plastic: The Perceived Environmental Friendliness of Product Packaging&nbsp;»</span>. <em>Journal of Consumer Research</em> 50 (3): 468‑91. <a href="https://doi.org/10.1093/jcr/ucad008">https://doi.org/10.1093/jcr/ucad008</a>.
</div>
<div id="ref-Venables:2000" class="csl-entry" role="listitem">
Venables, William N. 2000. <span>«&nbsp;Exegeses on Linear Models&nbsp;»</span>. In <em>S-PLUS User’s Conference</em>. Washington, D.C. <a href="https://www.stats.ox.ac.uk/pub/MASS3/Exegeses.pdf">https://www.stats.ox.ac.uk/pub/MASS3/Exegeses.pdf</a>.
</div>
<div id="ref-White:1980" class="csl-entry" role="listitem">
White, Halbert. 1980. <span>«&nbsp;A Heteroskedasticity-Consistent Covariance Matrix Estimator and a Direct Test for Heteroskedasticity&nbsp;»</span>. <em>Econometrica</em> 48 (4): 817‑38. <a href="https://doi.org/10.2307/1912934">https://doi.org/10.2307/1912934</a>.
</div>
</div>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copié");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copié");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    // For code content inside modals, clipBoardJS needs to be initialized with a container option
    // TODO: Check when it could be a function (https://github.com/zenorocha/clipboard.js/issues/860)
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp("https:\/\/lbelzile\.github\.io\/math60604\/");
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./vraisemblance.html" class="pagination-link" aria-label="Inférence basée sur la vraisemblance">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Inférence basée sur la vraisemblance</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./references.html" class="pagination-link" aria-label="Bibliographie">
        <span class="nav-page-text">Bibliographie</span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->
<footer class="footer">
  <div class="nav-footer">
    <div class="nav-footer-left">
      &nbsp;
    </div>   
    <div class="nav-footer-center">
<p>Tous droits réservés (Léo Belzile)</p>
<div class="toc-actions d-sm-block d-md-none"><ul><li><a href="https://github.com/lbelzile/math60604/edit/master/regression-lineaire.qmd" class="toc-action"><i class="bi bi-github"></i>Éditer cette page</a></li></ul></div></div>
    <div class="nav-footer-right">
      &nbsp;
    </div>
  </div>
</footer>




</body></html>