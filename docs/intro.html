<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>1 Introduction à l’inférence statistique | Modélisation statistique</title>
  <meta name="description" content="Ces notes forment un complément web du cours MATH 60604 (Modélisation statistique) offert à la M.Sc. en gestion (science des données et analytique d’affaires) à HEC Montréal.." />
  <meta name="generator" content="bookdown 0.20 and GitBook 2.6.7" />

  <meta property="og:title" content="1 Introduction à l’inférence statistique | Modélisation statistique" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="Ces notes forment un complément web du cours MATH 60604 (Modélisation statistique) offert à la M.Sc. en gestion (science des données et analytique d’affaires) à HEC Montréal.." />
  <meta name="github-repo" content="lbelzile/math60604" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="1 Introduction à l’inférence statistique | Modélisation statistique" />
  
  <meta name="twitter:description" content="Ces notes forment un complément web du cours MATH 60604 (Modélisation statistique) offert à la M.Sc. en gestion (science des données et analytique d’affaires) à HEC Montréal.." />
  




  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="index.html"/>
<link rel="next" href="regression-lineaire.html"/>
<script src="libs/header-attrs-2.3/header-attrs.js"></script>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<script src="libs/accessible-code-block-0.0.1/empty-anchor.js"></script>



<link rel="stylesheet" href="css/style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Modélisation statistique</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Remarques</a></li>
<li class="chapter" data-level="1" data-path="intro.html"><a href="intro.html"><i class="fa fa-check"></i><b>1</b> Introduction à l’inférence statistique</a></li>
<li class="chapter" data-level="2" data-path="regression-lineaire.html"><a href="regression-lineaire.html"><i class="fa fa-check"></i><b>2</b> Régression linéaire</a></li>
<li class="chapter" data-level="3" data-path="modeles-lineaires-generalises.html"><a href="modeles-lineaires-generalises.html"><i class="fa fa-check"></i><b>3</b> Modèles linéaires généralisés</a></li>
<li class="chapter" data-level="4" data-path="donnees-correlees-longitudinales.html"><a href="donnees-correlees-longitudinales.html"><i class="fa fa-check"></i><b>4</b> Données corrélées et longitudinales</a></li>
<li class="chapter" data-level="5" data-path="modeles-lineaires-mixtes.html"><a href="modeles-lineaires-mixtes.html"><i class="fa fa-check"></i><b>5</b> Modèles linéaires mixtes</a></li>
<li class="chapter" data-level="6" data-path="survie.html"><a href="survie.html"><i class="fa fa-check"></i><b>6</b> Analyse de survie</a></li>
<li class="chapter" data-level="7" data-path="vraisemblance.html"><a href="vraisemblance.html"><i class="fa fa-check"></i><b>7</b> Inférence basée sur la vraisemblance</a></li>
<li class="appendix"><span><b>Annexe</b></span></li>
<li><a href="r.html#r"><strong>R</strong></a></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Publié avec bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Modélisation statistique</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="intro" class="section level1" number="1">
<h1><span class="header-section-number">1</span> Introduction à l’inférence statistique</h1>
<div id="prérequis" class="section level2" number="1.1">
<h2><span class="header-section-number">1.1</span> Prérequis</h2>
<p>Bien que sans prérequis, nous assumerons que l’étudiant(e) a une connaissance préalable des notions suivantes:</p>
<ul>
<li>population et échantillon,</li>
<li>types de variables: continues, catégorielles (ordinales ou nominales), binaires,</li>
<li>variables aléatoires et leurs lois (Bernoulli, binomiale, géométrique, Poisson, normale, Student, exponentielle, Weibull, etc.),</li>
<li>propriétés de variables aléatoires: espérance, variance, biais,</li>
<li>graphiques de base (histogramme, nuage de point, densité, boîte à moustache, etc.),</li>
<li>tests d’hypothèses, puissance et erreur de type I,</li>
<li>théorème central limite,</li>
<li>valeurs-<span class="math inline">\(p\)</span> et intervalles de confiance,</li>
<li>tests-<span class="math inline">\(t\)</span> pour un et deux échantillons et pour données appariées,</li>
<li>régression linéaire simple.</li>
</ul>
<p>Ces notions sont d’ordinaire traitées dans un cours d’introduction à la statistique au niveau baccalauréat/licence, voir même au collégial.</p>
<p>L’inférence statistique a pour but de tirer des conclusions formelles à partir de données. Dans le cadre de la recherche scientifique, le chercheur formule une hypothèse, collecte des données pour valider ou infirmer cette dernière et conclure quant à la plausibilité de son hypothèse.</p>
<p>On distingue deux types de jeux de données: les données <strong>expérimentales</strong> sont typiquement collectées en milieu contrôlé suivant un protocole d’enquête et un plan d’expérience: elles servent à répondre à une question prédéterminée. L’approche expérimentale est désirable pour éviter le «jardin des embranchements» (une <a href="http://www.stat.columbia.edu/~gelman/research/unpublished/p_hacking.pdf">allégorie signifiant qu’un chercheur peut raffiner son hypothèse à la lumière des données, sans ajustement pour des variables confondantes</a>), mais elle n’est pas toujours réalisable: par exemple, un économiste ne peut pas modifier les taux d’intérêts pour observer les impacts sur le taux d’épargne des consommateurs. Lorsque les données ont déjà été collectées, on parle de données <strong>observationnelles</strong>.</p>
<p>On fera dans ce cours une distinction entre inférence et prédiction, bien que ces deux objectifs ne soient pas mutuellement exclusifs. La plupart des boîtes noires utilisées en apprentissage automatique tombent dans la catégorie des modèles prédictifs: ces modèles ne sont pas interprétables et ignorent parfois la structure inhérente aux données. Par contraste, les modèles explicatifs qui servent à l’inférence sont souvent simples et interprétables.</p>
<p>Ce chapitre porte sur deux concepts fondamentaux pour la modélisation, à savoir les principes sous-jacents aux tests d’hypothèses et l’analyse exploratoire des données. Il contient également des exemples de problèmes quotidiens pour lesquels la statistique offre des pistes de réflexion.</p>
<p>Plusieurs exemples seront traités dans le cours:</p>
<ul>
<li>Est-ce qu’il y a de la discrimination salariale envers les femmes professeurs d’un collège américain?</li>
<li>Quels sont les critères médicaux qui impactent les primes d’assurance maladies?</li>
<li>Qu’est-ce qui explique que les prix de l’essence soient plus élevés en Gaspésie qu’ailleurs au Québec? <a href="http://www.regie-energie.qc.ca/energie/rapports/Rapport_PrixGasp%C3%A9sie_20191219.pdf">Un rapport de surveillance des prix de l’essence en Gaspésie par la Régie de l’énergie se penche sur la question.</a></li>
<li>Est-ce que les examens pratiques de conduite sont plus faciles en régions en Grande-Bretagne? <a href="https://www.theguardian.com/world/2019/aug/23/an-easy-ride-scottish-village-fuels-debate-driving-test-pass-rates">Une analyse du journal britannique <em>The Guardian</em></a> laisse penser que c’est le cas.</li>
<li>Est-ce le risque de transmission de la Covid augmente en fonction de la distanciation? <a href="https://www.thelancet.com/journals/lancet/article/PIIS0140-6736(20)31142-9/fulltext">Une (mauvaise) méta-analyse souligne que c’est le cas</a> (ou l’art de tirer des conclusions erronées à partir d’une étude bancale).</li>
</ul>
</div>
<div id="tests-dhypothèse-heuristique" class="section level2" number="1.2">
<h2><span class="header-section-number">1.2</span> Tests d’hypothèse (heuristique)</h2>
<p>Un test d’hypothèse statistique est une façon d’évaluer la preuve statistique provenant d’un échantillon afin de faire une décision quant à la population sous-jacente. Les étapes principales sont:</p>
<ul>
<li>définir les hypothèses que l’on veut tester en fonction de paramètres du modèle,</li>
<li>calculer la statistique de test,</li>
<li>déterminer son comportement sous <span class="math inline">\(\Hy_0\)</span> (loi nulle),</li>
<li>calculer la valeur-<span class="math inline">\(p\)</span>,</li>
<li>conclure dans le contexte du problème (rejetter ou ne pas rejetter <span class="math inline">\(\Hy_0\)</span>).</li>
</ul>
<p>Mon approche privilégiée pour présenter les tests d’hypothèse est de faire un parallèle avec un procès pour meurtre où vous êtes nommé juré.</p>
<ul>
<li>Le juge vous demande de choisir entre deux hypothèses mutuellement exclusives, coupable ou non-coupable, sur la base des preuves présentées.</li>
<li>Votre postulat de départ repose sur la présomption d’innocence: vous condamnerez uniquement le suspect si la preuve est accablante. Cela permet d’éviter les erreurs judiciaires. L’hypothèse nulle <span class="math inline">\(\Hy_0\)</span> est donc <em>non-coupable</em>, et l’hypothèse alternative <span class="math inline">\(\Hy_a\)</span> est coupable. En cas de doute raisonnable, vous émettrez un verdict de non-culpabilité.</li>
<li>La preuve présentée est la statistique de test. La couronne choisit la preuve de manière à appuyer son postulat de culpabilité le mieux possible. Ce choix reflète la <strong>puissance</strong> (plus la preuve est accablante, plus grande est la chance d’un verdict de culpabilité — le procureur a donc tout intérêt à bien choisir les faits présentés en cour).</li>
<li>En qualité de juré, vous analysez la preuve à partir de la jurisprudence et de l’avis d’expert pour vous assurer que les faits ne relèvent pas du hasard. Pour le test d’hypothèse, ce rôle est tenu par la loi sous <span class="math inline">\(\Hy_0\)</span>: si la personne était innocente, est-ce que les preuves présentées tiendraient la route? Des preuves probantes (ADN, etc.) auront davantage de poids que des preuves circonstancielles (la pièce de théâtre <em>Douze hommes en colère</em> de Reginald Rose présente un bel exemple de procès où un des juré émet un doute raisonnable et convainc un à un les autres membres du jury de prononcer un verdict de non-culpabilité).</li>
<li>Vous émettez un verdict, à savoir une décision binaire, où l’accusé est déclaré soit non-coupable, soit coupable. Si vous avez une valeur-<span class="math inline">\(p\)</span>, disons <span class="math inline">\(P\)</span>, pour votre statistique de test et que vous effectuez ce dernier à niveau <span class="math inline">\(\alpha\)</span>, la règle de décision revient à rejeter <span class="math inline">\(\Hy_0\)</span> si <span class="math inline">\(P &lt; \alpha\)</span>.</li>
</ul>
<p>On s’attarde davantage sur ces définitions heuristiques et le vocabulaire employé pour parler de tests d’hypothèse. Le matériel de la section suivante a été préparé par Juliana Schulz.</p>
<div id="hypothèse" class="section level3" number="1.2.1">
<h3><span class="header-section-number">1.2.1</span> Hypothèse</h3>
<p>Dans les test statistique il y a toujours deux hypothèse: l’hypothèse nulle (<span class="math inline">\(\Hy_0\)</span>) et l’hypothèse alternative (<span class="math inline">\(\Hy_a\)</span>). Habituellement, l’hypothèse nulle est le « statu quo » et l’alternative est l’hypothèse que l’on cherche à démontrer. Un test d’hypothèse statistique nous permet de décider si nos données nous fournissent assez de preuves pour rejeter <span class="math inline">\(\Hy_0\)</span> en faveur de <span class="math inline">\(\Hy_a\)</span>, selon un risque d’erreur spécifié. Généralement, les tests d’hypothèses sont exprimés en fonction de paramètres (de valeurs inconnues) du modèle sous-jacent, par ex. <span class="math inline">\(\theta\)</span>. Un test d’hypothèse bilatéral concernant un paramètre unidimensionnel <span class="math inline">\(\theta\)</span> s’exprimerait la forme suivante:
<span class="math display">\[\begin{align*}
\Hy_0: \theta=\theta_0 \qquad \text{versus} \qquad \Hy_a:\theta \neq \theta_0.
\end{align*}\]</span>
Ces hypothèses permettent de tester si <span class="math inline">\(\theta\)</span> est égal précisément à une valeur, <span class="math inline">\(\theta_0\)</span>.</p>
<p>Par exemple, pour un test bilatéral concernant le paramètre d’un modèle de régression <span class="math inline">\(\beta_j\)</span> associé à une variable explicative d’intérêt <span class="math inline">\(\mathrm{X}_j\)</span> dans la population, les hypothèses sont:
<span class="math display">\[\begin{align*}
\Hy_0: \beta_j=\beta_j^0 \qquad \text{versus} \qquad \Hy_a:\beta_j \neq \beta_j^0, 
\end{align*}\]</span>
où <span class="math inline">\(\beta_j^0\)</span> est une valeur précise qui est reliée à la question de recherche. Par exemple, si <span class="math inline">\(\beta_j^0=0\)</span> la question de recherche sous-jacente est: est-ce que la covariable <span class="math inline">\(\mathrm{X}_j\)</span> impacte la variable réponse d’intérêt <span class="math inline">\(Y\)</span>?</p>
<p>Remarque: il est possible d’imposer une direction dans les tests en considérant une hypothèse alternative de la forme <span class="math inline">\(\Hy_a: \theta &gt; \theta_0\)</span> ou <span class="math inline">\(\Hy_a: \theta &lt; \theta_0\)</span>.</p>
</div>
<div id="statistique-de-test" class="section level3" number="1.2.2">
<h3><span class="header-section-number">1.2.2</span> Statistique de test</h3>
<p>Une statistique de test <span class="math inline">\(T\)</span> est une fonction des données d’échantillon qui contient de résume l’information contenue dans les données pour <span class="math inline">\(\theta\)</span>. La forme de la statistique de test est choisie de façon à ce que son comportement sous <span class="math inline">\(\Hy_0\)</span>, c’est-à-dire l’ensemble des valeurs que prend <span class="math inline">\(T\)</span> si <span class="math inline">\(\Hy_0\)</span> est vraie et leur probabilité relative, soit connu. En effet, <span class="math inline">\(T\)</span> est une variable aléatoire et sa valeur va changer selon l’échantillon. La <strong>loi nulle</strong> de la statistique de test nous permet de déterminer quelles valeurs de <span class="math inline">\(T\)</span> sont plausibles si <span class="math inline">\(\Hy_0\)</span> est vraie. Plusieurs statistiques que l’on couvrira dans ce cours sont des <strong>statistiques de Wald</strong>, de la forme
<span class="math display">\[\begin{align*}
T = \frac{\widehat{\theta} - \theta_0}{\mathrm{se}(\widehat{\theta})} 
\end{align*}\]</span>
où <span class="math inline">\(\widehat{\theta}\)</span> est l’estimateur du paramètre <span class="math inline">\(\theta\)</span> et <span class="math inline">\(\mathrm{se}(\widehat{\theta})\)</span> est l’estimateur de l’écart-type de <span class="math inline">\(\widehat{\theta}\)</span>.</p>
<p>Un <strong>estimateur</strong> est une règle ou une formule utilisée pour calculer l’estimation d’un paramètre ou quantité d’intérêt selon des données observées. Par exemple, la moyenne d’échantillon <span class="math inline">\(\overline{X}\)</span> est un estimateur de la moyenne dans la population <span class="math inline">\(\mu\)</span>. Une fois qu’on a des données observées, on peut calculer la valeur de <span class="math inline">\(\overline{X}\)</span>, c’est-à-dire, on obtient une valeur numérique, appelée estimé. Autrement dit, un estimateur est la procédure ou formule qui nous dit comment utiliser les données pour calculer une estimation. Un estimateur est une variable aléatoire car sa valeur dépend sur l’échantillon. L’estimé, quant à lui, est la valeur numérique calculée sur un échantillon donné.</p>
<p>Par exemple, pour une hypothèse sur la moyenne d’une population de la forme
<span class="math display">\[\begin{align*}
\Hy_0: \mu=0 \qquad \text{versus} \qquad \Hy_a:\mu \neq 0, 
\end{align*}\]</span>
la statistique de test de Wald est
<span class="math display">\[\begin{align*}
T &amp;= \frac{\overline{X}-0}{S_n/\sqrt{n}}
\end{align*}\]</span>
où <span class="math inline">\(\overline{X}\)</span> est la moyenne de l’échantillon <span class="math inline">\(X_1, \ldots, X_n\)</span>,
<span class="math display">\[\begin{align*}
\overline{X} &amp;= \frac{1}{n} \sum_{i=1}^n X_i
\end{align*}\]</span>
et l’erreur-type de la moyenne <span class="math inline">\(\overline{X}\)</span> est <span class="math inline">\(S_n/\sqrt{n}\)</span>; l’écart-type <span class="math inline">\(S_n\)</span> est un estimateur de <span class="math inline">\(\sigma\)</span>, où
<span class="math display">\[\begin{align*}
S^2_n &amp;= \frac{1}{n-1} \sum_{i=1}^n (X_i-\overline{X})^2.
\end{align*}\]</span></p>
</div>
<div id="loi-nulle-et-valeur-p" class="section level3" number="1.2.3">
<h3><span class="header-section-number">1.2.3</span> Loi nulle et valeur-<span class="math inline">\(p\)</span></h3>
<p>La <strong>valeur-<span class="math inline">\(p\)</span></strong> nous permet de déterminer si la valeur observée de la statistique de test <span class="math inline">\(T\)</span> est plausible sous <span class="math inline">\(\Hy_0\)</span>. Plus précisément, la valeur-<span class="math inline">\(p\)</span> est la probabilité que la statistique de test est égal or encore plus extrême de ce qu’on observe selon les données, en supposant que <span class="math inline">\(\Hy_0\)</span> est vraie. Suppose qu’on a un échantillon <span class="math inline">\(X_1, \ldots, X_n\)</span> et qu’on observe une valeur de la statistique de test de <span class="math inline">\(T=t\)</span>. Pour un test d’hypothèse bilatéral <span class="math inline">\(\Hy_0:\theta=\theta_0\)</span> vs. <span class="math inline">\(\Hy_a:\theta \neq \theta_0\)</span>, la valeur-<span class="math inline">\(p\)</span> est
<span class="math inline">\(\pr[0]{|T| \geq |t|}\)</span>, c’est-à-dire, la probabilité que <span class="math inline">\(|T|\)</span> est égal ou plus grand que ce qu’on observe, en valeur absolue, sous <span class="math inline">\(\Hy_0\)</span>. Si la distribution de <span class="math inline">\(T\)</span> est symétrique autour de <span class="math inline">\(0\)</span>, la valeur-<span class="math inline">\(p\)</span> vaut
<span class="math display">\[\begin{align*}
p = 2 \times \pr[0]{T \geq |t|}, 
\end{align*}\]</span></p>
<p>Prenons l’exemple d’un test d’hypothèse bilatéral pour la moyenne au population <span class="math inline">\(\Hy_0:\mu=0\)</span> contre <span class="math inline">\(\Hy_a:\mu \neq 0\)</span>. Si l’échantillon provient d’une (population de) loi normale <span class="math inline">\(\mathsf{No}(\mu, \sigma^2)\)</span>, on peut démontrer que, si <span class="math inline">\(\Hy_0\)</span> est vraie et donc, <span class="math inline">\(\mu=0\)</span>), la statistique de test
<span class="math display">\[\begin{align*}
T = \frac{\overline{X}}{S/\sqrt{n}}
\end{align*}\]</span>
suit une loi de Student-<span class="math inline">\(t\)</span> avec <span class="math inline">\(n-1\)</span> degrés de liberté. Avec cette loi nulle, on peut calculer la valeur-<span class="math inline">\(p\)</span> (ou bien à partir d’une table ou en utilisant un logiciel statistique). Puisque la distribution Student-<span class="math inline">\(t\)</span> est symétrique autour de <span class="math inline">\(0\)</span>, on peut calculer la valeur-<span class="math inline">\(p\)</span> comme <span class="math inline">\(P = 2\times\pr{T_{n-1} &gt; |t|}\)</span>, où <span class="math inline">\(T_{n-1}\)</span> dénote une variable aléatoire avec distribution de Student-<span class="math inline">\(t\)</span> avec <span class="math inline">\(n-1\)</span> degrés de liberté.</p>
</div>
<div id="conclusion" class="section level3" number="1.2.4">
<h3><span class="header-section-number">1.2.4</span> Conclusion</h3>
<p>La valeur-<span class="math inline">\(p\)</span> nous permet de faire une décision quant aux hypothèses du test. Si <span class="math inline">\(\Hy_0\)</span> est vraie, la valeur-<span class="math inline">\(p\)</span> suit une loi uniforme. Si la valeur-<span class="math inline">\(p\)</span> est petite, ça veut dire que le fait d’observer une statistique de test égal ou encore plus extrême que <span class="math inline">\(t\)</span> est peu probable, et donc nous aurons tendance de croire que <span class="math inline">\(\Hy_0\)</span> n’est pas vraie. Il y a pourtant toujours un risque sous-jacent qu’on fait un erreur quand on fait une décision. En statistique, il y a deux types d’erreurs:</p>
<ul>
<li>erreur de type I: on rejette <span class="math inline">\(\Hy_0\)</span> alors que <span class="math inline">\(\Hy_0\)</span> est vraie</li>
<li>erreur de type II: on ne rejette pas <span class="math inline">\(\Hy_0\)</span> alors que <span class="math inline">\(\Hy_0\)</span> est fausse</li>
</ul>
<p>Si le modèle générant les données est correct (sic), alors l’hypothèse nulle ou l’hypothèse alternative est vraie (ces deux scénarios couvrant l’univers des possibles).</p>
<table>
<thead>
<tr class="header">
<th align="left">Décision\ vrai modèle</th>
<th align="center"><span class="math inline">\(\Hy_0\)</span></th>
<th align="center"><span class="math inline">\(\Hy_a\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">ne pas rejeter <span class="math inline">\(\Hy_0\)</span></td>
<td align="center"><span class="math inline">\(\checkmark\)</span></td>
<td align="center">erreur de type II</td>
</tr>
<tr class="even">
<td align="left">rejeter <span class="math inline">\(\Hy_0\)</span></td>
<td align="center">erreur de type I</td>
<td align="center"><span class="math inline">\(\checkmark\)</span></td>
</tr>
</tbody>
</table>
<p>Comme chercheur, on doit fixer préalablement le niveau de risque que nous sommes prêt à tolérer. Si on connaît la distribution de <span class="math inline">\(T\)</span> sous <span class="math inline">\(\Hy_0\)</span>, on peut contrôler le risque de faire un erreur de type I. Ceci fait référence au <strong>niveau</strong> du test, dénoté par <span class="math inline">\(\alpha\)</span>:
<span class="math display">\[\begin{align*}
\alpha = \pr[0]{\text{ rejetter } \Hy_0}.
\end{align*}\]</span>
La valeur de <span class="math inline">\(\alpha \in (0, 1)\)</span> est la probabilité qu’on rejette <span class="math inline">\(\Hy_0\)</span> quand <span class="math inline">\(\Hy_0\)</span> est en fait vraie. Comme chercheur, on choisit ce niveau <span class="math inline">\(\alpha\)</span>; habituellement <span class="math inline">\(1\)</span>%, <span class="math inline">\(5\)</span>% ou <span class="math inline">\(10\)</span>%. Pour prendre une décision, on doit comparer la valeur-<span class="math inline">\(p\)</span> <span class="math inline">\(P\)</span> avec le niveau du test <span class="math inline">\(\alpha\)</span>:</p>
<ul>
<li>si <span class="math inline">\(P &lt; \alpha\)</span> on rejette <span class="math inline">\(\Hy_0\)</span>,</li>
<li>si <span class="math inline">\(P \geq \alpha\)</span> on ne rejette pas <span class="math inline">\(\Hy_0\)</span>.</li>
</ul>
</div>
<div id="puissance-statistique" class="section level3" number="1.2.5">
<h3><span class="header-section-number">1.2.5</span> Puissance statistique</h3>
<p>Quand on ne rejette pas <span class="math inline">\(\Hy_0\)</span> et que <span class="math inline">\(\Hy_a\)</span> est en fait vraie, on fait un erreur de type II. Dénotons par <span class="math inline">\(1-\beta\)</span> la probabilité de faire une erreur de type II, c’est-à-dire
<span class="math display">\[\begin{align*}
\beta = \pr[a]{\text{ rejetter} \Hy_0}
\end{align*}\]</span>
La <strong>puissance statistique</strong> d’un test est la probabilité que le test rejette <span class="math inline">\(\Hy_0\)</span> alors que <span class="math inline">\(\Hy_0\)</span> est fausse, soit <span class="math inline">\(\beta\)</span>. On veut qu’un test ait une puissance élevée, c’est-à-dire, on veut que <span class="math inline">\(\beta\)</span> soit le plus près de 1 possible. Minimalement, la puissance du test devrait être <span class="math inline">\(\alpha\)</span> parce qu’on rejette <span class="math inline">\(\alpha\)</span> pourcent du temps même quand l’hypothèse nulle est vraie. La variabilité des données et la taille de l’écart réel dans la population influent sur la puissance, mais nous n’avons pas de contrôle sur ces paramètres. À l’inverse, on peut augmenter la taille de l’échantillon pour augmenter la puissance. Le choix de la statistique de test influe aussi sur la puissance, mais les statistiques de test que nous choisirons sont souvent standard et parmi les plus puissantes qui soient, aussi on ne traitera pas de ce point dans le cadre de ce cours.</p>
</div>
<div id="intervalle-de-confiance" class="section level3" number="1.2.6">
<h3><span class="header-section-number">1.2.6</span> Intervalle de confiance</h3>
<p>Un <strong>intervalle de confiance</strong> est une manière alternative de rapporter les conclusions d’un test, en ce sent qu’on fournit une estimation ponctuelle de <span class="math inline">\(\hat{\theta}\)</span> avec une marge d’erreur. L’intervalle de confiance donne donc une indication de la variabilité de la procédure d’estimation. Un intervalle de confiance de Wald à <span class="math inline">\((1-\alpha)\)</span> pour un paramètre <span class="math inline">\(\theta\)</span> est de la forme
<span class="math display">\[\begin{align*}
\widehat{\theta} \pm \mathfrak{q}_{\alpha/2} \; \mathrm{se}(\widehat{\theta})
\end{align*}\]</span>
où <span class="math inline">\(\mathfrak{q}_{\alpha/2}\)</span> est le quantile d’ordre <span class="math inline">\(1-\alpha/2\)</span> de la loi nulle de la statistique de Wald <span class="math inline">\(T\)</span>, soit
<span class="math display">\[\begin{align*}
T =\frac{\widehat{\theta}-\theta}{\mathrm{se}(\widehat{\theta})}
\end{align*}\]</span>
et <span class="math inline">\(\theta\)</span> représente la valeur du paramètre <span class="math inline">\(\theta\)</span> (supposé fixe, mais inconnu) de la population. Les bornes de l’intervalle de confiance sont aléatoires puisque <span class="math inline">\(\widehat{\theta}\)</span> et <span class="math inline">\(\mathrm{se}(\widehat{\theta})\)</span> sont des variable aléatoires: leurs valeurs dépend sur l’échantillon et donc varient d’un échantillon à un autre.</p>
<p>Par exemple, pour un échantillon aléatoire <span class="math inline">\(X_1, \ldots, X_n\)</span> provenant d’une loi normale <span class="math inline">\(\mathsf{No}(\mu, \sigma)\)</span>, l’intervalle de confiance à <span class="math inline">\((1-\alpha)\)</span> pour la moyenne (dans la population) <span class="math inline">\(\mu\)</span> est
<span class="math display">\[\begin{align*}
\overline{X} \pm t_{n-1, \alpha/2} \frac{S}{\sqrt{n}}
\end{align*}\]</span>
où <span class="math inline">\(t_{n-1, \alpha/2}\)</span> est le quantile d’ordre <span class="math inline">\(1-\alpha/2\)</span> de la loi Student-<span class="math inline">\(t\)</span> avec <span class="math inline">\(n-1\)</span> degrés de libertés.</p>
<p>Avant qu’on calcule l’intervalle de confiance, il y a une probabilité de <span class="math inline">\(1-\alpha\)</span> que <span class="math inline">\(\theta\)</span> soit contenu dans l’intervalle <strong>aléatoire</strong> symmétrique <span class="math inline">\((\widehat{\theta} - \mathfrak{q}_{\alpha/2} \; \mathrm{se}(\widehat{\theta}), \widehat{\theta} + \mathfrak{q}_{\alpha/2} \; \mathrm{se}(\widehat{\theta}))\)</span>. Une fois qu’on a un échantillon et qu’on calcule les bornes de l’intervalle de confiance, il n’y a plus de notion de probabilité. La vraie valeur du paramètre <span class="math inline">\(\theta\)</span> est soit contenue dans l’intervalle de confiance, soit pas. La seule interprétation de l’intervalle de confiance qui soit valable alors est la suivante: si on répète l’expérience plusieurs fois et qu’à chaque fois on calcule un intervalle de confiance à <span class="math inline">\(1-\alpha\)</span>, alors <span class="math inline">\(1-\alpha\)</span> de ces intervalles devraient contenir la vraie valeur de <span class="math inline">\(\theta\)</span> (de la même manière, si vous lancez une pièce de monnaie équilibrée, vous devriez obtenir une fréquence de 50% de pile et 50% de face, mais chaque lancer donnera un ou l’autre de ces choix).</p>
<div class="figure" style="text-align: center"><span id="fig:intconf"></span>
<img src="MATH60604_Modelisation_statistique_files/figure-html/intconf-1.png" alt="Intervalles de confiance à 95\% pour la moyenne d'une population normale $\mathsf{No}(0,1)$. Environ 95 de ces 100 intervalles devraient inclure zéro." width="70%" />
<p class="caption">
Figure 1.1: Intervalles de confiance à 95% pour la moyenne d’une population normale <span class="math inline">\(\mathsf{No}(0,1)\)</span>. Environ 95 de ces 100 intervalles devraient inclure zéro.
</p>
</div>
<p>L’intervalle de confiance peut être considéré comme le pendant du test d’hypothèse. À niveau <span class="math inline">\(\alpha\)</span>, on ne rejetterait aucune des valeurs contenues dans l’intervalle de confiance de niveau <span class="math inline">\(1-\alpha\)</span>. Si la valeur-<span class="math inline">\(p\)</span> est inférieure à <span class="math inline">\(\alpha\)</span>, la valeur postulée pour <span class="math inline">\(\theta\)</span> est donc hors intervalle. La valeur-<span class="math inline">\(p\)</span> ne donne la probabilité que pour une valeur postulée, mais permet de quantifier à quel point le résultat est extrême.</p>
</div>
<div id="exemple-achat-en-ligne-de-milléniaux" class="section level3" number="1.2.7">
<h3><span class="header-section-number">1.2.7</span> Exemple: achat en ligne de milléniaux</h3>
<p>Supposons qu’un chercheur veut faire une étude sur l’évolution des ventes en ligne au Canada. Elle postule que la génération Y (les milléniaux) font plus d’achats en ligne que les générations antérieures. Pour répondre à cette question, un sondage est envoyé à un échantillon aléatoire de <span class="math inline">\(n=500\)</span> individus représentatif de la population avec 160 milléniaux et 340 personnes plus âgées issues des générations X et des baby-boomers. La variable <code>depenses</code> mesure le montant d’achat effectués en ligne dans le mois dernier (en dollars).</p>
<p>On pourrait simplement considérer la différence entre le montant moyen des Y et celui des autres générations; on standardise par l’écart-type de l’échantillon pour obtenir une valeur sans unité de mesure. La différence de moyenne observée dans l’échantillon est de 16.49 dollars et donc les milléniaux ont dépensé davantage. En revanche, notre échantillon est aléatoire et le montant d’achat en ligne d’un individu à l’autre (et d’un mois à l’autre) est variable.</p>
<p>La première étape de notre analyse consiste à définir les quantités d’intérêt et à formuler nos hypothèse en fonction de paramètres du modèle; il convient également de définir ces derniers. Dans cet exemple, on considère un test pour la différence de moyenne dans les populations postulées <span class="math inline">\(\mu_1\)</span> (pour la génération Y) et <span class="math inline">\(\mu_2\)</span> (pour les générations antérieures) d’écart-type respectif <span class="math inline">\(\sigma_1\)</span> et <span class="math inline">\(\sigma_2\)</span>. Comment déterminer quelle hypothèse on considère? Comme statisticien, on se fait l’avocat du Diable: l’hypothèse d’intérêt du chercheur est l’hypothèse alternative et ici, <span class="math inline">\(\Hy_a: \mu_1 &gt; \mu_2\)</span>, où <span class="math inline">\(\mu_1\)</span> représente la moyenne des achats mensuels des milléniaux. L’hypothèse nulle en toutes les autres valeurs, soit <span class="math inline">\(\Hy_0: \mu_1 \leq \mu_2\)</span>, mais il suffit de considérer le cas <span class="math inline">\(\mu_1=\mu_2\)</span> (pourquoi?). S’il n’y a aucune différence de moyenne entre les groupes, alors <span class="math inline">\(\overline{X}_1-\overline{X}_2\)</span> a moyenne zéro; la différence de moyenne a une variance de <span class="math inline">\(\sigma^2_1/n_1+\sigma^2_2/n_2\)</span>. Il y a toujours possibilité de commettre une erreur judiciaire (dit erreur de Type 1, c’est-à-dire de condamner un innocent ou rejeter <span class="math inline">\(\Hy_0\)</span> alors que l’hypothèse nulle est vraie). Pour se prémunir de ce risque, on fixe préalablement un niveau de tolérance. On effectuera le test à niveau <span class="math inline">\(\alpha=0.05\)</span>; cela veut dire que, si <span class="math inline">\(\Hy_0\)</span> est vraie, on commettra une erreur de type I en moyenne cinq fois sur 100. Plus on choisit un <span class="math inline">\(\alpha\)</span> petit, moins on arrivera à détecter quand l’hypothèse nulle est fausse (rappelez-vous que nous sommes intéressés à démontrer que l’hypothèse alternative).</p>
<p>La deuxième étape consiste à choisir une statistique de test. Ici, on considère la statistique de Welch (<span class="citation">Welch (<a href="#ref-Welch:1947" role="doc-biblioref">1947</a>)</span>) pour une différence de moyenne entre deux échantillons:
<span class="math display">\[\begin{align*}
T = \frac{\overline{X}_1 - \overline{X}_2}{\left(\frac{S_1^2}{n_1}+\frac{S_2^2}{n_2} \right)^{1/2}}, 
\end{align*}\]</span>
où <span class="math inline">\(\overline{X}_i\)</span> est la moyenne empirique dans l’échantillon <span class="math inline">\(i\)</span> (<span class="math inline">\(i=1, 2\)</span>) et <span class="math inline">\(S_i^2\)</span> est la variance empirique et <span class="math inline">\(n_i\)</span> la taille de l’échantillon du groupe <span class="math inline">\(i\)</span>. La statistique est utilisée pour calculer la différence de moyennes de deux échantillons de variance potentiellement différente. La valeur de la statistique dans l’échantillon est 2.76, mais on obtiendrait une valeur différente avec un autre échantillon. Il convient donc de déterminer si cette valeur est compatible avec notre hypothèse nulle en la comparant à la loi nulle sous <span class="math inline">\(\Hy_0\)</span> de <span class="math inline">\(T\)</span>.</p>
<p>La troisième étape est l’obtention d’un étalon de mesure pour déterminer si notre résultat est extrême ou inattendu. Vous remarquerez que la statistique de Welch a moyenne zéro et variance un sous l’hypothèse nulle que <span class="math inline">\(\mu_1=\mu_2\)</span>: standardiser une statistique permet d’obtenir un objet dont on connaît le comportement pour de grands échantillons.
Asymptotiquement, <span class="math inline">\(T\)</span> suit une loi normale <span class="math inline">\(\mathsf{No}(0, 1)\)</span>, mais il existe une meilleure approximation pour <span class="math inline">\(n\)</span> petit; on compare le comportement de <span class="math inline">\(T\)</span> à l’aide d’une loi de Student (approximation de <span class="citation">Satterthwaite (<a href="#ref-Satterthwaite:1946" role="doc-biblioref">1946</a>)</span>).</p>
<p>La dernière étape consiste à obtenir une valeur-<span class="math inline">\(p\)</span>, soit la probabilité d’observer un résultat aussi extrême sous <span class="math inline">\(\Hy_0\)</span>: l’avantage de la valeur-<span class="math inline">\(p\)</span> est que cette valeur est une probabilité (dans <span class="math inline">\([0, 1]\)</span>) et qu’elle suit une loi uniforme sous <span class="math inline">\(\Hy_0\)</span>. Puisque nous avons une hypothèse alternative unilatérale, on regarde la probabilité sous <span class="math inline">\(\Hy_0\)</span> que <span class="math inline">\(\pr[0]{T &gt; t}\)</span>. Cette <span class="math inline">\(p\)</span>-valeur vaut <span class="math inline">\(P=0\)</span> et donc, à niveau 5%, on rejette l’hypothèse nulle pour conclure que la génération Y dépense davantage en ligne que les générations antérieures.</p>
<p>Le choix du statu quo (typiquement <span class="math inline">\(\Hy_0\)</span>) s’explique plus facilement avec un exemple médical. Si vous voulez prouver qu’un nouveau traitement est meilleur que l’actuel (ou l’absence de traitement), vous devez démontrer hors de tout doute raisonnable que ce dernier ne cause pas de torts aux patients et offre une nette amélioration (pensez à Didier Raoult et ses allégations non-étayées voulant que la chloroquine, un antipaludique, soit efficace face au virus de la Covid19). Aux fins de démonstration, il faut amasser suffisamment de preuves: la puissance, qui correspond à notre habileté à détecter quand <span class="math inline">\(\Hy_0\)</span> est fausse, dépend de plusieurs critères, à savoir:</p>
<ul>
<li>la taille de l’effet: plus la différence est grande entre <span class="math inline">\(\Hy_0\)</span> et le comportement observé, plus il est facile de la détecter;</li>
<li>la variabilité: moins celle-ci est grande, plus il est facile de déterminer que la différence observée est significative;</li>
<li>la taille de l’échantillon: plus on a d’observations, plus notre capacité à détecter quelque chose augmente.</li>
</ul>
</div>
<div id="exemple-prix-de-billets-de-trains" class="section level3" number="1.2.8">
<h3><span class="header-section-number">1.2.8</span> Exemple: prix de billets de trains</h3>
<p>La compagnie nationale de chemin de fer <a href="https://www.renfe.com/">Renfe</a> gère les trains régionaux et les trains à haute vitesse dans toute l’Espagne. Les prix des billets venus sont disponibles en ligne. On s’intéresse ici à une seule ligne, Madrid–Barcelone. Notre question scientifique est la suivante: est-ce que le prix des billets pour un aller (une direction) est plus chère pour un retour? Pour ce faire, on considère uniquement un échantillon de billets au tarif Promotionnel pour des trains AVE. Notre statistique de test sera simplement la différence de moyenne entre les deux échantillons: la différence entre le prix en euros d’un train Madrid–Barcelone (<span class="math inline">\(\mu_1\)</span>) et le prix d’un billet Barcelone–Madrid (<span class="math inline">\(\mu_2\)</span>) est <span class="math inline">\(\mu_1-\mu_2\)</span> et notre hypothèse nulle est qu’il n’y a aucune différence de prix, soit <span class="math inline">\(\Hy_0: \mu_1-\mu_2=0\)</span>.</p>
<p>Plutôt que d’utiliser la loi asymptotique (due au théorème central limite et valide pour de grands échantillons), on peut considérer une approximation sous une hypothèse moins restrictive d’échangeabilité des données. Le <a href="https://www.jwilber.me/permutationtest/">test de permutation</a> consiste à permuter les observations. S’il n’y a aucune différence entre deux groupes, on peut permuter les étiquettes et recréer deux groupes de taille identique à notre échantillon original. On recalcule la statistique de test sur ces nouvelle données (pour toutes les permutations possible, mais typiquement pour un nombre aléatoire suffisamment grand): si la valeur de notre statistique observée sur l’échantillon original est extrême, c’est autant de preuve contre l’hypothèse nulle.</p>
</div>
</div>
<div id="analyse-exploratoire-de-données" class="section level2" number="1.3">
<h2><span class="header-section-number">1.3</span> Analyse exploratoire de données</h2>

</div>
</div>
<h3>References</h3>
<div id="refs" class="references">
<div id="ref-Satterthwaite:1946">
<p>Satterthwaite, F. E. 1946. “An Approximate Distribution of Estimates of Variance Components.” <em>Biometrics Bulletin</em> 2 (6): 110–14. <a href="http://www.jstor.org/stable/3002019">http://www.jstor.org/stable/3002019</a>.</p>
</div>
<div id="ref-Welch:1947">
<p>Welch, B. L. 1947. “The generalization of ‘Student’s’ problem when several population variances are involved.” <em>Biometrika</em> 34 (1–2): 28–35. <a href="https://doi.org/10.1093/biomet/34.1-2.28">https://doi.org/10.1093/biomet/34.1-2.28</a>.</p>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="index.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="regression-lineaire.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["MATH60604_Modelisation_statistique.pdf"],
"toc": {
"collapse": "section",
"scroll_highlight": true
},
"split_bib": false
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
