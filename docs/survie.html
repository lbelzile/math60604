<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>7 Analyse de survie | Modélisation statistique</title>
  <meta name="description" content="Ces notes forment un complément web du cours MATH 60604 (Modélisation statistique) offert à la M.Sc. en gestion (science des données et analytique d’affaires) à HEC Montréal." />
  <meta name="generator" content="bookdown 0.30 and GitBook 2.6.7" />

  <meta property="og:title" content="7 Analyse de survie | Modélisation statistique" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="Ces notes forment un complément web du cours MATH 60604 (Modélisation statistique) offert à la M.Sc. en gestion (science des données et analytique d’affaires) à HEC Montréal." />
  <meta name="github-repo" content="lbelzile/math60604" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="7 Analyse de survie | Modélisation statistique" />
  
  <meta name="twitter:description" content="Ces notes forment un complément web du cours MATH 60604 (Modélisation statistique) offert à la M.Sc. en gestion (science des données et analytique d’affaires) à HEC Montréal." />
  




  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="modeles-lineaires-mixtes.html"/>
<link rel="next" href="math.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>
<script src="libs/kePrint-0.0.1/kePrint.js"></script>
<link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet" />
<script src="libs/htmlwidgets-1.5.4/htmlwidgets.js"></script>
<script src="libs/plotly-binding-4.10.1/plotly.js"></script>
<script src="libs/typedarray-0.1/typedarray.min.js"></script>
<link href="libs/crosstalk-1.2.0/css/crosstalk.min.css" rel="stylesheet" />
<script src="libs/crosstalk-1.2.0/js/crosstalk.min.js"></script>
<link href="libs/plotly-htmlwidgets-css-2.11.1/plotly-htmlwidgets.css" rel="stylesheet" />
<script src="libs/plotly-main-2.11.1/plotly-latest.min.js"></script>



<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="css/style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Modélisation statistique</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Remarques</a></li>
<li class="chapter" data-level="1" data-path="intro.html"><a href="intro.html"><i class="fa fa-check"></i><b>1</b> Introduction à l’inférence statistique</a></li>
<li class="chapter" data-level="2" data-path="regression-lineaire.html"><a href="regression-lineaire.html"><i class="fa fa-check"></i><b>2</b> Régression linéaire</a></li>
<li class="chapter" data-level="3" data-path="vraisemblance.html"><a href="vraisemblance.html"><i class="fa fa-check"></i><b>3</b> Inférence basée sur la vraisemblance</a></li>
<li class="chapter" data-level="4" data-path="modeles-lineaires-generalises.html"><a href="modeles-lineaires-generalises.html"><i class="fa fa-check"></i><b>4</b> Modèles linéaires généralisés</a></li>
<li class="chapter" data-level="5" data-path="donnees-correlees-longitudinales.html"><a href="donnees-correlees-longitudinales.html"><i class="fa fa-check"></i><b>5</b> Données corrélées et longitudinales</a></li>
<li class="chapter" data-level="6" data-path="modeles-lineaires-mixtes.html"><a href="modeles-lineaires-mixtes.html"><i class="fa fa-check"></i><b>6</b> Modèles linéaires mixtes</a></li>
<li class="chapter" data-level="7" data-path="survie.html"><a href="survie.html"><i class="fa fa-check"></i><b>7</b> Analyse de survie</a></li>
<li class="chapter" data-level="8" data-path="math.html"><a href="math.html"><i class="fa fa-check"></i><b>8</b> Dérivations mathématiques</a></li>
<li class="chapter" data-level="" data-path="r.html"><a href="r.html"><i class="fa fa-check"></i><strong>R</strong></a></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">Publié avec bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Modélisation statistique</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="survie" class="section level1 hasAnchor" number="7">
<h1><span class="header-section-number">7</span> Analyse de survie<a href="survie.html#survie" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p>Dans le cadre de l’analyse de survie, on s’intéresse au temps jusqu’à ce qu’un événement survienne. On considère une variable réponse positive <span class="math inline">\(T_i\)</span>, qui représente le temps de survie avant que l’événement d’intérêt survienne pour le sujet <span class="math inline">\(i\)</span> (<span class="math inline">\(i=1, \ldots, n\)</span>). Le temps de survie <span class="math inline">\(T_i\)</span> est aussi appelé temps de défaillance et est généralement mesuré à des moments précis: ainsi, si la variable est continue (le temps exact en secondes), les données sont généralement discrètes (arrondies à la journée ou au mois près).
Parmi les exemples de phénomènes de survie hors contexte médical, on peut penser à</p>
<ul>
<li>le temps avant qu’une personne au chômage ne retrouve un emploi ou ne quitte le marché du travail</li>
<li>le temps d’attente avant qu’un client soit servi lors d’un appel téléphonique</li>
<li>le temps précédant l’annulation d’un abonnement à un gym</li>
</ul>
<p>Afin de bien définir le temps de survie <span class="math inline">\(T_i\)</span>, il faut avoir une notion du {temps d’entrée} (ou de départ) qui marque le début de la mesure (quand on démarre le chronomètre). Le temps d’entrée peut être le même pour tous les sujets (étude longitudinale), par exemple si on mesure la durée des études d’une cohorte d’étudiants pour compléter leurs études. Il peut également être différent d’un sujet à un autre, comme par exemple si une personne patiente au téléphone pour être servie.</p>
<p>{Censure}</p>
<p>% - La variable d’intérêt est le temps <span class="math inline">\(T_i\)</span> avant que l’événement survienne.
% - Cependant, au cours de la période d’étude, l’événement ne survient pas nécessairement pour chaque sujet.
Une des plus grandes difficultés avec l’analyse de survie est qu’.
Cela pourrait être parce que</p>
<ul>
<li><p>le sujet survit après la fin de la période d’étude,</p></li>
<li><p><span class="math inline">\(T\)</span> représente le temps de survie d’un individu après avoir été diagnostiqué avec un cancer</p></li>
<li><p>il se peut que le sujet soit toujours vivant à la fin de l’étude.</p></li>
<li><p>le sujet quitte l’étude avant la fin,</p></li>
<li><p><span class="math inline">\(T\)</span> représente le temps que ça prend à un étudiant pour compléter leur programme</p></li>
<li><p>il se peut que certains étudiants abandonnent leur programme.</p></li>
<li><p>un événement concurrentse produit, ce qui rend l’événement d’intérêt impossible.</p></li>
<li><p><span class="math inline">\(T\)</span> représente le nombre d’années de service avant la retraite pour des employées d’un entreprise</p></li>
<li><p>il se peut qu’un sujet décède avant de prendre sa retraite.</p></li>
</ul>
<p>%
%
%
% - Cela est appelée la {censure}.
%
%<br />
% - Quand un observation est censurée, c’est comme si nous avons que de l’information partielle sur le sujet.
%
%
%
%
%
%
% {Exemples de censure à droite}
% Le type de censure le plus commun est la {censure à droite}:
%
%
%<br />
%
%
%
%</p>
<p>{Censure}</p>
<ul>
<li><p>Il existe plusieurs types de censure</p></li>
<li><p>: on sait que l’événement se produit après un certain temps <span class="math inline">\(t\)</span>, c’est-à-dire <span class="math inline">\(T_i \geq t\)</span>.</p></li>
<li><p>: l’événement d’intérêt survient avant qu’on observe l’individu. C’est-à-dire, tout ce qu’on sait est que <span class="math inline">\(T&lt;t\)</span>.</p></li>
<li><p>: l’événement d’intérêt survient à un point inconnu dans un intervalle de temps, mais on ne sait pas quand exactement. C’est-à-dire, tout ce qu’on sait est que <span class="math inline">\(T \in [t_1,t_2]\)</span></p></li>
<li><p>Avec la censure, l’idée générale est qu’on ne sait la valeur précise de <span class="math inline">\(T\)</span>, mais on a tout de même de l’information concernant un intervalle dans laquelle <span class="math inline">\(T\)</span> peut tomber.</p></li>
<li><p>par ex: <span class="math inline">\(T&gt;t\)</span>, ou <span class="math inline">\(T&lt;t\)</span>, ou <span class="math inline">\(T \in [t_1,t_2]\)</span></p></li>
</ul>
<p>{Examples de censure}
- Supposons qu’un chercheur s’intéresse à l’âge à partir duquel les enfants sont capables d’écrire leur prénom.
- <span class="math inline">\(T\)</span> est le temps (en années) jusqu’à ce qu’un enfant puisse écrire son nom.
- Le chercheur suit un groupe d’enfants dans une classe de maternelle tout au long de l’année scolaire.
- Lorsque le chercheur arrive, certains enfants sont déjà capables d’écrire leur nom: <span class="math inline">\(T\)</span> est .
- Certains enfants apprennent à écrire leur prénom pendant les vacances de Noël: <span class="math inline">\(T\)</span> est . - Certains enfants ne savent toujours pas comment écrire leur nom rendu à la fin de l’année scolaire: <span class="math inline">\(T\)</span> est .</p>
<p>{Censure non-informative}</p>
<ul>
<li><p>Nous supposons généralement que la censure est {non-informative}.</p></li>
<li><p>C’est-à-dire, la censure est non-informative de l’événement; le temps de censure est indépendant du temps de survie.</p></li>
<li><p>Autrement dit, le temps de censure ne nous donne aucune information sur ce que pourrait être le temps de survie.</p></li>
<li><p>Un exemple de censure :</p></li>
<li><p>Supposons qu’un groupe de patients en phase terminale d’une maladie suit un traitement expérimental, et que ce traitement peut avoir des effets secondaires nocifs. Donc, pour des raisons éthiques, les patients qui deviennent très malades sont retirés de l’étude. Les patients qui sont retirés de l’étude auront un temps <span class="math inline">\(T\)</span> qui est censuré à droite. Cependant, ces patients qui abandonnent l’étude sont probablement en moins bonne santé et risquent davantage de mourir plus tôt.</p></li>
</ul>
<p>{Type de censure à droite non-informative}
On distingue entre plusieurs formes de censure à droite qui est non-informative:
- censure de type 1: la collecte de donnée prend fin au temps <span class="math inline">\(C\)</span>; toute observation résiduelle est censurée à droite.
- censure de type 2: on collecte des données jusqu’à un nombre prédéterminé <span class="math inline">\(k\)</span> d’événements.
- : le temps de survie observé est <span class="math inline">\(T_i = \min\{T_i^0, C_i\}\)</span>, où la durée de survie <span class="math inline">\(T_i^0\)</span> et le temps de censure <span class="math inline">\(C_i\)</span> sont des variables aléatoires .</p>
<p>{Troncation}
Dans certaines études, on collecte les données seulement pendant un créneau prédéterminé <span class="math inline">\([a, b]\)</span>.
- La trajectoire du temps est si le temps de survie excède zéro au temps <span class="math inline">\(a\)</span></p>
<p>Par exemple, lors d’une enquête sur le chômage, on considère toutes les personnes qui sont inscrites au chômage entre janvier et mars.
- Certaines personnes ont perdu leur emploi depuis plusieurs mois lors du début de l’enquête (troncation à gauche).
- Si la personne est toujours en recherche d’emploi à <span class="math inline">\(b\)</span>, elle sera censurée à droite (censure à droite de type 1).</p>
{Diagramme de Lexis}
<p>{ Diagramme de Lexis représentant les trajectoires temporelles. Les <span class="math inline">\(\mathrm{x}\)</span> dénotent les temps de défaillance observés, tandis que les <span class="math inline">\(\circ\)</span> indiquent les valeurs censurées. Les temps de survie résiduels au temps <span class="math inline">\(5\)</span> sont censurés. La trajectoire en rouge dénote un individu dont le temps de survie est tronqué à gauche.</p>
<p>{Fonctions de survie et de risque}</p>
<p>Soit <span class="math inline">\(T\)</span> la variable aléatoire représentant le temps de survie
%- On dénote la fonction de répartition <span class="math inline">\(F(t) = {\mathsf P}_{}\left(T \leq t\right)\)</span> et la fonction de densité <span class="math inline">\(f(t) = \mathrm{d}F(t) / \mathrm{d}t\)</span>.
- La {fonction de survie}, <span class="math inline">\(S(t) = {\mathsf P}_{}\left(T&gt;t\right)\)</span>, caractérise complètement la loi de <span class="math inline">\(T\)</span>.
- On veut souvent savoir quelles périodes présentent un plus fort taux de défaillance.
La {fonction de risque} (taux de défaillance, taux de risque) de <span class="math inline">\(T\)</span> est
<span class="math display">\[\begin{align*}
h(t) &amp;= \lim_{\delta \to 0} \frac{{\mathsf P}_{}\left(t &lt; T&lt;t + \delta \mid T&gt;t\right)}{\delta}
\\&amp;= \lim_{\delta \to 0} \frac{1}{\delta}\frac{{\mathsf P}_{}\left(t &lt; T &lt; t + \delta\right)}{{\mathsf P}_{}\left(T&gt;t\right)} \\&amp;= \frac{f(t)}{S(t)}
\end{align*}\]</span>
On peut interpréter la fonction de risque comme étant la probabilité instantanée de ``mourir’’ au temps <span class="math inline">\(t\)</span>, compte tenu de la survie jusqu’au temps <span class="math inline">\(t\)</span>.</p>
{Fonctions de survie et de risque}
<p>{</p>
<p>La fonction de survie décroît de <span class="math inline">\(S(0)=1\)</span> de manière monotone. Plus le risque <span class="math inline">\(h(t)\)</span> est élevé, plus la survie décroît rapidement.</p>
<p>}</p>
{Fonction de risque en forme de bain}
<p>{</p>
<p>Le risque initial est fort (mortalité infantile, défaut de fabrication) initialement, puis décroît et se stabilise. Au fil du temps, le risque augmente de nouveau (défaillance accrue avec l’âge).</p>
<p>}</p>
<p>{Censure aléatoire et vraisemblance}
On observe <span class="math inline">\(T_i = \min\{T_i^0, C_i\}\)</span>. Si une observation est censurée à droite au temps <span class="math inline">\(c\)</span>, on sait que <span class="math inline">\(S(c)={\mathsf P}_{}\left(T_i^0 &gt; c\right)\)</span>
- en d’autres mots, le temps de survie excède <span class="math inline">\(c\)</span>.</p>
<p>Si on a de la censure aléatoire, la base de données contient un indicateur <span class="math inline">\(\delta_i\)</span> où
<span class="math display">\[\begin{align*}
T_i =
\begin{cases}
T_i^0, &amp; \delta_i=1 \text{ (événement observé)}\\
C_i, &amp; \delta_i=0 \text{ (censure à droite)}
\end{cases}
\end{align*}\]</span></p>
<p>{Contribution à la vraisemblance}
Soit <span class="math inline">\(S(t; \boldsymbol{\theta}) = {\mathsf P}_{}\left(T_{i}^0 &gt; t\right)\)</span> la fonction de survie de <span class="math inline">\(T_i^0\)</span>. Avec <span class="math inline">\(T_i^0\)</span> indépendant de <span class="math inline">\(C_i\)</span>, chaque observation contribue
<span class="math display">\[\begin{align*}
L_i(\boldsymbol{\theta}) =
\begin{cases}
f(t_i; \boldsymbol{\theta}), &amp; \delta_i=1 \text{ (événement observé)}\\
S(t_i; \boldsymbol{\theta}), &amp; \delta_i=0 \text{ (censure à droite)}
\end{cases}
\end{align*}\]</span>
à la vraisemblance. La log vraisemblance s’écrit
<span class="math display">\[\begin{align*}
\ell(\boldsymbol{\theta}) \equiv \sum_{i: \delta_i=1} \ln f(t_i; \boldsymbol{\theta}) + \sum_{i: \delta_i=0} \ln S(t_i; \boldsymbol{\theta})
\end{align*}\]</span></p>
<p>{Approches pour l’inférence}</p>
<p>Plusieurs approches s’offrent à nous pour estimer la fonction de survie (ou la fonction de risque).
- paramétrique: choisir une famille de lois (Weibull, log normale, Gompertz, exponentielle) pour <span class="math inline">\(T\)</span>.</p>
<p>-[<span class="math inline">\(+\)</span>] permet d’incorporer des variables explicatives aisément
-[<span class="math inline">\(+\)</span>] estimés continus, permet d’extrapoler la courbe
-[<span class="math inline">\(-\)</span>] notre modèle peut être mal spécifié
-[<span class="math inline">\(-\)</span>] peu flexible: la loi peut mal s’ajuster aux données</p>
<ul>
<li>nonparamétrique: aucune distribution assumée.</li>
</ul>
<p>-[<span class="math inline">\(-\)</span>] pas de variables explicatives
-[<span class="math inline">\(+\)</span>] hypothèse minimales, garanties théoriques quand la taille de l’échantillon <span class="math inline">\(n\)</span> est grande.
-[<span class="math inline">\(+\)</span>] flexible.
-[<span class="math inline">\(-\)</span>] estimés discontinus,
-[<span class="math inline">\(-\)</span>] on ne peux extrapoler au delà du plus grand temps de défaillance observé.</p>
<p>{Modèles paramétriques pour la survie: loi exponentielle}
Soit <span class="math inline">\(T_i \simiid \mathsf{E}(\lambda)\)</span> des variables exponentielles d’espérance <span class="math inline">\(\lambda^{-1}\)</span>.
-
La fonction de survie de <span class="math inline">\(T\)</span> est <span class="math inline">\(S(T) = \exp(-\lambda t)\)</span> et
- la fonction de risque <span class="math inline">\(h(t)=\lambda\)</span> est .</p>
<p>La log vraisemblance pour un échantillon aléatoire de taille <span class="math inline">\(n\)</span> s’écrit
<span class="math display">\[\begin{align*}
\ell(\lambda) =\sum_{i=1}^n \{\delta_i \ln \lambda - \lambda T_i\}.
\end{align*}\]</span>
Le maximum de vraisemblance est $ =_{i=1}^n <em>i/ </em>{i=1}^n T_i $.</p>
<ul>
<li>L’estimé du temps de survie est infini si aucune défaillance n’est observée.</li>
<li>On obtient les erreurs-types à l’aide de la matrice d’information observée <span class="math inline">\(j(\widehat{\lambda}) = \sum_{i=1}^n \delta_i/\widehat{\lambda}^2\)</span>; les données censurées ne contribuent pas d’information.</li>
</ul>
<p>%
% {Régression probit}
% - On peut utiliser l’inférence basée sur la vraisemblance plus généralement pour d’autres scénarios de survie.
% -
% On considère une variable latente <span class="math inline">\(Z_i \sim \mathsf{No}(\mathbf{x}_i \boldsymbol{\beta}, 1)\)</span>, mais on observe
% <span class="math display">\[\begin{align*}
%  Y_i = \begin{cases}
%         0 &amp; Z_i \leq 0, \text{ (censure à gauche)}\\
%         1 &amp; Z_i &gt; 0  \text{ (censure à droite)}.
%        \end{cases}
% \end{align*}
% -  On a $\P{Y_i = 0} = \P{Z_i \leq 0} = %1-\P{Z_i-\mathbf{x}_i\bs{\beta} \leq -\mathbf{x}_i\bs{\beta}}=
% \Phi(-\mathbf{x}_i\bs{\beta})=1-\Phi(\mathbf{x}_i\bs{\beta})$.
% - Cela revient à ajuster un modèle linéaire généralisé pour des données binaires avec fonction de liaison $g(x)=\Phi^{-1}(x)$.
%
%



{Notation}
On considère $T$ une variable aléatoire continue et un échantillon de taille $n$.

%- Suppose we have $n$ subjects, for which we either observe the time until the event, or a (right) censored time.
- Supposons qu&#39;il y a $D$ temps distincts de défaillance.
- Soit $0 \leq t_1 &lt; t_2 &lt; \cdots &lt; t_D$ ces $D$ temps en ordre croissant.
- Soit $r_j$ le nombre d&#39;individus \emph{à risque} d&#39;expérimenter l&#39;événement au temps $t_j$.

- C&#39;est-à-dire, ces individus n&#39;ont toujours pas expérimenté l&#39;événement (et n&#39;ont pas été censuré) avant le temps $t_j$.
- Donc, $r_j$ est le nombre de survivants juste avant le temps $t_j$ qui sont à risques d&#39;expérimenter l&#39;événement au temps $t_j$.

- Soit $d_j \in \{0, \ldots, r_j\}$ le nombre d&#39;individus qui expérimentent l&#39;événement au temps $t_j$ (par exemple, il y a $d_j$ décès au temps $t_j$).



{Dérivation de l&#39;estimateur de Kaplan--Meier}
La probabilité de mourir dans l&#39;intervalle $(t_j, t_{j+1}]$ étant donné que l&#39;individu a survécu jusqu&#39;à $t_j$ est
\begin{align*}
  h_j = {\mathsf P}_{}\left(t_j &lt; T \leq t_{j+1} \mid T &gt; t_j\right)
%   \\&amp; = \frac{\P{t_j &lt; T \leq t_{j+1}}}{\P{T &gt; t_j} }
%   \\&amp;
  = \frac{S(t_j) - S(t_{j+1})}{S(t_j)}.
\end{align*}\]</span>
d’où une récursion qui donne <span class="math display">\[\begin{align*}
S(t) = \prod_{j: t_j &lt; t} (1-h_j).
\end{align*}\]</span>
L’estimateur de Kaplan–Meier est {non-paramétrique},
- on ne fait pas d’hypothèse sur la loi de probabilité de <span class="math inline">\(T_i\)</span>.
- on considère plutôt les <span class="math inline">\(\{h_j\}_{j=1}^D\)</span> comme des paramètres du modèle.</p>
<p>{Vraisemblance pour données discrètes}
- Chacun des décès au temps <span class="math inline">\(t_j\)</span> contribue <span class="math inline">\(h_j\)</span> à la vraisemblance
- la probabilité de défaillance à <span class="math inline">\(t_j\)</span> sachant qu’un individu a survécu jusque là.<br />
-
Les survivants au temps <span class="math inline">\(t_j\)</span> contributent <span class="math inline">\(1-h_j\)</span>.
-
On peut donc écrire la log vraisemblance comme
<span class="math display">\[\begin{align*}
\ell(\boldsymbol{h}) = \sum_{j=1}^D \{ d_j \ln(h_j) + (r_j-d_j)\ln(1-h_j)\},
\end{align*}\]</span>
soit la somme des contributions de variables binomiales du risque au temps <span class="math inline">\(t_j\)</span>.</p>
<p>{Optimisation des différents probabilité de survie}</p>
<ul>
<li>Si on différencie <span class="math inline">\(\ell(\boldsymbol{h})\)</span> par rapport à <span class="math inline">\(h_j\)</span>, on trouve <span class="math inline">\(\widehat{h}_j = d_j/r_j\)</span>.</li>
<li>L’estimateur de Kaplan–Meier pour la fonction de survie est
<span class="math display">\[\begin{align*}
\widehat{S}(t) = \prod_{t_j &lt; t} \left( 1 - \frac{d_j}{r_j} \right)
\end{align*}\]</span></li>
<li>Intuition: <span class="math inline">\(d_j/r_j\)</span> représente la probabilité conditionnelle de survivre jusqu’avant le temps <span class="math inline">\(t_j\)</span> et d’expérimenter l’événement au temps <span class="math inline">\(t_j\)</span>.</li>
</ul>
<p>{Le maximum de vraisemblance est indépendant de la valeur de <span class="math inline">\(S(\cdot)\)</span> à <span class="math inline">\(t_j\)</span>; on définit généralement que la fonction de survie est continue à gauche.}</p>
<p>{Exemple}
Les données tirées de Sedmak (1989) traitent de survie de patients atteints du cancer du sein et contiennent les variables suivantes:</p>
<ul>
<li>: temps de survie ou temps écoulé à la fin de l’étude (en mois)</li>
<li>: variable indicatrice pour la mort, pour censure, pour décès</li>
<li>: réaction à un examen immunohistochimique, soit négative () ou positive ()</li>
</ul>
<p>%<br />
%
% -[] {
% Ces données proviennent de (), comme l’illustre le livre par John P. Klein &amp; Melvin L. Moeschberger}
%</p>
{Statistiques descriptives pour }
<p>{
En pratique, l’utilisation de l’estimateur de Kaplan–Meier avec si peu de données est déconseillée. La qualité de l’approximation dépend fortement du nombre d’observations (correct si <span class="math inline">\(n \gg 1000\)</span>).</p>
<p>Les observations censurées fournissent beaucoup moins d’information que les temps de défaillance observés.</p>
<p>}</p>
<p>{Estimation de la fonction de survie }</p>
<p>{
L’argument indique la variable de temps <span class="math inline">\(T_i\)</span> () et l’indicateur de censure <span class="math inline">\(\delta_i\)</span>, incluant la valeur de référence pour les observations censurées à droite ()</p>
<p>}</p>
{Estimé de la fonction de survie}
{Graphique de la fonction de survie}
<p>{ </p>
<p>La courbe de survie estimée est déficiente: <span class="math inline">\(\widehat{S}(t)\)</span> ne descend jamais à <span class="math inline">\(0\)</span> parce que le temps de survie le plus long dans les données est censuré à droite.</p>
<p>}</p>
<p>%
%<br />
% - On voit que la dernière observation de temps à <span class="math inline">\(t=189\)</span> est représenté par une coche dans le graphique car l’observation est censurée.
% - La dernière baisse de <span class="math inline">\(\widehat{S}(t)\)</span> sera à <span class="math inline">\(t_D\)</span>: le plus grand temps de décès observé.<br />
%
% \begin{center}
%
% \end{center}
%
%
%
%</p>
<p>{Durée de l’allaitement}
La base de données contient des données provenant de l’Enquête longitudinale nationale sur les jeunes sur la durée de la période d’allaitement de mères depuis la naissance de leur bébé. On se concentre sur les variables suivantes:</p>
<ul>
<li>: durée de l’allaitement (en semaines)</li>
<li>: variable indicatrice de la fin de l’allaitement,</li>
<li>soit observée ()</li>
<li>soit censurée ()</li>
</ul>
<p>%- : race of mother (1=white, 2=black, 3=other)
%- : poverty status of mother (1=yes, 0=no)
%- : smoking status of mother at birth of child (1=yes, 0=no)
%- : alcohol-drinking status of mother at birth of child (1=yes, 0=no)
%- age of mother at birth of child
%- year of child’s birth
%- : education level of mother (years of school)
%- : lack of prenatal care status (1= mother did not seek within first 3 months, 0=mother sought prenatal care in first three months of pregnancy)</p>
<p>%
% -[] {Ces données proviennent de l’Enquête longitudinale nationale sur les jeunes, tels qu’illustrés dans le livre par John P. Klein &amp; Melvin L. Moeschberger}
%</p>
<p>{Courbe de survie pour les données }</p>
<p>{<span class="math inline">\(\widehat{S}(t)\)</span> atteindra zéro puisque le plus grand temps de survie est observé.</p>
<p>}</p>
<p>%
%
% {Exemple}
%
% - Dans cet exemple, la courbe de survie estimée atteint <span class="math inline">\(0\)</span>.
% - C’est parce que le temps de survie le plus grand dans les données n’est pas censuré:
%
%<br />
%
% %\begin{center}
% \begin{tabular}{c c}
% %\begin{footnotesize}
% &amp; \
% 192 &amp; 1
% %\end{footnotesize}
% \end{tabular}
% %\end{center}
%
% - La dernière baisse dans <span class="math inline">\(\widehat{S}(t)\)</span> atteindra zéro puisque le plus grand temps de survie observé dans les données est en fait le dernier temps d’événement <span class="math inline">\(t_D\)</span>.<br />
%
% \begin{center}
%
% \end{center}
%
%
%</p>
<p>{La médiane de survie}
La médiane du temps de survie est le temps <span class="math inline">\(t_M\)</span> auquel <span class="math inline">\(S(t_M)=0.5\)</span>.</p>
<ul>
<li>C’est-à-dire, le temps médian <span class="math inline">\(t_M\)</span> est tel que <span class="math inline">\(50\%\)</span> des individus survivent jusqu’au temps <span class="math inline">\(t_M\)</span>.</li>
</ul>
On peut facilement trouver la médiane du temps de survie en cherchant le temps <span class="math inline">\(t\)</span> o`u la ligne horizontale <span class="math inline">\(\widehat{S}(t) = 0.5\)</span> croise la courbe de survie.
<p>%
% {La médiane de survie}
%
% - SAS va automatiquement calculer la médiane du temps de survie.
% - Dans les données sur les patients avec le cancer du sein, on obtient un temps de survie médian de <span class="math inline">\(89\)</span>
%<br />
% \begin{center}
%
% \end{center}
% - Notez que si le temps observé le plus long est {censuré} et que la courbe de survie estimée atteint un plateau qui est plus {élevé} que la ligne horizontale de <span class="math inline">\(0.5\)</span>, alors nous ne pourrons pas estimer la médiane du temps de survie.
% \begin{center}
%
% \end{center}
%
%</p>
<p>{Moyenne de la survie}
Pour une variable aléatoire positive, <span class="math inline">\(T&gt;0\)</span>, on peut démontrer que
<span class="math display">\[\begin{align*}
{\mathsf E}_{}\left(T\right) = \int_0^{\infty} S(t) \mathrm{d}t
\end{align*}\]</span>
On peut estimer l’espérance du temps de survie <span class="math inline">\({\mathsf E}_{}\left(T\right)\)</span> en calculant l’aire sous la courbe de survie estimée <span class="math inline">\(\widehat{S}(t)\)</span>.</p>
<ul>
<li>Par exemple, le temps de survie moyen pour les données d’allaitement est <span class="math inline">\(16.89\)</span> semaines avec erreur-type <span class="math inline">\(0.614\)</span> semaines.</li>
<li>Si le temps observé le plus long est {censuré}, la courbe de survie estimée <span class="math inline">\(\widehat{S}(t)\)</span> va atteindre un plateau et ne descendra jamais à <span class="math inline">\(0\)</span>. L’aire sous la courbe est infinie.</li>
<li>Dans ce cas, on peut plutôt estimer le temps de survie moyen limité: <span class="math inline">\({\mathsf E}_{}\left(\min\{T,\tau\}\right)\)</span> pour une valeur choisie <span class="math inline">\(\tau\)</span>. C’est-à-dire, nous calculerons le temps de survie moyen comme si la courbe descendait à <span class="math inline">\(0\)</span> au temps <span class="math inline">\(\tau\)</span> (option dans ).</li>
</ul>
<p>{Motivation}</p>
<ul>
<li><p>L’estimateur de Kaplan–Meier permet d’estimer de manière nonparamétrique la fonction de survie.</p></li>
<li><p>Qu’est-ce qu’on ferait si on voulait mesurer l’effet de variables explicatives <span class="math inline">\(\mathrm{X}_1, \ldots, \mathrm{X}_p\)</span> sur la survie?</p></li>
<li><p>avec des variables catégorielles (et beaucoup de données), on pourra estimer la fonction pour chaque sous-groupe à l’aide de l’estimateur de Kaplan–Meier.</p></li>
<li><p>cette approche ne fonctionne pas si <span class="math inline">\(\mathrm{X}_j\)</span> est continue ou le nombre d’observations par groupe est petite.</p></li>
</ul>
<p>%
%
% {Modèle à risques proportionnels de Cox}
%
% - Le modèle de Cox à risques proportionnels est un modèle {semi-paramétrique} pour la fonction de risque <span class="math inline">\(h(t)\)</span>.
%
%<br />
% - C’est un modèle semi-paramétrique car il comprend à la fois une partie paramétrique et une partie non-paramétrique.
% - La partie paramétrique du modèle est paramétrisée en terme de coefficients de régression <span class="math inline">\(\beta_1, \ldots, \beta_p\)</span>, qui mesure les effets des variables explicatives sur la survie.
%
%
%</p>
<p>{Fonction de risque cumulative}</p>
<p>Pour <span class="math inline">\(T\)</span> continue<span class="math inline">\({}^*\)</span>, la fonction de risque cumulative est
<span class="math display">\[\begin{align*}
H(t) = \int_{0}^{t} h(u) \mathrm{d}u = \int_0^t \frac{f(u)}{S(u)}\mathrm{d}u = -\ln\{S(t)\}
\end{align*}\]</span>
et donc on peut écrire la fonction de survie<br />
<span class="math display">\[\begin{align*}
S(t) = \exp\{-H(t)\}.
\end{align*}\]</span></p>
<p>On peut aussi écrire la log vraisemblance en terme de la fonction de risque (cumulative)
<span class="math display">\[\begin{align*}
\ell(\boldsymbol{\theta}) = \sum_{i=1}^n \{\delta_i \ln h(t_i; \boldsymbol{\theta}) - H(t_i; \boldsymbol{\theta})\}
\end{align*}\]</span></p>
<p>%
% {Fonction de risque}
%
% - Pour un temps de survie <span class="math inline">\(T\)</span>, la {fonction de survie} est <span class="math inline">\(S(t) = {\mathsf P}_{}\left(T&gt;t\right)\)</span>
% -[] et la {fonction de répartition} est <span class="math inline">\(F(t) = {\mathsf P}_{}\left(T\leq t\right)\)</span>
%
% - Rappel: on peut écrire la fonction de survie en terme de la fonction de répartition:
% <span class="math display">\[\begin{align*}
% S(t) = 1 - F(t)
% \end{align*}
% - La {fonction de risque} (ou {taux de défaillance} ou {taux de risque}) est définie comme
% \begin{align*}
% h(t) = \lim_{\delta \to 0} \frac{\P{t &lt; T&lt;t + \delta \mid T&gt;t}}{\delta} = \lim_{\delta \to 0} \frac{1}{\delta}\frac{\P{t&lt;T&lt;t + \delta}}{\P{T&gt;t}}
% \end{align*}
% - On peut interpréter la fonction de risque comme étant la probabilité instantanée de ``mourir&#39;&#39; au temps $t$, compte tenu de la survie jusqu&#39;au temps $t$.
% %- \emph{We can think of the hazard rate as being the instantaneous probability of ``dying&#39;&#39; at temps $t$, given survival to temps $t$. }
%
%

%
% {Fonction de risque}
%
% - Quand $T$ est continue, on peut montrer que la fonction de risque est en fait
% \begin{align*}
% h(t) = \frac{-\d \ln S(t) }{\d t}
% \end{align*}
% - On peut donc écrire la {fonction de survie} en terme de la {fonction de risque}:
% \begin{align*}
% S(t) = \exp\left\{ - \int_0^t h(u) \d u \right\}
% \end{align*}
% - Alors, si on connait la fonction de survie, on peut établir la fonction de risque, et vice versa.
% - Connexion entre la courbe de survie et la fonction de risque:
%
%  
% - un taux de risque plus faible à $t$ implique une probabilité plus faible que l&#39;événement (ex. la mort) survienne; la courbe de survie a une pente moins prononcée à $t$
% - un taux de risque plus élevé implique une plus grande probabilité que l&#39;événement (ex. la mort) survienne; la pente de la courbe de survie est plus abrupte à $t$.
%
%
%


{Postulat de risques proportionnels}
Dans le modèle à risques proportionnels, la fonction de risque est
\begin{align*}
h(t; \mathbf{x}_i) = h_0(t)\exp(\mathbf{x}_i\boldsymbol{\beta})
\end{align*}\]</span>
où
- la fonction de risque de base, <span class="math inline">\(h_0(t)\)</span> est le seul terme de droite qui varie dans le temps.
- l’hypothèse dite de {risques proportionnels} est que le rapport <span class="math inline">\(h(t; \mathbf{x}_i)/h(t; \mathbf{x}_j)\)</span> est constant peut importe la valeur de <span class="math inline">\(t\)</span>.
- l’interprétation des effets des variables explicatives est simplifiée, parce que ces effets ne varient pas avec le temps.
- ce postulat est très restrictif et doit être validé en pratique, mais il est particulièrement commode pour les dérivations.</p>
<p> il n’y a pas d’ordonnée à l’origine dans le modèle de Cox: cette dernière est incorporée dans <span class="math inline">\(h_0(t)\)</span>.
% Avec l’hypothèse de risque proportionnels, la fonction de survie devient
% <span class="math display">\[
% S(t; \mathbf{x}_i) = \exp\left\{H_0(t_j)\right\}^{\exp(\mathbf{x}_i\bs{\beta})}
% \]</span>
% et la fonction de densité
% <span class="math display">\[\begin{align*}
% f(t; \mathbf{x}_i) = \exp(\bs{\beta}\mathbf{x}_i) h_0(t) S_0(t)^{\exp(\bs{\beta}\mathbf{x}_i)}.
% \end{align*}


{Dérivation du modèle à risques proportionnels}
On considère les temps de défaillance observés $0 \leq t_1 &lt; \cdots &lt; t_D$, supposés uniques (pas de doublons) pour simplifier la dérivation.


La fonction de risque cumulative de base,
\[
H_0(t) = \sum_{j: t_j \leq t} h_0(t_j),
\] est une fonction escalier avec des sauts uniquement aux temps de défaillance observés.

On considère
- $\mathcal{R}_j$, l&#39;ensemble des individus à risques au temps $t_j$
- $\delta_i$, un indicateur binaire qui vaut $1$ en cas de défaillance observée, et $0$ si l&#39;observation est censurée à droite.




{Fonction de vraisemblance du modèle de Cox}
Soit $h_j = h_0(t_j)$ et $g_i=\exp(\mathbf{x}_i \boldsymbol{\beta})$. La log vraisemblance est
\begin{align*}
  \ell(\boldsymbol{h}, \boldsymbol{\beta}) &amp;= \sum_{i=1}^n \left[ \delta_i \ln \{\exp(\mathbf{x}_i \boldsymbol{\beta})h_i\}-\exp(\mathbf{x}_i \boldsymbol{\beta})H_0(t_j)\right]
  \\&amp; =  \sum_{i=1}^n \left\{ \delta_i \mathbf{x}_i \boldsymbol{\beta} + \delta_i \ln h_i -h_i \sum_{j \in \mathcal{R}_i}\exp(\mathbf{x}_j \boldsymbol{\beta})\right\}
\end{align*}\]</span></p>
<ul>
<li>Puisqu’on s’intéresse principalement aux effets des variables explicatives <span class="math inline">\(\mathbf{X}\)</span>, on considère les paramètres <span class="math inline">\(h_1,\ldots, h_D\)</span> comme des paramètres de nuisance.</li>
<li>Si <span class="math inline">\(\boldsymbol{\beta}\)</span> est fixe, le maximum de vraisemblance de <span class="math inline">\(h_i\)</span> est <span class="math inline">\(\widehat{h}_i = \delta_i/\sum_{j \in \mathcal{R}_i} \exp(\mathbf{x}_j \boldsymbol{\beta})\)</span>.</li>
<li>Ce estimé est positif seulement si <span class="math inline">\(\delta_i=1\)</span> (temps de défaillance observé).</li>
</ul>
<p>{Vraisemblance profilée du modèle de Cox}
On peut dériver la log vraisemblance profilée pour <span class="math inline">\(\boldsymbol{\beta}\)</span>,
<span class="math display">\[\begin{align*}
  \ell_{\mathrm{p}}(\boldsymbol{\beta}) = \max_{\boldsymbol{h}}  \ell(\boldsymbol{h}, \boldsymbol{\beta})  = \sum_{i=1}^n \delta_i \ln \left( \frac{\exp(\mathbf{x}_i\boldsymbol{\beta})}{\sum_{j \in \mathcal{R}_i}\exp(\mathbf{x}_j\boldsymbol{\beta})}\right)
\end{align*}\]</span>
Il suffit alors de maximiser <span class="math inline">\(\ell_{\mathrm{p}}(\boldsymbol{\beta})\)</span>.
Même si ce modèle a un nombre de paramètres qui excède le nombre d’observations (!), <span class="math inline">\(\ell_{\mathrm{p}}(\boldsymbol{\beta})\)</span> se comporte à toute fin pratique comme une vraisemblance ordinaire.
- Erreurs-type via l’information observée.
- Tests de rapport de vraisemblance, du score ou de Wald pour les paramètres <span class="math inline">\(\boldsymbol{\beta}\)</span>.</p>
<p>{
La situation est plus complexe s’il y a des doublons, mais les ajustements sont faits automatiquement par les logiciels (plusieurs options disponibles, certaines meilleurs et plus coûteuses que d’autres).</p>
<p>}</p>
<p>Une fois les estimateurs du maximum de vraisemblance <span class="math inline">\(\widehat{\boldsymbol{\beta}}\)</span> recouvrés, on obtient la fonction de risque cumulative estimée
<span class="math display">\[\begin{align*}
  \widehat{H}_0(t) &amp;= \sum_{i: t_i \leq t} \frac{\delta_i}{\sum_{j \in \mathcal{R}_i} \exp(\mathbf{x}_j\widehat{\boldsymbol{\beta}})},
  \intertext{d&#39;où l&#39;estimé de la fonction de survie avec covariables $\mathbf{x}$,}
  \widehat{S}(t; \mathbf{x}) &amp;= \exp\left\{-\exp(\mathbf{x}\widehat{\boldsymbol{\beta}})\widehat{H}_0(t)\right\}.
\end{align*}\]</span></p>
<p>%
%
%
% - Le modèle de Cox à risques proportionnels spécifie la fonction de risque comme étant une fonction des variables explicatives.
% - Pour un sujet <span class="math inline">\(i\)</span> avec des variables explicatives <span class="math inline">\(\mathrm{X}_{i1}, \ldots, \mathrm{X}_{ip}\)</span>, la fonction de risque <span class="math inline">\(h_i(t)\)</span> est écrit comme
% <span class="math display">\[\begin{align*}
% h_i(t) = h_0(t) \exp(\beta_1 \mathrm{X}_{i1} + \cdots + \beta_p \mathrm{X}_{ip})
% \end{align*}
% - Dans ce modèle, $h_0(t)$ est la fonction de risque de base (``baseline hazards&#39;&#39;).
%
%  
% - Il s&#39;agit du taux de risque quand toutes les variables explicatives sont $0$.
% - Notez qu&#39;il n&#39;y a pas de paramètre $\beta_0$ pour l&#39;ordonnée à l&#39;origine --- cette dernière est absorbée dans la fonction de risque de base $h_0(t)$.
% - Le modèle de Cox à risques proportionnels n&#39;estemps pas le risque de base $h_0(t)$, il est simplement inclus dans le modèle implicitement\ldots
%
% - Remarquez que la partie régression du modèle, $\beta_1\mathrm{X}_{i1} + \cdots + \beta_p \mathrm{X}_{ip}$, ne dépend pas sur le temps $t$! Seul le risque de base $h_0(t)$ dépend sur le temps $t$.
%
%
%
%
% {Modèle de Cox à risques proportionnels}
% \begin{align*}
% h_i(t) = h_0(t) \exp(\beta_1 \mathrm{X}_{i1} + \cdots + \beta_p \mathrm{X}_{ip})
% \end{align*}
%
% - Pour les modèles de régression on est principalement intéressé à mesurer les effets des variables $\mathrm{X}_1, \ldots, \mathrm{X}_p$ sur la variable réponse $T$.
% - Dans le cadre du modèle de Cox à risques proportionnels, ça veut dire qu&#39;on n&#39;est pas vraiment intéressé par le risque de base $h_0(t)$, et on est plutôt intéressé à la partie régression $\exp(\beta_1 \mathrm{X}_1 + \cdots + \beta_p \mathrm{X}_p)$.
% - Le fait que la partie régression du modèle ne dépend pas sur le temps $t$ permet pour une interprétation simplifiée des effets des variables explicatives, parce que ces effets ne varient pas avec le temps!
% - Comme on a vu plus tôt, il y a une relation entre la fonction de risque et la fonction de survie. Alors, le modèle de Cox à risques proportionnels permet de mesurer les effets des variables explicatives sur la fonction de risque et aussi sur la fonction de survie.  
%
%


{Interprétations des paramètres}

- Pour interpréter les paramètres du modèle de Cox à risques proportionnels, on peut comparer les taux de risques (modèle multiplicatif).
- Prenons deux individus qui sont presque identiques, sauf que leurs valeurs pour la variable $\mathrm{X}_j$ diffère par une unité.

- Pour l&#39;individu $i$ avec $\mathrm{X}_{ij}=\mathrm{x}_j$, la fonction de risque est
\begin{align*}
h(t; \mathbf{x}_i) = h_0(t) \exp(\beta_1 \mathrm{x}_1 + \cdots + \beta_j \mathrm{x}_j+\cdots + \beta_p \mathrm{x}_p)
\end{align*}\]</span>
- Pour l’individu <span class="math inline">\(k\)</span> avec <span class="math inline">\(\mathrm{X}_{kj}=\mathrm{x}_j+1\)</span>, la fonction de risque est
<span class="math display">\[\begin{align*}
h(t; \mathbf{x}_k) = h_0(t) \exp(\beta_1 \mathrm{x}_1 + \cdots + \beta_j (\mathrm{x}_j+1)+\cdots + \beta_p \mathrm{x}_p)
\end{align*}\]</span></p>
<ul>
<li>Le {rapport} des fonctions de risque est
<span class="math display">\[\begin{align*}
\frac{h(t; \mathbf{x}_k)}{h(t; \mathbf{x}_i)} &amp;=
% \frac{h_0(t) \exp(\beta_1 \mathbf{x}_1 + \ldots + \beta_j (\mathbf{x}_j+1)+\ldots + \beta_p \mathbf{x}_p)}{h_0(t) \exp( \beta_1 \mathbf{x}_1 + \ldots + \beta_j \mathbf{x}_j+\ldots + \beta_p \mathbf{x}_p)} \\
% &amp;= \frac{\exp(\beta_j(\mathbf{x}_j+1)}{\exp(\beta_j \mathbf{x}_j)} \\ &amp;=
\exp(\beta_j)
\end{align*}\]</span></li>
</ul>
<p>{Rapport de risque}</p>
<ul>
<li><p>Pour chaque augmentation d’une unité pour la variable <span class="math inline">\(\mathrm{X}_j\)</span>, la fonction de risque sera {multipliée} par un facteur <span class="math inline">\(\exp(\beta_j)\)</span>, .
% - La quantité <span class="math inline">\(\exp(\beta_j)\)</span> est appelée le {rapport de risques}.
% (``hazard ratio’’ ou HR), car elle représente le rapport des taux de risques.</p></li>
<li><p>Si <span class="math inline">\(\exp(\beta_j)=1\)</span>, <span class="math inline">\(\mathrm{X}_j\)</span> n’a pas d’effet sur la fonction de risque.</p></li>
<li><p>Si <span class="math inline">\(\exp(\beta_j)&gt;1\)</span>, le taux de risque quand <span class="math inline">\(\mathrm{X}_j\)</span> augmente.</p></li>
<li><p>Des valeurs plus élevées de <span class="math inline">\(\mathrm{X}_j\)</span> correspondent à un risque plus élevé que l’événement survienne, et donc un temps de survie plus court.</p></li>
<li><p>Si <span class="math inline">\(\exp(\beta_j)&lt;1\)</span>, le taux de risque quand <span class="math inline">\(\mathrm{X}_j\)</span> augmente.</p></li>
<li><p>Des valeurs plus élevées de <span class="math inline">\(\mathrm{X}_j\)</span> correspondent à un risque moins élevé que l’événement survienne, et donc un temps de survie plus long.</p></li>
</ul>
<p>%
% {Interprétations des paramètres}
%
% - Alors, pour chaque augmentation d’une unité pour la variable <span class="math inline">\(\mathrm{X}_j\)</span>, la fonction de risque sera {multipliée} par un facteur de <span class="math inline">\(\exp(\beta_j)\)</span>, lorsque {toutes les autres variables restent inchangées.}
% - La quantité <span class="math inline">\(\exp(\beta_j)\)</span> est appelée le {ratio de risque} (``hazard ratio’’ ou HR), car elle représente le rapport des taux de risques.
%
%<br />
% - Si <span class="math inline">\(\exp(\beta_j)=HR=1\)</span>, ça veut dire que le ratio <span class="math inline">\({h_i(t)}/{h_k(t)}=1\)</span>, et donc <span class="math inline">\(\mathrm{X}_j\)</span> n’a pas d’effet sur la fonction de risque.
% - Si <span class="math inline">\(\exp(\beta_j)=HR&gt;1\)</span>, le ratio <span class="math inline">\({h_i(t)}/{h_k(t)}&gt;1\)</span>, et donc le taux de risque {augmente} quand <span class="math inline">\(\mathrm{X}_j\)</span> augmente.
%
%<br />
% - Cela signifie que des valeurs plus élevées de <span class="math inline">\(\mathrm{X}_j\)</span> correspondent à un risque plus élevé que l’événement survienne, et donc des prévisions de temps de survie plus courts.
%
% - Si <span class="math inline">\(\exp(\beta_j)=HR&lt;1\)</span>, le ratio <span class="math inline">\({h_i(t)}/{h_k(t)}&lt;1\)</span>, et donc le taux de risque {diminue} quand <span class="math inline">\(\mathrm{X}_j\)</span> augmente.
%
%<br />
% - Cela signifie que des valeurs plus élevées de <span class="math inline">\(\mathrm{X}_j\)</span> correspondent à un risque moins élevé que l’événement survienne, et donc des prévisions de temps de survie plus longs.
%
%
%
%</p>
<p>{Exemple avec données }
Le fichier contient des données de survie pour des patients atteints d’une tumeur maligne, un mélanome qui a été enlevé lors d’une opération chirurgicale. La base de données contient les variables suivantes:</p>
<p>{ </p>
<p>-sep0em
- : temps de survie (en jours) depuis l’opération
- : si le patient est mort, si le temps est censuré
- : sexe du patient, soit pour les hommes et pour les femmes
- : l’âge (an années) au moment de l’opération
% - : l’année de l’opération
- : l’épaisseur (en mm) de la tumeur
- : variable indicatrice, en cas d’ulcération, sinon.</p>
<p>}</p>
{Statistiques descriptives pour données }
<p>{Modèle de Cox pour données }
Le modèle de Cox à risques proportionnels est
<span class="math display">\[\begin{align*}
h(t) = h_0(t) \exp( \beta_1 \code{sexe} + \beta_2 \code{age} + \beta_3 \code{epaisseur} + \beta_4 \code{ulcere})
\end{align*}\]</span>
On peut ajuster ce modèle dans avec la procédure :</p>
<p>{Tests basés sur la vraisemblance}</p>
<p>{
La sortie inclut la valeur de la log vraisemblance avec et sans variables explicatives, et les tests usuels pour <span class="math inline">\(\Hy_0: \boldsymbol{\beta}=\boldsymbol{0}_p\)</span> versus <span class="math inline">\(\Hy_a: \boldsymbol{\beta} \neq \boldsymbol{0}_p\)</span>.</p>
<p>}</p>
<p>{Coefficients estimés du modèle de Cox}</p>
<p>%</p>
<p>{Interprétation}</p>
<ul>
<li>Pour la variable , <span class="math inline">\(\exp(\widehat{\beta}_1)=1.542\)</span> représente le rapport de risque entre un homme et une femme du même âge, avec la même épaisseur de tumeur et le même état d’ulcération. Ainsi, le taux de risque pour les hommes est <span class="math inline">\(1.542\)</span> fois celui pour les femmes, lorsque toutes les autres variables restent inchangées.</li>
<li>Pour la variable , <span class="math inline">\(\exp(\widehat{\beta}_3)=1.115\)</span>. Pour chaque augmentation de <span class="math inline">\(1\)</span>mm de l’épaisseur de la tumeur, le taux de risque augmente d’un facteur de <span class="math inline">\(1.115\)</span> (ou <span class="math inline">\(11.5\)</span>%), lorsque toutes les autres variables restent inchangées.</li>
</ul>
<p>%</p>
<p>{Comparaison de courbes de survie}
Les données contiennent les résultats d’une étude sur la survie de femmes atteintes du cancer du sein.</p>
<ul>
<li>: temps avant la mort, ou la fin de l’étude, en mois.</li>
<li>: variable indicatrice pour la mort, pour les survivantes et pour les décédées</li>
<li>: réponse immunohistochimique, soit négative () ou positive ()</li>
</ul>
<p>On s’intéresse à la question suivante:</p>
<ul>
<li>Est-ce que les femmes qui répondent positivement à l’examen immunohistochimique ont tendance à survivre moins longtemps que celles qui répondent négativement?</li>
</ul>
<p>{Comparaison de courbes de survie}
On peut ajuster des courbes de survie différentes par groupe avec l’option .</p>
<p>{</p>
<p> va estimer la courbe de survie pour les individus avec une réaction négative (groupe ) séparément de ceux qui ont une réaction positive (groupe ).</p>
<p>}</p>
{Courbes de survie (Kaplan–Meier)}
<p>{Comparaison de courbes de survie}
Il semble que les femmes ayant une réaction négative à l’examen () ont un {meilleur} taux de survie que celles qui ont une réaction positive ().</p>
<p>%<br />
% - On peut dire ceci puisque la courbe estimée pour le groupe , <span class="math inline">\(\widehat{S}_1(t)\)</span>, se situe principalement au-dessus de la courbe estimée pour le groupe , <span class="math inline">\(\widehat{S}_2(t)\)</span>.
- Pour la majorité des temps <span class="math inline">\(t\)</span>, <span class="math inline">\(\widehat{S}_1(t) &gt; \widehat{S}_2(t)\)</span> et donc ceux avec ont une probabilité de survie supérieure à ceux avec </p>
<p>% - Mais est-ce que ces courbes sont différentes?
%
%<br />
Est-ce que la fonction de survie est significativement différente dans les deux groupes et ?
%
%<br />
% -[] <span class="math inline">\(\Hy_0\)</span>: les courbes de survie sont les mêmes dans les deux groupes
% -[] <span class="math inline">\(\Hy_1\)</span>: les courbes de survie sont différentes dans les deux groupes
%
%
% - De façon plus formelle, on est intéressé à tester</p>
<p>-[] <span class="math inline">\(\Hy_0: S_0(t) = S_1(t)\)</span> pour tout <span class="math inline">\(t\)</span>,
-[] <span class="math inline">\(\Hy_1: S_0(t) \neq S_1(t)\)</span> pour au moins une valeur de <span class="math inline">\(t\)</span>.</p>
<p>%</p>
<p>{Test du log rang}
Considérons un modèle à risques proportionnels de Cox avec fonction de risque
<span class="math display">\[\begin{align}
  h(t) = h_0(t)\exp(\beta \code{repimmuno}). \tag{$\star$} \label{lograngtest}
\end{align}\]</span></p>
<ul>
<li><p>L’hypothèse nulle pour l’égalité des fonctions de survie est équivalente à <span class="math inline">\(\Hy_0: \beta=0\)</span>.</p></li>
<li><p>La statistique du score permet de tester cette hypothèse sans ajuster le modèle.</p></li>
<li><p>On recouvre l’estimateur de Kaplan–Meier de la fonction de survie si <span class="math inline">\(\beta=0\)</span>.</p></li>
<li><p>Il suffit de calculer le gradient et la hessienne du modèle décrit par <span class="math inline">\(\eqref{lograngtest}\)</span> et l’évaluer en <span class="math inline">\(\beta=0\)</span>.</p></li>
<li><p>Ce sont des fonctions simples du nombre de personnes à risque dans chaque groupe aux temps <span class="math inline">\(t_i\)</span>.</p></li>
</ul>
<p>%
% {Statistique du log rang}
%<br />
%<br />
%<br />
% Pour deux groupes, s’il n’y a pas de doublons, on obtient
% <span class="math display">\[\begin{align*}
% \left.U(\beta)\right|_{\beta=0}&amp; = \sum_{i: \delta_i=1} \left(f_i - \frac{m_{i1}}{m_{i0}+m_{i1}}\right),
% \\\left.j(\beta)\right|_{\beta=0}&amp;= \sum_{i: \delta_i=1} \frac{m_{i0}m_{i1}}{(m_{i0} + m_{i1})^2}
%  \end{align*}
% où
%  - $f_j$ vaut un si l&#39;individu $i$ expérience l&#39;événement au temps $t_i$ et
% - $m_{ij}$ est le nombre d&#39;individus à risque au temps $t_i$ pour le groupe $j$.
%
%

{Ajustement du modèle à risques proportionnels}
\begin{tcolorbox}[colback=white,colframe=hecblue, title=Code \SASlang{} pour le modèle de risques proportionnels]
\begin{verbatim}
proc phreg data=modstat.cancersein;
model temps*mort(0) = repimmuno;
run;
\end{verbatim}
\end{tcolorbox}
\begin{center}
\includegraphics[width = 0.5\textwidth]{img/c7/diapos7e16}
\includegraphics[width = 0.45\textwidth]{img/c7/diapos7e17}
\end{center}
{\footnotesize

Le test du log rang est aussi présenté par défaut dans la sortie \SASlang{} de la procédure \code{lifetest} (gauche).

}



{Test du log rang}
- Sous $\Hy_0: \beta=0$, la loi nulle de la statistique de score est approximativement $\chi^2_1$.
- La valeur-$p$  est $0.0191$: on rejette $\Hy_0$ à niveau $5\%$ et on conclut que les fonctions de survie sont significativement différentes pour les femmes avec des réactions négatives / positives à l&#39;examen immunohistochimique.
- On peut généraliser le test du log rang en utilisant un modèle de Cox qui n&#39;inclut qu&#39;une variable catégorielle à $k$ niveaux
- la loi nulle de la statistique du test de score sera $\chi^2_{k-1}$.






&lt;!--chapter:end:07-survie.Rmd--&gt;

# (APPENDIX) Annexe {-}

# Compléments mathématiques {#complement}


## Population et échantillons {#population-echantillon}

Ce qui différencie la statistique des autres sciences est la prise en compte de l&#39;incertitude et de la notion d&#39;aléatoire. Règle générale, on cherche à estimer une caractéristique d&#39;une population définie à l&#39;aide d&#39;un échantillon (un sous-groupe de la population) de taille restreinte.

La **population d&#39;intérêt** est une collection d&#39;individus formant la matière première d&#39;une étude statistique. Par exemple, pour l&#39;Enquête sur la population active (EPA) de Statistique Canada, « la population cible comprend la population canadienne civile non institutionnalisée de 15 ans et plus ». Même si on faisait un recensement et qu&#39;on interrogeait tous les membres de la population cible, la caractéristique d&#39;intérêt peut varier selon le moment de la collecte; une personne peut trouver un emploi, quitter le marché du travail ou encore se retrouver au chômage. Cela explique la variabilité intrinsèque.

En général, on se base sur un **échantillon**  pour obtenir de l&#39;information. L&#39;**inférence statistique** vise à tirer des conclusions, pour toute la population, en utilisant seulement l&#39;information contenue dans l&#39;échantillon et en tenant compte des sources de variabilité. Le sondeur George Gallup (traduction libre) a fait cette merveilleuse analogie entre échantillon et population:

&gt; «Il n&#39;est pas nécessaire de manger un bol complet de soupe pour savoir si elle est trop salé; pour autant qu&#39;elle ait été bien brassée, une cuillère suffit.»

Un **échantillon** est un sous-groupe d&#39;individus tiré aléatoirement de la population. La création de plans d&#39;enquête est un sujet complexe et des cours entiers d&#39;échantillonnage y sont consacrés. Même si on ne collectera pas de données, il convient de noter la condition essentielle pour pouvoir tirer des conclusions fiables à partir d&#39;un échantillon: ce dernier doit être représentatif de la population étudiée, en ce sens que sa composition doit être similaire à celle de la population. On doit ainsi éviter les biais de sélection, notamment les échantillons de commodité qui consistent en une sélection d&#39;amis et de connaissances.

Si notre échantillon est **aléatoire**, notre mesure d&#39;une caractéristique d&#39;intérêt le sera également et la conclusion de notre procédure de test variera d&#39;un échantillon à l&#39;autre. Plus la taille de ce dernier est grande, plus on obtiendra une mesure précise de la quantité d&#39;intérêt. L&#39;exemple suivant illustre pourquoi le choix de l&#39;échantillon est important.

::: {.example #Galluppoll}

Désireuse de prédire le résultat de l&#39;élection présidentielle américaine de 1936, la revue *Literary Digest* a sondé 10 millions d&#39;électeurs par la poste, dont 2.4 millions ont répondu au sondage en donnant une nette avance au candidat républicain Alf Landon (57\%) face au président sortant Franklin D. Roosevelt (43\%). Ce dernier a néanmoins remporté l&#39;élection avec 62\% des suffrages, une erreur de prédiction de 19\%.  Le plan d&#39;échantillonnage avait été conçu en utilisant des bottins téléphoniques, des enregistrements d&#39;automobiles et des listes de membres de clubs privés, etc.:  \href{https://www.jstor.org/stable/2749114}{la non-réponse différentielle et un échantillon biaisé vers les classes supérieures sont en grande partie responsable de cette erreur.}

Gallup avait de son côté correctement prédit la victoire de Roosevelt en utilisant un échantillon aléatoire de (seulement) 50 000 électeurs. \href{https://medium.com/@ozanozbey/how-not-to-sample-11579793dac}{L&#39;histoire complète (en anglais).}

:::

## Variables aléatoires {#variable-aleatoire}

Suppsons qu&#39;on cherche à décrire le comportement d&#39;un phénomène aléatoire. Pour ce faire, on cherche à décrire l&#39;ensemble des valeurs possibles et leur probabilité/fréquence relative au sein de la population: ces dernières sont encodées dans la loi de la variable aléatoire.

On fera la distinction entre deux cas de figure: quand le phénomène prend des valeurs finies, comme par exemple un événement binaire (achat/non-achat d&#39;un produit) ou un continuum de valeurs (par exemple, le prix d&#39;un item). On dénote les variables aléatoires par des lettres majuscules: par exemple, $Y \sim \mathsf{No}(\mu, \sigma^2)$ indique que $Y$ suit une loi normale de paramètres $\mu$ et $\sigma$, qui représentent respectivement l&#39;espérance et l&#39;écart-type de $Y$.

La fonction de répartition $F(y)$ donne la probabilité cumulative qu&#39;un événement n&#39;excède pas une variable donnée, $F(y) = \mathsf{Pr}(Y \leq y)$.

Si la variable $Y$ prend des valeurs discrètes, alors on utilise la fonction de masse $f(y)=\mathsf{Pr}(Y=y)$ qui donne la probabilité pour chacune des valeurs de $y$.
Si la variable $Y$ est continue, aucune valeur numérique de $y$ n&#39;a de probabilité non-nulle; la densité sert à estimer la probabilité que la variable $Y$ appartienne à un ensemble $B$, via $\mathsf{Pr}(Y \in B) = \int_B f(y) \mathrm{d} y$; la fonction de répartition est ainsi $F(y) = \int_{-\infty}^y f(x) \mathrm{d} x$.


&lt;div class=&quot;figure&quot; style=&quot;text-align: center&quot;&gt;
&lt;img src=&quot;images/02-ttest-DF_illustration_fr.png&quot; alt=&quot;Fonctions de répartition (panneau supérieur) et fonctions de densité et de masse (panneau inférieur) pour une loi continue (gauche) et discrète (droite).&quot; width=&quot;70%&quot; /&gt;
&lt;p class=&quot;caption&quot;&gt;(\#fig:distributions)Fonctions de répartition (panneau supérieur) et fonctions de densité et de masse (panneau inférieur) pour une loi continue (gauche) et discrète (droite).&lt;/p&gt;
&lt;/div&gt;


### Moments
Un premier cours de statistique débute souvent par la présentation de statistiques descriptives comme la moyenne et l&#39;écart-type. Ce sont des estimateurs des moments (centrés), qui caractérisent la loi du phénomène d&#39;intérêt. Dans le cas de la loi normale unidimensionnelle, qui a deux paramètres, l&#39;espérance et la variance caractérisent complètement le modèle.

Soit $Y$ une variable aléatoire de fonction de densité (ou de masse) $f(x)$. Cette fonction est non-négative et satisfait $\int_{\mathbb{R}} f(x) \mathrm{d}x=1$: elle décrit la probabilité d&#39;obtenir un résultat dans un ensemble donné des réels $\mathbb{R}$.

On définit l&#39;espérance d&#39;une variable aléatoire $Y$ comme \[\mathsf{E}(Y)=\int_{\mathbb{R}} x f(x) \mathrm{d} x.\]
L&#39;espérance est  la « moyenne théorique» : dans le cas discret, $\mu = \mathsf{E}(Y)=\sum_{x \in \mathcal{X}} x \mathsf{Pr}(X=x)$, où $\mathcal{X}$ représente le support de la loi, à savoir les valeurs qui ont une probabilité non-nulle. Plus généralement, l&#39;espérance d&#39;une fonction $g(x)$ pour une variable aléatoire $Y$  est simplement l&#39;intégrale de $g(x)$ pondérée par la densité $f(x)$. De même, si l&#39;intégrale est convergente, la variance est
\[\mathsf{Va}(Y)=\mathsf{E}\{Y-\mathsf{E}(Y)\}^2 \equiv \int_{\mathbb{R}} (x-\mu)^2 f(x) \mathrm{d} x.\]

Un estimateur $\hat{\theta}$ pour un paramètre $\theta$ est sans biais  si son biais $\mathsf{biais}(\hat{\theta})=\mathsf{E}(\hat{\theta})- \theta$ est nul.
L&#39;estimateur sans biais de l&#39;espérance de $Y$ est $\overline{Y}_n = n^{-1} \sum_{i=1}^n Y_i$ et celui de la variance $S_n = (n-1)^{-1} \sum_{i=1}^n (Y_i-\overline{Y})^2$. Un estimateur sans biais est souhaitable, mais pas toujours optimal. Quelquefois, il n&#39;existe pas d&#39;estimateur non-biaisé!



Souvent, on cherche à balancer le biais et la variance: rappelez-vous qu&#39;un estimateur est une variable aléatoire (étant une fonction de variables aléatoires) et qu&#39;il est lui-même variable: même s&#39;il est sans biais, la valeur numérique obtenue fluctuera d&#39;un échantillon à l&#39;autre. On peut chercher un estimateur qui minimise l&#39;erreur moyenne quadratique, \[\mathsf{EMQ}(\hat{\theta}) = \mathsf{E}\{(\hat{\theta}-\theta)^2\}=\mathsf{Va}(\hat{\theta}) + \{\mathsf{E}(\hat{\theta})\}^2.\]
C&#39;est donc un compromis entre le carré du biais  et la variance de l&#39;estimateur.
La plupart des estimateurs que nous considérerons dans le cadre du cours sont
des estimateurs du maximum de vraisemblance. Ces derniers sont asymptotiquement efficaces, c&#39;est-à-dire qu&#39;ils minimisent l&#39;erreur moyenne quadratique parmi tous les estimateurs possibles quand la taille de l&#39;échantillon est suffisamment grande. Ils ont également d&#39;autre propriétés qui les rendent attractifs comme choix par défaut pour l&#39;estimation.

### Distributions

Plusieurs lois aléatoires décrivent des phénomènes physiques simples et ont donc une justification empirique; on revisite les distributions les plus fréquemment couvertes.

::: {.example #loibern name=&quot;Loi de Bernoulli&quot;}
On considère un phénomène binaire, comme le lancer d&#39;une pièce de monnaie (pile/face). De manière générale, on associe les deux possibilités à succès/échec et on suppose que la probabilité de succès est $\pi$. Par convention, on représente les échecs (non) par des zéros et les réussites (oui) par des uns. Donc, si la variable $Y$ vaut $0$ ou $1$, alors  $\mathsf{Pr}(Y=1)=\pi$ et $\mathsf{Pr}(Y=0)=1-\pi$ (complémentaire). La fonction de masse de la [loi Bernoulli](https://fr.wikipedia.org/wiki/Loi_de_Bernoulli) s&#39;écrit de façon plus compacte
\begin{align*}
\mathsf{Pr}(Y=y) = \pi^y (1-\pi)^{1-y}, \quad y=0, 1.
\end{align*}\]</span></p>
<p>Un calcul rapide montre que <span class="math inline">\(\mathsf{E}(Y)=\pi\)</span> et <span class="math inline">\(\mathsf{Va}(Y)=\pi(1-\pi)\)</span>.
Voici quelques exemples de questions de recherches comprenant une variable réponse binaire:</p>
<ul>
<li>est-ce qu’un client potentiel a répondu favorablement à une offre
promotionnelle?</li>
<li>est-ce qu’un client est satisfait du service après-vente?</li>
<li>est-ce qu’une firme va faire faillite au cours des trois prochaines années?</li>
<li>est-ce qu’un participant à une étude réussit une tâche?</li>
</ul>
<p>:::</p>
<div class="example">
<p><span id="exm:loibinom" class="example"><strong>Exemple 7.1  (Loi binomiale) </strong></span>Si les données représentent la somme d’événements Bernoulli indépendants, la loi du nombre de réussites <span class="math inline">\(Y\)</span> pour un nombre d’essais donné <span class="math inline">\(m\)</span> est dite <a href="https://fr.wikipedia.org/wiki/Loi_binomiale">binomiale</a>, dénotée <span class="math inline">\(\mathsf{Bin}(m, \pi)\)</span>; sa fonction de masse est
<span class="math display">\[\begin{align*}
\mathsf{Pr}(Y=y) = \binom{m}{y}\pi^y (1-\pi)^{1-y}, \quad y=0, 1.
\end{align*}\]</span>
La vraisemblance pour un échantillon de la loi binomiale est (à constante de normalisation près qui ne dépend pas de <span class="math inline">\(\pi\)</span>) la même que pour un échantillon aléatoire de <span class="math inline">\(m\)</span> variables Bernoulli indépendantes. L’espérance d’une variable binomiale est <span class="math inline">\(\mathsf{E}(Y)=m\pi\)</span> et la variance <span class="math inline">\(\mathsf{Va}(Y)=m\pi(1-\pi)\)</span>.</p>
<p>On peut ainsi considérer le nombre de personnes qui ont obtenu leur permis de conduire parmi <span class="math inline">\(m\)</span> candidat(e)s ou le nombre de clients sur <span class="math inline">\(m\)</span> qui ont passé une commande de plus de 10$ dans un magasin.</p>
</div>
<p>Plus généralement, on peut considérer des variables de dénombrement qui prennent des valeurs entières. Parmi les exemples de questions de recherches comprenant une variable réponse de dénombrement:</p>
<ul>
<li>le nombre de réclamations faites par un client d’une compagnie d’assurance
au cours d’une année.</li>
<li>le nombre d’achats effectués par un client depuis un mois.</li>
<li>le nombre de tâches réussies par un participant lors d’une étude.</li>
</ul>
<div class="example">
<p><span id="exm:loigeom" class="example"><strong>Exemple 7.2  (Loi géométrique) </strong></span>La <a href="https://fr.wikipedia.org/wiki/Loi_g%C3%A9om%C3%A9trique">loi géométrique</a> décrit le comportement du nombre d’essais Bernoulli de probabilité de succès <span class="math inline">\(\pi\)</span> nécessaires avant l’obtention d’un premier succès. La fonction de masse de <span class="math inline">\(Y \sim \mathsf{Geo}(\pi)\)</span> est
<span class="math display">\[\begin{align*}
\mathsf{Pr}(Y=y) = \pi (1-\pi)^{y-1}, \quad y=1,2, \ldots
\end{align*}\]</span></p>
<p>Par exemple, on pourrait modéliser le nombre de visites d’une maison en vente avant une première offre d’achat à l’aide d’une variable géométrique.</p>
</div>
<div class="example">
<p><span id="exm:loipoisson" class="example"><strong>Exemple 7.3  (Loi de Poisson) </strong></span>Si la probabilité d’un événement Bernoulli est petite (succès rare) dans le sens où <span class="math inline">\(m\pi \to \lambda\)</span> quand le nombre d’essais <span class="math inline">\(m\)</span> augmente, alors le nombre de succès suit une loi de Poisson de fonction de masse
<span class="math display">\[\begin{align*}
\mathsf{Pr}(Y=y) = \frac{\exp(-\lambda)\lambda^y}{\Gamma(y+1)}, \quad y=0, 1, 2, \ldots
\end{align*}\]</span>
où <span class="math inline">\(\Gamma(\cdot)\)</span> dénote la fonction gamma. Le paramètre <span class="math inline">\(\lambda\)</span> de la loi de Poisson représente à la fois l’espérance et la variance de la variable, c’est-à-dire que <span class="math inline">\(\mathsf{E}(Y)=\mathsf{Va}(Y)=\lambda\)</span>.</p>
</div>
<div class="example">
<p><span id="exm:loibinneg" class="example"><strong>Exemple 7.4  (Loi binomiale négative) </strong></span>On considère une série d’essais Bernoulli de probabilité de succès <span class="math inline">\(\pi\)</span> jusqu’à l’obtention de <span class="math inline">\(m\)</span> succès. Soit <span class="math inline">\(Y\)</span>, le nombre d’échecs: puisque la dernière réalisation doit forcément être un succès, mais que l’ordre des succès/échecs précédents n’importe pas, la fonction de masse est
<span class="math display">\[\begin{align*}
\mathsf{Pr}(Y=y)= \binom{m-1+y}{y} \pi^m (1-\pi)^{y}.
\end{align*}\]</span></p>
<p>La loi binomiale négative apparaît également si on considère la loi non-conditionnelle du modèle hiérarchique gamma-Poisson, dans lequel on suppose que le paramètre de la moyenne de la loi Poisson est aussi aléatoire, c’est-à-dire <span class="math inline">\(Y \mid \Lambda=\lambda \sim \mathsf{Po}(\lambda)\)</span> et <span class="math inline">\(\Lambda\)</span> suit une loi gamma de paramètre de forme <span class="math inline">\(r\)</span> et de paramètre d’échelle <span class="math inline">\(\theta\)</span>, dont la densité est <span class="math display">\[f(x) = \theta^{-r}x^{r-1}\exp(-x/\theta)/\Gamma(r).\]</span> Le nombre d’événements suit alors une loi binomiale négative.</p>
<p>La paramétrisation la plus courante pour la modélisation est légèrement différente: on utilise la fonction de masse est
<span class="math display">\[\begin{align*}
\mathsf{Pr}(Y=y)=\frac{\Gamma(y+r)}{\Gamma(y+1)\Gamma(r)} \left(\frac{r}{r + \mu} \right)^{r} \left(\frac{\mu}{r+\mu}\right)^y, y=0, 1, \ldots, \mu,r &gt;0,
\end{align*}\]</span>
où <span class="math inline">\(\Gamma\)</span> dénote la fonction gamma. À noter que le paramètre <span class="math inline">\(r&gt;0\)</span> n’est plus nécessairement entier. La moyenne théorique et la variance sont
<span class="math inline">\(\mathsf{E}(Y)=\mu\)</span> et <span class="math inline">\(\mathsf{Va}(Y)=\mu+k\mu^2\)</span>, où <span class="math inline">\(k=1/r\)</span>. La variance d’une variable binomiale négative est <em>supérieure</em> à sa moyenne et le modèle est utilisé comme alternative à la loi de Poisson pour modéliser la surdispersion.</p>
</div>
<div id="diagramme-qq" class="section level3 hasAnchor" number="7.0.1">
<h3><span class="header-section-number">7.0.1</span> Diagrammes quantiles-quantiles<a href="survie.html#diagramme-qq" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Si on ajuste un modèle à des données, il convient de vérifier la qualité de l’ajustement et l’adéquation du modèle, par exemple graphiquement. Le diagramme quantile-quantile sert à vérifier l’adéquation du modèle et découle du constat suivant: si <span class="math inline">\(Y\)</span> est une variable aléatoire continue et <span class="math inline">\(F\)</span> sa fonction de répartition, alors l’application <span class="math inline">\(F(Y) \sim \mathsf{U}(0,1)\)</span>. De la même façon, appliquer la fonction quantile à une variable uniforme permet de simuler de la loi <span class="math inline">\(F\)</span>, et donc <span class="math inline">\(F^{-1}(U)\)</span>. Supposons un échantillon de taille <span class="math inline">\(n\)</span> de variables uniformes. On peut démontrer que les statistiques d’ordre <span class="math inline">\(U_{(1)} \leq \cdots \leq U_{(n)}\)</span> ont une loi marginale Beta: et <span class="math inline">\(U_{(k)} \sim \mathsf{Beta}(k, n+1-k)\)</span> d’espérance <span class="math inline">\(k/(n+1)\)</span>.</p>
<p>Les paramètres de la loi <span class="math inline">\(F\)</span> sont inconnus, mais on peut obtenir un estimateur <span class="math inline">\(\widehat{F}\)</span> et appliquer la transformation inverse pour obtenir une variable approximativement uniforme. Un diagramme quantile-quantile représente les données en fonction des moments des statistiques d’ordre transformées</p>
<ul>
<li>sur l’axe des abscisses, les quantiles théoriques <span class="math inline">\(\widehat{F}^{-1}\{\mathrm{rang}(Y_i)/(n+1)\}\)</span></li>
<li>sur l’axe des ordonnées, les quantiles empiriques <span class="math inline">\(Y_i\)</span></li>
</ul>
<p>Si le modèle est adéquat, les valeurs ordonnées devraient suivre une droite de pente unitaire qui passe par l’origine. L’oeil humain a de la difficulté à juger de la qualité de l’adéquation en regardant une droite, aussi est-il préférable de soustraire cette pente pour faciliter l’interprétation (une méthode proposée par Tukey, mais faire attention à l’échelle!) Le diagramme des différences moyennes prend les positions du diagramme quantile-quantile, (<span class="math inline">\(x_i, y_i\)</span>), et représente graphiquement la moyenne des coordonnées sur l’axe des abcisses versus la différence(<span class="math inline">\(\{x_i + y_i\}/2, y_i - x_i\)</span>) sur l’axe des ordonnées. Les données de la Figure <a href="survie.html#fig:diagrammeqq2">7.1</a> montrent ces deux représentations sur des mêmes données simulées d’une loi normale standard.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:diagrammeqq2"></span>
<img src="MATH60604_Modelisation_statistique_files/figure-html/diagrammeqq2-1.png" alt="Diagramme quantile-quantile normal (gauche) et représentation de Tukey du même diagramme (en soustrayant la traîne)" width="70%" />
<p class="caption">
Figure 7.1: Diagramme quantile-quantile normal (gauche) et représentation de Tukey du même diagramme (en soustrayant la traîne)
</p>
</div>
<p>Même si on connaissait exactement la loi aléatoire des données, la variabilité intrinsèque à l’échantillon fait en sorte que des déviations qui semblent significatives et anormales à l’oeil de l’analyste sont en fait compatibles avec le modèle: un simple estimé ponctuel sans mesure d’incertitude ne permet donc pas facilement de voir ce qui est plausible ou pas. On va donc idéalement ajouter un intervalle de confiance (approximatif) ponctuel ou conjoint au diagramme.</p>
<p>Pour obtenir l’intervalle de confiance approximatif, la méthode la plus simple est par simulation (autoamorçage paramétrique), en répétant <span class="math inline">\(B\)</span> fois les étapes suivantes</p>
<ol style="list-style-type: decimal">
<li>simuler un échantillon <span class="math inline">\(\{Y^{(b)}_{i}\} (i=1,\ldots, n)\)</span> du modèle <span class="math inline">\(\widehat{F}\)</span></li>
<li>estimer les paramètres du modèle <span class="math inline">\(F\)</span> pour obtenir <span class="math inline">\(\widehat{F}_{(b)}\)</span></li>
<li>calculer et stocker les positions <span class="math inline">\(\widehat{F}^{-1}_{(b)}\{i/(n+1)\}\)</span>.</li>
</ol>
<p>Le résultat de cette opération sera une matrice <span class="math inline">\(n \times B\)</span> de données simulées; on obtient un intervalle de confiance symmétrique en conservant le quantile <span class="math inline">\(\alpha/2\)</span> et <span class="math inline">\(1-\alpha/2\)</span> de chaque ligne. Le nombre de simulation <span class="math inline">\(B\)</span> devrait être large (typiquement 999 ou davantage) et être choisi de manière à ce que <span class="math inline">\(B/alpha\)</span> soit un entier.</p>
<p>Pour l’intervalle de confiance ponctuel, chaque valeur représente une statistique et donc individuellement, la probabilité qu’une statistique d’ordre sorte de l’intervalle de confiance est <span class="math inline">\(\alpha\)</span>. En revanche, les statistiques d’ordres ne sont pas indépendantes et sont qui est plus ordonnées, ce qui fait qu’un point hors de l’intervalle risque de n’être pas isolé. [Il est aussi possible d’obtenir par autoamorçage un intervalle de confiance (approximatif) conjoint, pour lequel une valeur sort de l’intervalle <span class="math inline">\(100(1-\alpha)\)</span>% du temps; <a href="https://lbelzile.github.io/lineaRmodels/qqplot.html">voir à ce sujet mes notes de cours Section 4.4.3 (en anglais)</a>. Les intervalles présentés dans la Figure <a href="survie.html#fig:diagrammeqq2">7.1</a> sont ponctuels. La variabilité des statistiques d’ordre uniformes est plus grande à mesure qu’on s’éloigne de 1/2, mais celles des variables transformées dépend de <span class="math inline">\(F\)</span>.</p>
</div>
<div id="loi-grands-nombres" class="section level2 hasAnchor" number="7.1">
<h2><span class="header-section-number">7.1</span> Loi des grands nombres<a href="survie.html#loi-grands-nombres" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Un estimateur est dit <strong>convergent</strong> si la valeur obtenue à mesure que la taille de l’échantillon augmente s’approche de la vraie valeur que l’on cherche à estimer. Mathématiquement parlant, un estimateur est dit convergent s’il converge en probabilité, ou <span class="math inline">\(\hat{\theta} \stackrel{\mathsf{Pr}}{\to} \theta\)</span>: en langage commun, la probabilité que la différence entre <span class="math inline">\(\hat{\theta}\)</span> et <span class="math inline">\(\theta\)</span> diffèrent est négligeable quand <span class="math inline">\(n\)</span> est grand.</p>
<p>La condition <em>a minima</em> pour le choix d’un estimateur est donc la convergence: plus on récolte d’information, plus notre estimateur devrait s’approcher de la valeur qu’on tente d’estimer.</p>
<p>La loi des grands nombres établit que la moyenne empirique de <span class="math inline">\(n\)</span> observations indépendantes de même espérance, <span class="math inline">\(\overline{Y}_n\)</span>, tend vers l’espérance commune des variables <span class="math inline">\(\mu\)</span>, où <span class="math inline">\(\overline{Y}_n \rightarrow \mu\)</span>. En gros, ce résultat nous dit que l’on réussit à approximer de mieux en mieux la quantité d’intérêt quand la taille de l’échantillon (et donc la quantité d’information disponible sur le paramètre) augmente. La loi des grands nombres est très utile dans les expériences Monte Carlo: on peut ainsi approximer par simulation la moyenne d’une fonction <span class="math inline">\(g(x)\)</span> de variables aléatoires en simulant de façon répétée des variables <span class="math inline">\(Y\)</span> indépendantes et identiquement distribuées et en prenant la moyenne empirique <span class="math inline">\(n^{-1} \sum_{i=1}^n g(Y_i)\)</span>.</p>
<p>Si la loi des grands nombres nous renseigne sur le comportement limite ponctuel, il ne nous donne aucune information sur la variabilité de notre estimé de la moyenne et la vitesse à laquelle on s’approche de la vraie valeur du paramètre.</p>
</div>
<div id="TCL" class="section level2 hasAnchor" number="7.2">
<h2><span class="header-section-number">7.2</span> Théorème central limite<a href="survie.html#TCL" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Le théorème central limite dit que, pour un échantillon aléatoire de taille <span class="math inline">\(n\)</span> dont les observations sont indépendantes et tirées d’une loi quelconque d’espérance <span class="math inline">\(\mu\)</span> et de variance finie <span class="math inline">\(\sigma^2\)</span>, alors la moyenne empirique tend non seulement vers <span class="math inline">\(\mu\)</span>, mais à une vitesse précise:</p>
<ul>
<li>l’estimateur <span class="math inline">\(\overline{Y}\)</span> sera centré autour de <span class="math inline">\(\mu\)</span>,</li>
<li>l’erreur-type sera de <span class="math inline">\(\sigma/\sqrt{n}\)</span>; le taux de convergence est donc de <span class="math inline">\(\sqrt{n}\)</span>. Ainsi, pour un échantillon de taille 100, l’erreur-type de la moyenne empirique sera 10 fois moindre que l’écart-type de la variable aléatoire sous-jacente.</li>
<li>la loi approximative de la moyenne <span class="math inline">\(\overline{Y}\)</span> sera normale.</li>
</ul>
<p>Mathématiquement, le théorème central limite dicte que <span class="math inline">\(\sqrt{n}(\overline{Y}-\mu) \stackrel{\mathrm{d}}{\rightarrow} \mathsf{No}(0, \sigma^2)\)</span>. Si <span class="math inline">\(n\)</span> est grand (typiquement supérieur à <span class="math inline">\(30\)</span>, mais cette règle dépend de la loi sous-jacente de <span class="math inline">\(Y\)</span>), alors <span class="math inline">\(\overline{Y} \stackrel{\cdot}{\sim} \mathsf{No}(\mu, \sigma^2/n)\)</span>.</p>
<p>Comment interpréter ce résultat? On considère comme exemple le temps de trajet moyen de trains à haute vitesse AVE entre Madrid et Barcelone opérés par la Renfe.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:renfeclt"></span>
<img src="MATH60604_Modelisation_statistique_files/figure-html/renfeclt-1.png" alt="Distribution empirique des temps de trajet en trains à grande vitesse." width="70%" />
<p class="caption">
Figure 7.2: Distribution empirique des temps de trajet en trains à grande vitesse.
</p>
</div>
<p>Une analyse exploratoire indique que la durée du trajet de la base de données est celle affichée sur le billet (et non le temps réel du parcours). Ainsi, il n’y a ainsi que 15 valeurs possibles. Le temps affiché moyen pour le parcours, estimé sur la base de 9603 observations, est de 170 minutes et 41 secondes. La Figure (voir <a href="survie.html#fig:renfeclt">7.2</a>) montre la distribution empirique des données.</p>
<p>Considérons maintenant des échantillons de taille <span class="math inline">\(n=10\)</span>. Dans notre premier échantillon aléatoire, la durée moyenne affichée est 170.9 minutes, elle est de 164.5 minutes dans le deuxième, de 172.3 dans le troisième, et ainsi de suite.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:renfemeanCLT"></span>
<img src="MATH60604_Modelisation_statistique_files/figure-html/renfemeanCLT-1.png" alt="Représentation graphique du théorème central limite: échantillon aléatoire de 20 observations avec leur moyenne empirique (trait vertical rouge) (en haut à gauche). Les trois autres panneaux montrent les histogrammes des moyennes empiriques d'échantillons répétés de taille 5 (en haut à droite), 20 (en bas à gauche) et les histogrammes pour $n=5, 20, 100$ (en bas à droite) avec courbe de densité de l'approximation normale fournie par le théorème central limite." width="90%" />
<p class="caption">
Figure 7.3: Représentation graphique du théorème central limite: échantillon aléatoire de 20 observations avec leur moyenne empirique (trait vertical rouge) (en haut à gauche). Les trois autres panneaux montrent les histogrammes des moyennes empiriques d’échantillons répétés de taille 5 (en haut à droite), 20 (en bas à gauche) et les histogrammes pour <span class="math inline">\(n=5, 20, 100\)</span> (en bas à droite) avec courbe de densité de l’approximation normale fournie par le théorème central limite.
</p>
</div>
<p>Supposons qu’on tire <span class="math inline">\(B=1000\)</span> échantillons différents, chacun de taille <span class="math inline">\(n=5\)</span>, de notre ensemble, et qu’on calcule la moyenne de chacun d’entre eux. Le graphique supérieur droit <a href="survie.html#fig:renfemeanCLT">7.3</a> montre un de ces 1000 échantillons aléatoire de taille <span class="math inline">\(n=20\)</span> tiré de notre base de données. Les autres graphiques de la Figure <a href="survie.html#fig:renfemeanCLT">7.3</a> illustrent l’effet de l’augmentation de la taille de l’échantillon: si l’approximation normale est approximative avec <span class="math inline">\(n=5\)</span>, la distribution des moyennes est virtuellement identique à partir de <span class="math inline">\(n=20\)</span>. Plus la moyenne est calculée à partir d’un grand échantillon (c’est-à-dire, plus <span class="math inline">\(n\)</span> augmente), plus la qualité de l’approximation normale est meilleure et plus la courbe se concentre autour de la vraie moyenne; malgré le fait que nos données sont discrètes, la distribution des moyennes est approximativement normale.</p>
<p>On a considéré une seule loi aléatoire inspirée de l’exemple, mais vous pouvez vous amuser à regarder l’effet de la distribution sous-jacent et de la taille de l’échantillon nécessaire pour que l’effet du théorème central limite prenne effet: il suffit pour cela de simulant des observations d’une loi quelconque de variance finie, en utilisant par exemple cette <a href="http://195.134.76.37/applets/AppletCentralLimit/Appl_CentralLimit2.html">applette</a>.</p>
<p>Les statistiques de test qui découlent d’une moyenne centrée-réduite (ou d’une quantité équivalente pour laquelle un théorème central limite s’applique) ont souvent une loi nulle standard normale, du moins asymptotiquement (quand <span class="math inline">\(n\)</span> est grand, typiquement <span class="math inline">\(n&gt;30\)</span> est suffisant). C’est ce qui garantie la validité de notre inférence!</p>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="modeles-lineaires-mixtes.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="math.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": null,
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["MATH60604_Modelisation_statistique.pdf"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "section",
"scroll_highlight": true
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
